{"instance_id": "pydicom__pydicom-1139_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nMake PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n\n</issue>\n<code>\n[start of README.md]\n1 *pydicom*\n2 =======\n3 \n4 [![Build Status](https://travis-ci.org/pydicom/pydicom.svg?branch=master)](https://travis-ci.org/pydicom/pydicom)\n5 [![AppVeyor](https://ci.appveyor.com/api/projects/status/1vjtkr82lumnd3i7?svg=true)](https://ci.appveyor.com/project/glemaitre/pydicom)\n6 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n7 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n8 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n9 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n10 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3891702.svg)](https://doi.org/10.5281/zenodo.3891702)\n11 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n12 \n13 *pydicom* is a pure python package for working with [DICOM](http://medical.nema.org/) files.\n14 It was made for inspecting and modifying DICOM data in an easy \"pythonic\" way.\n15 The modifications can be written again to a new file.\n16 \n17 As a pure python package, *pydicom* can run anywhere python runs without any other requirements,\n18 although [NumPy](http://www.numpy.org) is needed if manipulating pixel data.\n19 \n20 *pydicom* is not a DICOM server, and is not primarily about viewing images.\n21 It is designed to let you\n22 manipulate data elements in DICOM files with python code.\n23 \n24 Limitations -- for files with _compressed_ pixel data, *pydicom* can decompress\n25 it (with additional libraries installed) and allow you to manipulate the data,\n26 but can only store changed pixel data as uncompressed. Files can always be\n27 read and saved (including compressed pixel data that has not been modified),\n28 but once decompressed, modified pixel data cannot be compressed again.\n29 \n30 Documentation\n31 -------------\n32 \n33 *pydicom* documentation is available on GitHub Pages both for the [development\n34  (master) version](https://pydicom.github.io/pydicom/dev) and for the\n35 [released version](https://pydicom.github.io/pydicom/stable). The\n36 documentation for [the previous 0.9.9 version](https://pydicom.github.io/pydicom/0.9/)\n37 is still there for reference.\n38 \n39 See [Getting Started](https://pydicom.github.io/pydicom/stable/old/getting_started.html)\n40 for installation and basic information, and the\n41 [User Guide](https://pydicom.github.io/pydicom/stable/pydicom_user_guide.html)\n42 for an overview of how to use the *pydicom* library.\n43 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n44 To contribute an example or extension of *pydicom* that does not belong with\n45 the core software, see our contribution repository,\n46 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n47 \n[end of README.md]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 \n11 import base64\n12 import json\n13 from collections import namedtuple\n14 \n15 from pydicom import config  # don't import datetime_conversion directly\n16 from pydicom.config import logger\n17 from pydicom import config\n18 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n19                               dictionary_keyword, dictionary_is_retired,\n20                               private_dictionary_description, dictionary_VR,\n21                               repeater_has_tag)\n22 from pydicom.jsonrep import JsonDataElementConverter\n23 from pydicom.multival import MultiValue\n24 from pydicom.tag import Tag, BaseTag\n25 from pydicom.uid import UID\n26 from pydicom import jsonrep\n27 import pydicom.valuerep  # don't import DS directly as can be changed by config\n28 from pydicom.valuerep import PersonName\n29 \n30 if config.have_numpy:\n31     import numpy\n32 \n33 BINARY_VR_VALUES = [\n34     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n35     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n36 ]\n37 \n38 \n39 def empty_value_for_VR(VR, raw=False):\n40     \"\"\"Return the value for an empty element for `VR`.\n41 \n42     .. versionadded:: 1.4\n43 \n44     The behavior of this property depends on the setting of\n45     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n46     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n47     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n48     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n49     empty string is used as empty value representation, for all other VRs\n50     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n51     is used in all cases.\n52     Note that this is used only if decoding the element - it is always\n53     possible to set the value to another empty value representation,\n54     which will be preserved during the element object lifetime.\n55 \n56     Parameters\n57     ----------\n58     VR : str\n59         The VR of the corresponding element.\n60 \n61     raw : bool\n62         If ``True``, returns the value for a :class:`RawDataElement`,\n63         otherwise for a :class:`DataElement`\n64 \n65     Returns\n66     -------\n67     str or bytes or None or list\n68         The value a data element with `VR` is assigned on decoding\n69         if it is empty.\n70     \"\"\"\n71     if VR == 'SQ':\n72         return b'' if raw else []\n73     if config.use_none_as_empty_text_VR_value:\n74         return None\n75     if VR in ('AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT',\n76               'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR', 'UT'):\n77         return b'' if raw else ''\n78     return None\n79 \n80 \n81 def _is_bytes(val):\n82     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n83     return isinstance(val, bytes)\n84 \n85 \n86 # double '\\' because it is used as escape chr in Python\n87 _backslash_str = \"\\\\\"\n88 _backslash_byte = b\"\\\\\"\n89 \n90 \n91 class DataElement:\n92     \"\"\"Contain and manipulate a DICOM Element.\n93 \n94     Examples\n95     --------\n96 \n97     While its possible to create a new :class:`DataElement` directly and add\n98     it to a :class:`~pydicom.dataset.Dataset`:\n99 \n100     >>> from pydicom import Dataset\n101     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n102     >>> ds = Dataset()\n103     >>> ds.add(elem)\n104 \n105     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n106     to add a new :class:`DataElement`, as the VR and tag are determined\n107     automatically from the DICOM dictionary:\n108 \n109     >>> ds = Dataset()\n110     >>> ds.PatientName = 'CITIZEN^Joan'\n111 \n112     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n113     value for text VRs and `None` for non-text (binary) VRs:\n114 \n115     >>> ds = Dataset()\n116     >>> ds.PatientName = None\n117     >>> ds.PatientName\n118     ''\n119 \n120     >>> ds.BitsAllocated = None\n121     >>> ds.BitsAllocated\n122 \n123     >>> str(ds.BitsAllocated)\n124     'None'\n125 \n126     Attributes\n127     ----------\n128     descripWidth : int\n129         For string display, this is the maximum width of the description\n130         field (default ``35``).\n131     is_undefined_length : bool\n132         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n133         (ie undefined).\n134     maxBytesToDisplay : int\n135         For string display, elements with values containing data which is\n136         longer than this value will display ``\"array of # bytes\"``\n137         (default ``16``).\n138     showVR : bool\n139         For string display, include the element's VR just before it's value\n140         (default ``True``).\n141     tag : BaseTag\n142         The element's tag.\n143     value\n144         The element's stored value(s).\n145     VR : str\n146         The element's Value Representation.\n147     \"\"\"\n148 \n149     descripWidth = 35\n150     maxBytesToDisplay = 16\n151     showVR = True\n152     is_raw = False\n153 \n154     def __init__(self,\n155                  tag,\n156                  VR,\n157                  value,\n158                  file_value_tell=None,\n159                  is_undefined_length=False,\n160                  already_converted=False):\n161         \"\"\"Create a new :class:`DataElement`.\n162 \n163         Parameters\n164         ----------\n165         tag : int or or str or list or tuple\n166             The DICOM (group, element) tag in any form accepted by\n167             :func:`~pydicom.tag.Tag` such as ``[0x0010, 0x0010]``,\n168             ``(0x10, 0x10)``, ``0x00100010``, etc.\n169         VR : str\n170             The 2 character DICOM value representation (see DICOM Standard,\n171             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n172         value\n173             The value of the data element. One of the following:\n174 \n175             * a single string value\n176             * a number\n177             * a :class:`list` or :class:`tuple` with all strings or all numbers\n178             * a multi-value string with backslash separator\n179 \n180         file_value_tell : int or None\n181             Used internally by :class:`~pydicom.dataset.Dataset` to\n182             store the write position for the ``ReplaceDataElementValue()``\n183             method. Default is ``None``.\n184         is_undefined_length : bool\n185             Used internally to store whether the length field for this element\n186             was ``0xFFFFFFFFL``, i.e. 'undefined length'. Default is ``False``.\n187         already_converted : bool\n188             Used to determine whether or not the element's value requires\n189             conversion to a value with VM > 1. Default is ``False``.\n190         \"\"\"\n191         if not isinstance(tag, BaseTag):\n192             tag = Tag(tag)\n193         self.tag = tag\n194 \n195         # a known tag shall only have the VR 'UN' if it has a length that\n196         # exceeds the size that can be encoded in 16 bit - all other cases\n197         # can be seen as an encoding error and can be corrected\n198         if (VR == 'UN' and not tag.is_private and\n199                 config.replace_un_with_known_vr and\n200                 (is_undefined_length or value is None or len(value) < 0xffff)):\n201             try:\n202                 VR = dictionary_VR(tag)\n203             except KeyError:\n204                 pass\n205 \n206         self.VR = VR  # Note: you must set VR before setting value\n207         if already_converted:\n208             self._value = value\n209         else:\n210             self.value = value  # calls property setter which will convert\n211         self.file_tell = file_value_tell\n212         self.is_undefined_length = is_undefined_length\n213         self.private_creator = None\n214 \n215     @classmethod\n216     def from_json(cls, dataset_class, tag, vr, value, value_key,\n217                   bulk_data_uri_handler=None):\n218         \"\"\"Return a :class:`DataElement` from JSON.\n219 \n220         .. versionadded:: 1.3\n221 \n222         Parameters\n223         ----------\n224         dataset_class : dataset.Dataset derived class\n225             Class used to create sequence items.\n226         tag : BaseTag or int\n227             The data element tag.\n228         vr : str\n229             The data element value representation.\n230         value : list\n231             The data element's value(s).\n232         value_key : str or None\n233             Key of the data element that contains the value\n234             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n235         bulk_data_uri_handler: callable or None\n236             Callable function that accepts the \"BulkDataURI\" of the JSON\n237             representation of a data element and returns the actual value of\n238             that data element (retrieved via DICOMweb WADO-RS)\n239 \n240         Returns\n241         -------\n242         DataElement\n243         \"\"\"\n244         # TODO: test wado-rs retrieve wrapper\n245         converter = JsonDataElementConverter(dataset_class, tag, vr, value,\n246                                              value_key, bulk_data_uri_handler)\n247         elem_value = converter.get_element_values()\n248         try:\n249             return DataElement(tag=tag, value=elem_value, VR=vr)\n250         except Exception:\n251             raise ValueError(\n252                 'Data element \"{}\" could not be loaded from JSON: {}'.format(\n253                     tag, elem_value\n254                 )\n255             )\n256 \n257     def to_json_dict(self, bulk_data_element_handler, bulk_data_threshold):\n258         \"\"\"Return a dictionary representation of the :class:`DataElement`\n259         conforming to the DICOM JSON Model as described in the DICOM\n260         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n261 \n262         .. versionadded:: 1.4\n263 \n264         Parameters\n265         ----------\n266         bulk_data_element_handler: callable or None\n267             Callable that accepts a bulk data element and returns the\n268             \"BulkDataURI\" for retrieving the value of the data element\n269             via DICOMweb WADO-RS\n270         bulk_data_threshold: int\n271             Size of base64 encoded data element above which a value will be\n272             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n273             Ignored if no bulk data handler is given.\n274 \n275         Returns\n276         -------\n277         dict\n278             Mapping representing a JSON encoded data element\n279         \"\"\"\n280         json_element = {'vr': self.VR, }\n281         if self.VR in jsonrep.BINARY_VR_VALUES:\n282             if not self.is_empty:\n283                 binary_value = self.value\n284                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n285                 if (bulk_data_element_handler is not None and\n286                         len(encoded_value) > bulk_data_threshold):\n287                     json_element['BulkDataURI'] = bulk_data_element_handler(\n288                         self\n289                     )\n290                 else:\n291                     logger.info(\n292                         'encode bulk data element \"{}\" inline'.format(\n293                             self.name\n294                         )\n295                     )\n296                     json_element['InlineBinary'] = encoded_value\n297         elif self.VR == 'SQ':\n298             # recursive call to get sequence item JSON dicts\n299             value = [\n300                 ds.to_json(\n301                     bulk_data_element_handler=bulk_data_element_handler,\n302                     bulk_data_threshold=bulk_data_threshold,\n303                     dump_handler=lambda d: d\n304                 )\n305                 for ds in self\n306             ]\n307             json_element['Value'] = value\n308         elif self.VR == 'PN':\n309             if not self.is_empty:\n310                 elem_value = []\n311                 if self.VM > 1:\n312                     value = self.value\n313                 else:\n314                     value = [self.value]\n315                 for v in value:\n316                     comps = {'Alphabetic': v.components[0]}\n317                     if len(v.components) > 1:\n318                         comps['Ideographic'] = v.components[1]\n319                     if len(v.components) > 2:\n320                         comps['Phonetic'] = v.components[2]\n321                     elem_value.append(comps)\n322                 json_element['Value'] = elem_value\n323         elif self.VR == 'AT':\n324             if not self.is_empty:\n325                 value = self.value\n326                 if self.VM == 1:\n327                     value = [value]\n328                 json_element['Value'] = [format(v, '08X') for v in value]\n329         else:\n330             if not self.is_empty:\n331                 if self.VM > 1:\n332                     value = self.value\n333                 else:\n334                     value = [self.value]\n335                 json_element['Value'] = [v for v in value]\n336         if hasattr(json_element, 'Value'):\n337             json_element['Value'] = jsonrep.convert_to_python_number(\n338                 json_element['Value'], self.VR\n339             )\n340         return json_element\n341 \n342     def to_json(self, bulk_data_threshold=1024, bulk_data_element_handler=None,\n343                 dump_handler=None):\n344         \"\"\"Return a JSON representation of the :class:`DataElement`.\n345 \n346         .. versionadded:: 1.3\n347 \n348         Parameters\n349         ----------\n350         bulk_data_element_handler: callable or None\n351             Callable that accepts a bulk data element and returns the\n352             \"BulkDataURI\" for retrieving the value of the data element\n353             via DICOMweb WADO-RS\n354         bulk_data_threshold: int\n355             Size of base64 encoded data element above which a value will be\n356             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n357             Ignored if no bulk data handler is given.\n358         dump_handler : callable, optional\n359             Callable function that accepts a :class:`dict` and returns the\n360             serialized (dumped) JSON string (by default uses\n361             :func:`json.dumps`).\n362 \n363         Returns\n364         -------\n365         dict\n366             Mapping representing a JSON encoded data element\n367 \n368         See also\n369         --------\n370         Dataset.to_json\n371         \"\"\"\n372         if dump_handler is None:\n373             def json_dump(d):\n374                 return json.dumps(d, sort_keys=True)\n375 \n376             dump_handler = json_dump\n377 \n378         return dump_handler(\n379             self.to_json_dict(bulk_data_threshold, bulk_data_element_handler))\n380 \n381     @property\n382     def value(self):\n383         \"\"\"Return the element's value.\"\"\"\n384         return self._value\n385 \n386     @value.setter\n387     def value(self, val):\n388         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n389         # Check if is a string with multiple values separated by '\\'\n390         # If so, turn them into a list of separate strings\n391         #  Last condition covers 'US or SS' etc\n392         if isinstance(val, (str, bytes)) and self.VR not in \\\n393                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n394                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n395                  'OW or OB', 'UN'] and 'US' not in self.VR:\n396             try:\n397                 if _backslash_str in val:\n398                     val = val.split(_backslash_str)\n399             except TypeError:\n400                 if _backslash_byte in val:\n401                     val = val.split(_backslash_byte)\n402         self._value = self._convert_value(val)\n403 \n404     @property\n405     def VM(self):\n406         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n407         if self.value is None:\n408             return 0\n409         if isinstance(self.value, (str, bytes, PersonName)):\n410             return 1 if self.value else 0\n411         try:\n412             iter(self.value)\n413         except TypeError:\n414             return 1\n415         return len(self.value)\n416 \n417     @property\n418     def is_empty(self):\n419         \"\"\"Return ``True`` if the element has no value.\n420 \n421         .. versionadded:: 1.4\n422         \"\"\"\n423         return self.VM == 0\n424 \n425     @property\n426     def empty_value(self):\n427         \"\"\"Return the value for an empty element.\n428 \n429         .. versionadded:: 1.4\n430 \n431         See :func:`empty_value_for_VR` for more information.\n432 \n433         Returns\n434         -------\n435         str or None\n436             The value this data element is assigned on decoding if it is empty.\n437         \"\"\"\n438         return empty_value_for_VR(self.VR)\n439 \n440     def clear(self):\n441         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n442 \n443         .. versionadded:: 1.4\n444 \n445         See :func:`empty_value_for_VR`.\n446         \"\"\"\n447         self._value = self.empty_value\n448 \n449     def _convert_value(self, val):\n450         \"\"\"Convert `val` to an appropriate type and return the result.\n451 \n452         Uses the element's VR in order to determine the conversion method and\n453         resulting type.\n454         \"\"\"\n455         if self.VR == 'SQ':  # a sequence - leave it alone\n456             from pydicom.sequence import Sequence\n457             if isinstance(val, Sequence):\n458                 return val\n459             else:\n460                 return Sequence(val)\n461 \n462         # if the value is a list, convert each element\n463         try:\n464             val.append\n465         except AttributeError:  # not a list\n466             return self._convert(val)\n467         else:\n468             return MultiValue(self._convert, val)\n469 \n470     def _convert(self, val):\n471         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n472         # If the value is a byte string and has a VR that can only be encoded\n473         # using the default character repertoire, we convert it to a string\n474         # here to allow for byte string input in these cases\n475         if _is_bytes(val) and self.VR in (\n476                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n477             val = val.decode()\n478 \n479         if self.VR == 'IS':\n480             return pydicom.valuerep.IS(val)\n481         elif self.VR == 'DA' and config.datetime_conversion:\n482             return pydicom.valuerep.DA(val)\n483         elif self.VR == 'DS':\n484             return pydicom.valuerep.DS(val)\n485         elif self.VR == 'DT' and config.datetime_conversion:\n486             return pydicom.valuerep.DT(val)\n487         elif self.VR == 'TM' and config.datetime_conversion:\n488             return pydicom.valuerep.TM(val)\n489         elif self.VR == \"UI\":\n490             return UID(val) if val is not None else None\n491         elif self.VR == \"PN\":\n492             return PersonName(val)\n493         # Later may need this for PersonName as for UI,\n494         #    but needs more thought\n495         # elif self.VR == \"PN\":\n496         #    return PersonName(val)\n497         else:  # is either a string or a type 2 optionally blank string\n498             return val  # this means a \"numeric\" value could be empty string \"\"\n499         # except TypeError:\n500             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n501             # % (repr(val), self.VR, self.tag)\n502         # except ValueError:\n503             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n504             # % (repr(val), self.VR, self.tag)\n505 \n506     def __eq__(self, other):\n507         \"\"\"Compare `self` and `other` for equality.\n508 \n509         Returns\n510         -------\n511         bool\n512             The result if `self` and `other` are the same class\n513         NotImplemented\n514             If `other` is not the same class as `self` then returning\n515             :class:`NotImplemented` delegates the result to\n516             ``superclass.__eq__(subclass)``.\n517         \"\"\"\n518         # Faster result if same object\n519         if other is self:\n520             return True\n521 \n522         if isinstance(other, self.__class__):\n523             if self.tag != other.tag or self.VR != other.VR:\n524                 return False\n525 \n526             # tag and VR match, now check the value\n527             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n528                 return (len(self.value) == len(other.value)\n529                         and numpy.allclose(self.value, other.value))\n530             else:\n531                 return self.value == other.value\n532 \n533         return NotImplemented\n534 \n535     def __ne__(self, other):\n536         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n537         return not (self == other)\n538 \n539     def __str__(self):\n540         \"\"\"Return :class:`str` representation of the element.\"\"\"\n541         repVal = self.repval or ''\n542         if self.showVR:\n543             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n544                                     self.description()[:self.descripWidth],\n545                                     self.VR, repVal)\n546         else:\n547             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n548                                 self.description()[:self.descripWidth], repVal)\n549         return s\n550 \n551     @property\n552     def repval(self):\n553         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n554         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n555         if set(self.VR.split(\" or \")) & long_VRs:\n556             try:\n557                 length = len(self.value)\n558             except TypeError:\n559                 pass\n560             else:\n561                 if length > self.maxBytesToDisplay:\n562                     return \"Array of %d elements\" % length\n563         if self.VM > self.maxBytesToDisplay:\n564             repVal = \"Array of %d elements\" % self.VM\n565         elif isinstance(self.value, UID):\n566             repVal = self.value.name\n567         else:\n568             repVal = repr(self.value)  # will tolerate unicode too\n569         return repVal\n570 \n571     def __unicode__(self):\n572         \"\"\"Return unicode representation of the element.\"\"\"\n573         if isinstance(self.value, str):\n574             # start with the string rep then replace the value part\n575             #   with the unicode\n576             strVal = str(self)\n577             strVal = strVal.replace(self.repval, \"\")\n578             uniVal = str(strVal) + self.value\n579             return uniVal\n580         else:\n581             return str(self)\n582 \n583     def __getitem__(self, key):\n584         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n585         try:\n586             return self.value[key]\n587         except TypeError:\n588             raise TypeError(\"DataElement value is unscriptable \"\n589                             \"(not a Sequence)\")\n590 \n591     @property\n592     def name(self):\n593         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n594 \n595         For officially registered DICOM Data Elements this will be the *Name*\n596         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n597         For private elements known to *pydicom*\n598         this will be the *Name* in the format ``'[name]'``. For unknown\n599         private elements this will be ``'Private Creator'``. For unknown\n600         elements this will return an empty string ``''``.\n601         \"\"\"\n602         return self.description()\n603 \n604     def description(self):\n605         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n606         if self.tag.is_private:\n607             name = \"Private tag data\"  # default\n608             if self.private_creator:\n609                 try:\n610                     # If have name from private dictionary, use it, but\n611                     #   but put in square brackets so is differentiated,\n612                     #   and clear that cannot access it by name\n613                     name = private_dictionary_description(\n614                         self.tag, self.private_creator)\n615                     name = \"[%s]\" % (name)\n616                 except KeyError:\n617                     pass\n618             elif self.tag.element >> 8 == 0:\n619                 name = \"Private Creator\"\n620         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n621             name = dictionary_description(self.tag)\n622 \n623         # implied Group Length dicom versions < 3\n624         elif self.tag.element == 0:\n625             name = \"Group Length\"\n626         else:\n627             name = \"\"\n628         return name\n629 \n630     @property\n631     def is_retired(self):\n632         \"\"\"Return the element's retired status as :class:`bool`.\n633 \n634         For officially registered DICOM Data Elements this will be ``True`` if\n635         the retired status as given in the DICOM Standard, Part 6,\n636         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n637         or unknown elements this will always be ``False``.\n638         \"\"\"\n639         if dictionary_has_tag(self.tag):\n640             return dictionary_is_retired(self.tag)\n641         else:\n642             return False\n643 \n644     @property\n645     def keyword(self):\n646         \"\"\"Return the element's keyword (if known) as :class:`str`.\n647 \n648         For officially registered DICOM Data Elements this will be the\n649         *Keyword* as given in\n650         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n651         unknown elements this will return an empty string ``''``.\n652         \"\"\"\n653         if dictionary_has_tag(self.tag):\n654             return dictionary_keyword(self.tag)\n655         else:\n656             return ''\n657 \n658     def __repr__(self):\n659         \"\"\"Return the representation of the element.\"\"\"\n660         if self.VR == \"SQ\":\n661             return repr(self.value)\n662         else:\n663             return str(self)\n664 \n665 \n666 msg = 'tag VR length value value_tell is_implicit_VR is_little_endian'\n667 RawDataElement = namedtuple('RawDataElement', msg)\n668 RawDataElement.is_raw = True\n669 \n670 \n671 # The first and third values of the following elements are always US\n672 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n673 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n674 # (0028,3002) LUT Descriptor\n675 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n676 \n677 \n678 def DataElement_from_raw(raw_data_element, encoding=None):\n679     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n680 \n681     Parameters\n682     ----------\n683     raw_data_element : RawDataElement namedtuple\n684         The raw data to convert to a :class:`DataElement`.\n685     encoding : str, optional\n686         The character encoding of the raw data.\n687 \n688     Returns\n689     -------\n690     DataElement\n691     \"\"\"\n692     # XXX buried here to avoid circular import\n693     # filereader->Dataset->convert_value->filereader\n694     # (for SQ parsing)\n695 \n696     from pydicom.values import convert_value\n697     raw = raw_data_element\n698 \n699     # If user has hooked into conversion of raw values, call his/her routine\n700     if config.data_element_callback:\n701         data_elem = config.data_element_callback\n702         raw = data_elem(raw_data_element,\n703                         **config.data_element_callback_kwargs)\n704     VR = raw.VR\n705     if VR is None:  # Can be if was implicit VR\n706         try:\n707             VR = dictionary_VR(raw.tag)\n708         except KeyError:\n709             # just read the bytes, no way to know what they mean\n710             if raw.tag.is_private:\n711                 # for VR for private tags see PS3.5, 6.2.2\n712                 if raw.tag.is_private_creator:\n713                     VR = 'LO'\n714                 else:\n715                     VR = 'UN'\n716 \n717             # group length tag implied in versions < 3.0\n718             elif raw.tag.element == 0:\n719                 VR = 'UL'\n720             else:\n721                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n722                 msg += \" can't look up VR\"\n723                 raise KeyError(msg)\n724     elif (VR == 'UN' and not raw.tag.is_private and\n725           config.replace_un_with_known_vr):\n726         # handle rare case of incorrectly set 'UN' in explicit encoding\n727         # see also DataElement.__init__()\n728         if (raw.length == 0xffffffff or raw.value is None or\n729                 len(raw.value) < 0xffff):\n730             try:\n731                 VR = dictionary_VR(raw.tag)\n732             except KeyError:\n733                 pass\n734     try:\n735         value = convert_value(VR, raw, encoding)\n736     except NotImplementedError as e:\n737         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n738 \n739     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n740         # We only fix the first value as the third value is 8 or 16\n741         try:\n742             if value[0] < 0:\n743                 value[0] += 65536\n744         except TypeError:\n745             pass\n746 \n747     return DataElement(raw.tag, VR, value, raw.value_tell,\n748                        raw.length == 0xFFFFFFFF, already_converted=True)\n749 \n[end of pydicom/dataelem.py]\n[start of pydicom/multival.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Code for multi-value data elements values,\n3 or any list of items that must all be the same type.\n4 \"\"\"\n5 \n6 try:\n7     from collections.abc import MutableSequence\n8 except ImportError:\n9     from collections import MutableSequence\n10 \n11 \n12 class MultiValue(MutableSequence):\n13     \"\"\"Class to hold any multi-valued DICOM value, or any list of items that\n14     are all of the same type.\n15 \n16     This class enforces that any items added to the list are of the correct\n17     type, by calling the constructor on any items that are added. Therefore,\n18     the constructor must behave nicely if passed an object that is already its\n19     type. The constructor should raise :class:`TypeError` if the item cannot be\n20     converted.\n21 \n22     Note, however, that DS and IS types can be a blank string ``''`` rather\n23     than an instance of their classes.\n24     \"\"\"\n25 \n26     def __init__(self, type_constructor, iterable):\n27         \"\"\"Initialize the list of values\n28 \n29         Parameters\n30         ----------\n31         type_constructor : type\n32             A constructor for the required type for all list items. Could be\n33             the class, or a factory function. For DICOM multi-value data\n34             elements, this will be the class or type corresponding to the VR.\n35         iterable : iterable\n36             An iterable (e.g. :class:`list`, :class:`tuple`) of items to\n37             initialize the :class:`MultiValue` list.\n38         \"\"\"\n39         from pydicom.valuerep import DSfloat, DSdecimal, IS\n40 \n41         def number_string_type_constructor(x):\n42             return self.type_constructor(x) if x != '' else x\n43 \n44         self._list = list()\n45         self.type_constructor = type_constructor\n46         if type_constructor in (DSfloat, IS, DSdecimal):\n47             type_constructor = number_string_type_constructor\n48         for x in iterable:\n49             self._list.append(type_constructor(x))\n50 \n51     def insert(self, position, val):\n52         self._list.insert(position, self.type_constructor(val))\n53 \n54     def append(self, val):\n55         self._list.append(self.type_constructor(val))\n56 \n57     def __setitem__(self, i, val):\n58         \"\"\"Set an item of the list, making sure it is of the right VR type\"\"\"\n59         if isinstance(i, slice):\n60             val = [self.type_constructor(v) for v in val]\n61             self._list.__setitem__(i, val)\n62         else:\n63             self._list.__setitem__(i, self.type_constructor(val))\n64 \n65     def __str__(self):\n66         if not self:\n67             return ''\n68         lines = [\"'{}'\".format(x) if isinstance(x, (str, bytes))\n69                  else str(x) for x in self]\n70         return \"[\" + \", \".join(lines) + \"]\"\n71 \n72     __repr__ = __str__\n73 \n74     def __len__(self):\n75         return len(self._list)\n76 \n77     def __getitem__(self, index):\n78         return self._list[index]\n79 \n80     def __delitem__(self, index):\n81         del self._list[index]\n82 \n83     def __iter__(self):\n84         return iter(self._list)\n85 \n86     def __eq__(self, other):\n87         return self._list == other\n88 \n89     def __ne__(self, other):\n90         return self._list != other\n91 \n92     def sort(self, key=None, reverse=False):\n93         self._list.sort(key=key, reverse=reverse)\n94 \n[end of pydicom/multival.py]\n[start of pydicom/util/codify.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"\n3 Produce runnable python code which can recreate DICOM objects or files.\n4 \n5 Can run as a script to produce code for an entire file,\n6 or import and use specific functions to provide code for pydicom DICOM classes\n7 \n8 \"\"\"\n9 \n10 # Run this from the same directory as a \"base\" dicom file and\n11 # this code will output to screen the dicom parameters like:\n12 #    ds.PatientName = 'TEST'\n13 # etc for all parameters in the file.\n14 # This can then be pasted into a python file and parameters edited as necessary\n15 # to create a DICOM file from scratch\n16 \n17 import sys\n18 import os.path\n19 import pydicom\n20 from pydicom.datadict import dictionary_keyword\n21 \n22 import re\n23 \n24 line_term = \"\\n\"\n25 \n26 # Helper functions first\n27 \n28 # Precompiled search patterns for camel_to_underscore()\n29 first_cap_re = re.compile('(.)([A-Z][a-z]+)')\n30 all_cap_re = re.compile('([a-z0-9])([A-Z])')\n31 \n32 byte_VRs = [\n33     'OB', 'OW', 'OW/OB', 'OW or OB', 'OB or OW', 'US or SS or OW', 'US or SS',\n34     'OD', 'OL'\n35 ]\n36 \n37 \n38 def camel_to_underscore(name):\n39     \"\"\"Convert name from CamelCase to lower_case_with_underscores\"\"\"\n40     # From http://stackoverflow.com/questions/1175208\n41     s1 = first_cap_re.sub(r'\\1_\\2', name)\n42     return all_cap_re.sub(r'\\1_\\2', s1).lower()\n43 \n44 \n45 def tag_repr(tag):\n46     \"\"\"String of tag value as (0xgggg, 0xeeee)\"\"\"\n47     return \"(0x{group:04x}, 0x{elem:04x})\".format(\n48         group=tag.group, elem=tag.element)\n49 \n50 \n51 def default_name_filter(name):\n52     \"\"\"Callable to reduce some names in code to more readable short form\n53 \n54     :arg name: a sequence variable name or sequence item name\n55     :return: a shorter version of name if a known conversion,\n56              else return original name\n57 \n58     \"\"\"\n59     name = camel_to_underscore(name)\n60     name = name.replace(\"control_point\", \"cp\")\n61     name = name.replace(\"reference\", \"ref\")\n62     name = name.replace(\"fraction_group\", \"frxn_gp\")\n63     return name\n64 \n65 \n66 # Functions to produce python code\n67 def code_imports():\n68     \"\"\"Code the import statements needed by other codify results\n69 \n70     :return: a string of import statement lines\n71 \n72     \"\"\"\n73     line1 = \"import pydicom\"\n74     line2 = \"from pydicom.dataset import Dataset, FileMetaDataset\"\n75     line3 = \"from pydicom.sequence import Sequence\"\n76     return line_term.join((line1, line2, line3))\n77 \n78 \n79 def code_dataelem(dataelem,\n80                   dataset_name=\"ds\",\n81                   exclude_size=None,\n82                   include_private=False):\n83     \"\"\"Code lines for a single DICOM data element\n84 \n85     :arg dataelem: the DataElement instance to turn into code\n86     :arg dataset_name: variable name of the Dataset containing dataelem\n87     :arg exclude_size: if specified, values longer than this (in bytes)\n88                        will only have a commented string for a value,\n89                        causing a syntax error when the code is run,\n90                        and thus prompting the user to remove or fix that line.\n91     :return: a string containing code to recreate the data element\n92              If the data element is a sequence, calls code_sequence\n93 \n94     \"\"\"\n95 \n96     if dataelem.VR == \"SQ\":\n97         return code_sequence(dataelem, dataset_name, exclude_size,\n98                              include_private)\n99 \n100     # If in DICOM dictionary, set using the keyword\n101     # If not (e.g. is private element), set using add_new method\n102     have_keyword = True\n103     try:\n104         keyword = dictionary_keyword(dataelem.tag)\n105     except KeyError:\n106         have_keyword = False\n107 \n108     valuerep = repr(dataelem.value)\n109 \n110     if exclude_size:\n111         if (dataelem.VR in byte_VRs and\n112                 len(dataelem.value) > exclude_size):\n113             valuerep = (\n114                 \"# XXX Array of %d bytes excluded\" % len(dataelem.value))\n115 \n116     if have_keyword:\n117         format_str = \"{ds_name}.{keyword} = {valuerep}\"\n118         line = format_str.format(\n119             ds_name=dataset_name, keyword=keyword, valuerep=valuerep)\n120     else:\n121         format_str = \"{ds_name}.add_new({tag}, '{VR}', {valuerep})\"\n122         line = format_str.format(\n123             ds_name=dataset_name,\n124             tag=tag_repr(dataelem.tag),\n125             VR=dataelem.VR,\n126             valuerep=valuerep)\n127     return line\n128 \n129 \n130 def code_sequence(dataelem,\n131                   dataset_name=\"ds\",\n132                   exclude_size=None,\n133                   include_private=False,\n134                   name_filter=default_name_filter):\n135     \"\"\"Code lines for recreating a Sequence data element\n136 \n137     :arg dataelem: the DataElement instance of the Sequence\n138     :arg dataset_name: variable name of the dataset containing the Sequence\n139     :arg exclude_size: if specified, values longer than this (in bytes)\n140                        will only have a commented string for a value,\n141                        causing a syntax error when the code is run,\n142                        and thus prompting the user to remove or fix that line.\n143     :arg include_private: If True, private data elements will be coded.\n144                           If False, private elements are skipped\n145     :arg name_filter: a callable taking a sequence name or sequence item name,\n146                       and returning a shorter name for easier code reading\n147     :return: a string containing code lines to recreate a DICOM sequence\n148 \n149     \"\"\"\n150     lines = []\n151     seq = dataelem.value\n152     seq_name = dataelem.name\n153     seq_item_name = seq_name.replace(' Sequence', '')\n154     seq_keyword = dictionary_keyword(dataelem.tag)\n155 \n156     # Create comment line to document the start of Sequence\n157     lines.append('')\n158     lines.append(\"# \" + seq_name)\n159 \n160     # Code line to create a new Sequence object\n161     if name_filter:\n162         seq_var = name_filter(seq_keyword)\n163     lines.append(seq_var + \" = Sequence()\")\n164 \n165     # Code line to add the sequence to its parent\n166     lines.append(dataset_name + \".\" + seq_keyword + \" = \" + seq_var)\n167 \n168     # Code lines to add sequence items to the Sequence\n169     for i, ds in enumerate(seq):\n170         # Determine index to use. If seq item has a data element with 'Index',\n171         #    use that; if one with 'Number', use that, else start at 1\n172         index_keyword = seq_keyword.replace(\"Sequence\", \"\") + \"Index\"\n173         number_keyword = seq_keyword.replace(\"Sequence\", \"\") + \"Number\"\n174         if index_keyword in ds:\n175             index_str = str(getattr(ds, index_keyword))\n176         elif number_keyword in ds:\n177             index_str = str(getattr(ds, number_keyword))\n178         else:\n179             index_str = str(i + 1)\n180 \n181         # Code comment line to mark start of sequence item\n182         lines.append('')\n183         lines.append(\"# \" + seq_name + \": \" + seq_item_name + \" \" + index_str)\n184 \n185         # Determine the variable name to use for the sequence item (dataset)\n186         ds_name = seq_var.replace(\"_sequence\", \"\") + index_str\n187 \n188         # Code the sequence item\n189         code_item = code_dataset(ds, ds_name, exclude_size, include_private)\n190         lines.append(code_item)\n191 \n192         # Code the line to append the item to its parent sequence\n193         lines.append(seq_var + \".append(\" + ds_name + \")\")\n194 \n195     # Join the lines and return a single string\n196     return line_term.join(lines)\n197 \n198 \n199 def code_dataset(ds,\n200                  dataset_name=\"ds\",\n201                  exclude_size=None,\n202                  include_private=False,\n203                  is_file_meta=False):\n204     \"\"\"Return python code lines for import statements needed by other code\n205 \n206     :arg exclude_size: if specified, values longer than this (in bytes)\n207                        will only have a commented string for a value,\n208                        causing a syntax error when the code is run,\n209                        and thus prompting the user to remove or fix that line.\n210     :arg include_private: If True, private data elements will be coded.\n211                           If False, private elements are skipped\n212     :return: a list of code lines containing import statements\n213 \n214     \"\"\"\n215     lines = []\n216     ds_class = \" = FileMetaDataset()\" if is_file_meta else \" = Dataset()\"\n217     lines.append(dataset_name + ds_class)\n218     for dataelem in ds:\n219         # If a private data element and flag says so, skip it and go to next\n220         if not include_private and dataelem.tag.is_private:\n221             continue\n222         # Otherwise code the line and add it to the lines list\n223         code_line = code_dataelem(dataelem, dataset_name, exclude_size,\n224                                   include_private)\n225         lines.append(code_line)\n226         # Add blank line if just coded a sequence\n227         if dataelem.VR == \"SQ\":\n228             lines.append('')\n229     # If sequence was end of this dataset, remove the extra blank line\n230     if len(lines) and lines[-1] == '':\n231         lines.pop()\n232     # Join all the code lines and return them\n233     return line_term.join(lines)\n234 \n235 \n236 def code_file(filename, exclude_size=None, include_private=False):\n237     \"\"\"Write a complete source code file to recreate a DICOM file\n238 \n239     :arg filename: complete path and filename of a DICOM file to convert\n240     :arg exclude_size: if specified, values longer than this (in bytes)\n241                        will only have a commented string for a value,\n242                        causing a syntax error when the code is run,\n243                        and thus prompting the user to remove or fix that line.\n244     :arg include_private: If True, private data elements will be coded.\n245                           If False, private elements are skipped\n246     :return: a string containing code lines to recreate entire file\n247 \n248     \"\"\"\n249     lines = []\n250 \n251     ds = pydicom.dcmread(filename, force=True)\n252 \n253     # Code a nice header for the python file\n254     lines.append(\"# Coded version of DICOM file '{0}'\".format(filename))\n255     lines.append(\"# Produced by pydicom codify utility script\")\n256 \n257     # Code the necessary imports\n258     lines.append(code_imports())\n259     lines.append('')\n260 \n261     # Code the file_meta information\n262     lines.append(\"# File meta info data elements\")\n263     code_meta = code_dataset(ds.file_meta, \"file_meta\", exclude_size,\n264                              include_private, is_file_meta=True)\n265     lines.append(code_meta)\n266     lines.append('')\n267 \n268     # Code the main dataset\n269     lines.append(\"# Main data elements\")\n270     code_ds = code_dataset(\n271         ds, exclude_size=exclude_size, include_private=include_private)\n272     lines.append(code_ds)\n273     lines.append('')\n274 \n275     # Add the file meta to the dataset, and set transfer syntax\n276     lines.append(\"ds.file_meta = file_meta\")\n277     lines.append(\"ds.is_implicit_VR = \" + str(ds.is_implicit_VR))\n278     lines.append(\"ds.is_little_endian = \" + str(ds.is_little_endian))\n279 \n280     # Return the complete code string\n281     return line_term.join(lines)\n282 \n283 \n284 def main(default_exclude_size, args=None):\n285     \"\"\"Create python code according to user options\n286 \n287     Parameters:\n288     -----------\n289     default_exclude_size:  int\n290         Values longer than this will be coded as a commented syntax error\n291 \n292     args: list\n293         Command-line arguments to parse.  If None, then sys.argv is used\n294     \"\"\"\n295 \n296     try:\n297         import argparse\n298     except ImportError:\n299         print(\"The argparse module is required to run this script\")\n300         print(\"argparse is standard in python >= 2.7,\")\n301         print(\"   or can be installed with 'pip install argparse'\")\n302         sys.exit(-1)\n303 \n304     parser = argparse.ArgumentParser(\n305         description=\"Produce python/pydicom code from a DICOM file\",\n306         epilog=\"Binary data (e.g. pixels) larger than --exclude-size \"\n307         \"(default %d bytes) is not included. A dummy line \"\n308         \"with a syntax error is produced. \"\n309         \"Private data elements are not included \"\n310         \"by default.\" % default_exclude_size)\n311     parser.add_argument(\n312         'infile', help=\"DICOM file from which to produce code lines\")\n313     parser.add_argument(\n314         'outfile',\n315         nargs='?',\n316         type=argparse.FileType('w'),\n317         help=(\"Filename to write python code to. \"\n318               \"If not specified, code is written to stdout\"),\n319         default=sys.stdout)\n320     help_exclude_size = 'Exclude binary data larger than specified (bytes). '\n321     help_exclude_size += 'Default is %d bytes' % default_exclude_size\n322     parser.add_argument(\n323         '-e',\n324         '--exclude-size',\n325         type=int,\n326         default=default_exclude_size,\n327         help=help_exclude_size)\n328     parser.add_argument(\n329         '-p',\n330         '--include-private',\n331         action=\"store_true\",\n332         help='Include private data elements '\n333         '(default is to exclude them)')\n334     parser.add_argument(\n335         '-s',\n336         '--save-as',\n337         help=(\"Specify the filename for ds.save_as(save_filename); \"\n338               \"otherwise the input name + '_from_codify' will be used\"))\n339 \n340     args = parser.parse_args(args)\n341 \n342     # Read the requested file and convert to python/pydicom code lines\n343     filename = args.infile  # name\n344     code_lines = code_file(filename, args.exclude_size, args.include_private)\n345 \n346     # If requested, write a code line to save the dataset\n347     if args.save_as:\n348         save_as_filename = args.save_as\n349     else:\n350         base, ext = os.path.splitext(filename)\n351         save_as_filename = base + \"_from_codify\" + \".dcm\"\n352     line = \"\\nds.save_as(r'{filename}', write_like_original=False)\"\n353     save_line = line.format(filename=save_as_filename)\n354     code_lines += save_line\n355 \n356     # Write the code lines to specified file or to standard output\n357     # For test_util, captured output .name throws error, ignore it:\n358     try:\n359         if args.outfile.name != \"<stdout>\":\n360             print(\"Writing code to file '%s'\" % args.outfile.name)\n361     except AttributeError:\n362         pass\n363     args.outfile.write(code_lines)\n364 \n365 \n366 if __name__ == \"__main__\":\n367     main(default_exclude_size=100)\n368 \n[end of pydicom/util/codify.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "b9fb05c177b685bf683f7f57b2d57374eb7d882d", "problem_statement": "Make PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n", "hints_text": "I think it is reasonable to support at least some `str` methods (definitely `__contains__` for the example above), but there are many that don't make a lot of sense in this context though - e.g. `join`, `ljust`, `maketrans`, `splitlines` just to name a few, but I suppose each would either never be actually used or would have no effect.\r\n\r\nI have a vague memory that one or more of the `PersonName` classes was at one time subclassed from `str`, or at least that it was discussed... does anyone remember?  Maybe it would be easier now with only Python 3 supported.\n`PersonName` was derived from `str` or `unicode` in Python 2, but that caused a number of problems, which is why you switched to `PersonName3` in Python 3, I think. I agree though that it makes sense to implement `str` methods, either by implementing some of them, or generically by adding `__getattr__` that converts it to `str` and applies the attribute to that string. ", "created_at": "2020-06-26T11:47:17Z", "patch": "<patch>\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -1,6 +1,5 @@\n # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n-from copy import deepcopy\n from decimal import Decimal\n import re\n \n@@ -750,6 +749,25 @@ def __ne__(self, other):\n     def __str__(self):\n         return '='.join(self.components).__str__()\n \n+    def __next__(self):\n+        # Get next character or stop iteration\n+        if self._i < self._rep_len:\n+            c = self._str_rep[self._i]\n+            self._i += 1\n+            return c\n+        else:\n+            raise StopIteration\n+\n+    def __iter__(self):\n+        # Get string rep. and length, initialize index counter\n+        self._str_rep = self.__str__()\n+        self._rep_len = len(self._str_rep)\n+        self._i = 0\n+        return self\n+\n+    def __contains__(self, x):\n+        return x in self.__str__()\n+\n     def __repr__(self):\n         return '='.join(self.components).__repr__()\n \n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -427,6 +427,62 @@ def test_hash(self):\n         )\n         assert hash(pn1) == hash(pn2)\n \n+    def test_next(self):\n+        \"\"\"Test that the next function works on it's own\"\"\"\n+        # Test getting the first character\n+        pn1 = PersonName(\"John^Doe^^Dr\", encodings=default_encoding)\n+        pn1_itr = iter(pn1)\n+        assert next(pn1_itr) == \"J\"\n+\n+        # Test getting multiple characters\n+        pn2 = PersonName(\n+            \"Yamada^Tarou=\u5c71\u7530^\u592a\u90ce=\u3084\u307e\u3060^\u305f\u308d\u3046\", [default_encoding, \"iso2022_jp\"]\n+        )\n+        pn2_itr = iter(pn2)\n+        assert next(pn2_itr) == \"Y\"\n+        assert next(pn2_itr) == \"a\"\n+\n+        # Test getting all characters\n+        pn3 = PersonName(\"SomeName\")\n+        pn3_itr = iter(pn3)\n+        assert next(pn3_itr) == \"S\"\n+        assert next(pn3_itr) == \"o\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+        assert next(pn3_itr) == \"N\"\n+        assert next(pn3_itr) == \"a\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+\n+        # Attempting to get next characeter should stop the iteration\n+        # I.e. next can only start once\n+        with pytest.raises(StopIteration):\n+            next(pn3_itr)\n+\n+        # Test that next() doesn't work without instantiating an iterator\n+        pn4 = PersonName(\"SomeName\")\n+        with pytest.raises(AttributeError):\n+            next(pn4)\n+\n+    def test_iterator(self):\n+        \"\"\"Test that iterators can be corretly constructed\"\"\"\n+        name_str = \"John^Doe^^Dr\"\n+        pn1 = PersonName(name_str)\n+        \n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+        # Ensure that multiple iterators can be created on the same variable\n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+    def test_contains(self):\n+        \"\"\"Test that characters can be check if they are within the name\"\"\"\n+        pn1 = PersonName(\"John^Doe\")\n+        assert (\"J\" in pn1) == True\n+        assert (\"o\" in pn1) == True\n+        assert (\"x\" in pn1) == False\n+\n \n class TestDateTime:\n     \"\"\"Unit tests for DA, DT, TM conversion to datetime objects\"\"\"\n", "version": "2.0", "FAIL_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\"]", "environment_setup_commit": "9d69811e539774f296c2f289839147e741251716"}
{"instance_id": "pydicom__pydicom-1139_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nMake PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n\n</issue>\n<code>\n[start of README.md]\n1 *pydicom*\n2 =======\n3 \n4 [![Build Status](https://travis-ci.org/pydicom/pydicom.svg?branch=master)](https://travis-ci.org/pydicom/pydicom)\n5 [![AppVeyor](https://ci.appveyor.com/api/projects/status/1vjtkr82lumnd3i7?svg=true)](https://ci.appveyor.com/project/glemaitre/pydicom)\n6 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n7 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n8 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n9 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n10 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3891702.svg)](https://doi.org/10.5281/zenodo.3891702)\n11 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n12 \n13 *pydicom* is a pure python package for working with [DICOM](http://medical.nema.org/) files.\n14 It was made for inspecting and modifying DICOM data in an easy \"pythonic\" way.\n15 The modifications can be written again to a new file.\n16 \n17 As a pure python package, *pydicom* can run anywhere python runs without any other requirements,\n18 although [NumPy](http://www.numpy.org) is needed if manipulating pixel data.\n19 \n20 *pydicom* is not a DICOM server, and is not primarily about viewing images.\n21 It is designed to let you\n22 manipulate data elements in DICOM files with python code.\n23 \n24 Limitations -- for files with _compressed_ pixel data, *pydicom* can decompress\n25 it (with additional libraries installed) and allow you to manipulate the data,\n26 but can only store changed pixel data as uncompressed. Files can always be\n27 read and saved (including compressed pixel data that has not been modified),\n28 but once decompressed, modified pixel data cannot be compressed again.\n29 \n30 Documentation\n31 -------------\n32 \n33 *pydicom* documentation is available on GitHub Pages both for the [development\n34  (master) version](https://pydicom.github.io/pydicom/dev) and for the\n35 [released version](https://pydicom.github.io/pydicom/stable). The\n36 documentation for [the previous 0.9.9 version](https://pydicom.github.io/pydicom/0.9/)\n37 is still there for reference.\n38 \n39 See [Getting Started](https://pydicom.github.io/pydicom/stable/old/getting_started.html)\n40 for installation and basic information, and the\n41 [User Guide](https://pydicom.github.io/pydicom/stable/pydicom_user_guide.html)\n42 for an overview of how to use the *pydicom* library.\n43 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n44 To contribute an example or extension of *pydicom* that does not belong with\n45 the core software, see our contribution repository,\n46 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n47 \n[end of README.md]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 \n11 import base64\n12 import json\n13 from collections import namedtuple\n14 \n15 from pydicom import config  # don't import datetime_conversion directly\n16 from pydicom.config import logger\n17 from pydicom import config\n18 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n19                               dictionary_keyword, dictionary_is_retired,\n20                               private_dictionary_description, dictionary_VR,\n21                               repeater_has_tag)\n22 from pydicom.jsonrep import JsonDataElementConverter\n23 from pydicom.multival import MultiValue\n24 from pydicom.tag import Tag, BaseTag\n25 from pydicom.uid import UID\n26 from pydicom import jsonrep\n27 import pydicom.valuerep  # don't import DS directly as can be changed by config\n28 from pydicom.valuerep import PersonName\n29 \n30 if config.have_numpy:\n31     import numpy\n32 \n33 BINARY_VR_VALUES = [\n34     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n35     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n36 ]\n37 \n38 \n39 def empty_value_for_VR(VR, raw=False):\n40     \"\"\"Return the value for an empty element for `VR`.\n41 \n42     .. versionadded:: 1.4\n43 \n44     The behavior of this property depends on the setting of\n45     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n46     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n47     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n48     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n49     empty string is used as empty value representation, for all other VRs\n50     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n51     is used in all cases.\n52     Note that this is used only if decoding the element - it is always\n53     possible to set the value to another empty value representation,\n54     which will be preserved during the element object lifetime.\n55 \n56     Parameters\n57     ----------\n58     VR : str\n59         The VR of the corresponding element.\n60 \n61     raw : bool\n62         If ``True``, returns the value for a :class:`RawDataElement`,\n63         otherwise for a :class:`DataElement`\n64 \n65     Returns\n66     -------\n67     str or bytes or None or list\n68         The value a data element with `VR` is assigned on decoding\n69         if it is empty.\n70     \"\"\"\n71     if VR == 'SQ':\n72         return b'' if raw else []\n73     if config.use_none_as_empty_text_VR_value:\n74         return None\n75     if VR in ('AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT',\n76               'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR', 'UT'):\n77         return b'' if raw else ''\n78     return None\n79 \n80 \n81 def _is_bytes(val):\n82     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n83     return isinstance(val, bytes)\n84 \n85 \n86 # double '\\' because it is used as escape chr in Python\n87 _backslash_str = \"\\\\\"\n88 _backslash_byte = b\"\\\\\"\n89 \n90 \n91 class DataElement:\n92     \"\"\"Contain and manipulate a DICOM Element.\n93 \n94     Examples\n95     --------\n96 \n97     While its possible to create a new :class:`DataElement` directly and add\n98     it to a :class:`~pydicom.dataset.Dataset`:\n99 \n100     >>> from pydicom import Dataset\n101     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n102     >>> ds = Dataset()\n103     >>> ds.add(elem)\n104 \n105     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n106     to add a new :class:`DataElement`, as the VR and tag are determined\n107     automatically from the DICOM dictionary:\n108 \n109     >>> ds = Dataset()\n110     >>> ds.PatientName = 'CITIZEN^Joan'\n111 \n112     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n113     value for text VRs and `None` for non-text (binary) VRs:\n114 \n115     >>> ds = Dataset()\n116     >>> ds.PatientName = None\n117     >>> ds.PatientName\n118     ''\n119 \n120     >>> ds.BitsAllocated = None\n121     >>> ds.BitsAllocated\n122 \n123     >>> str(ds.BitsAllocated)\n124     'None'\n125 \n126     Attributes\n127     ----------\n128     descripWidth : int\n129         For string display, this is the maximum width of the description\n130         field (default ``35``).\n131     is_undefined_length : bool\n132         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n133         (ie undefined).\n134     maxBytesToDisplay : int\n135         For string display, elements with values containing data which is\n136         longer than this value will display ``\"array of # bytes\"``\n137         (default ``16``).\n138     showVR : bool\n139         For string display, include the element's VR just before it's value\n140         (default ``True``).\n141     tag : BaseTag\n142         The element's tag.\n143     value\n144         The element's stored value(s).\n145     VR : str\n146         The element's Value Representation.\n147     \"\"\"\n148 \n149     descripWidth = 35\n150     maxBytesToDisplay = 16\n151     showVR = True\n152     is_raw = False\n153 \n154     def __init__(self,\n155                  tag,\n156                  VR,\n157                  value,\n158                  file_value_tell=None,\n159                  is_undefined_length=False,\n160                  already_converted=False):\n161         \"\"\"Create a new :class:`DataElement`.\n162 \n163         Parameters\n164         ----------\n165         tag : int or or str or list or tuple\n166             The DICOM (group, element) tag in any form accepted by\n167             :func:`~pydicom.tag.Tag` such as ``[0x0010, 0x0010]``,\n168             ``(0x10, 0x10)``, ``0x00100010``, etc.\n169         VR : str\n170             The 2 character DICOM value representation (see DICOM Standard,\n171             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n172         value\n173             The value of the data element. One of the following:\n174 \n175             * a single string value\n176             * a number\n177             * a :class:`list` or :class:`tuple` with all strings or all numbers\n178             * a multi-value string with backslash separator\n179 \n180         file_value_tell : int or None\n181             Used internally by :class:`~pydicom.dataset.Dataset` to\n182             store the write position for the ``ReplaceDataElementValue()``\n183             method. Default is ``None``.\n184         is_undefined_length : bool\n185             Used internally to store whether the length field for this element\n186             was ``0xFFFFFFFFL``, i.e. 'undefined length'. Default is ``False``.\n187         already_converted : bool\n188             Used to determine whether or not the element's value requires\n189             conversion to a value with VM > 1. Default is ``False``.\n190         \"\"\"\n191         if not isinstance(tag, BaseTag):\n192             tag = Tag(tag)\n193         self.tag = tag\n194 \n195         # a known tag shall only have the VR 'UN' if it has a length that\n196         # exceeds the size that can be encoded in 16 bit - all other cases\n197         # can be seen as an encoding error and can be corrected\n198         if (VR == 'UN' and not tag.is_private and\n199                 config.replace_un_with_known_vr and\n200                 (is_undefined_length or value is None or len(value) < 0xffff)):\n201             try:\n202                 VR = dictionary_VR(tag)\n203             except KeyError:\n204                 pass\n205 \n206         self.VR = VR  # Note: you must set VR before setting value\n207         if already_converted:\n208             self._value = value\n209         else:\n210             self.value = value  # calls property setter which will convert\n211         self.file_tell = file_value_tell\n212         self.is_undefined_length = is_undefined_length\n213         self.private_creator = None\n214 \n215     @classmethod\n216     def from_json(cls, dataset_class, tag, vr, value, value_key,\n217                   bulk_data_uri_handler=None):\n218         \"\"\"Return a :class:`DataElement` from JSON.\n219 \n220         .. versionadded:: 1.3\n221 \n222         Parameters\n223         ----------\n224         dataset_class : dataset.Dataset derived class\n225             Class used to create sequence items.\n226         tag : BaseTag or int\n227             The data element tag.\n228         vr : str\n229             The data element value representation.\n230         value : list\n231             The data element's value(s).\n232         value_key : str or None\n233             Key of the data element that contains the value\n234             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n235         bulk_data_uri_handler: callable or None\n236             Callable function that accepts the \"BulkDataURI\" of the JSON\n237             representation of a data element and returns the actual value of\n238             that data element (retrieved via DICOMweb WADO-RS)\n239 \n240         Returns\n241         -------\n242         DataElement\n243         \"\"\"\n244         # TODO: test wado-rs retrieve wrapper\n245         converter = JsonDataElementConverter(dataset_class, tag, vr, value,\n246                                              value_key, bulk_data_uri_handler)\n247         elem_value = converter.get_element_values()\n248         try:\n249             return DataElement(tag=tag, value=elem_value, VR=vr)\n250         except Exception:\n251             raise ValueError(\n252                 'Data element \"{}\" could not be loaded from JSON: {}'.format(\n253                     tag, elem_value\n254                 )\n255             )\n256 \n257     def to_json_dict(self, bulk_data_element_handler, bulk_data_threshold):\n258         \"\"\"Return a dictionary representation of the :class:`DataElement`\n259         conforming to the DICOM JSON Model as described in the DICOM\n260         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n261 \n262         .. versionadded:: 1.4\n263 \n264         Parameters\n265         ----------\n266         bulk_data_element_handler: callable or None\n267             Callable that accepts a bulk data element and returns the\n268             \"BulkDataURI\" for retrieving the value of the data element\n269             via DICOMweb WADO-RS\n270         bulk_data_threshold: int\n271             Size of base64 encoded data element above which a value will be\n272             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n273             Ignored if no bulk data handler is given.\n274 \n275         Returns\n276         -------\n277         dict\n278             Mapping representing a JSON encoded data element\n279         \"\"\"\n280         json_element = {'vr': self.VR, }\n281         if self.VR in jsonrep.BINARY_VR_VALUES:\n282             if not self.is_empty:\n283                 binary_value = self.value\n284                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n285                 if (bulk_data_element_handler is not None and\n286                         len(encoded_value) > bulk_data_threshold):\n287                     json_element['BulkDataURI'] = bulk_data_element_handler(\n288                         self\n289                     )\n290                 else:\n291                     logger.info(\n292                         'encode bulk data element \"{}\" inline'.format(\n293                             self.name\n294                         )\n295                     )\n296                     json_element['InlineBinary'] = encoded_value\n297         elif self.VR == 'SQ':\n298             # recursive call to get sequence item JSON dicts\n299             value = [\n300                 ds.to_json(\n301                     bulk_data_element_handler=bulk_data_element_handler,\n302                     bulk_data_threshold=bulk_data_threshold,\n303                     dump_handler=lambda d: d\n304                 )\n305                 for ds in self\n306             ]\n307             json_element['Value'] = value\n308         elif self.VR == 'PN':\n309             if not self.is_empty:\n310                 elem_value = []\n311                 if self.VM > 1:\n312                     value = self.value\n313                 else:\n314                     value = [self.value]\n315                 for v in value:\n316                     comps = {'Alphabetic': v.components[0]}\n317                     if len(v.components) > 1:\n318                         comps['Ideographic'] = v.components[1]\n319                     if len(v.components) > 2:\n320                         comps['Phonetic'] = v.components[2]\n321                     elem_value.append(comps)\n322                 json_element['Value'] = elem_value\n323         elif self.VR == 'AT':\n324             if not self.is_empty:\n325                 value = self.value\n326                 if self.VM == 1:\n327                     value = [value]\n328                 json_element['Value'] = [format(v, '08X') for v in value]\n329         else:\n330             if not self.is_empty:\n331                 if self.VM > 1:\n332                     value = self.value\n333                 else:\n334                     value = [self.value]\n335                 json_element['Value'] = [v for v in value]\n336         if hasattr(json_element, 'Value'):\n337             json_element['Value'] = jsonrep.convert_to_python_number(\n338                 json_element['Value'], self.VR\n339             )\n340         return json_element\n341 \n342     def to_json(self, bulk_data_threshold=1024, bulk_data_element_handler=None,\n343                 dump_handler=None):\n344         \"\"\"Return a JSON representation of the :class:`DataElement`.\n345 \n346         .. versionadded:: 1.3\n347 \n348         Parameters\n349         ----------\n350         bulk_data_element_handler: callable or None\n351             Callable that accepts a bulk data element and returns the\n352             \"BulkDataURI\" for retrieving the value of the data element\n353             via DICOMweb WADO-RS\n354         bulk_data_threshold: int\n355             Size of base64 encoded data element above which a value will be\n356             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n357             Ignored if no bulk data handler is given.\n358         dump_handler : callable, optional\n359             Callable function that accepts a :class:`dict` and returns the\n360             serialized (dumped) JSON string (by default uses\n361             :func:`json.dumps`).\n362 \n363         Returns\n364         -------\n365         dict\n366             Mapping representing a JSON encoded data element\n367 \n368         See also\n369         --------\n370         Dataset.to_json\n371         \"\"\"\n372         if dump_handler is None:\n373             def json_dump(d):\n374                 return json.dumps(d, sort_keys=True)\n375 \n376             dump_handler = json_dump\n377 \n378         return dump_handler(\n379             self.to_json_dict(bulk_data_threshold, bulk_data_element_handler))\n380 \n381     @property\n382     def value(self):\n383         \"\"\"Return the element's value.\"\"\"\n384         return self._value\n385 \n386     @value.setter\n387     def value(self, val):\n388         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n389         # Check if is a string with multiple values separated by '\\'\n390         # If so, turn them into a list of separate strings\n391         #  Last condition covers 'US or SS' etc\n392         if isinstance(val, (str, bytes)) and self.VR not in \\\n393                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n394                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n395                  'OW or OB', 'UN'] and 'US' not in self.VR:\n396             try:\n397                 if _backslash_str in val:\n398                     val = val.split(_backslash_str)\n399             except TypeError:\n400                 if _backslash_byte in val:\n401                     val = val.split(_backslash_byte)\n402         self._value = self._convert_value(val)\n403 \n404     @property\n405     def VM(self):\n406         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n407         if self.value is None:\n408             return 0\n409         if isinstance(self.value, (str, bytes, PersonName)):\n410             return 1 if self.value else 0\n411         try:\n412             iter(self.value)\n413         except TypeError:\n414             return 1\n415         return len(self.value)\n416 \n417     @property\n418     def is_empty(self):\n419         \"\"\"Return ``True`` if the element has no value.\n420 \n421         .. versionadded:: 1.4\n422         \"\"\"\n423         return self.VM == 0\n424 \n425     @property\n426     def empty_value(self):\n427         \"\"\"Return the value for an empty element.\n428 \n429         .. versionadded:: 1.4\n430 \n431         See :func:`empty_value_for_VR` for more information.\n432 \n433         Returns\n434         -------\n435         str or None\n436             The value this data element is assigned on decoding if it is empty.\n437         \"\"\"\n438         return empty_value_for_VR(self.VR)\n439 \n440     def clear(self):\n441         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n442 \n443         .. versionadded:: 1.4\n444 \n445         See :func:`empty_value_for_VR`.\n446         \"\"\"\n447         self._value = self.empty_value\n448 \n449     def _convert_value(self, val):\n450         \"\"\"Convert `val` to an appropriate type and return the result.\n451 \n452         Uses the element's VR in order to determine the conversion method and\n453         resulting type.\n454         \"\"\"\n455         if self.VR == 'SQ':  # a sequence - leave it alone\n456             from pydicom.sequence import Sequence\n457             if isinstance(val, Sequence):\n458                 return val\n459             else:\n460                 return Sequence(val)\n461 \n462         # if the value is a list, convert each element\n463         try:\n464             val.append\n465         except AttributeError:  # not a list\n466             return self._convert(val)\n467         else:\n468             return MultiValue(self._convert, val)\n469 \n470     def _convert(self, val):\n471         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n472         # If the value is a byte string and has a VR that can only be encoded\n473         # using the default character repertoire, we convert it to a string\n474         # here to allow for byte string input in these cases\n475         if _is_bytes(val) and self.VR in (\n476                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n477             val = val.decode()\n478 \n479         if self.VR == 'IS':\n480             return pydicom.valuerep.IS(val)\n481         elif self.VR == 'DA' and config.datetime_conversion:\n482             return pydicom.valuerep.DA(val)\n483         elif self.VR == 'DS':\n484             return pydicom.valuerep.DS(val)\n485         elif self.VR == 'DT' and config.datetime_conversion:\n486             return pydicom.valuerep.DT(val)\n487         elif self.VR == 'TM' and config.datetime_conversion:\n488             return pydicom.valuerep.TM(val)\n489         elif self.VR == \"UI\":\n490             return UID(val) if val is not None else None\n491         elif self.VR == \"PN\":\n492             return PersonName(val)\n493         # Later may need this for PersonName as for UI,\n494         #    but needs more thought\n495         # elif self.VR == \"PN\":\n496         #    return PersonName(val)\n497         else:  # is either a string or a type 2 optionally blank string\n498             return val  # this means a \"numeric\" value could be empty string \"\"\n499         # except TypeError:\n500             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n501             # % (repr(val), self.VR, self.tag)\n502         # except ValueError:\n503             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n504             # % (repr(val), self.VR, self.tag)\n505 \n506     def __eq__(self, other):\n507         \"\"\"Compare `self` and `other` for equality.\n508 \n509         Returns\n510         -------\n511         bool\n512             The result if `self` and `other` are the same class\n513         NotImplemented\n514             If `other` is not the same class as `self` then returning\n515             :class:`NotImplemented` delegates the result to\n516             ``superclass.__eq__(subclass)``.\n517         \"\"\"\n518         # Faster result if same object\n519         if other is self:\n520             return True\n521 \n522         if isinstance(other, self.__class__):\n523             if self.tag != other.tag or self.VR != other.VR:\n524                 return False\n525 \n526             # tag and VR match, now check the value\n527             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n528                 return (len(self.value) == len(other.value)\n529                         and numpy.allclose(self.value, other.value))\n530             else:\n531                 return self.value == other.value\n532 \n533         return NotImplemented\n534 \n535     def __ne__(self, other):\n536         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n537         return not (self == other)\n538 \n539     def __str__(self):\n540         \"\"\"Return :class:`str` representation of the element.\"\"\"\n541         repVal = self.repval or ''\n542         if self.showVR:\n543             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n544                                     self.description()[:self.descripWidth],\n545                                     self.VR, repVal)\n546         else:\n547             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n548                                 self.description()[:self.descripWidth], repVal)\n549         return s\n550 \n551     @property\n552     def repval(self):\n553         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n554         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n555         if set(self.VR.split(\" or \")) & long_VRs:\n556             try:\n557                 length = len(self.value)\n558             except TypeError:\n559                 pass\n560             else:\n561                 if length > self.maxBytesToDisplay:\n562                     return \"Array of %d elements\" % length\n563         if self.VM > self.maxBytesToDisplay:\n564             repVal = \"Array of %d elements\" % self.VM\n565         elif isinstance(self.value, UID):\n566             repVal = self.value.name\n567         else:\n568             repVal = repr(self.value)  # will tolerate unicode too\n569         return repVal\n570 \n571     def __unicode__(self):\n572         \"\"\"Return unicode representation of the element.\"\"\"\n573         if isinstance(self.value, str):\n574             # start with the string rep then replace the value part\n575             #   with the unicode\n576             strVal = str(self)\n577             strVal = strVal.replace(self.repval, \"\")\n578             uniVal = str(strVal) + self.value\n579             return uniVal\n580         else:\n581             return str(self)\n582 \n583     def __getitem__(self, key):\n584         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n585         try:\n586             return self.value[key]\n587         except TypeError:\n588             raise TypeError(\"DataElement value is unscriptable \"\n589                             \"(not a Sequence)\")\n590 \n591     @property\n592     def name(self):\n593         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n594 \n595         For officially registered DICOM Data Elements this will be the *Name*\n596         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n597         For private elements known to *pydicom*\n598         this will be the *Name* in the format ``'[name]'``. For unknown\n599         private elements this will be ``'Private Creator'``. For unknown\n600         elements this will return an empty string ``''``.\n601         \"\"\"\n602         return self.description()\n603 \n604     def description(self):\n605         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n606         if self.tag.is_private:\n607             name = \"Private tag data\"  # default\n608             if self.private_creator:\n609                 try:\n610                     # If have name from private dictionary, use it, but\n611                     #   but put in square brackets so is differentiated,\n612                     #   and clear that cannot access it by name\n613                     name = private_dictionary_description(\n614                         self.tag, self.private_creator)\n615                     name = \"[%s]\" % (name)\n616                 except KeyError:\n617                     pass\n618             elif self.tag.element >> 8 == 0:\n619                 name = \"Private Creator\"\n620         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n621             name = dictionary_description(self.tag)\n622 \n623         # implied Group Length dicom versions < 3\n624         elif self.tag.element == 0:\n625             name = \"Group Length\"\n626         else:\n627             name = \"\"\n628         return name\n629 \n630     @property\n631     def is_retired(self):\n632         \"\"\"Return the element's retired status as :class:`bool`.\n633 \n634         For officially registered DICOM Data Elements this will be ``True`` if\n635         the retired status as given in the DICOM Standard, Part 6,\n636         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n637         or unknown elements this will always be ``False``.\n638         \"\"\"\n639         if dictionary_has_tag(self.tag):\n640             return dictionary_is_retired(self.tag)\n641         else:\n642             return False\n643 \n644     @property\n645     def keyword(self):\n646         \"\"\"Return the element's keyword (if known) as :class:`str`.\n647 \n648         For officially registered DICOM Data Elements this will be the\n649         *Keyword* as given in\n650         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n651         unknown elements this will return an empty string ``''``.\n652         \"\"\"\n653         if dictionary_has_tag(self.tag):\n654             return dictionary_keyword(self.tag)\n655         else:\n656             return ''\n657 \n658     def __repr__(self):\n659         \"\"\"Return the representation of the element.\"\"\"\n660         if self.VR == \"SQ\":\n661             return repr(self.value)\n662         else:\n663             return str(self)\n664 \n665 \n666 msg = 'tag VR length value value_tell is_implicit_VR is_little_endian'\n667 RawDataElement = namedtuple('RawDataElement', msg)\n668 RawDataElement.is_raw = True\n669 \n670 \n671 # The first and third values of the following elements are always US\n672 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n673 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n674 # (0028,3002) LUT Descriptor\n675 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n676 \n677 \n678 def DataElement_from_raw(raw_data_element, encoding=None):\n679     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n680 \n681     Parameters\n682     ----------\n683     raw_data_element : RawDataElement namedtuple\n684         The raw data to convert to a :class:`DataElement`.\n685     encoding : str, optional\n686         The character encoding of the raw data.\n687 \n688     Returns\n689     -------\n690     DataElement\n691     \"\"\"\n692     # XXX buried here to avoid circular import\n693     # filereader->Dataset->convert_value->filereader\n694     # (for SQ parsing)\n695 \n696     from pydicom.values import convert_value\n697     raw = raw_data_element\n698 \n699     # If user has hooked into conversion of raw values, call his/her routine\n700     if config.data_element_callback:\n701         data_elem = config.data_element_callback\n702         raw = data_elem(raw_data_element,\n703                         **config.data_element_callback_kwargs)\n704     VR = raw.VR\n705     if VR is None:  # Can be if was implicit VR\n706         try:\n707             VR = dictionary_VR(raw.tag)\n708         except KeyError:\n709             # just read the bytes, no way to know what they mean\n710             if raw.tag.is_private:\n711                 # for VR for private tags see PS3.5, 6.2.2\n712                 if raw.tag.is_private_creator:\n713                     VR = 'LO'\n714                 else:\n715                     VR = 'UN'\n716 \n717             # group length tag implied in versions < 3.0\n718             elif raw.tag.element == 0:\n719                 VR = 'UL'\n720             else:\n721                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n722                 msg += \" can't look up VR\"\n723                 raise KeyError(msg)\n724     elif (VR == 'UN' and not raw.tag.is_private and\n725           config.replace_un_with_known_vr):\n726         # handle rare case of incorrectly set 'UN' in explicit encoding\n727         # see also DataElement.__init__()\n728         if (raw.length == 0xffffffff or raw.value is None or\n729                 len(raw.value) < 0xffff):\n730             try:\n731                 VR = dictionary_VR(raw.tag)\n732             except KeyError:\n733                 pass\n734     try:\n735         value = convert_value(VR, raw, encoding)\n736     except NotImplementedError as e:\n737         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n738 \n739     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n740         # We only fix the first value as the third value is 8 or 16\n741         try:\n742             if value[0] < 0:\n743                 value[0] += 65536\n744         except TypeError:\n745             pass\n746 \n747     return DataElement(raw.tag, VR, value, raw.value_tell,\n748                        raw.length == 0xFFFFFFFF, already_converted=True)\n749 \n[end of pydicom/dataelem.py]\n[start of pydicom/multival.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Code for multi-value data elements values,\n3 or any list of items that must all be the same type.\n4 \"\"\"\n5 \n6 try:\n7     from collections.abc import MutableSequence\n8 except ImportError:\n9     from collections import MutableSequence\n10 \n11 \n12 class MultiValue(MutableSequence):\n13     \"\"\"Class to hold any multi-valued DICOM value, or any list of items that\n14     are all of the same type.\n15 \n16     This class enforces that any items added to the list are of the correct\n17     type, by calling the constructor on any items that are added. Therefore,\n18     the constructor must behave nicely if passed an object that is already its\n19     type. The constructor should raise :class:`TypeError` if the item cannot be\n20     converted.\n21 \n22     Note, however, that DS and IS types can be a blank string ``''`` rather\n23     than an instance of their classes.\n24     \"\"\"\n25 \n26     def __init__(self, type_constructor, iterable):\n27         \"\"\"Initialize the list of values\n28 \n29         Parameters\n30         ----------\n31         type_constructor : type\n32             A constructor for the required type for all list items. Could be\n33             the class, or a factory function. For DICOM multi-value data\n34             elements, this will be the class or type corresponding to the VR.\n35         iterable : iterable\n36             An iterable (e.g. :class:`list`, :class:`tuple`) of items to\n37             initialize the :class:`MultiValue` list.\n38         \"\"\"\n39         from pydicom.valuerep import DSfloat, DSdecimal, IS\n40 \n41         def number_string_type_constructor(x):\n42             return self.type_constructor(x) if x != '' else x\n43 \n44         self._list = list()\n45         self.type_constructor = type_constructor\n46         if type_constructor in (DSfloat, IS, DSdecimal):\n47             type_constructor = number_string_type_constructor\n48         for x in iterable:\n49             self._list.append(type_constructor(x))\n50 \n51     def insert(self, position, val):\n52         self._list.insert(position, self.type_constructor(val))\n53 \n54     def append(self, val):\n55         self._list.append(self.type_constructor(val))\n56 \n57     def __setitem__(self, i, val):\n58         \"\"\"Set an item of the list, making sure it is of the right VR type\"\"\"\n59         if isinstance(i, slice):\n60             val = [self.type_constructor(v) for v in val]\n61             self._list.__setitem__(i, val)\n62         else:\n63             self._list.__setitem__(i, self.type_constructor(val))\n64 \n65     def __str__(self):\n66         if not self:\n67             return ''\n68         lines = [\"'{}'\".format(x) if isinstance(x, (str, bytes))\n69                  else str(x) for x in self]\n70         return \"[\" + \", \".join(lines) + \"]\"\n71 \n72     __repr__ = __str__\n73 \n74     def __len__(self):\n75         return len(self._list)\n76 \n77     def __getitem__(self, index):\n78         return self._list[index]\n79 \n80     def __delitem__(self, index):\n81         del self._list[index]\n82 \n83     def __iter__(self):\n84         return iter(self._list)\n85 \n86     def __eq__(self, other):\n87         return self._list == other\n88 \n89     def __ne__(self, other):\n90         return self._list != other\n91 \n92     def sort(self, key=None, reverse=False):\n93         self._list.sort(key=key, reverse=reverse)\n94 \n[end of pydicom/multival.py]\n[start of pydicom/util/codify.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"\n3 Produce runnable python code which can recreate DICOM objects or files.\n4 \n5 Can run as a script to produce code for an entire file,\n6 or import and use specific functions to provide code for pydicom DICOM classes\n7 \n8 \"\"\"\n9 \n10 # Run this from the same directory as a \"base\" dicom file and\n11 # this code will output to screen the dicom parameters like:\n12 #    ds.PatientName = 'TEST'\n13 # etc for all parameters in the file.\n14 # This can then be pasted into a python file and parameters edited as necessary\n15 # to create a DICOM file from scratch\n16 \n17 import sys\n18 import os.path\n19 import pydicom\n20 from pydicom.datadict import dictionary_keyword\n21 \n22 import re\n23 \n24 line_term = \"\\n\"\n25 \n26 # Helper functions first\n27 \n28 # Precompiled search patterns for camel_to_underscore()\n29 first_cap_re = re.compile('(.)([A-Z][a-z]+)')\n30 all_cap_re = re.compile('([a-z0-9])([A-Z])')\n31 \n32 byte_VRs = [\n33     'OB', 'OW', 'OW/OB', 'OW or OB', 'OB or OW', 'US or SS or OW', 'US or SS',\n34     'OD', 'OL'\n35 ]\n36 \n37 \n38 def camel_to_underscore(name):\n39     \"\"\"Convert name from CamelCase to lower_case_with_underscores\"\"\"\n40     # From http://stackoverflow.com/questions/1175208\n41     s1 = first_cap_re.sub(r'\\1_\\2', name)\n42     return all_cap_re.sub(r'\\1_\\2', s1).lower()\n43 \n44 \n45 def tag_repr(tag):\n46     \"\"\"String of tag value as (0xgggg, 0xeeee)\"\"\"\n47     return \"(0x{group:04x}, 0x{elem:04x})\".format(\n48         group=tag.group, elem=tag.element)\n49 \n50 \n51 def default_name_filter(name):\n52     \"\"\"Callable to reduce some names in code to more readable short form\n53 \n54     :arg name: a sequence variable name or sequence item name\n55     :return: a shorter version of name if a known conversion,\n56              else return original name\n57 \n58     \"\"\"\n59     name = camel_to_underscore(name)\n60     name = name.replace(\"control_point\", \"cp\")\n61     name = name.replace(\"reference\", \"ref\")\n62     name = name.replace(\"fraction_group\", \"frxn_gp\")\n63     return name\n64 \n65 \n66 # Functions to produce python code\n67 def code_imports():\n68     \"\"\"Code the import statements needed by other codify results\n69 \n70     :return: a string of import statement lines\n71 \n72     \"\"\"\n73     line1 = \"import pydicom\"\n74     line2 = \"from pydicom.dataset import Dataset, FileMetaDataset\"\n75     line3 = \"from pydicom.sequence import Sequence\"\n76     return line_term.join((line1, line2, line3))\n77 \n78 \n79 def code_dataelem(dataelem,\n80                   dataset_name=\"ds\",\n81                   exclude_size=None,\n82                   include_private=False):\n83     \"\"\"Code lines for a single DICOM data element\n84 \n85     :arg dataelem: the DataElement instance to turn into code\n86     :arg dataset_name: variable name of the Dataset containing dataelem\n87     :arg exclude_size: if specified, values longer than this (in bytes)\n88                        will only have a commented string for a value,\n89                        causing a syntax error when the code is run,\n90                        and thus prompting the user to remove or fix that line.\n91     :return: a string containing code to recreate the data element\n92              If the data element is a sequence, calls code_sequence\n93 \n94     \"\"\"\n95 \n96     if dataelem.VR == \"SQ\":\n97         return code_sequence(dataelem, dataset_name, exclude_size,\n98                              include_private)\n99 \n100     # If in DICOM dictionary, set using the keyword\n101     # If not (e.g. is private element), set using add_new method\n102     have_keyword = True\n103     try:\n104         keyword = dictionary_keyword(dataelem.tag)\n105     except KeyError:\n106         have_keyword = False\n107 \n108     valuerep = repr(dataelem.value)\n109 \n110     if exclude_size:\n111         if (dataelem.VR in byte_VRs and\n112                 len(dataelem.value) > exclude_size):\n113             valuerep = (\n114                 \"# XXX Array of %d bytes excluded\" % len(dataelem.value))\n115 \n116     if have_keyword:\n117         format_str = \"{ds_name}.{keyword} = {valuerep}\"\n118         line = format_str.format(\n119             ds_name=dataset_name, keyword=keyword, valuerep=valuerep)\n120     else:\n121         format_str = \"{ds_name}.add_new({tag}, '{VR}', {valuerep})\"\n122         line = format_str.format(\n123             ds_name=dataset_name,\n124             tag=tag_repr(dataelem.tag),\n125             VR=dataelem.VR,\n126             valuerep=valuerep)\n127     return line\n128 \n129 \n130 def code_sequence(dataelem,\n131                   dataset_name=\"ds\",\n132                   exclude_size=None,\n133                   include_private=False,\n134                   name_filter=default_name_filter):\n135     \"\"\"Code lines for recreating a Sequence data element\n136 \n137     :arg dataelem: the DataElement instance of the Sequence\n138     :arg dataset_name: variable name of the dataset containing the Sequence\n139     :arg exclude_size: if specified, values longer than this (in bytes)\n140                        will only have a commented string for a value,\n141                        causing a syntax error when the code is run,\n142                        and thus prompting the user to remove or fix that line.\n143     :arg include_private: If True, private data elements will be coded.\n144                           If False, private elements are skipped\n145     :arg name_filter: a callable taking a sequence name or sequence item name,\n146                       and returning a shorter name for easier code reading\n147     :return: a string containing code lines to recreate a DICOM sequence\n148 \n149     \"\"\"\n150     lines = []\n151     seq = dataelem.value\n152     seq_name = dataelem.name\n153     seq_item_name = seq_name.replace(' Sequence', '')\n154     seq_keyword = dictionary_keyword(dataelem.tag)\n155 \n156     # Create comment line to document the start of Sequence\n157     lines.append('')\n158     lines.append(\"# \" + seq_name)\n159 \n160     # Code line to create a new Sequence object\n161     if name_filter:\n162         seq_var = name_filter(seq_keyword)\n163     lines.append(seq_var + \" = Sequence()\")\n164 \n165     # Code line to add the sequence to its parent\n166     lines.append(dataset_name + \".\" + seq_keyword + \" = \" + seq_var)\n167 \n168     # Code lines to add sequence items to the Sequence\n169     for i, ds in enumerate(seq):\n170         # Determine index to use. If seq item has a data element with 'Index',\n171         #    use that; if one with 'Number', use that, else start at 1\n172         index_keyword = seq_keyword.replace(\"Sequence\", \"\") + \"Index\"\n173         number_keyword = seq_keyword.replace(\"Sequence\", \"\") + \"Number\"\n174         if index_keyword in ds:\n175             index_str = str(getattr(ds, index_keyword))\n176         elif number_keyword in ds:\n177             index_str = str(getattr(ds, number_keyword))\n178         else:\n179             index_str = str(i + 1)\n180 \n181         # Code comment line to mark start of sequence item\n182         lines.append('')\n183         lines.append(\"# \" + seq_name + \": \" + seq_item_name + \" \" + index_str)\n184 \n185         # Determine the variable name to use for the sequence item (dataset)\n186         ds_name = seq_var.replace(\"_sequence\", \"\") + index_str\n187 \n188         # Code the sequence item\n189         code_item = code_dataset(ds, ds_name, exclude_size, include_private)\n190         lines.append(code_item)\n191 \n192         # Code the line to append the item to its parent sequence\n193         lines.append(seq_var + \".append(\" + ds_name + \")\")\n194 \n195     # Join the lines and return a single string\n196     return line_term.join(lines)\n197 \n198 \n199 def code_dataset(ds,\n200                  dataset_name=\"ds\",\n201                  exclude_size=None,\n202                  include_private=False,\n203                  is_file_meta=False):\n204     \"\"\"Return python code lines for import statements needed by other code\n205 \n206     :arg exclude_size: if specified, values longer than this (in bytes)\n207                        will only have a commented string for a value,\n208                        causing a syntax error when the code is run,\n209                        and thus prompting the user to remove or fix that line.\n210     :arg include_private: If True, private data elements will be coded.\n211                           If False, private elements are skipped\n212     :return: a list of code lines containing import statements\n213 \n214     \"\"\"\n215     lines = []\n216     ds_class = \" = FileMetaDataset()\" if is_file_meta else \" = Dataset()\"\n217     lines.append(dataset_name + ds_class)\n218     for dataelem in ds:\n219         # If a private data element and flag says so, skip it and go to next\n220         if not include_private and dataelem.tag.is_private:\n221             continue\n222         # Otherwise code the line and add it to the lines list\n223         code_line = code_dataelem(dataelem, dataset_name, exclude_size,\n224                                   include_private)\n225         lines.append(code_line)\n226         # Add blank line if just coded a sequence\n227         if dataelem.VR == \"SQ\":\n228             lines.append('')\n229     # If sequence was end of this dataset, remove the extra blank line\n230     if len(lines) and lines[-1] == '':\n231         lines.pop()\n232     # Join all the code lines and return them\n233     return line_term.join(lines)\n234 \n235 \n236 def code_file(filename, exclude_size=None, include_private=False):\n237     \"\"\"Write a complete source code file to recreate a DICOM file\n238 \n239     :arg filename: complete path and filename of a DICOM file to convert\n240     :arg exclude_size: if specified, values longer than this (in bytes)\n241                        will only have a commented string for a value,\n242                        causing a syntax error when the code is run,\n243                        and thus prompting the user to remove or fix that line.\n244     :arg include_private: If True, private data elements will be coded.\n245                           If False, private elements are skipped\n246     :return: a string containing code lines to recreate entire file\n247 \n248     \"\"\"\n249     lines = []\n250 \n251     ds = pydicom.dcmread(filename, force=True)\n252 \n253     # Code a nice header for the python file\n254     lines.append(\"# Coded version of DICOM file '{0}'\".format(filename))\n255     lines.append(\"# Produced by pydicom codify utility script\")\n256 \n257     # Code the necessary imports\n258     lines.append(code_imports())\n259     lines.append('')\n260 \n261     # Code the file_meta information\n262     lines.append(\"# File meta info data elements\")\n263     code_meta = code_dataset(ds.file_meta, \"file_meta\", exclude_size,\n264                              include_private, is_file_meta=True)\n265     lines.append(code_meta)\n266     lines.append('')\n267 \n268     # Code the main dataset\n269     lines.append(\"# Main data elements\")\n270     code_ds = code_dataset(\n271         ds, exclude_size=exclude_size, include_private=include_private)\n272     lines.append(code_ds)\n273     lines.append('')\n274 \n275     # Add the file meta to the dataset, and set transfer syntax\n276     lines.append(\"ds.file_meta = file_meta\")\n277     lines.append(\"ds.is_implicit_VR = \" + str(ds.is_implicit_VR))\n278     lines.append(\"ds.is_little_endian = \" + str(ds.is_little_endian))\n279 \n280     # Return the complete code string\n281     return line_term.join(lines)\n282 \n283 \n284 def main(default_exclude_size, args=None):\n285     \"\"\"Create python code according to user options\n286 \n287     Parameters:\n288     -----------\n289     default_exclude_size:  int\n290         Values longer than this will be coded as a commented syntax error\n291 \n292     args: list\n293         Command-line arguments to parse.  If None, then sys.argv is used\n294     \"\"\"\n295 \n296     try:\n297         import argparse\n298     except ImportError:\n299         print(\"The argparse module is required to run this script\")\n300         print(\"argparse is standard in python >= 2.7,\")\n301         print(\"   or can be installed with 'pip install argparse'\")\n302         sys.exit(-1)\n303 \n304     parser = argparse.ArgumentParser(\n305         description=\"Produce python/pydicom code from a DICOM file\",\n306         epilog=\"Binary data (e.g. pixels) larger than --exclude-size \"\n307         \"(default %d bytes) is not included. A dummy line \"\n308         \"with a syntax error is produced. \"\n309         \"Private data elements are not included \"\n310         \"by default.\" % default_exclude_size)\n311     parser.add_argument(\n312         'infile', help=\"DICOM file from which to produce code lines\")\n313     parser.add_argument(\n314         'outfile',\n315         nargs='?',\n316         type=argparse.FileType('w'),\n317         help=(\"Filename to write python code to. \"\n318               \"If not specified, code is written to stdout\"),\n319         default=sys.stdout)\n320     help_exclude_size = 'Exclude binary data larger than specified (bytes). '\n321     help_exclude_size += 'Default is %d bytes' % default_exclude_size\n322     parser.add_argument(\n323         '-e',\n324         '--exclude-size',\n325         type=int,\n326         default=default_exclude_size,\n327         help=help_exclude_size)\n328     parser.add_argument(\n329         '-p',\n330         '--include-private',\n331         action=\"store_true\",\n332         help='Include private data elements '\n333         '(default is to exclude them)')\n334     parser.add_argument(\n335         '-s',\n336         '--save-as',\n337         help=(\"Specify the filename for ds.save_as(save_filename); \"\n338               \"otherwise the input name + '_from_codify' will be used\"))\n339 \n340     args = parser.parse_args(args)\n341 \n342     # Read the requested file and convert to python/pydicom code lines\n343     filename = args.infile  # name\n344     code_lines = code_file(filename, args.exclude_size, args.include_private)\n345 \n346     # If requested, write a code line to save the dataset\n347     if args.save_as:\n348         save_as_filename = args.save_as\n349     else:\n350         base, ext = os.path.splitext(filename)\n351         save_as_filename = base + \"_from_codify\" + \".dcm\"\n352     line = \"\\nds.save_as(r'{filename}', write_like_original=False)\"\n353     save_line = line.format(filename=save_as_filename)\n354     code_lines += save_line\n355 \n356     # Write the code lines to specified file or to standard output\n357     # For test_util, captured output .name throws error, ignore it:\n358     try:\n359         if args.outfile.name != \"<stdout>\":\n360             print(\"Writing code to file '%s'\" % args.outfile.name)\n361     except AttributeError:\n362         pass\n363     args.outfile.write(code_lines)\n364 \n365 \n366 if __name__ == \"__main__\":\n367     main(default_exclude_size=100)\n368 \n[end of pydicom/util/codify.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "b9fb05c177b685bf683f7f57b2d57374eb7d882d", "problem_statement": "Make PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n", "hints_text": "I think it is reasonable to support at least some `str` methods (definitely `__contains__` for the example above), but there are many that don't make a lot of sense in this context though - e.g. `join`, `ljust`, `maketrans`, `splitlines` just to name a few, but I suppose each would either never be actually used or would have no effect.\r\n\r\nI have a vague memory that one or more of the `PersonName` classes was at one time subclassed from `str`, or at least that it was discussed... does anyone remember?  Maybe it would be easier now with only Python 3 supported.\n`PersonName` was derived from `str` or `unicode` in Python 2, but that caused a number of problems, which is why you switched to `PersonName3` in Python 3, I think. I agree though that it makes sense to implement `str` methods, either by implementing some of them, or generically by adding `__getattr__` that converts it to `str` and applies the attribute to that string. ", "created_at": "2020-06-26T11:47:17Z", "patch": "<patch>\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -1,6 +1,5 @@\n # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n-from copy import deepcopy\n from decimal import Decimal\n import re\n \n@@ -750,6 +749,25 @@ def __ne__(self, other):\n     def __str__(self):\n         return '='.join(self.components).__str__()\n \n+    def __next__(self):\n+        # Get next character or stop iteration\n+        if self._i < self._rep_len:\n+            c = self._str_rep[self._i]\n+            self._i += 1\n+            return c\n+        else:\n+            raise StopIteration\n+\n+    def __iter__(self):\n+        # Get string rep. and length, initialize index counter\n+        self._str_rep = self.__str__()\n+        self._rep_len = len(self._str_rep)\n+        self._i = 0\n+        return self\n+\n+    def __contains__(self, x):\n+        return x in self.__str__()\n+\n     def __repr__(self):\n         return '='.join(self.components).__repr__()\n \n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -427,6 +427,62 @@ def test_hash(self):\n         )\n         assert hash(pn1) == hash(pn2)\n \n+    def test_next(self):\n+        \"\"\"Test that the next function works on it's own\"\"\"\n+        # Test getting the first character\n+        pn1 = PersonName(\"John^Doe^^Dr\", encodings=default_encoding)\n+        pn1_itr = iter(pn1)\n+        assert next(pn1_itr) == \"J\"\n+\n+        # Test getting multiple characters\n+        pn2 = PersonName(\n+            \"Yamada^Tarou=\u5c71\u7530^\u592a\u90ce=\u3084\u307e\u3060^\u305f\u308d\u3046\", [default_encoding, \"iso2022_jp\"]\n+        )\n+        pn2_itr = iter(pn2)\n+        assert next(pn2_itr) == \"Y\"\n+        assert next(pn2_itr) == \"a\"\n+\n+        # Test getting all characters\n+        pn3 = PersonName(\"SomeName\")\n+        pn3_itr = iter(pn3)\n+        assert next(pn3_itr) == \"S\"\n+        assert next(pn3_itr) == \"o\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+        assert next(pn3_itr) == \"N\"\n+        assert next(pn3_itr) == \"a\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+\n+        # Attempting to get next characeter should stop the iteration\n+        # I.e. next can only start once\n+        with pytest.raises(StopIteration):\n+            next(pn3_itr)\n+\n+        # Test that next() doesn't work without instantiating an iterator\n+        pn4 = PersonName(\"SomeName\")\n+        with pytest.raises(AttributeError):\n+            next(pn4)\n+\n+    def test_iterator(self):\n+        \"\"\"Test that iterators can be corretly constructed\"\"\"\n+        name_str = \"John^Doe^^Dr\"\n+        pn1 = PersonName(name_str)\n+        \n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+        # Ensure that multiple iterators can be created on the same variable\n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+    def test_contains(self):\n+        \"\"\"Test that characters can be check if they are within the name\"\"\"\n+        pn1 = PersonName(\"John^Doe\")\n+        assert (\"J\" in pn1) == True\n+        assert (\"o\" in pn1) == True\n+        assert (\"x\" in pn1) == False\n+\n \n class TestDateTime:\n     \"\"\"Unit tests for DA, DT, TM conversion to datetime objects\"\"\"\n", "version": "2.0", "FAIL_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\"]", "environment_setup_commit": "9d69811e539774f296c2f289839147e741251716"}
{"instance_id": "pydicom__pydicom-1139_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nMake PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n\n</issue>\n<code>\n[start of README.md]\n1 *pydicom*\n2 =======\n3 \n4 [![Build Status](https://travis-ci.org/pydicom/pydicom.svg?branch=master)](https://travis-ci.org/pydicom/pydicom)\n5 [![AppVeyor](https://ci.appveyor.com/api/projects/status/1vjtkr82lumnd3i7?svg=true)](https://ci.appveyor.com/project/glemaitre/pydicom)\n6 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n7 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n8 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n9 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n10 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3891702.svg)](https://doi.org/10.5281/zenodo.3891702)\n11 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n12 \n13 *pydicom* is a pure python package for working with [DICOM](http://medical.nema.org/) files.\n14 It was made for inspecting and modifying DICOM data in an easy \"pythonic\" way.\n15 The modifications can be written again to a new file.\n16 \n17 As a pure python package, *pydicom* can run anywhere python runs without any other requirements,\n18 although [NumPy](http://www.numpy.org) is needed if manipulating pixel data.\n19 \n20 *pydicom* is not a DICOM server, and is not primarily about viewing images.\n21 It is designed to let you\n22 manipulate data elements in DICOM files with python code.\n23 \n24 Limitations -- for files with _compressed_ pixel data, *pydicom* can decompress\n25 it (with additional libraries installed) and allow you to manipulate the data,\n26 but can only store changed pixel data as uncompressed. Files can always be\n27 read and saved (including compressed pixel data that has not been modified),\n28 but once decompressed, modified pixel data cannot be compressed again.\n29 \n30 Documentation\n31 -------------\n32 \n33 *pydicom* documentation is available on GitHub Pages both for the [development\n34  (master) version](https://pydicom.github.io/pydicom/dev) and for the\n35 [released version](https://pydicom.github.io/pydicom/stable). The\n36 documentation for [the previous 0.9.9 version](https://pydicom.github.io/pydicom/0.9/)\n37 is still there for reference.\n38 \n39 See [Getting Started](https://pydicom.github.io/pydicom/stable/old/getting_started.html)\n40 for installation and basic information, and the\n41 [User Guide](https://pydicom.github.io/pydicom/stable/pydicom_user_guide.html)\n42 for an overview of how to use the *pydicom* library.\n43 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n44 To contribute an example or extension of *pydicom* that does not belong with\n45 the core software, see our contribution repository,\n46 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n47 \n[end of README.md]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 \n11 import base64\n12 import json\n13 from collections import namedtuple\n14 \n15 from pydicom import config  # don't import datetime_conversion directly\n16 from pydicom.config import logger\n17 from pydicom import config\n18 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n19                               dictionary_keyword, dictionary_is_retired,\n20                               private_dictionary_description, dictionary_VR,\n21                               repeater_has_tag)\n22 from pydicom.jsonrep import JsonDataElementConverter\n23 from pydicom.multival import MultiValue\n24 from pydicom.tag import Tag, BaseTag\n25 from pydicom.uid import UID\n26 from pydicom import jsonrep\n27 import pydicom.valuerep  # don't import DS directly as can be changed by config\n28 from pydicom.valuerep import PersonName\n29 \n30 if config.have_numpy:\n31     import numpy\n32 \n33 BINARY_VR_VALUES = [\n34     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n35     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n36 ]\n37 \n38 \n39 def empty_value_for_VR(VR, raw=False):\n40     \"\"\"Return the value for an empty element for `VR`.\n41 \n42     .. versionadded:: 1.4\n43 \n44     The behavior of this property depends on the setting of\n45     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n46     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n47     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n48     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n49     empty string is used as empty value representation, for all other VRs\n50     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n51     is used in all cases.\n52     Note that this is used only if decoding the element - it is always\n53     possible to set the value to another empty value representation,\n54     which will be preserved during the element object lifetime.\n55 \n56     Parameters\n57     ----------\n58     VR : str\n59         The VR of the corresponding element.\n60 \n61     raw : bool\n62         If ``True``, returns the value for a :class:`RawDataElement`,\n63         otherwise for a :class:`DataElement`\n64 \n65     Returns\n66     -------\n67     str or bytes or None or list\n68         The value a data element with `VR` is assigned on decoding\n69         if it is empty.\n70     \"\"\"\n71     if VR == 'SQ':\n72         return b'' if raw else []\n73     if config.use_none_as_empty_text_VR_value:\n74         return None\n75     if VR in ('AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT',\n76               'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR', 'UT'):\n77         return b'' if raw else ''\n78     return None\n79 \n80 \n81 def _is_bytes(val):\n82     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n83     return isinstance(val, bytes)\n84 \n85 \n86 # double '\\' because it is used as escape chr in Python\n87 _backslash_str = \"\\\\\"\n88 _backslash_byte = b\"\\\\\"\n89 \n90 \n91 class DataElement:\n92     \"\"\"Contain and manipulate a DICOM Element.\n93 \n94     Examples\n95     --------\n96 \n97     While its possible to create a new :class:`DataElement` directly and add\n98     it to a :class:`~pydicom.dataset.Dataset`:\n99 \n100     >>> from pydicom import Dataset\n101     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n102     >>> ds = Dataset()\n103     >>> ds.add(elem)\n104 \n105     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n106     to add a new :class:`DataElement`, as the VR and tag are determined\n107     automatically from the DICOM dictionary:\n108 \n109     >>> ds = Dataset()\n110     >>> ds.PatientName = 'CITIZEN^Joan'\n111 \n112     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n113     value for text VRs and `None` for non-text (binary) VRs:\n114 \n115     >>> ds = Dataset()\n116     >>> ds.PatientName = None\n117     >>> ds.PatientName\n118     ''\n119 \n120     >>> ds.BitsAllocated = None\n121     >>> ds.BitsAllocated\n122 \n123     >>> str(ds.BitsAllocated)\n124     'None'\n125 \n126     Attributes\n127     ----------\n128     descripWidth : int\n129         For string display, this is the maximum width of the description\n130         field (default ``35``).\n131     is_undefined_length : bool\n132         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n133         (ie undefined).\n134     maxBytesToDisplay : int\n135         For string display, elements with values containing data which is\n136         longer than this value will display ``\"array of # bytes\"``\n137         (default ``16``).\n138     showVR : bool\n139         For string display, include the element's VR just before it's value\n140         (default ``True``).\n141     tag : BaseTag\n142         The element's tag.\n143     value\n144         The element's stored value(s).\n145     VR : str\n146         The element's Value Representation.\n147     \"\"\"\n148 \n149     descripWidth = 35\n150     maxBytesToDisplay = 16\n151     showVR = True\n152     is_raw = False\n153 \n154     def __init__(self,\n155                  tag,\n156                  VR,\n157                  value,\n158                  file_value_tell=None,\n159                  is_undefined_length=False,\n160                  already_converted=False):\n161         \"\"\"Create a new :class:`DataElement`.\n162 \n163         Parameters\n164         ----------\n165         tag : int or or str or list or tuple\n166             The DICOM (group, element) tag in any form accepted by\n167             :func:`~pydicom.tag.Tag` such as ``[0x0010, 0x0010]``,\n168             ``(0x10, 0x10)``, ``0x00100010``, etc.\n169         VR : str\n170             The 2 character DICOM value representation (see DICOM Standard,\n171             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n172         value\n173             The value of the data element. One of the following:\n174 \n175             * a single string value\n176             * a number\n177             * a :class:`list` or :class:`tuple` with all strings or all numbers\n178             * a multi-value string with backslash separator\n179 \n180         file_value_tell : int or None\n181             Used internally by :class:`~pydicom.dataset.Dataset` to\n182             store the write position for the ``ReplaceDataElementValue()``\n183             method. Default is ``None``.\n184         is_undefined_length : bool\n185             Used internally to store whether the length field for this element\n186             was ``0xFFFFFFFFL``, i.e. 'undefined length'. Default is ``False``.\n187         already_converted : bool\n188             Used to determine whether or not the element's value requires\n189             conversion to a value with VM > 1. Default is ``False``.\n190         \"\"\"\n191         if not isinstance(tag, BaseTag):\n192             tag = Tag(tag)\n193         self.tag = tag\n194 \n195         # a known tag shall only have the VR 'UN' if it has a length that\n196         # exceeds the size that can be encoded in 16 bit - all other cases\n197         # can be seen as an encoding error and can be corrected\n198         if (VR == 'UN' and not tag.is_private and\n199                 config.replace_un_with_known_vr and\n200                 (is_undefined_length or value is None or len(value) < 0xffff)):\n201             try:\n202                 VR = dictionary_VR(tag)\n203             except KeyError:\n204                 pass\n205 \n206         self.VR = VR  # Note: you must set VR before setting value\n207         if already_converted:\n208             self._value = value\n209         else:\n210             self.value = value  # calls property setter which will convert\n211         self.file_tell = file_value_tell\n212         self.is_undefined_length = is_undefined_length\n213         self.private_creator = None\n214 \n215     @classmethod\n216     def from_json(cls, dataset_class, tag, vr, value, value_key,\n217                   bulk_data_uri_handler=None):\n218         \"\"\"Return a :class:`DataElement` from JSON.\n219 \n220         .. versionadded:: 1.3\n221 \n222         Parameters\n223         ----------\n224         dataset_class : dataset.Dataset derived class\n225             Class used to create sequence items.\n226         tag : BaseTag or int\n227             The data element tag.\n228         vr : str\n229             The data element value representation.\n230         value : list\n231             The data element's value(s).\n232         value_key : str or None\n233             Key of the data element that contains the value\n234             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n235         bulk_data_uri_handler: callable or None\n236             Callable function that accepts the \"BulkDataURI\" of the JSON\n237             representation of a data element and returns the actual value of\n238             that data element (retrieved via DICOMweb WADO-RS)\n239 \n240         Returns\n241         -------\n242         DataElement\n243         \"\"\"\n244         # TODO: test wado-rs retrieve wrapper\n245         converter = JsonDataElementConverter(dataset_class, tag, vr, value,\n246                                              value_key, bulk_data_uri_handler)\n247         elem_value = converter.get_element_values()\n248         try:\n249             return DataElement(tag=tag, value=elem_value, VR=vr)\n250         except Exception:\n251             raise ValueError(\n252                 'Data element \"{}\" could not be loaded from JSON: {}'.format(\n253                     tag, elem_value\n254                 )\n255             )\n256 \n257     def to_json_dict(self, bulk_data_element_handler, bulk_data_threshold):\n258         \"\"\"Return a dictionary representation of the :class:`DataElement`\n259         conforming to the DICOM JSON Model as described in the DICOM\n260         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n261 \n262         .. versionadded:: 1.4\n263 \n264         Parameters\n265         ----------\n266         bulk_data_element_handler: callable or None\n267             Callable that accepts a bulk data element and returns the\n268             \"BulkDataURI\" for retrieving the value of the data element\n269             via DICOMweb WADO-RS\n270         bulk_data_threshold: int\n271             Size of base64 encoded data element above which a value will be\n272             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n273             Ignored if no bulk data handler is given.\n274 \n275         Returns\n276         -------\n277         dict\n278             Mapping representing a JSON encoded data element\n279         \"\"\"\n280         json_element = {'vr': self.VR, }\n281         if self.VR in jsonrep.BINARY_VR_VALUES:\n282             if not self.is_empty:\n283                 binary_value = self.value\n284                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n285                 if (bulk_data_element_handler is not None and\n286                         len(encoded_value) > bulk_data_threshold):\n287                     json_element['BulkDataURI'] = bulk_data_element_handler(\n288                         self\n289                     )\n290                 else:\n291                     logger.info(\n292                         'encode bulk data element \"{}\" inline'.format(\n293                             self.name\n294                         )\n295                     )\n296                     json_element['InlineBinary'] = encoded_value\n297         elif self.VR == 'SQ':\n298             # recursive call to get sequence item JSON dicts\n299             value = [\n300                 ds.to_json(\n301                     bulk_data_element_handler=bulk_data_element_handler,\n302                     bulk_data_threshold=bulk_data_threshold,\n303                     dump_handler=lambda d: d\n304                 )\n305                 for ds in self\n306             ]\n307             json_element['Value'] = value\n308         elif self.VR == 'PN':\n309             if not self.is_empty:\n310                 elem_value = []\n311                 if self.VM > 1:\n312                     value = self.value\n313                 else:\n314                     value = [self.value]\n315                 for v in value:\n316                     comps = {'Alphabetic': v.components[0]}\n317                     if len(v.components) > 1:\n318                         comps['Ideographic'] = v.components[1]\n319                     if len(v.components) > 2:\n320                         comps['Phonetic'] = v.components[2]\n321                     elem_value.append(comps)\n322                 json_element['Value'] = elem_value\n323         elif self.VR == 'AT':\n324             if not self.is_empty:\n325                 value = self.value\n326                 if self.VM == 1:\n327                     value = [value]\n328                 json_element['Value'] = [format(v, '08X') for v in value]\n329         else:\n330             if not self.is_empty:\n331                 if self.VM > 1:\n332                     value = self.value\n333                 else:\n334                     value = [self.value]\n335                 json_element['Value'] = [v for v in value]\n336         if hasattr(json_element, 'Value'):\n337             json_element['Value'] = jsonrep.convert_to_python_number(\n338                 json_element['Value'], self.VR\n339             )\n340         return json_element\n341 \n342     def to_json(self, bulk_data_threshold=1024, bulk_data_element_handler=None,\n343                 dump_handler=None):\n344         \"\"\"Return a JSON representation of the :class:`DataElement`.\n345 \n346         .. versionadded:: 1.3\n347 \n348         Parameters\n349         ----------\n350         bulk_data_element_handler: callable or None\n351             Callable that accepts a bulk data element and returns the\n352             \"BulkDataURI\" for retrieving the value of the data element\n353             via DICOMweb WADO-RS\n354         bulk_data_threshold: int\n355             Size of base64 encoded data element above which a value will be\n356             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n357             Ignored if no bulk data handler is given.\n358         dump_handler : callable, optional\n359             Callable function that accepts a :class:`dict` and returns the\n360             serialized (dumped) JSON string (by default uses\n361             :func:`json.dumps`).\n362 \n363         Returns\n364         -------\n365         dict\n366             Mapping representing a JSON encoded data element\n367 \n368         See also\n369         --------\n370         Dataset.to_json\n371         \"\"\"\n372         if dump_handler is None:\n373             def json_dump(d):\n374                 return json.dumps(d, sort_keys=True)\n375 \n376             dump_handler = json_dump\n377 \n378         return dump_handler(\n379             self.to_json_dict(bulk_data_threshold, bulk_data_element_handler))\n380 \n381     @property\n382     def value(self):\n383         \"\"\"Return the element's value.\"\"\"\n384         return self._value\n385 \n386     @value.setter\n387     def value(self, val):\n388         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n389         # Check if is a string with multiple values separated by '\\'\n390         # If so, turn them into a list of separate strings\n391         #  Last condition covers 'US or SS' etc\n392         if isinstance(val, (str, bytes)) and self.VR not in \\\n393                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n394                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n395                  'OW or OB', 'UN'] and 'US' not in self.VR:\n396             try:\n397                 if _backslash_str in val:\n398                     val = val.split(_backslash_str)\n399             except TypeError:\n400                 if _backslash_byte in val:\n401                     val = val.split(_backslash_byte)\n402         self._value = self._convert_value(val)\n403 \n404     @property\n405     def VM(self):\n406         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n407         if self.value is None:\n408             return 0\n409         if isinstance(self.value, (str, bytes, PersonName)):\n410             return 1 if self.value else 0\n411         try:\n412             iter(self.value)\n413         except TypeError:\n414             return 1\n415         return len(self.value)\n416 \n417     @property\n418     def is_empty(self):\n419         \"\"\"Return ``True`` if the element has no value.\n420 \n421         .. versionadded:: 1.4\n422         \"\"\"\n423         return self.VM == 0\n424 \n425     @property\n426     def empty_value(self):\n427         \"\"\"Return the value for an empty element.\n428 \n429         .. versionadded:: 1.4\n430 \n431         See :func:`empty_value_for_VR` for more information.\n432 \n433         Returns\n434         -------\n435         str or None\n436             The value this data element is assigned on decoding if it is empty.\n437         \"\"\"\n438         return empty_value_for_VR(self.VR)\n439 \n440     def clear(self):\n441         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n442 \n443         .. versionadded:: 1.4\n444 \n445         See :func:`empty_value_for_VR`.\n446         \"\"\"\n447         self._value = self.empty_value\n448 \n449     def _convert_value(self, val):\n450         \"\"\"Convert `val` to an appropriate type and return the result.\n451 \n452         Uses the element's VR in order to determine the conversion method and\n453         resulting type.\n454         \"\"\"\n455         if self.VR == 'SQ':  # a sequence - leave it alone\n456             from pydicom.sequence import Sequence\n457             if isinstance(val, Sequence):\n458                 return val\n459             else:\n460                 return Sequence(val)\n461 \n462         # if the value is a list, convert each element\n463         try:\n464             val.append\n465         except AttributeError:  # not a list\n466             return self._convert(val)\n467         else:\n468             return MultiValue(self._convert, val)\n469 \n470     def _convert(self, val):\n471         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n472         # If the value is a byte string and has a VR that can only be encoded\n473         # using the default character repertoire, we convert it to a string\n474         # here to allow for byte string input in these cases\n475         if _is_bytes(val) and self.VR in (\n476                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n477             val = val.decode()\n478 \n479         if self.VR == 'IS':\n480             return pydicom.valuerep.IS(val)\n481         elif self.VR == 'DA' and config.datetime_conversion:\n482             return pydicom.valuerep.DA(val)\n483         elif self.VR == 'DS':\n484             return pydicom.valuerep.DS(val)\n485         elif self.VR == 'DT' and config.datetime_conversion:\n486             return pydicom.valuerep.DT(val)\n487         elif self.VR == 'TM' and config.datetime_conversion:\n488             return pydicom.valuerep.TM(val)\n489         elif self.VR == \"UI\":\n490             return UID(val) if val is not None else None\n491         elif self.VR == \"PN\":\n492             return PersonName(val)\n493         # Later may need this for PersonName as for UI,\n494         #    but needs more thought\n495         # elif self.VR == \"PN\":\n496         #    return PersonName(val)\n497         else:  # is either a string or a type 2 optionally blank string\n498             return val  # this means a \"numeric\" value could be empty string \"\"\n499         # except TypeError:\n500             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n501             # % (repr(val), self.VR, self.tag)\n502         # except ValueError:\n503             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n504             # % (repr(val), self.VR, self.tag)\n505 \n506     def __eq__(self, other):\n507         \"\"\"Compare `self` and `other` for equality.\n508 \n509         Returns\n510         -------\n511         bool\n512             The result if `self` and `other` are the same class\n513         NotImplemented\n514             If `other` is not the same class as `self` then returning\n515             :class:`NotImplemented` delegates the result to\n516             ``superclass.__eq__(subclass)``.\n517         \"\"\"\n518         # Faster result if same object\n519         if other is self:\n520             return True\n521 \n522         if isinstance(other, self.__class__):\n523             if self.tag != other.tag or self.VR != other.VR:\n524                 return False\n525 \n526             # tag and VR match, now check the value\n527             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n528                 return (len(self.value) == len(other.value)\n529                         and numpy.allclose(self.value, other.value))\n530             else:\n531                 return self.value == other.value\n532 \n533         return NotImplemented\n534 \n535     def __ne__(self, other):\n536         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n537         return not (self == other)\n538 \n539     def __str__(self):\n540         \"\"\"Return :class:`str` representation of the element.\"\"\"\n541         repVal = self.repval or ''\n542         if self.showVR:\n543             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n544                                     self.description()[:self.descripWidth],\n545                                     self.VR, repVal)\n546         else:\n547             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n548                                 self.description()[:self.descripWidth], repVal)\n549         return s\n550 \n551     @property\n552     def repval(self):\n553         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n554         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n555         if set(self.VR.split(\" or \")) & long_VRs:\n556             try:\n557                 length = len(self.value)\n558             except TypeError:\n559                 pass\n560             else:\n561                 if length > self.maxBytesToDisplay:\n562                     return \"Array of %d elements\" % length\n563         if self.VM > self.maxBytesToDisplay:\n564             repVal = \"Array of %d elements\" % self.VM\n565         elif isinstance(self.value, UID):\n566             repVal = self.value.name\n567         else:\n568             repVal = repr(self.value)  # will tolerate unicode too\n569         return repVal\n570 \n571     def __unicode__(self):\n572         \"\"\"Return unicode representation of the element.\"\"\"\n573         if isinstance(self.value, str):\n574             # start with the string rep then replace the value part\n575             #   with the unicode\n576             strVal = str(self)\n577             strVal = strVal.replace(self.repval, \"\")\n578             uniVal = str(strVal) + self.value\n579             return uniVal\n580         else:\n581             return str(self)\n582 \n583     def __getitem__(self, key):\n584         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n585         try:\n586             return self.value[key]\n587         except TypeError:\n588             raise TypeError(\"DataElement value is unscriptable \"\n589                             \"(not a Sequence)\")\n590 \n591     @property\n592     def name(self):\n593         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n594 \n595         For officially registered DICOM Data Elements this will be the *Name*\n596         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n597         For private elements known to *pydicom*\n598         this will be the *Name* in the format ``'[name]'``. For unknown\n599         private elements this will be ``'Private Creator'``. For unknown\n600         elements this will return an empty string ``''``.\n601         \"\"\"\n602         return self.description()\n603 \n604     def description(self):\n605         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n606         if self.tag.is_private:\n607             name = \"Private tag data\"  # default\n608             if self.private_creator:\n609                 try:\n610                     # If have name from private dictionary, use it, but\n611                     #   but put in square brackets so is differentiated,\n612                     #   and clear that cannot access it by name\n613                     name = private_dictionary_description(\n614                         self.tag, self.private_creator)\n615                     name = \"[%s]\" % (name)\n616                 except KeyError:\n617                     pass\n618             elif self.tag.element >> 8 == 0:\n619                 name = \"Private Creator\"\n620         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n621             name = dictionary_description(self.tag)\n622 \n623         # implied Group Length dicom versions < 3\n624         elif self.tag.element == 0:\n625             name = \"Group Length\"\n626         else:\n627             name = \"\"\n628         return name\n629 \n630     @property\n631     def is_retired(self):\n632         \"\"\"Return the element's retired status as :class:`bool`.\n633 \n634         For officially registered DICOM Data Elements this will be ``True`` if\n635         the retired status as given in the DICOM Standard, Part 6,\n636         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n637         or unknown elements this will always be ``False``.\n638         \"\"\"\n639         if dictionary_has_tag(self.tag):\n640             return dictionary_is_retired(self.tag)\n641         else:\n642             return False\n643 \n644     @property\n645     def keyword(self):\n646         \"\"\"Return the element's keyword (if known) as :class:`str`.\n647 \n648         For officially registered DICOM Data Elements this will be the\n649         *Keyword* as given in\n650         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n651         unknown elements this will return an empty string ``''``.\n652         \"\"\"\n653         if dictionary_has_tag(self.tag):\n654             return dictionary_keyword(self.tag)\n655         else:\n656             return ''\n657 \n658     def __repr__(self):\n659         \"\"\"Return the representation of the element.\"\"\"\n660         if self.VR == \"SQ\":\n661             return repr(self.value)\n662         else:\n663             return str(self)\n664 \n665 \n666 msg = 'tag VR length value value_tell is_implicit_VR is_little_endian'\n667 RawDataElement = namedtuple('RawDataElement', msg)\n668 RawDataElement.is_raw = True\n669 \n670 \n671 # The first and third values of the following elements are always US\n672 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n673 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n674 # (0028,3002) LUT Descriptor\n675 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n676 \n677 \n678 def DataElement_from_raw(raw_data_element, encoding=None):\n679     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n680 \n681     Parameters\n682     ----------\n683     raw_data_element : RawDataElement namedtuple\n684         The raw data to convert to a :class:`DataElement`.\n685     encoding : str, optional\n686         The character encoding of the raw data.\n687 \n688     Returns\n689     -------\n690     DataElement\n691     \"\"\"\n692     # XXX buried here to avoid circular import\n693     # filereader->Dataset->convert_value->filereader\n694     # (for SQ parsing)\n695 \n696     from pydicom.values import convert_value\n697     raw = raw_data_element\n698 \n699     # If user has hooked into conversion of raw values, call his/her routine\n700     if config.data_element_callback:\n701         data_elem = config.data_element_callback\n702         raw = data_elem(raw_data_element,\n703                         **config.data_element_callback_kwargs)\n704     VR = raw.VR\n705     if VR is None:  # Can be if was implicit VR\n706         try:\n707             VR = dictionary_VR(raw.tag)\n708         except KeyError:\n709             # just read the bytes, no way to know what they mean\n710             if raw.tag.is_private:\n711                 # for VR for private tags see PS3.5, 6.2.2\n712                 if raw.tag.is_private_creator:\n713                     VR = 'LO'\n714                 else:\n715                     VR = 'UN'\n716 \n717             # group length tag implied in versions < 3.0\n718             elif raw.tag.element == 0:\n719                 VR = 'UL'\n720             else:\n721                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n722                 msg += \" can't look up VR\"\n723                 raise KeyError(msg)\n724     elif (VR == 'UN' and not raw.tag.is_private and\n725           config.replace_un_with_known_vr):\n726         # handle rare case of incorrectly set 'UN' in explicit encoding\n727         # see also DataElement.__init__()\n728         if (raw.length == 0xffffffff or raw.value is None or\n729                 len(raw.value) < 0xffff):\n730             try:\n731                 VR = dictionary_VR(raw.tag)\n732             except KeyError:\n733                 pass\n734     try:\n735         value = convert_value(VR, raw, encoding)\n736     except NotImplementedError as e:\n737         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n738 \n739     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n740         # We only fix the first value as the third value is 8 or 16\n741         try:\n742             if value[0] < 0:\n743                 value[0] += 65536\n744         except TypeError:\n745             pass\n746 \n747     return DataElement(raw.tag, VR, value, raw.value_tell,\n748                        raw.length == 0xFFFFFFFF, already_converted=True)\n749 \n[end of pydicom/dataelem.py]\n[start of pydicom/multival.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Code for multi-value data elements values,\n3 or any list of items that must all be the same type.\n4 \"\"\"\n5 \n6 try:\n7     from collections.abc import MutableSequence\n8 except ImportError:\n9     from collections import MutableSequence\n10 \n11 \n12 class MultiValue(MutableSequence):\n13     \"\"\"Class to hold any multi-valued DICOM value, or any list of items that\n14     are all of the same type.\n15 \n16     This class enforces that any items added to the list are of the correct\n17     type, by calling the constructor on any items that are added. Therefore,\n18     the constructor must behave nicely if passed an object that is already its\n19     type. The constructor should raise :class:`TypeError` if the item cannot be\n20     converted.\n21 \n22     Note, however, that DS and IS types can be a blank string ``''`` rather\n23     than an instance of their classes.\n24     \"\"\"\n25 \n26     def __init__(self, type_constructor, iterable):\n27         \"\"\"Initialize the list of values\n28 \n29         Parameters\n30         ----------\n31         type_constructor : type\n32             A constructor for the required type for all list items. Could be\n33             the class, or a factory function. For DICOM multi-value data\n34             elements, this will be the class or type corresponding to the VR.\n35         iterable : iterable\n36             An iterable (e.g. :class:`list`, :class:`tuple`) of items to\n37             initialize the :class:`MultiValue` list.\n38         \"\"\"\n39         from pydicom.valuerep import DSfloat, DSdecimal, IS\n40 \n41         def number_string_type_constructor(x):\n42             return self.type_constructor(x) if x != '' else x\n43 \n44         self._list = list()\n45         self.type_constructor = type_constructor\n46         if type_constructor in (DSfloat, IS, DSdecimal):\n47             type_constructor = number_string_type_constructor\n48         for x in iterable:\n49             self._list.append(type_constructor(x))\n50 \n51     def insert(self, position, val):\n52         self._list.insert(position, self.type_constructor(val))\n53 \n54     def append(self, val):\n55         self._list.append(self.type_constructor(val))\n56 \n57     def __setitem__(self, i, val):\n58         \"\"\"Set an item of the list, making sure it is of the right VR type\"\"\"\n59         if isinstance(i, slice):\n60             val = [self.type_constructor(v) for v in val]\n61             self._list.__setitem__(i, val)\n62         else:\n63             self._list.__setitem__(i, self.type_constructor(val))\n64 \n65     def __str__(self):\n66         if not self:\n67             return ''\n68         lines = [\"'{}'\".format(x) if isinstance(x, (str, bytes))\n69                  else str(x) for x in self]\n70         return \"[\" + \", \".join(lines) + \"]\"\n71 \n72     __repr__ = __str__\n73 \n74     def __len__(self):\n75         return len(self._list)\n76 \n77     def __getitem__(self, index):\n78         return self._list[index]\n79 \n80     def __delitem__(self, index):\n81         del self._list[index]\n82 \n83     def __iter__(self):\n84         return iter(self._list)\n85 \n86     def __eq__(self, other):\n87         return self._list == other\n88 \n89     def __ne__(self, other):\n90         return self._list != other\n91 \n92     def sort(self, key=None, reverse=False):\n93         self._list.sort(key=key, reverse=reverse)\n94 \n[end of pydicom/multival.py]\n[start of pydicom/util/codify.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"\n3 Produce runnable python code which can recreate DICOM objects or files.\n4 \n5 Can run as a script to produce code for an entire file,\n6 or import and use specific functions to provide code for pydicom DICOM classes\n7 \n8 \"\"\"\n9 \n10 # Run this from the same directory as a \"base\" dicom file and\n11 # this code will output to screen the dicom parameters like:\n12 #    ds.PatientName = 'TEST'\n13 # etc for all parameters in the file.\n14 # This can then be pasted into a python file and parameters edited as necessary\n15 # to create a DICOM file from scratch\n16 \n17 import sys\n18 import os.path\n19 import pydicom\n20 from pydicom.datadict import dictionary_keyword\n21 \n22 import re\n23 \n24 line_term = \"\\n\"\n25 \n26 # Helper functions first\n27 \n28 # Precompiled search patterns for camel_to_underscore()\n29 first_cap_re = re.compile('(.)([A-Z][a-z]+)')\n30 all_cap_re = re.compile('([a-z0-9])([A-Z])')\n31 \n32 byte_VRs = [\n33     'OB', 'OW', 'OW/OB', 'OW or OB', 'OB or OW', 'US or SS or OW', 'US or SS',\n34     'OD', 'OL'\n35 ]\n36 \n37 \n38 def camel_to_underscore(name):\n39     \"\"\"Convert name from CamelCase to lower_case_with_underscores\"\"\"\n40     # From http://stackoverflow.com/questions/1175208\n41     s1 = first_cap_re.sub(r'\\1_\\2', name)\n42     return all_cap_re.sub(r'\\1_\\2', s1).lower()\n43 \n44 \n45 def tag_repr(tag):\n46     \"\"\"String of tag value as (0xgggg, 0xeeee)\"\"\"\n47     return \"(0x{group:04x}, 0x{elem:04x})\".format(\n48         group=tag.group, elem=tag.element)\n49 \n50 \n51 def default_name_filter(name):\n52     \"\"\"Callable to reduce some names in code to more readable short form\n53 \n54     :arg name: a sequence variable name or sequence item name\n55     :return: a shorter version of name if a known conversion,\n56              else return original name\n57 \n58     \"\"\"\n59     name = camel_to_underscore(name)\n60     name = name.replace(\"control_point\", \"cp\")\n61     name = name.replace(\"reference\", \"ref\")\n62     name = name.replace(\"fraction_group\", \"frxn_gp\")\n63     return name\n64 \n65 \n66 # Functions to produce python code\n67 def code_imports():\n68     \"\"\"Code the import statements needed by other codify results\n69 \n70     :return: a string of import statement lines\n71 \n72     \"\"\"\n73     line1 = \"import pydicom\"\n74     line2 = \"from pydicom.dataset import Dataset, FileMetaDataset\"\n75     line3 = \"from pydicom.sequence import Sequence\"\n76     return line_term.join((line1, line2, line3))\n77 \n78 \n79 def code_dataelem(dataelem,\n80                   dataset_name=\"ds\",\n81                   exclude_size=None,\n82                   include_private=False):\n83     \"\"\"Code lines for a single DICOM data element\n84 \n85     :arg dataelem: the DataElement instance to turn into code\n86     :arg dataset_name: variable name of the Dataset containing dataelem\n87     :arg exclude_size: if specified, values longer than this (in bytes)\n88                        will only have a commented string for a value,\n89                        causing a syntax error when the code is run,\n90                        and thus prompting the user to remove or fix that line.\n91     :return: a string containing code to recreate the data element\n92              If the data element is a sequence, calls code_sequence\n93 \n94     \"\"\"\n95 \n96     if dataelem.VR == \"SQ\":\n97         return code_sequence(dataelem, dataset_name, exclude_size,\n98                              include_private)\n99 \n100     # If in DICOM dictionary, set using the keyword\n101     # If not (e.g. is private element), set using add_new method\n102     have_keyword = True\n103     try:\n104         keyword = dictionary_keyword(dataelem.tag)\n105     except KeyError:\n106         have_keyword = False\n107 \n108     valuerep = repr(dataelem.value)\n109 \n110     if exclude_size:\n111         if (dataelem.VR in byte_VRs and\n112                 len(dataelem.value) > exclude_size):\n113             valuerep = (\n114                 \"# XXX Array of %d bytes excluded\" % len(dataelem.value))\n115 \n116     if have_keyword:\n117         format_str = \"{ds_name}.{keyword} = {valuerep}\"\n118         line = format_str.format(\n119             ds_name=dataset_name, keyword=keyword, valuerep=valuerep)\n120     else:\n121         format_str = \"{ds_name}.add_new({tag}, '{VR}', {valuerep})\"\n122         line = format_str.format(\n123             ds_name=dataset_name,\n124             tag=tag_repr(dataelem.tag),\n125             VR=dataelem.VR,\n126             valuerep=valuerep)\n127     return line\n128 \n129 \n130 def code_sequence(dataelem,\n131                   dataset_name=\"ds\",\n132                   exclude_size=None,\n133                   include_private=False,\n134                   name_filter=default_name_filter):\n135     \"\"\"Code lines for recreating a Sequence data element\n136 \n137     :arg dataelem: the DataElement instance of the Sequence\n138     :arg dataset_name: variable name of the dataset containing the Sequence\n139     :arg exclude_size: if specified, values longer than this (in bytes)\n140                        will only have a commented string for a value,\n141                        causing a syntax error when the code is run,\n142                        and thus prompting the user to remove or fix that line.\n143     :arg include_private: If True, private data elements will be coded.\n144                           If False, private elements are skipped\n145     :arg name_filter: a callable taking a sequence name or sequence item name,\n146                       and returning a shorter name for easier code reading\n147     :return: a string containing code lines to recreate a DICOM sequence\n148 \n149     \"\"\"\n150     lines = []\n151     seq = dataelem.value\n152     seq_name = dataelem.name\n153     seq_item_name = seq_name.replace(' Sequence', '')\n154     seq_keyword = dictionary_keyword(dataelem.tag)\n155 \n156     # Create comment line to document the start of Sequence\n157     lines.append('')\n158     lines.append(\"# \" + seq_name)\n159 \n160     # Code line to create a new Sequence object\n161     if name_filter:\n162         seq_var = name_filter(seq_keyword)\n163     lines.append(seq_var + \" = Sequence()\")\n164 \n165     # Code line to add the sequence to its parent\n166     lines.append(dataset_name + \".\" + seq_keyword + \" = \" + seq_var)\n167 \n168     # Code lines to add sequence items to the Sequence\n169     for i, ds in enumerate(seq):\n170         # Determine index to use. If seq item has a data element with 'Index',\n171         #    use that; if one with 'Number', use that, else start at 1\n172         index_keyword = seq_keyword.replace(\"Sequence\", \"\") + \"Index\"\n173         number_keyword = seq_keyword.replace(\"Sequence\", \"\") + \"Number\"\n174         if index_keyword in ds:\n175             index_str = str(getattr(ds, index_keyword))\n176         elif number_keyword in ds:\n177             index_str = str(getattr(ds, number_keyword))\n178         else:\n179             index_str = str(i + 1)\n180 \n181         # Code comment line to mark start of sequence item\n182         lines.append('')\n183         lines.append(\"# \" + seq_name + \": \" + seq_item_name + \" \" + index_str)\n184 \n185         # Determine the variable name to use for the sequence item (dataset)\n186         ds_name = seq_var.replace(\"_sequence\", \"\") + index_str\n187 \n188         # Code the sequence item\n189         code_item = code_dataset(ds, ds_name, exclude_size, include_private)\n190         lines.append(code_item)\n191 \n192         # Code the line to append the item to its parent sequence\n193         lines.append(seq_var + \".append(\" + ds_name + \")\")\n194 \n195     # Join the lines and return a single string\n196     return line_term.join(lines)\n197 \n198 \n199 def code_dataset(ds,\n200                  dataset_name=\"ds\",\n201                  exclude_size=None,\n202                  include_private=False,\n203                  is_file_meta=False):\n204     \"\"\"Return python code lines for import statements needed by other code\n205 \n206     :arg exclude_size: if specified, values longer than this (in bytes)\n207                        will only have a commented string for a value,\n208                        causing a syntax error when the code is run,\n209                        and thus prompting the user to remove or fix that line.\n210     :arg include_private: If True, private data elements will be coded.\n211                           If False, private elements are skipped\n212     :return: a list of code lines containing import statements\n213 \n214     \"\"\"\n215     lines = []\n216     ds_class = \" = FileMetaDataset()\" if is_file_meta else \" = Dataset()\"\n217     lines.append(dataset_name + ds_class)\n218     for dataelem in ds:\n219         # If a private data element and flag says so, skip it and go to next\n220         if not include_private and dataelem.tag.is_private:\n221             continue\n222         # Otherwise code the line and add it to the lines list\n223         code_line = code_dataelem(dataelem, dataset_name, exclude_size,\n224                                   include_private)\n225         lines.append(code_line)\n226         # Add blank line if just coded a sequence\n227         if dataelem.VR == \"SQ\":\n228             lines.append('')\n229     # If sequence was end of this dataset, remove the extra blank line\n230     if len(lines) and lines[-1] == '':\n231         lines.pop()\n232     # Join all the code lines and return them\n233     return line_term.join(lines)\n234 \n235 \n236 def code_file(filename, exclude_size=None, include_private=False):\n237     \"\"\"Write a complete source code file to recreate a DICOM file\n238 \n239     :arg filename: complete path and filename of a DICOM file to convert\n240     :arg exclude_size: if specified, values longer than this (in bytes)\n241                        will only have a commented string for a value,\n242                        causing a syntax error when the code is run,\n243                        and thus prompting the user to remove or fix that line.\n244     :arg include_private: If True, private data elements will be coded.\n245                           If False, private elements are skipped\n246     :return: a string containing code lines to recreate entire file\n247 \n248     \"\"\"\n249     lines = []\n250 \n251     ds = pydicom.dcmread(filename, force=True)\n252 \n253     # Code a nice header for the python file\n254     lines.append(\"# Coded version of DICOM file '{0}'\".format(filename))\n255     lines.append(\"# Produced by pydicom codify utility script\")\n256 \n257     # Code the necessary imports\n258     lines.append(code_imports())\n259     lines.append('')\n260 \n261     # Code the file_meta information\n262     lines.append(\"# File meta info data elements\")\n263     code_meta = code_dataset(ds.file_meta, \"file_meta\", exclude_size,\n264                              include_private, is_file_meta=True)\n265     lines.append(code_meta)\n266     lines.append('')\n267 \n268     # Code the main dataset\n269     lines.append(\"# Main data elements\")\n270     code_ds = code_dataset(\n271         ds, exclude_size=exclude_size, include_private=include_private)\n272     lines.append(code_ds)\n273     lines.append('')\n274 \n275     # Add the file meta to the dataset, and set transfer syntax\n276     lines.append(\"ds.file_meta = file_meta\")\n277     lines.append(\"ds.is_implicit_VR = \" + str(ds.is_implicit_VR))\n278     lines.append(\"ds.is_little_endian = \" + str(ds.is_little_endian))\n279 \n280     # Return the complete code string\n281     return line_term.join(lines)\n282 \n283 \n284 def main(default_exclude_size, args=None):\n285     \"\"\"Create python code according to user options\n286 \n287     Parameters:\n288     -----------\n289     default_exclude_size:  int\n290         Values longer than this will be coded as a commented syntax error\n291 \n292     args: list\n293         Command-line arguments to parse.  If None, then sys.argv is used\n294     \"\"\"\n295 \n296     try:\n297         import argparse\n298     except ImportError:\n299         print(\"The argparse module is required to run this script\")\n300         print(\"argparse is standard in python >= 2.7,\")\n301         print(\"   or can be installed with 'pip install argparse'\")\n302         sys.exit(-1)\n303 \n304     parser = argparse.ArgumentParser(\n305         description=\"Produce python/pydicom code from a DICOM file\",\n306         epilog=\"Binary data (e.g. pixels) larger than --exclude-size \"\n307         \"(default %d bytes) is not included. A dummy line \"\n308         \"with a syntax error is produced. \"\n309         \"Private data elements are not included \"\n310         \"by default.\" % default_exclude_size)\n311     parser.add_argument(\n312         'infile', help=\"DICOM file from which to produce code lines\")\n313     parser.add_argument(\n314         'outfile',\n315         nargs='?',\n316         type=argparse.FileType('w'),\n317         help=(\"Filename to write python code to. \"\n318               \"If not specified, code is written to stdout\"),\n319         default=sys.stdout)\n320     help_exclude_size = 'Exclude binary data larger than specified (bytes). '\n321     help_exclude_size += 'Default is %d bytes' % default_exclude_size\n322     parser.add_argument(\n323         '-e',\n324         '--exclude-size',\n325         type=int,\n326         default=default_exclude_size,\n327         help=help_exclude_size)\n328     parser.add_argument(\n329         '-p',\n330         '--include-private',\n331         action=\"store_true\",\n332         help='Include private data elements '\n333         '(default is to exclude them)')\n334     parser.add_argument(\n335         '-s',\n336         '--save-as',\n337         help=(\"Specify the filename for ds.save_as(save_filename); \"\n338               \"otherwise the input name + '_from_codify' will be used\"))\n339 \n340     args = parser.parse_args(args)\n341 \n342     # Read the requested file and convert to python/pydicom code lines\n343     filename = args.infile  # name\n344     code_lines = code_file(filename, args.exclude_size, args.include_private)\n345 \n346     # If requested, write a code line to save the dataset\n347     if args.save_as:\n348         save_as_filename = args.save_as\n349     else:\n350         base, ext = os.path.splitext(filename)\n351         save_as_filename = base + \"_from_codify\" + \".dcm\"\n352     line = \"\\nds.save_as(r'{filename}', write_like_original=False)\"\n353     save_line = line.format(filename=save_as_filename)\n354     code_lines += save_line\n355 \n356     # Write the code lines to specified file or to standard output\n357     # For test_util, captured output .name throws error, ignore it:\n358     try:\n359         if args.outfile.name != \"<stdout>\":\n360             print(\"Writing code to file '%s'\" % args.outfile.name)\n361     except AttributeError:\n362         pass\n363     args.outfile.write(code_lines)\n364 \n365 \n366 if __name__ == \"__main__\":\n367     main(default_exclude_size=100)\n368 \n[end of pydicom/util/codify.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "b9fb05c177b685bf683f7f57b2d57374eb7d882d", "problem_statement": "Make PersonName3 iterable\n```python\r\nfrom pydicom import Dataset\r\n\r\nds = Dataset()\r\nds.PatientName = 'SomeName'\r\n\r\n'S' in ds.PatientName\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: argument of type 'PersonName3' is not iterable\r\n```\r\n\r\nI'm not really sure if this is intentional or if PN elements should support `str` methods. And yes I know I can `str(ds.PatientName)` but it's a bit silly, especially when I keep having to write exceptions to my element iterators just for PN elements.\n", "hints_text": "I think it is reasonable to support at least some `str` methods (definitely `__contains__` for the example above), but there are many that don't make a lot of sense in this context though - e.g. `join`, `ljust`, `maketrans`, `splitlines` just to name a few, but I suppose each would either never be actually used or would have no effect.\r\n\r\nI have a vague memory that one or more of the `PersonName` classes was at one time subclassed from `str`, or at least that it was discussed... does anyone remember?  Maybe it would be easier now with only Python 3 supported.\n`PersonName` was derived from `str` or `unicode` in Python 2, but that caused a number of problems, which is why you switched to `PersonName3` in Python 3, I think. I agree though that it makes sense to implement `str` methods, either by implementing some of them, or generically by adding `__getattr__` that converts it to `str` and applies the attribute to that string. ", "created_at": "2020-06-26T11:47:17Z", "patch": "<patch>\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -1,6 +1,5 @@\n # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n-from copy import deepcopy\n from decimal import Decimal\n import re\n \n@@ -750,6 +749,25 @@ def __ne__(self, other):\n     def __str__(self):\n         return '='.join(self.components).__str__()\n \n+    def __next__(self):\n+        # Get next character or stop iteration\n+        if self._i < self._rep_len:\n+            c = self._str_rep[self._i]\n+            self._i += 1\n+            return c\n+        else:\n+            raise StopIteration\n+\n+    def __iter__(self):\n+        # Get string rep. and length, initialize index counter\n+        self._str_rep = self.__str__()\n+        self._rep_len = len(self._str_rep)\n+        self._i = 0\n+        return self\n+\n+    def __contains__(self, x):\n+        return x in self.__str__()\n+\n     def __repr__(self):\n         return '='.join(self.components).__repr__()\n \n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -427,6 +427,62 @@ def test_hash(self):\n         )\n         assert hash(pn1) == hash(pn2)\n \n+    def test_next(self):\n+        \"\"\"Test that the next function works on it's own\"\"\"\n+        # Test getting the first character\n+        pn1 = PersonName(\"John^Doe^^Dr\", encodings=default_encoding)\n+        pn1_itr = iter(pn1)\n+        assert next(pn1_itr) == \"J\"\n+\n+        # Test getting multiple characters\n+        pn2 = PersonName(\n+            \"Yamada^Tarou=\u5c71\u7530^\u592a\u90ce=\u3084\u307e\u3060^\u305f\u308d\u3046\", [default_encoding, \"iso2022_jp\"]\n+        )\n+        pn2_itr = iter(pn2)\n+        assert next(pn2_itr) == \"Y\"\n+        assert next(pn2_itr) == \"a\"\n+\n+        # Test getting all characters\n+        pn3 = PersonName(\"SomeName\")\n+        pn3_itr = iter(pn3)\n+        assert next(pn3_itr) == \"S\"\n+        assert next(pn3_itr) == \"o\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+        assert next(pn3_itr) == \"N\"\n+        assert next(pn3_itr) == \"a\"\n+        assert next(pn3_itr) == \"m\"\n+        assert next(pn3_itr) == \"e\"\n+\n+        # Attempting to get next characeter should stop the iteration\n+        # I.e. next can only start once\n+        with pytest.raises(StopIteration):\n+            next(pn3_itr)\n+\n+        # Test that next() doesn't work without instantiating an iterator\n+        pn4 = PersonName(\"SomeName\")\n+        with pytest.raises(AttributeError):\n+            next(pn4)\n+\n+    def test_iterator(self):\n+        \"\"\"Test that iterators can be corretly constructed\"\"\"\n+        name_str = \"John^Doe^^Dr\"\n+        pn1 = PersonName(name_str)\n+        \n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+        # Ensure that multiple iterators can be created on the same variable\n+        for i, c in enumerate(pn1):\n+            assert name_str[i] == c\n+\n+    def test_contains(self):\n+        \"\"\"Test that characters can be check if they are within the name\"\"\"\n+        pn1 = PersonName(\"John^Doe\")\n+        assert (\"J\" in pn1) == True\n+        assert (\"o\" in pn1) == True\n+        assert (\"x\" in pn1) == False\n+\n \n class TestDateTime:\n     \"\"\"Unit tests for DA, DT, TM conversion to datetime objects\"\"\"\n", "version": "2.0", "FAIL_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\"]", "environment_setup_commit": "9d69811e539774f296c2f289839147e741251716"}
{"instance_id": "pylint-dev__astroid-2240_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n`.arguments` property ignores keyword-only args, *args, and **kwargs\n```python\r\n>>> from astroid import extract_node\r\n>>> node = extract_node(\"\"\"def a(*args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[]\r\n```\r\n\r\nExpected to find all the arguments from the function signature.\r\n\r\nThe wanted data can be found here:\r\n\r\n```python\r\n>>> node.args.vararg\r\n'args'\r\n>>> node.args.kwarg\r\n'kwargs'\r\n>>> node.args.kwonlyargs\r\n[<AssignName.b l.1 at 0x1048189b0>, <AssignName.c l.1 at 0x104818830>]\r\n```\r\n\r\nDiscussed at https://github.com/pylint-dev/pylint/pull/7577#discussion_r989000829.\r\n\r\nNotice that positional-only args are found for some reason \ud83e\udd37 \n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://codecov.io/gh/pylint-dev/astroid/branch/main/graph/badge.svg?token=Buxy4WptLb\n5     :target: https://codecov.io/gh/pylint-dev/astroid\n6     :alt: Coverage badge from codecov\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/pylint-dev/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/pylint-dev/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/pylint-dev/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest\n90 \n[end of README.rst]\n[start of astroid/arguments.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 from astroid import nodes\n8 from astroid.bases import Instance\n9 from astroid.context import CallContext, InferenceContext\n10 from astroid.exceptions import InferenceError, NoDefault\n11 from astroid.typing import InferenceResult\n12 from astroid.util import Uninferable, UninferableBase, safe_infer\n13 \n14 \n15 class CallSite:\n16     \"\"\"Class for understanding arguments passed into a call site.\n17 \n18     It needs a call context, which contains the arguments and the\n19     keyword arguments that were passed into a given call site.\n20     In order to infer what an argument represents, call :meth:`infer_argument`\n21     with the corresponding function node and the argument name.\n22 \n23     :param callcontext:\n24         An instance of :class:`astroid.context.CallContext`, that holds\n25         the arguments for the call site.\n26     :param argument_context_map:\n27         Additional contexts per node, passed in from :attr:`astroid.context.Context.extra_context`\n28     :param context:\n29         An instance of :class:`astroid.context.Context`.\n30     \"\"\"\n31 \n32     def __init__(\n33         self,\n34         callcontext: CallContext,\n35         argument_context_map=None,\n36         context: InferenceContext | None = None,\n37     ):\n38         if argument_context_map is None:\n39             argument_context_map = {}\n40         self.argument_context_map = argument_context_map\n41         args = callcontext.args\n42         keywords = callcontext.keywords\n43         self.duplicated_keywords: set[str] = set()\n44         self._unpacked_args = self._unpack_args(args, context=context)\n45         self._unpacked_kwargs = self._unpack_keywords(keywords, context=context)\n46 \n47         self.positional_arguments = [\n48             arg for arg in self._unpacked_args if not isinstance(arg, UninferableBase)\n49         ]\n50         self.keyword_arguments = {\n51             key: value\n52             for key, value in self._unpacked_kwargs.items()\n53             if not isinstance(value, UninferableBase)\n54         }\n55 \n56     @classmethod\n57     def from_call(cls, call_node, context: InferenceContext | None = None):\n58         \"\"\"Get a CallSite object from the given Call node.\n59 \n60         context will be used to force a single inference path.\n61         \"\"\"\n62 \n63         # Determine the callcontext from the given `context` object if any.\n64         context = context or InferenceContext()\n65         callcontext = CallContext(call_node.args, call_node.keywords)\n66         return cls(callcontext, context=context)\n67 \n68     def has_invalid_arguments(self):\n69         \"\"\"Check if in the current CallSite were passed *invalid* arguments.\n70 \n71         This can mean multiple things. For instance, if an unpacking\n72         of an invalid object was passed, then this method will return True.\n73         Other cases can be when the arguments can't be inferred by astroid,\n74         for example, by passing objects which aren't known statically.\n75         \"\"\"\n76         return len(self.positional_arguments) != len(self._unpacked_args)\n77 \n78     def has_invalid_keywords(self) -> bool:\n79         \"\"\"Check if in the current CallSite were passed *invalid* keyword arguments.\n80 \n81         For instance, unpacking a dictionary with integer keys is invalid\n82         (**{1:2}), because the keys must be strings, which will make this\n83         method to return True. Other cases where this might return True if\n84         objects which can't be inferred were passed.\n85         \"\"\"\n86         return len(self.keyword_arguments) != len(self._unpacked_kwargs)\n87 \n88     def _unpack_keywords(\n89         self,\n90         keywords: list[tuple[str | None, nodes.NodeNG]],\n91         context: InferenceContext | None = None,\n92     ):\n93         values: dict[str | None, InferenceResult] = {}\n94         context = context or InferenceContext()\n95         context.extra_context = self.argument_context_map\n96         for name, value in keywords:\n97             if name is None:\n98                 # Then it's an unpacking operation (**)\n99                 inferred = safe_infer(value, context=context)\n100                 if not isinstance(inferred, nodes.Dict):\n101                     # Not something we can work with.\n102                     values[name] = Uninferable\n103                     continue\n104 \n105                 for dict_key, dict_value in inferred.items:\n106                     dict_key = safe_infer(dict_key, context=context)\n107                     if not isinstance(dict_key, nodes.Const):\n108                         values[name] = Uninferable\n109                         continue\n110                     if not isinstance(dict_key.value, str):\n111                         values[name] = Uninferable\n112                         continue\n113                     if dict_key.value in values:\n114                         # The name is already in the dictionary\n115                         values[dict_key.value] = Uninferable\n116                         self.duplicated_keywords.add(dict_key.value)\n117                         continue\n118                     values[dict_key.value] = dict_value\n119             else:\n120                 values[name] = value\n121         return values\n122 \n123     def _unpack_args(self, args, context: InferenceContext | None = None):\n124         values = []\n125         context = context or InferenceContext()\n126         context.extra_context = self.argument_context_map\n127         for arg in args:\n128             if isinstance(arg, nodes.Starred):\n129                 inferred = safe_infer(arg.value, context=context)\n130                 if isinstance(inferred, UninferableBase):\n131                     values.append(Uninferable)\n132                     continue\n133                 if not hasattr(inferred, \"elts\"):\n134                     values.append(Uninferable)\n135                     continue\n136                 values.extend(inferred.elts)\n137             else:\n138                 values.append(arg)\n139         return values\n140 \n141     def infer_argument(\n142         self, funcnode: InferenceResult, name: str, context: InferenceContext\n143     ):  # noqa: C901\n144         \"\"\"Infer a function argument value according to the call context.\"\"\"\n145         if not isinstance(funcnode, (nodes.FunctionDef, nodes.Lambda)):\n146             raise InferenceError(\n147                 f\"Can not infer function argument value for non-function node {funcnode!r}.\",\n148                 call_site=self,\n149                 func=funcnode,\n150                 arg=name,\n151                 context=context,\n152             )\n153 \n154         if name in self.duplicated_keywords:\n155             raise InferenceError(\n156                 \"The arguments passed to {func!r} have duplicate keywords.\",\n157                 call_site=self,\n158                 func=funcnode,\n159                 arg=name,\n160                 context=context,\n161             )\n162 \n163         # Look into the keywords first, maybe it's already there.\n164         try:\n165             return self.keyword_arguments[name].infer(context)\n166         except KeyError:\n167             pass\n168 \n169         # Too many arguments given and no variable arguments.\n170         if len(self.positional_arguments) > len(funcnode.args.args):\n171             if not funcnode.args.vararg and not funcnode.args.posonlyargs:\n172                 raise InferenceError(\n173                     \"Too many positional arguments \"\n174                     \"passed to {func!r} that does \"\n175                     \"not have *args.\",\n176                     call_site=self,\n177                     func=funcnode,\n178                     arg=name,\n179                     context=context,\n180                 )\n181 \n182         positional = self.positional_arguments[: len(funcnode.args.args)]\n183         vararg = self.positional_arguments[len(funcnode.args.args) :]\n184         argindex = funcnode.args.find_argname(name)[0]\n185         kwonlyargs = {arg.name for arg in funcnode.args.kwonlyargs}\n186         kwargs = {\n187             key: value\n188             for key, value in self.keyword_arguments.items()\n189             if key not in kwonlyargs\n190         }\n191         # If there are too few positionals compared to\n192         # what the function expects to receive, check to see\n193         # if the missing positional arguments were passed\n194         # as keyword arguments and if so, place them into the\n195         # positional args list.\n196         if len(positional) < len(funcnode.args.args):\n197             for func_arg in funcnode.args.args:\n198                 if func_arg.name in kwargs:\n199                     arg = kwargs.pop(func_arg.name)\n200                     positional.append(arg)\n201 \n202         if argindex is not None:\n203             boundnode = context.boundnode\n204             # 2. first argument of instance/class method\n205             if argindex == 0 and funcnode.type in {\"method\", \"classmethod\"}:\n206                 # context.boundnode is None when an instance method is called with\n207                 # the class, e.g. MyClass.method(obj, ...). In this case, self\n208                 # is the first argument.\n209                 if boundnode is None and funcnode.type == \"method\" and positional:\n210                     return positional[0].infer(context=context)\n211                 if boundnode is None:\n212                     # XXX can do better ?\n213                     boundnode = funcnode.parent.frame()\n214 \n215                 if isinstance(boundnode, nodes.ClassDef):\n216                     # Verify that we're accessing a method\n217                     # of the metaclass through a class, as in\n218                     # `cls.metaclass_method`. In this case, the\n219                     # first argument is always the class.\n220                     method_scope = funcnode.parent.scope()\n221                     if method_scope is boundnode.metaclass(context=context):\n222                         return iter((boundnode,))\n223 \n224                 if funcnode.type == \"method\":\n225                     if not isinstance(boundnode, Instance):\n226                         boundnode = boundnode.instantiate_class()\n227                     return iter((boundnode,))\n228                 if funcnode.type == \"classmethod\":\n229                     return iter((boundnode,))\n230             # if we have a method, extract one position\n231             # from the index, so we'll take in account\n232             # the extra parameter represented by `self` or `cls`\n233             if funcnode.type in {\"method\", \"classmethod\"} and boundnode:\n234                 argindex -= 1\n235             # 2. search arg index\n236             try:\n237                 return self.positional_arguments[argindex].infer(context)\n238             except IndexError:\n239                 pass\n240 \n241         if funcnode.args.kwarg == name:\n242             # It wants all the keywords that were passed into\n243             # the call site.\n244             if self.has_invalid_keywords():\n245                 raise InferenceError(\n246                     \"Inference failed to find values for all keyword arguments \"\n247                     \"to {func!r}: {unpacked_kwargs!r} doesn't correspond to \"\n248                     \"{keyword_arguments!r}.\",\n249                     keyword_arguments=self.keyword_arguments,\n250                     unpacked_kwargs=self._unpacked_kwargs,\n251                     call_site=self,\n252                     func=funcnode,\n253                     arg=name,\n254                     context=context,\n255                 )\n256             kwarg = nodes.Dict(\n257                 lineno=funcnode.args.lineno,\n258                 col_offset=funcnode.args.col_offset,\n259                 parent=funcnode.args,\n260                 end_lineno=funcnode.args.end_lineno,\n261                 end_col_offset=funcnode.args.end_col_offset,\n262             )\n263             kwarg.postinit(\n264                 [(nodes.const_factory(key), value) for key, value in kwargs.items()]\n265             )\n266             return iter((kwarg,))\n267         if funcnode.args.vararg == name:\n268             # It wants all the args that were passed into\n269             # the call site.\n270             if self.has_invalid_arguments():\n271                 raise InferenceError(\n272                     \"Inference failed to find values for all positional \"\n273                     \"arguments to {func!r}: {unpacked_args!r} doesn't \"\n274                     \"correspond to {positional_arguments!r}.\",\n275                     positional_arguments=self.positional_arguments,\n276                     unpacked_args=self._unpacked_args,\n277                     call_site=self,\n278                     func=funcnode,\n279                     arg=name,\n280                     context=context,\n281                 )\n282             args = nodes.Tuple(\n283                 lineno=funcnode.args.lineno,\n284                 col_offset=funcnode.args.col_offset,\n285                 parent=funcnode.args,\n286             )\n287             args.postinit(vararg)\n288             return iter((args,))\n289 \n290         # Check if it's a default parameter.\n291         try:\n292             return funcnode.args.default_value(name).infer(context)\n293         except NoDefault:\n294             pass\n295         raise InferenceError(\n296             \"No value found for argument {arg} to {func!r}\",\n297             call_site=self,\n298             func=funcnode,\n299             arg=name,\n300             context=context,\n301         )\n302 \n[end of astroid/arguments.py]\n[start of astroid/interpreter/objectmodel.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"\n6 Data object model, as per https://docs.python.org/3/reference/datamodel.html.\n7 \n8 This module describes, at least partially, a data object model for some\n9 of astroid's nodes. The model contains special attributes that nodes such\n10 as functions, classes, modules etc have, such as __doc__, __class__,\n11 __module__ etc, being used when doing attribute lookups over nodes.\n12 \n13 For instance, inferring `obj.__class__` will first trigger an inference\n14 of the `obj` variable. If it was successfully inferred, then an attribute\n15 `__class__ will be looked for in the inferred object. This is the part\n16 where the data model occurs. The model is attached to those nodes\n17 and the lookup mechanism will try to see if attributes such as\n18 `__class__` are defined by the model or not. If they are defined,\n19 the model will be requested to return the corresponding value of that\n20 attribute. Thus the model can be viewed as a special part of the lookup\n21 mechanism.\n22 \"\"\"\n23 \n24 from __future__ import annotations\n25 \n26 import itertools\n27 import os\n28 import pprint\n29 import types\n30 from collections.abc import Iterator\n31 from functools import lru_cache\n32 from typing import TYPE_CHECKING, Any, Literal\n33 \n34 import astroid\n35 from astroid import bases, nodes, util\n36 from astroid.context import InferenceContext, copy_context\n37 from astroid.exceptions import AttributeInferenceError, InferenceError, NoDefault\n38 from astroid.manager import AstroidManager\n39 from astroid.nodes import node_classes\n40 from astroid.typing import InferenceResult, SuccessfulInferenceResult\n41 \n42 if TYPE_CHECKING:\n43     from astroid.objects import Property\n44 \n45 IMPL_PREFIX = \"attr_\"\n46 LEN_OF_IMPL_PREFIX = len(IMPL_PREFIX)\n47 \n48 \n49 def _dunder_dict(instance, attributes):\n50     obj = node_classes.Dict(\n51         parent=instance,\n52         lineno=instance.lineno,\n53         col_offset=instance.col_offset,\n54         end_lineno=instance.end_lineno,\n55         end_col_offset=instance.end_col_offset,\n56     )\n57 \n58     # Convert the keys to node strings\n59     keys = [\n60         node_classes.Const(value=value, parent=obj) for value in list(attributes.keys())\n61     ]\n62 \n63     # The original attribute has a list of elements for each key,\n64     # but that is not useful for retrieving the special attribute's value.\n65     # In this case, we're picking the last value from each list.\n66     values = [elem[-1] for elem in attributes.values()]\n67 \n68     obj.postinit(list(zip(keys, values)))\n69     return obj\n70 \n71 \n72 def _get_bound_node(model: ObjectModel) -> Any:\n73     # TODO: Use isinstance instead of try ... except after _instance has typing\n74     try:\n75         return model._instance._proxied\n76     except AttributeError:\n77         return model._instance\n78 \n79 \n80 class ObjectModel:\n81     def __init__(self):\n82         self._instance = None\n83 \n84     def __repr__(self):\n85         result = []\n86         cname = type(self).__name__\n87         string = \"%(cname)s(%(fields)s)\"\n88         alignment = len(cname) + 1\n89         for field in sorted(self.attributes()):\n90             width = 80 - len(field) - alignment\n91             lines = pprint.pformat(field, indent=2, width=width).splitlines(True)\n92 \n93             inner = [lines[0]]\n94             for line in lines[1:]:\n95                 inner.append(\" \" * alignment + line)\n96             result.append(field)\n97 \n98         return string % {\n99             \"cname\": cname,\n100             \"fields\": (\",\\n\" + \" \" * alignment).join(result),\n101         }\n102 \n103     def __call__(self, instance):\n104         self._instance = instance\n105         return self\n106 \n107     def __get__(self, instance, cls=None):\n108         # ObjectModel needs to be a descriptor so that just doing\n109         # `special_attributes = SomeObjectModel` should be enough in the body of a node.\n110         # But at the same time, node.special_attributes should return an object\n111         # which can be used for manipulating the special attributes. That's the reason\n112         # we pass the instance through which it got accessed to ObjectModel.__call__,\n113         # returning itself afterwards, so we can still have access to the\n114         # underlying data model and to the instance for which it got accessed.\n115         return self(instance)\n116 \n117     def __contains__(self, name) -> bool:\n118         return name in self.attributes()\n119 \n120     @lru_cache  # noqa\n121     def attributes(self) -> list[str]:\n122         \"\"\"Get the attributes which are exported by this object model.\"\"\"\n123         return [o[LEN_OF_IMPL_PREFIX:] for o in dir(self) if o.startswith(IMPL_PREFIX)]\n124 \n125     def lookup(self, name):\n126         \"\"\"Look up the given *name* in the current model.\n127 \n128         It should return an AST or an interpreter object,\n129         but if the name is not found, then an AttributeInferenceError will be raised.\n130         \"\"\"\n131         if name in self.attributes():\n132             return getattr(self, IMPL_PREFIX + name)\n133         raise AttributeInferenceError(target=self._instance, attribute=name)\n134 \n135     @property\n136     def attr___new__(self) -> bases.BoundMethod:\n137         \"\"\"Calling cls.__new__(type) on an object returns an instance of 'type'.\"\"\"\n138         from astroid import builder  # pylint: disable=import-outside-toplevel\n139 \n140         node: nodes.FunctionDef = builder.extract_node(\n141             \"\"\"def __new__(self, cls): return cls()\"\"\"\n142         )\n143         # We set the parent as being the ClassDef of 'object' as that\n144         # triggers correct inference as a call to __new__ in bases.py\n145         node.parent = AstroidManager().builtins_module[\"object\"]\n146 \n147         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n148 \n149     @property\n150     def attr___init__(self) -> bases.BoundMethod:\n151         \"\"\"Calling cls.__init__() normally returns None.\"\"\"\n152         from astroid import builder  # pylint: disable=import-outside-toplevel\n153 \n154         # The *args and **kwargs are necessary not to trigger warnings about missing\n155         # or extra parameters for '__init__' methods we don't infer correctly.\n156         # This BoundMethod is the fallback value for those.\n157         node: nodes.FunctionDef = builder.extract_node(\n158             \"\"\"def __init__(self, *args, **kwargs): return None\"\"\"\n159         )\n160         # We set the parent as being the ClassDef of 'object' as that\n161         # is where this method originally comes from\n162         node.parent = AstroidManager().builtins_module[\"object\"]\n163 \n164         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n165 \n166 \n167 class ModuleModel(ObjectModel):\n168     def _builtins(self):\n169         builtins_ast_module = AstroidManager().builtins_module\n170         return builtins_ast_module.special_attributes.lookup(\"__dict__\")\n171 \n172     @property\n173     def attr_builtins(self):\n174         return self._builtins()\n175 \n176     @property\n177     def attr___path__(self):\n178         if not self._instance.package:\n179             raise AttributeInferenceError(target=self._instance, attribute=\"__path__\")\n180 \n181         path_objs = [\n182             node_classes.Const(\n183                 value=path\n184                 if not path.endswith(\"__init__.py\")\n185                 else os.path.dirname(path),\n186                 parent=self._instance,\n187             )\n188             for path in self._instance.path\n189         ]\n190 \n191         container = node_classes.List(parent=self._instance)\n192         container.postinit(path_objs)\n193 \n194         return container\n195 \n196     @property\n197     def attr___name__(self):\n198         return node_classes.Const(value=self._instance.name, parent=self._instance)\n199 \n200     @property\n201     def attr___doc__(self):\n202         return node_classes.Const(\n203             value=getattr(self._instance.doc_node, \"value\", None),\n204             parent=self._instance,\n205         )\n206 \n207     @property\n208     def attr___file__(self):\n209         return node_classes.Const(value=self._instance.file, parent=self._instance)\n210 \n211     @property\n212     def attr___dict__(self):\n213         return _dunder_dict(self._instance, self._instance.globals)\n214 \n215     @property\n216     def attr___package__(self):\n217         if not self._instance.package:\n218             value = \"\"\n219         else:\n220             value = self._instance.name\n221 \n222         return node_classes.Const(value=value, parent=self._instance)\n223 \n224     # These are related to the Python 3 implementation of the\n225     # import system,\n226     # https://docs.python.org/3/reference/import.html#import-related-module-attributes\n227 \n228     @property\n229     def attr___spec__(self):\n230         # No handling for now.\n231         return node_classes.Unknown()\n232 \n233     @property\n234     def attr___loader__(self):\n235         # No handling for now.\n236         return node_classes.Unknown()\n237 \n238     @property\n239     def attr___cached__(self):\n240         # No handling for now.\n241         return node_classes.Unknown()\n242 \n243 \n244 class FunctionModel(ObjectModel):\n245     @property\n246     def attr___name__(self):\n247         return node_classes.Const(value=self._instance.name, parent=self._instance)\n248 \n249     @property\n250     def attr___doc__(self):\n251         return node_classes.Const(\n252             value=getattr(self._instance.doc_node, \"value\", None),\n253             parent=self._instance,\n254         )\n255 \n256     @property\n257     def attr___qualname__(self):\n258         return node_classes.Const(value=self._instance.qname(), parent=self._instance)\n259 \n260     @property\n261     def attr___defaults__(self):\n262         func = self._instance\n263         if not func.args.defaults:\n264             return node_classes.Const(value=None, parent=func)\n265 \n266         defaults_obj = node_classes.Tuple(parent=func)\n267         defaults_obj.postinit(func.args.defaults)\n268         return defaults_obj\n269 \n270     @property\n271     def attr___annotations__(self):\n272         obj = node_classes.Dict(\n273             parent=self._instance,\n274             lineno=self._instance.lineno,\n275             col_offset=self._instance.col_offset,\n276             end_lineno=self._instance.end_lineno,\n277             end_col_offset=self._instance.end_col_offset,\n278         )\n279 \n280         if not self._instance.returns:\n281             returns = None\n282         else:\n283             returns = self._instance.returns\n284 \n285         args = self._instance.args\n286         pair_annotations = itertools.chain(\n287             zip(args.args or [], args.annotations),\n288             zip(args.kwonlyargs, args.kwonlyargs_annotations),\n289             zip(args.posonlyargs or [], args.posonlyargs_annotations),\n290         )\n291 \n292         annotations = {\n293             arg.name: annotation for (arg, annotation) in pair_annotations if annotation\n294         }\n295         if args.varargannotation:\n296             annotations[args.vararg] = args.varargannotation\n297         if args.kwargannotation:\n298             annotations[args.kwarg] = args.kwargannotation\n299         if returns:\n300             annotations[\"return\"] = returns\n301 \n302         items = [\n303             (node_classes.Const(key, parent=obj), value)\n304             for (key, value) in annotations.items()\n305         ]\n306 \n307         obj.postinit(items)\n308         return obj\n309 \n310     @property\n311     def attr___dict__(self):\n312         return node_classes.Dict(\n313             parent=self._instance,\n314             lineno=self._instance.lineno,\n315             col_offset=self._instance.col_offset,\n316             end_lineno=self._instance.end_lineno,\n317             end_col_offset=self._instance.end_col_offset,\n318         )\n319 \n320     attr___globals__ = attr___dict__\n321 \n322     @property\n323     def attr___kwdefaults__(self):\n324         def _default_args(args, parent):\n325             for arg in args.kwonlyargs:\n326                 try:\n327                     default = args.default_value(arg.name)\n328                 except NoDefault:\n329                     continue\n330 \n331                 name = node_classes.Const(arg.name, parent=parent)\n332                 yield name, default\n333 \n334         args = self._instance.args\n335         obj = node_classes.Dict(\n336             parent=self._instance,\n337             lineno=self._instance.lineno,\n338             col_offset=self._instance.col_offset,\n339             end_lineno=self._instance.end_lineno,\n340             end_col_offset=self._instance.end_col_offset,\n341         )\n342         defaults = dict(_default_args(args, obj))\n343 \n344         obj.postinit(list(defaults.items()))\n345         return obj\n346 \n347     @property\n348     def attr___module__(self):\n349         return node_classes.Const(self._instance.root().qname())\n350 \n351     @property\n352     def attr___get__(self):\n353         func = self._instance\n354 \n355         class DescriptorBoundMethod(bases.BoundMethod):\n356             \"\"\"Bound method which knows how to understand calling descriptor\n357             binding.\n358             \"\"\"\n359 \n360             def implicit_parameters(self) -> Literal[0]:\n361                 # Different than BoundMethod since the signature\n362                 # is different.\n363                 return 0\n364 \n365             def infer_call_result(\n366                 self,\n367                 caller: SuccessfulInferenceResult | None,\n368                 context: InferenceContext | None = None,\n369             ) -> Iterator[bases.BoundMethod]:\n370                 if len(caller.args) > 2 or len(caller.args) < 1:\n371                     raise InferenceError(\n372                         \"Invalid arguments for descriptor binding\",\n373                         target=self,\n374                         context=context,\n375                     )\n376 \n377                 context = copy_context(context)\n378                 try:\n379                     cls = next(caller.args[0].infer(context=context))\n380                 except StopIteration as e:\n381                     raise InferenceError(context=context, node=caller.args[0]) from e\n382 \n383                 if isinstance(cls, util.UninferableBase):\n384                     raise InferenceError(\n385                         \"Invalid class inferred\", target=self, context=context\n386                     )\n387 \n388                 # For some reason func is a Node that the below\n389                 # code is not expecting\n390                 if isinstance(func, bases.BoundMethod):\n391                     yield func\n392                     return\n393 \n394                 # Rebuild the original value, but with the parent set as the\n395                 # class where it will be bound.\n396                 new_func = func.__class__(\n397                     name=func.name,\n398                     lineno=func.lineno,\n399                     col_offset=func.col_offset,\n400                     parent=func.parent,\n401                     end_lineno=func.end_lineno,\n402                     end_col_offset=func.end_col_offset,\n403                 )\n404                 # pylint: disable=no-member\n405                 new_func.postinit(\n406                     func.args,\n407                     func.body,\n408                     func.decorators,\n409                     func.returns,\n410                     doc_node=func.doc_node,\n411                 )\n412 \n413                 # Build a proper bound method that points to our newly built function.\n414                 proxy = bases.UnboundMethod(new_func)\n415                 yield bases.BoundMethod(proxy=proxy, bound=cls)\n416 \n417             @property\n418             def args(self):\n419                 \"\"\"Overwrite the underlying args to match those of the underlying func.\n420 \n421                 Usually the underlying *func* is a function/method, as in:\n422 \n423                     def test(self):\n424                         pass\n425 \n426                 This has only the *self* parameter but when we access test.__get__\n427                 we get a new object which has two parameters, *self* and *type*.\n428                 \"\"\"\n429                 nonlocal func\n430                 arguments = astroid.Arguments(\n431                     parent=func.args.parent, vararg=None, kwarg=None\n432                 )\n433 \n434                 positional_or_keyword_params = func.args.args.copy()\n435                 positional_or_keyword_params.append(\n436                     astroid.AssignName(\n437                         name=\"type\",\n438                         lineno=0,\n439                         col_offset=0,\n440                         parent=arguments,\n441                         end_lineno=None,\n442                         end_col_offset=None,\n443                     )\n444                 )\n445 \n446                 positional_only_params = func.args.posonlyargs.copy()\n447 \n448                 arguments.postinit(\n449                     args=positional_or_keyword_params,\n450                     posonlyargs=positional_only_params,\n451                     defaults=[],\n452                     kwonlyargs=[],\n453                     kw_defaults=[],\n454                     annotations=[],\n455                     kwonlyargs_annotations=[],\n456                     posonlyargs_annotations=[],\n457                 )\n458                 return arguments\n459 \n460         return DescriptorBoundMethod(proxy=self._instance, bound=self._instance)\n461 \n462     # These are here just for completion.\n463     @property\n464     def attr___ne__(self):\n465         return node_classes.Unknown()\n466 \n467     attr___subclasshook__ = attr___ne__\n468     attr___str__ = attr___ne__\n469     attr___sizeof__ = attr___ne__\n470     attr___setattr___ = attr___ne__\n471     attr___repr__ = attr___ne__\n472     attr___reduce__ = attr___ne__\n473     attr___reduce_ex__ = attr___ne__\n474     attr___lt__ = attr___ne__\n475     attr___eq__ = attr___ne__\n476     attr___gt__ = attr___ne__\n477     attr___format__ = attr___ne__\n478     attr___delattr___ = attr___ne__\n479     attr___getattribute__ = attr___ne__\n480     attr___hash__ = attr___ne__\n481     attr___dir__ = attr___ne__\n482     attr___call__ = attr___ne__\n483     attr___class__ = attr___ne__\n484     attr___closure__ = attr___ne__\n485     attr___code__ = attr___ne__\n486 \n487 \n488 class ClassModel(ObjectModel):\n489     def __init__(self):\n490         # Add a context so that inferences called from an instance don't recurse endlessly\n491         self.context = InferenceContext()\n492 \n493         super().__init__()\n494 \n495     @property\n496     def attr___module__(self):\n497         return node_classes.Const(self._instance.root().qname())\n498 \n499     @property\n500     def attr___name__(self):\n501         return node_classes.Const(self._instance.name)\n502 \n503     @property\n504     def attr___qualname__(self):\n505         return node_classes.Const(self._instance.qname())\n506 \n507     @property\n508     def attr___doc__(self):\n509         return node_classes.Const(getattr(self._instance.doc_node, \"value\", None))\n510 \n511     @property\n512     def attr___mro__(self):\n513         if not self._instance.newstyle:\n514             raise AttributeInferenceError(target=self._instance, attribute=\"__mro__\")\n515 \n516         mro = self._instance.mro()\n517         obj = node_classes.Tuple(parent=self._instance)\n518         obj.postinit(mro)\n519         return obj\n520 \n521     @property\n522     def attr_mro(self):\n523         if not self._instance.newstyle:\n524             raise AttributeInferenceError(target=self._instance, attribute=\"mro\")\n525 \n526         other_self = self\n527 \n528         # Cls.mro is a method and we need to return one in order to have a proper inference.\n529         # The method we're returning is capable of inferring the underlying MRO though.\n530         class MroBoundMethod(bases.BoundMethod):\n531             def infer_call_result(\n532                 self,\n533                 caller: SuccessfulInferenceResult | None,\n534                 context: InferenceContext | None = None,\n535             ) -> Iterator[node_classes.Tuple]:\n536                 yield other_self.attr___mro__\n537 \n538         implicit_metaclass = self._instance.implicit_metaclass()\n539         mro_method = implicit_metaclass.locals[\"mro\"][0]\n540         return MroBoundMethod(proxy=mro_method, bound=implicit_metaclass)\n541 \n542     @property\n543     def attr___bases__(self):\n544         obj = node_classes.Tuple()\n545         context = InferenceContext()\n546         elts = list(self._instance._inferred_bases(context))\n547         obj.postinit(elts=elts)\n548         return obj\n549 \n550     @property\n551     def attr___class__(self):\n552         # pylint: disable=import-outside-toplevel; circular import\n553         from astroid import helpers\n554 \n555         return helpers.object_type(self._instance)\n556 \n557     @property\n558     def attr___subclasses__(self):\n559         \"\"\"Get the subclasses of the underlying class.\n560 \n561         This looks only in the current module for retrieving the subclasses,\n562         thus it might miss a couple of them.\n563         \"\"\"\n564         if not self._instance.newstyle:\n565             raise AttributeInferenceError(\n566                 target=self._instance, attribute=\"__subclasses__\"\n567             )\n568 \n569         qname = self._instance.qname()\n570         root = self._instance.root()\n571         classes = [\n572             cls\n573             for cls in root.nodes_of_class(nodes.ClassDef)\n574             if cls != self._instance and cls.is_subtype_of(qname, context=self.context)\n575         ]\n576 \n577         obj = node_classes.List(parent=self._instance)\n578         obj.postinit(classes)\n579 \n580         class SubclassesBoundMethod(bases.BoundMethod):\n581             def infer_call_result(\n582                 self,\n583                 caller: SuccessfulInferenceResult | None,\n584                 context: InferenceContext | None = None,\n585             ) -> Iterator[node_classes.List]:\n586                 yield obj\n587 \n588         implicit_metaclass = self._instance.implicit_metaclass()\n589         subclasses_method = implicit_metaclass.locals[\"__subclasses__\"][0]\n590         return SubclassesBoundMethod(proxy=subclasses_method, bound=implicit_metaclass)\n591 \n592     @property\n593     def attr___dict__(self):\n594         return node_classes.Dict(\n595             parent=self._instance,\n596             lineno=self._instance.lineno,\n597             col_offset=self._instance.col_offset,\n598             end_lineno=self._instance.end_lineno,\n599             end_col_offset=self._instance.end_col_offset,\n600         )\n601 \n602     @property\n603     def attr___call__(self):\n604         \"\"\"Calling a class A() returns an instance of A.\"\"\"\n605         return self._instance.instantiate_class()\n606 \n607 \n608 class SuperModel(ObjectModel):\n609     @property\n610     def attr___thisclass__(self):\n611         return self._instance.mro_pointer\n612 \n613     @property\n614     def attr___self_class__(self):\n615         return self._instance._self_class\n616 \n617     @property\n618     def attr___self__(self):\n619         return self._instance.type\n620 \n621     @property\n622     def attr___class__(self):\n623         return self._instance._proxied\n624 \n625 \n626 class UnboundMethodModel(ObjectModel):\n627     @property\n628     def attr___class__(self):\n629         # pylint: disable=import-outside-toplevel; circular import\n630         from astroid import helpers\n631 \n632         return helpers.object_type(self._instance)\n633 \n634     @property\n635     def attr___func__(self):\n636         return self._instance._proxied\n637 \n638     @property\n639     def attr___self__(self):\n640         return node_classes.Const(value=None, parent=self._instance)\n641 \n642     attr_im_func = attr___func__\n643     attr_im_class = attr___class__\n644     attr_im_self = attr___self__\n645 \n646 \n647 class ContextManagerModel(ObjectModel):\n648     \"\"\"Model for context managers.\n649 \n650     Based on 3.3.9 of the Data Model documentation:\n651     https://docs.python.org/3/reference/datamodel.html#with-statement-context-managers\n652     \"\"\"\n653 \n654     @property\n655     def attr___enter__(self) -> bases.BoundMethod:\n656         \"\"\"Representation of the base implementation of __enter__.\n657 \n658         As per Python documentation:\n659         Enter the runtime context related to this object. The with statement\n660         will bind this method's return value to the target(s) specified in the\n661         as clause of the statement, if any.\n662         \"\"\"\n663         from astroid import builder  # pylint: disable=import-outside-toplevel\n664 \n665         node: nodes.FunctionDef = builder.extract_node(\"\"\"def __enter__(self): ...\"\"\")\n666         # We set the parent as being the ClassDef of 'object' as that\n667         # is where this method originally comes from\n668         node.parent = AstroidManager().builtins_module[\"object\"]\n669 \n670         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n671 \n672     @property\n673     def attr___exit__(self) -> bases.BoundMethod:\n674         \"\"\"Representation of the base implementation of __exit__.\n675 \n676         As per Python documentation:\n677         Exit the runtime context related to this object. The parameters describe the\n678         exception that caused the context to be exited. If the context was exited\n679         without an exception, all three arguments will be None.\n680         \"\"\"\n681         from astroid import builder  # pylint: disable=import-outside-toplevel\n682 \n683         node: nodes.FunctionDef = builder.extract_node(\n684             \"\"\"def __exit__(self, exc_type, exc_value, traceback): ...\"\"\"\n685         )\n686         # We set the parent as being the ClassDef of 'object' as that\n687         # is where this method originally comes from\n688         node.parent = AstroidManager().builtins_module[\"object\"]\n689 \n690         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n691 \n692 \n693 class BoundMethodModel(FunctionModel):\n694     @property\n695     def attr___func__(self):\n696         return self._instance._proxied._proxied\n697 \n698     @property\n699     def attr___self__(self):\n700         return self._instance.bound\n701 \n702 \n703 class GeneratorModel(FunctionModel, ContextManagerModel):\n704     def __new__(cls, *args, **kwargs):\n705         # Append the values from the GeneratorType unto this object.\n706         ret = super().__new__(cls, *args, **kwargs)\n707         generator = AstroidManager().builtins_module[\"generator\"]\n708         for name, values in generator.locals.items():\n709             method = values[0]\n710 \n711             def patched(cls, meth=method):\n712                 return meth\n713 \n714             setattr(type(ret), IMPL_PREFIX + name, property(patched))\n715 \n716         return ret\n717 \n718     @property\n719     def attr___name__(self):\n720         return node_classes.Const(\n721             value=self._instance.parent.name, parent=self._instance\n722         )\n723 \n724     @property\n725     def attr___doc__(self):\n726         return node_classes.Const(\n727             value=getattr(self._instance.parent.doc_node, \"value\", None),\n728             parent=self._instance,\n729         )\n730 \n731 \n732 class AsyncGeneratorModel(GeneratorModel):\n733     def __new__(cls, *args, **kwargs):\n734         # Append the values from the AGeneratorType unto this object.\n735         ret = super().__new__(cls, *args, **kwargs)\n736         astroid_builtins = AstroidManager().builtins_module\n737         generator = astroid_builtins.get(\"async_generator\")\n738         if generator is None:\n739             # Make it backward compatible.\n740             generator = astroid_builtins.get(\"generator\")\n741 \n742         for name, values in generator.locals.items():\n743             method = values[0]\n744 \n745             def patched(cls, meth=method):\n746                 return meth\n747 \n748             setattr(type(ret), IMPL_PREFIX + name, property(patched))\n749 \n750         return ret\n751 \n752 \n753 class InstanceModel(ObjectModel):\n754     @property\n755     def attr___class__(self):\n756         return self._instance._proxied\n757 \n758     @property\n759     def attr___module__(self):\n760         return node_classes.Const(self._instance.root().qname())\n761 \n762     @property\n763     def attr___doc__(self):\n764         return node_classes.Const(getattr(self._instance.doc_node, \"value\", None))\n765 \n766     @property\n767     def attr___dict__(self):\n768         return _dunder_dict(self._instance, self._instance.instance_attrs)\n769 \n770 \n771 # Exception instances\n772 \n773 \n774 class ExceptionInstanceModel(InstanceModel):\n775     @property\n776     def attr_args(self) -> nodes.Tuple:\n777         return nodes.Tuple(parent=self._instance)\n778 \n779     @property\n780     def attr___traceback__(self):\n781         builtins_ast_module = AstroidManager().builtins_module\n782         traceback_type = builtins_ast_module[types.TracebackType.__name__]\n783         return traceback_type.instantiate_class()\n784 \n785 \n786 class SyntaxErrorInstanceModel(ExceptionInstanceModel):\n787     @property\n788     def attr_text(self):\n789         return node_classes.Const(\"\")\n790 \n791 \n792 class OSErrorInstanceModel(ExceptionInstanceModel):\n793     @property\n794     def attr_filename(self):\n795         return node_classes.Const(\"\")\n796 \n797     @property\n798     def attr_errno(self):\n799         return node_classes.Const(0)\n800 \n801     @property\n802     def attr_strerror(self):\n803         return node_classes.Const(\"\")\n804 \n805     attr_filename2 = attr_filename\n806 \n807 \n808 class ImportErrorInstanceModel(ExceptionInstanceModel):\n809     @property\n810     def attr_name(self):\n811         return node_classes.Const(\"\")\n812 \n813     @property\n814     def attr_path(self):\n815         return node_classes.Const(\"\")\n816 \n817 \n818 class UnicodeDecodeErrorInstanceModel(ExceptionInstanceModel):\n819     @property\n820     def attr_object(self):\n821         return node_classes.Const(\"\")\n822 \n823 \n824 BUILTIN_EXCEPTIONS = {\n825     \"builtins.SyntaxError\": SyntaxErrorInstanceModel,\n826     \"builtins.ImportError\": ImportErrorInstanceModel,\n827     \"builtins.UnicodeDecodeError\": UnicodeDecodeErrorInstanceModel,\n828     # These are all similar to OSError in terms of attributes\n829     \"builtins.OSError\": OSErrorInstanceModel,\n830     \"builtins.BlockingIOError\": OSErrorInstanceModel,\n831     \"builtins.BrokenPipeError\": OSErrorInstanceModel,\n832     \"builtins.ChildProcessError\": OSErrorInstanceModel,\n833     \"builtins.ConnectionAbortedError\": OSErrorInstanceModel,\n834     \"builtins.ConnectionError\": OSErrorInstanceModel,\n835     \"builtins.ConnectionRefusedError\": OSErrorInstanceModel,\n836     \"builtins.ConnectionResetError\": OSErrorInstanceModel,\n837     \"builtins.FileExistsError\": OSErrorInstanceModel,\n838     \"builtins.FileNotFoundError\": OSErrorInstanceModel,\n839     \"builtins.InterruptedError\": OSErrorInstanceModel,\n840     \"builtins.IsADirectoryError\": OSErrorInstanceModel,\n841     \"builtins.NotADirectoryError\": OSErrorInstanceModel,\n842     \"builtins.PermissionError\": OSErrorInstanceModel,\n843     \"builtins.ProcessLookupError\": OSErrorInstanceModel,\n844     \"builtins.TimeoutError\": OSErrorInstanceModel,\n845 }\n846 \n847 \n848 class DictModel(ObjectModel):\n849     @property\n850     def attr___class__(self):\n851         return self._instance._proxied\n852 \n853     def _generic_dict_attribute(self, obj, name):\n854         \"\"\"Generate a bound method that can infer the given *obj*.\"\"\"\n855 \n856         class DictMethodBoundMethod(astroid.BoundMethod):\n857             def infer_call_result(\n858                 self,\n859                 caller: SuccessfulInferenceResult | None,\n860                 context: InferenceContext | None = None,\n861             ) -> Iterator[InferenceResult]:\n862                 yield obj\n863 \n864         meth = next(self._instance._proxied.igetattr(name), None)\n865         return DictMethodBoundMethod(proxy=meth, bound=self._instance)\n866 \n867     @property\n868     def attr_items(self):\n869         from astroid import objects  # pylint: disable=import-outside-toplevel\n870 \n871         elems = []\n872         obj = node_classes.List(parent=self._instance)\n873         for key, value in self._instance.items:\n874             elem = node_classes.Tuple(parent=obj)\n875             elem.postinit((key, value))\n876             elems.append(elem)\n877         obj.postinit(elts=elems)\n878 \n879         items_obj = objects.DictItems(obj)\n880         return self._generic_dict_attribute(items_obj, \"items\")\n881 \n882     @property\n883     def attr_keys(self):\n884         from astroid import objects  # pylint: disable=import-outside-toplevel\n885 \n886         keys = [key for (key, _) in self._instance.items]\n887         obj = node_classes.List(parent=self._instance)\n888         obj.postinit(elts=keys)\n889 \n890         keys_obj = objects.DictKeys(obj)\n891         return self._generic_dict_attribute(keys_obj, \"keys\")\n892 \n893     @property\n894     def attr_values(self):\n895         from astroid import objects  # pylint: disable=import-outside-toplevel\n896 \n897         values = [value for (_, value) in self._instance.items]\n898         obj = node_classes.List(parent=self._instance)\n899         obj.postinit(values)\n900 \n901         values_obj = objects.DictValues(obj)\n902         return self._generic_dict_attribute(values_obj, \"values\")\n903 \n904 \n905 class PropertyModel(ObjectModel):\n906     \"\"\"Model for a builtin property.\"\"\"\n907 \n908     def _init_function(self, name):\n909         function = nodes.FunctionDef(\n910             name=name,\n911             parent=self._instance,\n912             lineno=self._instance.lineno,\n913             col_offset=self._instance.col_offset,\n914             end_lineno=self._instance.end_lineno,\n915             end_col_offset=self._instance.end_col_offset,\n916         )\n917 \n918         args = nodes.Arguments(parent=function, vararg=None, kwarg=None)\n919         args.postinit(\n920             args=[],\n921             defaults=[],\n922             kwonlyargs=[],\n923             kw_defaults=[],\n924             annotations=[],\n925             posonlyargs=[],\n926             posonlyargs_annotations=[],\n927             kwonlyargs_annotations=[],\n928         )\n929 \n930         function.postinit(args=args, body=[])\n931         return function\n932 \n933     @property\n934     def attr_fget(self):\n935         func = self._instance\n936 \n937         class PropertyFuncAccessor(nodes.FunctionDef):\n938             def infer_call_result(\n939                 self,\n940                 caller: SuccessfulInferenceResult | None,\n941                 context: InferenceContext | None = None,\n942             ) -> Iterator[InferenceResult]:\n943                 nonlocal func\n944                 if caller and len(caller.args) != 1:\n945                     raise InferenceError(\n946                         \"fget() needs a single argument\", target=self, context=context\n947                     )\n948 \n949                 yield from func.function.infer_call_result(\n950                     caller=caller, context=context\n951                 )\n952 \n953         property_accessor = PropertyFuncAccessor(\n954             name=\"fget\",\n955             parent=self._instance,\n956             lineno=self._instance.lineno,\n957             col_offset=self._instance.col_offset,\n958             end_lineno=self._instance.end_lineno,\n959             end_col_offset=self._instance.end_col_offset,\n960         )\n961         property_accessor.postinit(args=func.args, body=func.body)\n962         return property_accessor\n963 \n964     @property\n965     def attr_fset(self):\n966         func = self._instance\n967 \n968         def find_setter(func: Property) -> astroid.FunctionDef | None:\n969             \"\"\"\n970             Given a property, find the corresponding setter function and returns it.\n971 \n972             :param func: property for which the setter has to be found\n973             :return: the setter function or None\n974             \"\"\"\n975             for target in [\n976                 t for t in func.parent.get_children() if t.name == func.function.name\n977             ]:\n978                 for dec_name in target.decoratornames():\n979                     if dec_name.endswith(func.function.name + \".setter\"):\n980                         return target\n981             return None\n982 \n983         func_setter = find_setter(func)\n984         if not func_setter:\n985             raise InferenceError(\n986                 f\"Unable to find the setter of property {func.function.name}\"\n987             )\n988 \n989         class PropertyFuncAccessor(nodes.FunctionDef):\n990             def infer_call_result(\n991                 self,\n992                 caller: SuccessfulInferenceResult | None,\n993                 context: InferenceContext | None = None,\n994             ) -> Iterator[InferenceResult]:\n995                 nonlocal func_setter\n996                 if caller and len(caller.args) != 2:\n997                     raise InferenceError(\n998                         \"fset() needs two arguments\", target=self, context=context\n999                     )\n1000                 yield from func_setter.infer_call_result(caller=caller, context=context)\n1001 \n1002         property_accessor = PropertyFuncAccessor(\n1003             name=\"fset\",\n1004             parent=self._instance,\n1005             lineno=self._instance.lineno,\n1006             col_offset=self._instance.col_offset,\n1007             end_lineno=self._instance.end_lineno,\n1008             end_col_offset=self._instance.end_col_offset,\n1009         )\n1010         property_accessor.postinit(args=func_setter.args, body=func_setter.body)\n1011         return property_accessor\n1012 \n1013     @property\n1014     def attr_setter(self):\n1015         return self._init_function(\"setter\")\n1016 \n1017     @property\n1018     def attr_deleter(self):\n1019         return self._init_function(\"deleter\")\n1020 \n1021     @property\n1022     def attr_getter(self):\n1023         return self._init_function(\"getter\")\n1024 \n1025     # pylint: enable=import-outside-toplevel\n1026 \n[end of astroid/interpreter/objectmodel.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pylint-dev/astroid", "base_commit": "514991036806e9cda2b12cef8ab3184ac373bd6c", "problem_statement": "`.arguments` property ignores keyword-only args, *args, and **kwargs\n```python\r\n>>> from astroid import extract_node\r\n>>> node = extract_node(\"\"\"def a(*args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[]\r\n```\r\n\r\nExpected to find all the arguments from the function signature.\r\n\r\nThe wanted data can be found here:\r\n\r\n```python\r\n>>> node.args.vararg\r\n'args'\r\n>>> node.args.kwarg\r\n'kwargs'\r\n>>> node.args.kwonlyargs\r\n[<AssignName.b l.1 at 0x1048189b0>, <AssignName.c l.1 at 0x104818830>]\r\n```\r\n\r\nDiscussed at https://github.com/pylint-dev/pylint/pull/7577#discussion_r989000829.\r\n\r\nNotice that positional-only args are found for some reason \ud83e\udd37 \n", "hints_text": "Should the definition be changed as well? It states `args.arguments` returns required arguments, and AFAIK in the example none are required (I can call `a` without supplying any arguments).\r\n\r\nI tried running the following:\r\n\r\n```\r\n>>> node = extract_node(\"\"\"def a(kiwi, apple, *args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[<AssignName.kiwi l.1 at 0x7f5c55986b90>, <AssignName.apple l.1 at 0x7f5c55985a50>]\r\n```\r\n\r\nAnd it seems correct to me :thinking: \nhttps://github.com/pylint-dev/astroid/blob/fef38f2dd474b0dacd1dda3f15abbf61eb0e9a71/astroid/nodes/node_classes.py#L685-L688\r\n\r\nThe docstring seems to be correct?\nDepends on how you parse the language. \"positional and keyword\" could describe the argument `kiwi` and exclude keyword-only arguments.\r\n\r\nEssentially, the crux of this is whether we should\r\n- leave the function as is, and audit everywhere that uses it (given that we keep finding bugs)\r\n- change the function\r\n\r\n@crazybolillo have you happened to sample the places that use this function to be able to offer a view on that? I'd be eager to hear it!\nI think I got confused about the documentation :sob:. I was reading the docstring for `args` (`node.args.args` in the example):\r\n\r\nhttps://github.com/pylint-dev/astroid/blob/d4f4452fe089f600bf9144ffdcd8e698816df3c2/astroid/nodes/node_classes.py#L554-L555\r\n\r\n but we are dealing with `arguments` (`node.args.arguments`). I will review the code further to see if I can come up with something\r\n\r\n", "created_at": "2023-07-06T20:52:39Z", "patch": "<patch>\ndiff --git a/astroid/arguments.py b/astroid/arguments.py\n--- a/astroid/arguments.py\n+++ b/astroid/arguments.py\n@@ -181,7 +181,13 @@ def infer_argument(\n \n         positional = self.positional_arguments[: len(funcnode.args.args)]\n         vararg = self.positional_arguments[len(funcnode.args.args) :]\n-        argindex = funcnode.args.find_argname(name)[0]\n+\n+        # preserving previous behavior, when vararg and kwarg were not included in find_argname results\n+        if name in [funcnode.args.vararg, funcnode.args.kwarg]:\n+            argindex = None\n+        else:\n+            argindex = funcnode.args.find_argname(name)[0]\n+\n         kwonlyargs = {arg.name for arg in funcnode.args.kwonlyargs}\n         kwargs = {\n             key: value\ndiff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -605,7 +605,9 @@ def _infer(\n DEPRECATED_ARGUMENT_DEFAULT = \"DEPRECATED_ARGUMENT_DEFAULT\"\n \n \n-class Arguments(_base_nodes.AssignTypeNode):\n+class Arguments(\n+    _base_nodes.AssignTypeNode\n+):  # pylint: disable=too-many-instance-attributes\n     \"\"\"Class representing an :class:`ast.arguments` node.\n \n     An :class:`Arguments` node represents that arguments in a\n@@ -704,7 +706,20 @@ class Arguments(_base_nodes.AssignTypeNode):\n     kwargannotation: NodeNG | None\n     \"\"\"The type annotation for the variable length keyword arguments.\"\"\"\n \n-    def __init__(self, vararg: str | None, kwarg: str | None, parent: NodeNG) -> None:\n+    vararg_node: AssignName | None\n+    \"\"\"The node for variable length arguments\"\"\"\n+\n+    kwarg_node: AssignName | None\n+    \"\"\"The node for variable keyword arguments\"\"\"\n+\n+    def __init__(\n+        self,\n+        vararg: str | None,\n+        kwarg: str | None,\n+        parent: NodeNG,\n+        vararg_node: AssignName | None = None,\n+        kwarg_node: AssignName | None = None,\n+    ) -> None:\n         \"\"\"Almost all attributes can be None for living objects where introspection failed.\"\"\"\n         super().__init__(\n             parent=parent,\n@@ -720,6 +735,9 @@ def __init__(self, vararg: str | None, kwarg: str | None, parent: NodeNG) -> Non\n         self.kwarg = kwarg\n         \"\"\"The name of the variable length keyword arguments.\"\"\"\n \n+        self.vararg_node = vararg_node\n+        self.kwarg_node = kwarg_node\n+\n     # pylint: disable=too-many-arguments\n     def postinit(\n         self,\n@@ -780,8 +798,21 @@ def fromlineno(self) -> int:\n \n     @cached_property\n     def arguments(self):\n-        \"\"\"Get all the arguments for this node, including positional only and positional and keyword\"\"\"\n-        return list(itertools.chain((self.posonlyargs or ()), self.args or ()))\n+        \"\"\"Get all the arguments for this node. This includes:\n+        * Positional only arguments\n+        * Positional arguments\n+        * Keyword arguments\n+        * Variable arguments (.e.g *args)\n+        * Variable keyword arguments (e.g **kwargs)\n+        \"\"\"\n+        retval = list(itertools.chain((self.posonlyargs or ()), (self.args or ())))\n+        if self.vararg_node:\n+            retval.append(self.vararg_node)\n+        retval += self.kwonlyargs or ()\n+        if self.kwarg_node:\n+            retval.append(self.kwarg_node)\n+\n+        return retval\n \n     def format_args(self, *, skippable_names: set[str] | None = None) -> str:\n         \"\"\"Get the arguments formatted as string.\n@@ -911,15 +942,20 @@ def default_value(self, argname):\n         :raises NoDefault: If there is no default value defined for the\n             given argument.\n         \"\"\"\n-        args = self.arguments\n+        args = [\n+            arg for arg in self.arguments if arg.name not in [self.vararg, self.kwarg]\n+        ]\n+\n+        index = _find_arg(argname, self.kwonlyargs)[0]\n+        if index is not None and self.kw_defaults[index] is not None:\n+            return self.kw_defaults[index]\n+\n         index = _find_arg(argname, args)[0]\n         if index is not None:\n-            idx = index - (len(args) - len(self.defaults))\n+            idx = index - (len(args) - len(self.defaults) - len(self.kw_defaults))\n             if idx >= 0:\n                 return self.defaults[idx]\n-        index = _find_arg(argname, self.kwonlyargs)[0]\n-        if index is not None and self.kw_defaults[index] is not None:\n-            return self.kw_defaults[index]\n+\n         raise NoDefault(func=self.parent, name=argname)\n \n     def is_argument(self, name) -> bool:\n@@ -934,11 +970,7 @@ def is_argument(self, name) -> bool:\n             return True\n         if name == self.kwarg:\n             return True\n-        return (\n-            self.find_argname(name)[1] is not None\n-            or self.kwonlyargs\n-            and _find_arg(name, self.kwonlyargs)[1] is not None\n-        )\n+        return self.find_argname(name)[1] is not None\n \n     def find_argname(self, argname, rec=DEPRECATED_ARGUMENT_DEFAULT):\n         \"\"\"Get the index and :class:`AssignName` node for given name.\n@@ -956,7 +988,9 @@ def find_argname(self, argname, rec=DEPRECATED_ARGUMENT_DEFAULT):\n                 stacklevel=2,\n             )\n         if self.arguments:\n-            return _find_arg(argname, self.arguments)\n+            index, argument = _find_arg(argname, self.arguments)\n+            if argument:\n+                return index, argument\n         return None, None\n \n     def get_children(self):\ndiff --git a/astroid/nodes/scoped_nodes/scoped_nodes.py b/astroid/nodes/scoped_nodes/scoped_nodes.py\n--- a/astroid/nodes/scoped_nodes/scoped_nodes.py\n+++ b/astroid/nodes/scoped_nodes/scoped_nodes.py\n@@ -963,11 +963,7 @@ def argnames(self) -> list[str]:\n             names = [elt.name for elt in self.args.arguments]\n         else:\n             names = []\n-        if self.args.vararg:\n-            names.append(self.args.vararg)\n-        names += [elt.name for elt in self.args.kwonlyargs]\n-        if self.args.kwarg:\n-            names.append(self.args.kwarg)\n+\n         return names\n \n     def infer_call_result(\n@@ -1280,11 +1276,7 @@ def argnames(self) -> list[str]:\n             names = [elt.name for elt in self.args.arguments]\n         else:\n             names = []\n-        if self.args.vararg:\n-            names.append(self.args.vararg)\n-        names += [elt.name for elt in self.args.kwonlyargs]\n-        if self.args.kwarg:\n-            names.append(self.args.kwarg)\n+\n         return names\n \n     def getattr(\ndiff --git a/astroid/protocols.py b/astroid/protocols.py\n--- a/astroid/protocols.py\n+++ b/astroid/protocols.py\n@@ -352,14 +352,15 @@ def _arguments_infer_argname(\n     # more\n     from astroid import arguments  # pylint: disable=import-outside-toplevel\n \n-    if not (self.arguments or self.vararg or self.kwarg):\n+    if not self.arguments:\n         yield util.Uninferable\n         return\n \n+    args = [arg for arg in self.arguments if arg.name not in [self.vararg, self.kwarg]]\n     functype = self.parent.type\n     # first argument of instance/class method\n     if (\n-        self.arguments\n+        args\n         and getattr(self.arguments[0], \"name\", None) == name\n         and functype != \"staticmethod\"\n     ):\n@@ -388,7 +389,7 @@ def _arguments_infer_argname(\n     if name == self.vararg:\n         vararg = nodes.const_factory(())\n         vararg.parent = self\n-        if not self.arguments and self.parent.name == \"__init__\":\n+        if not args and self.parent.name == \"__init__\":\n             cls = self.parent.parent.scope()\n             vararg.elts = [cls.instantiate_class()]\n         yield vararg\ndiff --git a/astroid/rebuilder.py b/astroid/rebuilder.py\n--- a/astroid/rebuilder.py\n+++ b/astroid/rebuilder.py\n@@ -21,6 +21,7 @@\n from astroid.const import IS_PYPY, PY38, PY39_PLUS, PY312_PLUS, Context\n from astroid.manager import AstroidManager\n from astroid.nodes import NodeNG\n+from astroid.nodes.node_classes import AssignName\n from astroid.nodes.utils import Position\n from astroid.typing import InferenceResult\n \n@@ -561,10 +562,33 @@ def visit_arguments(self, node: ast.arguments, parent: NodeNG) -> nodes.Argument\n         \"\"\"Visit an Arguments node by returning a fresh instance of it.\"\"\"\n         vararg: str | None = None\n         kwarg: str | None = None\n+        vararg_node = node.vararg\n+        kwarg_node = node.kwarg\n+\n         newnode = nodes.Arguments(\n             node.vararg.arg if node.vararg else None,\n             node.kwarg.arg if node.kwarg else None,\n             parent,\n+            AssignName(\n+                vararg_node.arg,\n+                vararg_node.lineno,\n+                vararg_node.col_offset,\n+                parent,\n+                end_lineno=vararg_node.end_lineno,\n+                end_col_offset=vararg_node.end_col_offset,\n+            )\n+            if vararg_node\n+            else None,\n+            AssignName(\n+                kwarg_node.arg,\n+                kwarg_node.lineno,\n+                kwarg_node.col_offset,\n+                parent,\n+                end_lineno=kwarg_node.end_lineno,\n+                end_col_offset=kwarg_node.end_col_offset,\n+            )\n+            if kwarg_node\n+            else None,\n         )\n         args = [self.visit(child, newnode) for child in node.args]\n         defaults = [self.visit(child, newnode) for child in node.defaults]\n\n</patch>", "test_patch": "diff --git a/tests/test_nodes.py b/tests/test_nodes.py\n--- a/tests/test_nodes.py\n+++ b/tests/test_nodes.py\n@@ -22,6 +22,7 @@\n     Uninferable,\n     bases,\n     builder,\n+    extract_node,\n     nodes,\n     parse,\n     test_utils,\n@@ -1975,3 +1976,38 @@ def test_str_repr_no_warnings(node):\n     test_node = node(**args)\n     str(test_node)\n     repr(test_node)\n+\n+\n+def test_arguments_contains_all():\n+    \"\"\"Ensure Arguments.arguments actually returns all available arguments\"\"\"\n+\n+    def manually_get_args(arg_node) -> set:\n+        names = set()\n+        if arg_node.args.vararg:\n+            names.add(arg_node.args.vararg)\n+        if arg_node.args.kwarg:\n+            names.add(arg_node.args.kwarg)\n+\n+        names.update([x.name for x in arg_node.args.args])\n+        names.update([x.name for x in arg_node.args.kwonlyargs])\n+\n+        return names\n+\n+    node = extract_node(\"\"\"def a(fruit: str, *args, b=None, c=None, **kwargs): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+    node = extract_node(\"\"\"def a(mango: int, b=\"banana\", c=None, **kwargs): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+    node = extract_node(\"\"\"def a(self, num = 10, *args): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+\n+def test_arguments_default_value():\n+    node = extract_node(\n+        \"def fruit(eat='please', *, peel='no', trim='yes', **kwargs): ...\"\n+    )\n+    assert node.args.default_value(\"eat\").value == \"please\"\n+\n+    node = extract_node(\"def fruit(seeds, flavor='good', *, peel='maybe'): ...\")\n+    assert node.args.default_value(\"flavor\").value == \"good\"\n", "version": "3.0", "FAIL_TO_PASS": "[\"tests/test_nodes.py::test_arguments_contains_all\"]", "PASS_TO_PASS": "[\"tests/test_nodes.py::AsStringTest::test_3k_annotations_and_metaclass\", \"tests/test_nodes.py::AsStringTest::test_3k_as_string\", \"tests/test_nodes.py::AsStringTest::test_as_string\", \"tests/test_nodes.py::AsStringTest::test_as_string_for_list_containing_uninferable\", \"tests/test_nodes.py::AsStringTest::test_as_string_unknown\", \"tests/test_nodes.py::AsStringTest::test_class_def\", \"tests/test_nodes.py::AsStringTest::test_ellipsis\", \"tests/test_nodes.py::AsStringTest::test_f_strings\", \"tests/test_nodes.py::AsStringTest::test_frozenset_as_string\", \"tests/test_nodes.py::AsStringTest::test_func_signature_issue_185\", \"tests/test_nodes.py::AsStringTest::test_int_attribute\", \"tests/test_nodes.py::AsStringTest::test_module2_as_string\", \"tests/test_nodes.py::AsStringTest::test_module_as_string\", \"tests/test_nodes.py::AsStringTest::test_operator_precedence\", \"tests/test_nodes.py::AsStringTest::test_slice_and_subscripts\", \"tests/test_nodes.py::AsStringTest::test_slices\", \"tests/test_nodes.py::AsStringTest::test_tuple_as_string\", \"tests/test_nodes.py::AsStringTest::test_varargs_kwargs_as_string\", \"tests/test_nodes.py::IfNodeTest::test_block_range\", \"tests/test_nodes.py::IfNodeTest::test_if_elif_else_node\", \"tests/test_nodes.py::TryNodeTest::test_block_range\", \"tests/test_nodes.py::TryExceptNodeTest::test_block_range\", \"tests/test_nodes.py::TryFinallyNodeTest::test_block_range\", \"tests/test_nodes.py::TryExceptFinallyNodeTest::test_block_range\", \"tests/test_nodes.py::ImportNodeTest::test_absolute_import\", \"tests/test_nodes.py::ImportNodeTest::test_as_string\", \"tests/test_nodes.py::ImportNodeTest::test_bad_import_inference\", \"tests/test_nodes.py::ImportNodeTest::test_conditional\", \"tests/test_nodes.py::ImportNodeTest::test_conditional_import\", \"tests/test_nodes.py::ImportNodeTest::test_from_self_resolve\", \"tests/test_nodes.py::ImportNodeTest::test_import_self_resolve\", \"tests/test_nodes.py::ImportNodeTest::test_more_absolute_import\", \"tests/test_nodes.py::ImportNodeTest::test_real_name\", \"tests/test_nodes.py::CmpNodeTest::test_as_string\", \"tests/test_nodes.py::ConstNodeTest::test_bool\", \"tests/test_nodes.py::ConstNodeTest::test_complex\", \"tests/test_nodes.py::ConstNodeTest::test_copy\", \"tests/test_nodes.py::ConstNodeTest::test_float\", \"tests/test_nodes.py::ConstNodeTest::test_int\", \"tests/test_nodes.py::ConstNodeTest::test_none\", \"tests/test_nodes.py::ConstNodeTest::test_str\", \"tests/test_nodes.py::ConstNodeTest::test_str_kind\", \"tests/test_nodes.py::ConstNodeTest::test_unicode\", \"tests/test_nodes.py::NameNodeTest::test_assign_to_true\", \"tests/test_nodes.py::TestNamedExprNode::test_frame\", \"tests/test_nodes.py::TestNamedExprNode::test_scope\", \"tests/test_nodes.py::AnnAssignNodeTest::test_as_string\", \"tests/test_nodes.py::AnnAssignNodeTest::test_complex\", \"tests/test_nodes.py::AnnAssignNodeTest::test_primitive\", \"tests/test_nodes.py::AnnAssignNodeTest::test_primitive_without_initial_value\", \"tests/test_nodes.py::ArgumentsNodeTC::test_kwoargs\", \"tests/test_nodes.py::ArgumentsNodeTC::test_linenumbering\", \"tests/test_nodes.py::ArgumentsNodeTC::test_positional_only\", \"tests/test_nodes.py::UnboundMethodNodeTest::test_no_super_getattr\", \"tests/test_nodes.py::BoundMethodNodeTest::test_is_property\", \"tests/test_nodes.py::AliasesTest::test_aliases\", \"tests/test_nodes.py::Python35AsyncTest::test_async_await_keywords\", \"tests/test_nodes.py::Python35AsyncTest::test_asyncfor_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_asyncwith_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_await_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_decorated_async_def_as_string\", \"tests/test_nodes.py::ContextTest::test_list_del\", \"tests/test_nodes.py::ContextTest::test_list_load\", \"tests/test_nodes.py::ContextTest::test_list_store\", \"tests/test_nodes.py::ContextTest::test_starred_load\", \"tests/test_nodes.py::ContextTest::test_starred_store\", \"tests/test_nodes.py::ContextTest::test_subscript_del\", \"tests/test_nodes.py::ContextTest::test_subscript_load\", \"tests/test_nodes.py::ContextTest::test_subscript_store\", \"tests/test_nodes.py::ContextTest::test_tuple_load\", \"tests/test_nodes.py::ContextTest::test_tuple_store\", \"tests/test_nodes.py::test_unknown\", \"tests/test_nodes.py::test_type_comments_with\", \"tests/test_nodes.py::test_type_comments_for\", \"tests/test_nodes.py::test_type_coments_assign\", \"tests/test_nodes.py::test_type_comments_invalid_expression\", \"tests/test_nodes.py::test_type_comments_invalid_function_comments\", \"tests/test_nodes.py::test_type_comments_function\", \"tests/test_nodes.py::test_type_comments_arguments\", \"tests/test_nodes.py::test_type_comments_posonly_arguments\", \"tests/test_nodes.py::test_correct_function_type_comment_parent\", \"tests/test_nodes.py::test_is_generator_for_yield_assignments\", \"tests/test_nodes.py::test_f_string_correct_line_numbering\", \"tests/test_nodes.py::test_assignment_expression\", \"tests/test_nodes.py::test_assignment_expression_in_functiondef\", \"tests/test_nodes.py::test_get_doc\", \"tests/test_nodes.py::test_parse_fstring_debug_mode\", \"tests/test_nodes.py::test_parse_type_comments_with_proper_parent\", \"tests/test_nodes.py::test_const_itered\", \"tests/test_nodes.py::test_is_generator_for_yield_in_while\", \"tests/test_nodes.py::test_is_generator_for_yield_in_if\", \"tests/test_nodes.py::test_is_generator_for_yield_in_aug_assign\", \"tests/test_nodes.py::test_str_repr_no_warnings[AnnAssign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Arguments]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Assert]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Assign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AssignAttr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AssignName]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncFor]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncFunctionDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncWith]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Attribute]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AugAssign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Await]\", \"tests/test_nodes.py::test_str_repr_no_warnings[BinOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[BoolOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Break]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Call]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ClassDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Compare]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Comprehension]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ComprehensionScope]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Const]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Continue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Decorators]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DelAttr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Delete]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DelName]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Dict]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DictComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DictUnpack]\", \"tests/test_nodes.py::test_str_repr_no_warnings[EmptyNode]\", \"tests/test_nodes.py::test_str_repr_no_warnings[EvaluatedObject]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ExceptHandler]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Expr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[For]\", \"tests/test_nodes.py::test_str_repr_no_warnings[FormattedValue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[FunctionDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[GeneratorExp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Global]\", \"tests/test_nodes.py::test_str_repr_no_warnings[If]\", \"tests/test_nodes.py::test_str_repr_no_warnings[IfExp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Import]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ImportFrom]\", \"tests/test_nodes.py::test_str_repr_no_warnings[JoinedStr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Keyword]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Lambda]\", \"tests/test_nodes.py::test_str_repr_no_warnings[List]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ListComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[LocalsDictNodeNG]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Match]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchAs]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchCase]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchClass]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchMapping]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchOr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchSequence]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchSingleton]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchStar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchValue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Module]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Name]\", \"tests/test_nodes.py::test_str_repr_no_warnings[NamedExpr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Nonlocal]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ParamSpec]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Pass]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Pattern]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Raise]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Return]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Set]\", \"tests/test_nodes.py::test_str_repr_no_warnings[SetComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Slice]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Starred]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Subscript]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Try]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TryStar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Tuple]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeAlias]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeVar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeVarTuple]\", \"tests/test_nodes.py::test_str_repr_no_warnings[UnaryOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Unknown]\", \"tests/test_nodes.py::test_str_repr_no_warnings[While]\", \"tests/test_nodes.py::test_str_repr_no_warnings[With]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Yield]\", \"tests/test_nodes.py::test_str_repr_no_warnings[YieldFrom]\", \"tests/test_nodes.py::test_arguments_default_value\"]", "environment_setup_commit": "1113d490ec4a94cdc1b35f45abfdaca9f19fa31e"}
{"instance_id": "pylint-dev__astroid-2240_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n`.arguments` property ignores keyword-only args, *args, and **kwargs\n```python\r\n>>> from astroid import extract_node\r\n>>> node = extract_node(\"\"\"def a(*args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[]\r\n```\r\n\r\nExpected to find all the arguments from the function signature.\r\n\r\nThe wanted data can be found here:\r\n\r\n```python\r\n>>> node.args.vararg\r\n'args'\r\n>>> node.args.kwarg\r\n'kwargs'\r\n>>> node.args.kwonlyargs\r\n[<AssignName.b l.1 at 0x1048189b0>, <AssignName.c l.1 at 0x104818830>]\r\n```\r\n\r\nDiscussed at https://github.com/pylint-dev/pylint/pull/7577#discussion_r989000829.\r\n\r\nNotice that positional-only args are found for some reason \ud83e\udd37 \n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://codecov.io/gh/pylint-dev/astroid/branch/main/graph/badge.svg?token=Buxy4WptLb\n5     :target: https://codecov.io/gh/pylint-dev/astroid\n6     :alt: Coverage badge from codecov\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/pylint-dev/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/pylint-dev/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/pylint-dev/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest\n90 \n[end of README.rst]\n[start of astroid/arguments.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 from astroid import nodes\n8 from astroid.bases import Instance\n9 from astroid.context import CallContext, InferenceContext\n10 from astroid.exceptions import InferenceError, NoDefault\n11 from astroid.typing import InferenceResult\n12 from astroid.util import Uninferable, UninferableBase, safe_infer\n13 \n14 \n15 class CallSite:\n16     \"\"\"Class for understanding arguments passed into a call site.\n17 \n18     It needs a call context, which contains the arguments and the\n19     keyword arguments that were passed into a given call site.\n20     In order to infer what an argument represents, call :meth:`infer_argument`\n21     with the corresponding function node and the argument name.\n22 \n23     :param callcontext:\n24         An instance of :class:`astroid.context.CallContext`, that holds\n25         the arguments for the call site.\n26     :param argument_context_map:\n27         Additional contexts per node, passed in from :attr:`astroid.context.Context.extra_context`\n28     :param context:\n29         An instance of :class:`astroid.context.Context`.\n30     \"\"\"\n31 \n32     def __init__(\n33         self,\n34         callcontext: CallContext,\n35         argument_context_map=None,\n36         context: InferenceContext | None = None,\n37     ):\n38         if argument_context_map is None:\n39             argument_context_map = {}\n40         self.argument_context_map = argument_context_map\n41         args = callcontext.args\n42         keywords = callcontext.keywords\n43         self.duplicated_keywords: set[str] = set()\n44         self._unpacked_args = self._unpack_args(args, context=context)\n45         self._unpacked_kwargs = self._unpack_keywords(keywords, context=context)\n46 \n47         self.positional_arguments = [\n48             arg for arg in self._unpacked_args if not isinstance(arg, UninferableBase)\n49         ]\n50         self.keyword_arguments = {\n51             key: value\n52             for key, value in self._unpacked_kwargs.items()\n53             if not isinstance(value, UninferableBase)\n54         }\n55 \n56     @classmethod\n57     def from_call(cls, call_node, context: InferenceContext | None = None):\n58         \"\"\"Get a CallSite object from the given Call node.\n59 \n60         context will be used to force a single inference path.\n61         \"\"\"\n62 \n63         # Determine the callcontext from the given `context` object if any.\n64         context = context or InferenceContext()\n65         callcontext = CallContext(call_node.args, call_node.keywords)\n66         return cls(callcontext, context=context)\n67 \n68     def has_invalid_arguments(self):\n69         \"\"\"Check if in the current CallSite were passed *invalid* arguments.\n70 \n71         This can mean multiple things. For instance, if an unpacking\n72         of an invalid object was passed, then this method will return True.\n73         Other cases can be when the arguments can't be inferred by astroid,\n74         for example, by passing objects which aren't known statically.\n75         \"\"\"\n76         return len(self.positional_arguments) != len(self._unpacked_args)\n77 \n78     def has_invalid_keywords(self) -> bool:\n79         \"\"\"Check if in the current CallSite were passed *invalid* keyword arguments.\n80 \n81         For instance, unpacking a dictionary with integer keys is invalid\n82         (**{1:2}), because the keys must be strings, which will make this\n83         method to return True. Other cases where this might return True if\n84         objects which can't be inferred were passed.\n85         \"\"\"\n86         return len(self.keyword_arguments) != len(self._unpacked_kwargs)\n87 \n88     def _unpack_keywords(\n89         self,\n90         keywords: list[tuple[str | None, nodes.NodeNG]],\n91         context: InferenceContext | None = None,\n92     ):\n93         values: dict[str | None, InferenceResult] = {}\n94         context = context or InferenceContext()\n95         context.extra_context = self.argument_context_map\n96         for name, value in keywords:\n97             if name is None:\n98                 # Then it's an unpacking operation (**)\n99                 inferred = safe_infer(value, context=context)\n100                 if not isinstance(inferred, nodes.Dict):\n101                     # Not something we can work with.\n102                     values[name] = Uninferable\n103                     continue\n104 \n105                 for dict_key, dict_value in inferred.items:\n106                     dict_key = safe_infer(dict_key, context=context)\n107                     if not isinstance(dict_key, nodes.Const):\n108                         values[name] = Uninferable\n109                         continue\n110                     if not isinstance(dict_key.value, str):\n111                         values[name] = Uninferable\n112                         continue\n113                     if dict_key.value in values:\n114                         # The name is already in the dictionary\n115                         values[dict_key.value] = Uninferable\n116                         self.duplicated_keywords.add(dict_key.value)\n117                         continue\n118                     values[dict_key.value] = dict_value\n119             else:\n120                 values[name] = value\n121         return values\n122 \n123     def _unpack_args(self, args, context: InferenceContext | None = None):\n124         values = []\n125         context = context or InferenceContext()\n126         context.extra_context = self.argument_context_map\n127         for arg in args:\n128             if isinstance(arg, nodes.Starred):\n129                 inferred = safe_infer(arg.value, context=context)\n130                 if isinstance(inferred, UninferableBase):\n131                     values.append(Uninferable)\n132                     continue\n133                 if not hasattr(inferred, \"elts\"):\n134                     values.append(Uninferable)\n135                     continue\n136                 values.extend(inferred.elts)\n137             else:\n138                 values.append(arg)\n139         return values\n140 \n141     def infer_argument(\n142         self, funcnode: InferenceResult, name: str, context: InferenceContext\n143     ):  # noqa: C901\n144         \"\"\"Infer a function argument value according to the call context.\"\"\"\n145         if not isinstance(funcnode, (nodes.FunctionDef, nodes.Lambda)):\n146             raise InferenceError(\n147                 f\"Can not infer function argument value for non-function node {funcnode!r}.\",\n148                 call_site=self,\n149                 func=funcnode,\n150                 arg=name,\n151                 context=context,\n152             )\n153 \n154         if name in self.duplicated_keywords:\n155             raise InferenceError(\n156                 \"The arguments passed to {func!r} have duplicate keywords.\",\n157                 call_site=self,\n158                 func=funcnode,\n159                 arg=name,\n160                 context=context,\n161             )\n162 \n163         # Look into the keywords first, maybe it's already there.\n164         try:\n165             return self.keyword_arguments[name].infer(context)\n166         except KeyError:\n167             pass\n168 \n169         # Too many arguments given and no variable arguments.\n170         if len(self.positional_arguments) > len(funcnode.args.args):\n171             if not funcnode.args.vararg and not funcnode.args.posonlyargs:\n172                 raise InferenceError(\n173                     \"Too many positional arguments \"\n174                     \"passed to {func!r} that does \"\n175                     \"not have *args.\",\n176                     call_site=self,\n177                     func=funcnode,\n178                     arg=name,\n179                     context=context,\n180                 )\n181 \n182         positional = self.positional_arguments[: len(funcnode.args.args)]\n183         vararg = self.positional_arguments[len(funcnode.args.args) :]\n184         argindex = funcnode.args.find_argname(name)[0]\n185         kwonlyargs = {arg.name for arg in funcnode.args.kwonlyargs}\n186         kwargs = {\n187             key: value\n188             for key, value in self.keyword_arguments.items()\n189             if key not in kwonlyargs\n190         }\n191         # If there are too few positionals compared to\n192         # what the function expects to receive, check to see\n193         # if the missing positional arguments were passed\n194         # as keyword arguments and if so, place them into the\n195         # positional args list.\n196         if len(positional) < len(funcnode.args.args):\n197             for func_arg in funcnode.args.args:\n198                 if func_arg.name in kwargs:\n199                     arg = kwargs.pop(func_arg.name)\n200                     positional.append(arg)\n201 \n202         if argindex is not None:\n203             boundnode = context.boundnode\n204             # 2. first argument of instance/class method\n205             if argindex == 0 and funcnode.type in {\"method\", \"classmethod\"}:\n206                 # context.boundnode is None when an instance method is called with\n207                 # the class, e.g. MyClass.method(obj, ...). In this case, self\n208                 # is the first argument.\n209                 if boundnode is None and funcnode.type == \"method\" and positional:\n210                     return positional[0].infer(context=context)\n211                 if boundnode is None:\n212                     # XXX can do better ?\n213                     boundnode = funcnode.parent.frame()\n214 \n215                 if isinstance(boundnode, nodes.ClassDef):\n216                     # Verify that we're accessing a method\n217                     # of the metaclass through a class, as in\n218                     # `cls.metaclass_method`. In this case, the\n219                     # first argument is always the class.\n220                     method_scope = funcnode.parent.scope()\n221                     if method_scope is boundnode.metaclass(context=context):\n222                         return iter((boundnode,))\n223 \n224                 if funcnode.type == \"method\":\n225                     if not isinstance(boundnode, Instance):\n226                         boundnode = boundnode.instantiate_class()\n227                     return iter((boundnode,))\n228                 if funcnode.type == \"classmethod\":\n229                     return iter((boundnode,))\n230             # if we have a method, extract one position\n231             # from the index, so we'll take in account\n232             # the extra parameter represented by `self` or `cls`\n233             if funcnode.type in {\"method\", \"classmethod\"} and boundnode:\n234                 argindex -= 1\n235             # 2. search arg index\n236             try:\n237                 return self.positional_arguments[argindex].infer(context)\n238             except IndexError:\n239                 pass\n240 \n241         if funcnode.args.kwarg == name:\n242             # It wants all the keywords that were passed into\n243             # the call site.\n244             if self.has_invalid_keywords():\n245                 raise InferenceError(\n246                     \"Inference failed to find values for all keyword arguments \"\n247                     \"to {func!r}: {unpacked_kwargs!r} doesn't correspond to \"\n248                     \"{keyword_arguments!r}.\",\n249                     keyword_arguments=self.keyword_arguments,\n250                     unpacked_kwargs=self._unpacked_kwargs,\n251                     call_site=self,\n252                     func=funcnode,\n253                     arg=name,\n254                     context=context,\n255                 )\n256             kwarg = nodes.Dict(\n257                 lineno=funcnode.args.lineno,\n258                 col_offset=funcnode.args.col_offset,\n259                 parent=funcnode.args,\n260                 end_lineno=funcnode.args.end_lineno,\n261                 end_col_offset=funcnode.args.end_col_offset,\n262             )\n263             kwarg.postinit(\n264                 [(nodes.const_factory(key), value) for key, value in kwargs.items()]\n265             )\n266             return iter((kwarg,))\n267         if funcnode.args.vararg == name:\n268             # It wants all the args that were passed into\n269             # the call site.\n270             if self.has_invalid_arguments():\n271                 raise InferenceError(\n272                     \"Inference failed to find values for all positional \"\n273                     \"arguments to {func!r}: {unpacked_args!r} doesn't \"\n274                     \"correspond to {positional_arguments!r}.\",\n275                     positional_arguments=self.positional_arguments,\n276                     unpacked_args=self._unpacked_args,\n277                     call_site=self,\n278                     func=funcnode,\n279                     arg=name,\n280                     context=context,\n281                 )\n282             args = nodes.Tuple(\n283                 lineno=funcnode.args.lineno,\n284                 col_offset=funcnode.args.col_offset,\n285                 parent=funcnode.args,\n286             )\n287             args.postinit(vararg)\n288             return iter((args,))\n289 \n290         # Check if it's a default parameter.\n291         try:\n292             return funcnode.args.default_value(name).infer(context)\n293         except NoDefault:\n294             pass\n295         raise InferenceError(\n296             \"No value found for argument {arg} to {func!r}\",\n297             call_site=self,\n298             func=funcnode,\n299             arg=name,\n300             context=context,\n301         )\n302 \n[end of astroid/arguments.py]\n[start of astroid/interpreter/objectmodel.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"\n6 Data object model, as per https://docs.python.org/3/reference/datamodel.html.\n7 \n8 This module describes, at least partially, a data object model for some\n9 of astroid's nodes. The model contains special attributes that nodes such\n10 as functions, classes, modules etc have, such as __doc__, __class__,\n11 __module__ etc, being used when doing attribute lookups over nodes.\n12 \n13 For instance, inferring `obj.__class__` will first trigger an inference\n14 of the `obj` variable. If it was successfully inferred, then an attribute\n15 `__class__ will be looked for in the inferred object. This is the part\n16 where the data model occurs. The model is attached to those nodes\n17 and the lookup mechanism will try to see if attributes such as\n18 `__class__` are defined by the model or not. If they are defined,\n19 the model will be requested to return the corresponding value of that\n20 attribute. Thus the model can be viewed as a special part of the lookup\n21 mechanism.\n22 \"\"\"\n23 \n24 from __future__ import annotations\n25 \n26 import itertools\n27 import os\n28 import pprint\n29 import types\n30 from collections.abc import Iterator\n31 from functools import lru_cache\n32 from typing import TYPE_CHECKING, Any, Literal\n33 \n34 import astroid\n35 from astroid import bases, nodes, util\n36 from astroid.context import InferenceContext, copy_context\n37 from astroid.exceptions import AttributeInferenceError, InferenceError, NoDefault\n38 from astroid.manager import AstroidManager\n39 from astroid.nodes import node_classes\n40 from astroid.typing import InferenceResult, SuccessfulInferenceResult\n41 \n42 if TYPE_CHECKING:\n43     from astroid.objects import Property\n44 \n45 IMPL_PREFIX = \"attr_\"\n46 LEN_OF_IMPL_PREFIX = len(IMPL_PREFIX)\n47 \n48 \n49 def _dunder_dict(instance, attributes):\n50     obj = node_classes.Dict(\n51         parent=instance,\n52         lineno=instance.lineno,\n53         col_offset=instance.col_offset,\n54         end_lineno=instance.end_lineno,\n55         end_col_offset=instance.end_col_offset,\n56     )\n57 \n58     # Convert the keys to node strings\n59     keys = [\n60         node_classes.Const(value=value, parent=obj) for value in list(attributes.keys())\n61     ]\n62 \n63     # The original attribute has a list of elements for each key,\n64     # but that is not useful for retrieving the special attribute's value.\n65     # In this case, we're picking the last value from each list.\n66     values = [elem[-1] for elem in attributes.values()]\n67 \n68     obj.postinit(list(zip(keys, values)))\n69     return obj\n70 \n71 \n72 def _get_bound_node(model: ObjectModel) -> Any:\n73     # TODO: Use isinstance instead of try ... except after _instance has typing\n74     try:\n75         return model._instance._proxied\n76     except AttributeError:\n77         return model._instance\n78 \n79 \n80 class ObjectModel:\n81     def __init__(self):\n82         self._instance = None\n83 \n84     def __repr__(self):\n85         result = []\n86         cname = type(self).__name__\n87         string = \"%(cname)s(%(fields)s)\"\n88         alignment = len(cname) + 1\n89         for field in sorted(self.attributes()):\n90             width = 80 - len(field) - alignment\n91             lines = pprint.pformat(field, indent=2, width=width).splitlines(True)\n92 \n93             inner = [lines[0]]\n94             for line in lines[1:]:\n95                 inner.append(\" \" * alignment + line)\n96             result.append(field)\n97 \n98         return string % {\n99             \"cname\": cname,\n100             \"fields\": (\",\\n\" + \" \" * alignment).join(result),\n101         }\n102 \n103     def __call__(self, instance):\n104         self._instance = instance\n105         return self\n106 \n107     def __get__(self, instance, cls=None):\n108         # ObjectModel needs to be a descriptor so that just doing\n109         # `special_attributes = SomeObjectModel` should be enough in the body of a node.\n110         # But at the same time, node.special_attributes should return an object\n111         # which can be used for manipulating the special attributes. That's the reason\n112         # we pass the instance through which it got accessed to ObjectModel.__call__,\n113         # returning itself afterwards, so we can still have access to the\n114         # underlying data model and to the instance for which it got accessed.\n115         return self(instance)\n116 \n117     def __contains__(self, name) -> bool:\n118         return name in self.attributes()\n119 \n120     @lru_cache  # noqa\n121     def attributes(self) -> list[str]:\n122         \"\"\"Get the attributes which are exported by this object model.\"\"\"\n123         return [o[LEN_OF_IMPL_PREFIX:] for o in dir(self) if o.startswith(IMPL_PREFIX)]\n124 \n125     def lookup(self, name):\n126         \"\"\"Look up the given *name* in the current model.\n127 \n128         It should return an AST or an interpreter object,\n129         but if the name is not found, then an AttributeInferenceError will be raised.\n130         \"\"\"\n131         if name in self.attributes():\n132             return getattr(self, IMPL_PREFIX + name)\n133         raise AttributeInferenceError(target=self._instance, attribute=name)\n134 \n135     @property\n136     def attr___new__(self) -> bases.BoundMethod:\n137         \"\"\"Calling cls.__new__(type) on an object returns an instance of 'type'.\"\"\"\n138         from astroid import builder  # pylint: disable=import-outside-toplevel\n139 \n140         node: nodes.FunctionDef = builder.extract_node(\n141             \"\"\"def __new__(self, cls): return cls()\"\"\"\n142         )\n143         # We set the parent as being the ClassDef of 'object' as that\n144         # triggers correct inference as a call to __new__ in bases.py\n145         node.parent = AstroidManager().builtins_module[\"object\"]\n146 \n147         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n148 \n149     @property\n150     def attr___init__(self) -> bases.BoundMethod:\n151         \"\"\"Calling cls.__init__() normally returns None.\"\"\"\n152         from astroid import builder  # pylint: disable=import-outside-toplevel\n153 \n154         # The *args and **kwargs are necessary not to trigger warnings about missing\n155         # or extra parameters for '__init__' methods we don't infer correctly.\n156         # This BoundMethod is the fallback value for those.\n157         node: nodes.FunctionDef = builder.extract_node(\n158             \"\"\"def __init__(self, *args, **kwargs): return None\"\"\"\n159         )\n160         # We set the parent as being the ClassDef of 'object' as that\n161         # is where this method originally comes from\n162         node.parent = AstroidManager().builtins_module[\"object\"]\n163 \n164         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n165 \n166 \n167 class ModuleModel(ObjectModel):\n168     def _builtins(self):\n169         builtins_ast_module = AstroidManager().builtins_module\n170         return builtins_ast_module.special_attributes.lookup(\"__dict__\")\n171 \n172     @property\n173     def attr_builtins(self):\n174         return self._builtins()\n175 \n176     @property\n177     def attr___path__(self):\n178         if not self._instance.package:\n179             raise AttributeInferenceError(target=self._instance, attribute=\"__path__\")\n180 \n181         path_objs = [\n182             node_classes.Const(\n183                 value=path\n184                 if not path.endswith(\"__init__.py\")\n185                 else os.path.dirname(path),\n186                 parent=self._instance,\n187             )\n188             for path in self._instance.path\n189         ]\n190 \n191         container = node_classes.List(parent=self._instance)\n192         container.postinit(path_objs)\n193 \n194         return container\n195 \n196     @property\n197     def attr___name__(self):\n198         return node_classes.Const(value=self._instance.name, parent=self._instance)\n199 \n200     @property\n201     def attr___doc__(self):\n202         return node_classes.Const(\n203             value=getattr(self._instance.doc_node, \"value\", None),\n204             parent=self._instance,\n205         )\n206 \n207     @property\n208     def attr___file__(self):\n209         return node_classes.Const(value=self._instance.file, parent=self._instance)\n210 \n211     @property\n212     def attr___dict__(self):\n213         return _dunder_dict(self._instance, self._instance.globals)\n214 \n215     @property\n216     def attr___package__(self):\n217         if not self._instance.package:\n218             value = \"\"\n219         else:\n220             value = self._instance.name\n221 \n222         return node_classes.Const(value=value, parent=self._instance)\n223 \n224     # These are related to the Python 3 implementation of the\n225     # import system,\n226     # https://docs.python.org/3/reference/import.html#import-related-module-attributes\n227 \n228     @property\n229     def attr___spec__(self):\n230         # No handling for now.\n231         return node_classes.Unknown()\n232 \n233     @property\n234     def attr___loader__(self):\n235         # No handling for now.\n236         return node_classes.Unknown()\n237 \n238     @property\n239     def attr___cached__(self):\n240         # No handling for now.\n241         return node_classes.Unknown()\n242 \n243 \n244 class FunctionModel(ObjectModel):\n245     @property\n246     def attr___name__(self):\n247         return node_classes.Const(value=self._instance.name, parent=self._instance)\n248 \n249     @property\n250     def attr___doc__(self):\n251         return node_classes.Const(\n252             value=getattr(self._instance.doc_node, \"value\", None),\n253             parent=self._instance,\n254         )\n255 \n256     @property\n257     def attr___qualname__(self):\n258         return node_classes.Const(value=self._instance.qname(), parent=self._instance)\n259 \n260     @property\n261     def attr___defaults__(self):\n262         func = self._instance\n263         if not func.args.defaults:\n264             return node_classes.Const(value=None, parent=func)\n265 \n266         defaults_obj = node_classes.Tuple(parent=func)\n267         defaults_obj.postinit(func.args.defaults)\n268         return defaults_obj\n269 \n270     @property\n271     def attr___annotations__(self):\n272         obj = node_classes.Dict(\n273             parent=self._instance,\n274             lineno=self._instance.lineno,\n275             col_offset=self._instance.col_offset,\n276             end_lineno=self._instance.end_lineno,\n277             end_col_offset=self._instance.end_col_offset,\n278         )\n279 \n280         if not self._instance.returns:\n281             returns = None\n282         else:\n283             returns = self._instance.returns\n284 \n285         args = self._instance.args\n286         pair_annotations = itertools.chain(\n287             zip(args.args or [], args.annotations),\n288             zip(args.kwonlyargs, args.kwonlyargs_annotations),\n289             zip(args.posonlyargs or [], args.posonlyargs_annotations),\n290         )\n291 \n292         annotations = {\n293             arg.name: annotation for (arg, annotation) in pair_annotations if annotation\n294         }\n295         if args.varargannotation:\n296             annotations[args.vararg] = args.varargannotation\n297         if args.kwargannotation:\n298             annotations[args.kwarg] = args.kwargannotation\n299         if returns:\n300             annotations[\"return\"] = returns\n301 \n302         items = [\n303             (node_classes.Const(key, parent=obj), value)\n304             for (key, value) in annotations.items()\n305         ]\n306 \n307         obj.postinit(items)\n308         return obj\n309 \n310     @property\n311     def attr___dict__(self):\n312         return node_classes.Dict(\n313             parent=self._instance,\n314             lineno=self._instance.lineno,\n315             col_offset=self._instance.col_offset,\n316             end_lineno=self._instance.end_lineno,\n317             end_col_offset=self._instance.end_col_offset,\n318         )\n319 \n320     attr___globals__ = attr___dict__\n321 \n322     @property\n323     def attr___kwdefaults__(self):\n324         def _default_args(args, parent):\n325             for arg in args.kwonlyargs:\n326                 try:\n327                     default = args.default_value(arg.name)\n328                 except NoDefault:\n329                     continue\n330 \n331                 name = node_classes.Const(arg.name, parent=parent)\n332                 yield name, default\n333 \n334         args = self._instance.args\n335         obj = node_classes.Dict(\n336             parent=self._instance,\n337             lineno=self._instance.lineno,\n338             col_offset=self._instance.col_offset,\n339             end_lineno=self._instance.end_lineno,\n340             end_col_offset=self._instance.end_col_offset,\n341         )\n342         defaults = dict(_default_args(args, obj))\n343 \n344         obj.postinit(list(defaults.items()))\n345         return obj\n346 \n347     @property\n348     def attr___module__(self):\n349         return node_classes.Const(self._instance.root().qname())\n350 \n351     @property\n352     def attr___get__(self):\n353         func = self._instance\n354 \n355         class DescriptorBoundMethod(bases.BoundMethod):\n356             \"\"\"Bound method which knows how to understand calling descriptor\n357             binding.\n358             \"\"\"\n359 \n360             def implicit_parameters(self) -> Literal[0]:\n361                 # Different than BoundMethod since the signature\n362                 # is different.\n363                 return 0\n364 \n365             def infer_call_result(\n366                 self,\n367                 caller: SuccessfulInferenceResult | None,\n368                 context: InferenceContext | None = None,\n369             ) -> Iterator[bases.BoundMethod]:\n370                 if len(caller.args) > 2 or len(caller.args) < 1:\n371                     raise InferenceError(\n372                         \"Invalid arguments for descriptor binding\",\n373                         target=self,\n374                         context=context,\n375                     )\n376 \n377                 context = copy_context(context)\n378                 try:\n379                     cls = next(caller.args[0].infer(context=context))\n380                 except StopIteration as e:\n381                     raise InferenceError(context=context, node=caller.args[0]) from e\n382 \n383                 if isinstance(cls, util.UninferableBase):\n384                     raise InferenceError(\n385                         \"Invalid class inferred\", target=self, context=context\n386                     )\n387 \n388                 # For some reason func is a Node that the below\n389                 # code is not expecting\n390                 if isinstance(func, bases.BoundMethod):\n391                     yield func\n392                     return\n393 \n394                 # Rebuild the original value, but with the parent set as the\n395                 # class where it will be bound.\n396                 new_func = func.__class__(\n397                     name=func.name,\n398                     lineno=func.lineno,\n399                     col_offset=func.col_offset,\n400                     parent=func.parent,\n401                     end_lineno=func.end_lineno,\n402                     end_col_offset=func.end_col_offset,\n403                 )\n404                 # pylint: disable=no-member\n405                 new_func.postinit(\n406                     func.args,\n407                     func.body,\n408                     func.decorators,\n409                     func.returns,\n410                     doc_node=func.doc_node,\n411                 )\n412 \n413                 # Build a proper bound method that points to our newly built function.\n414                 proxy = bases.UnboundMethod(new_func)\n415                 yield bases.BoundMethod(proxy=proxy, bound=cls)\n416 \n417             @property\n418             def args(self):\n419                 \"\"\"Overwrite the underlying args to match those of the underlying func.\n420 \n421                 Usually the underlying *func* is a function/method, as in:\n422 \n423                     def test(self):\n424                         pass\n425 \n426                 This has only the *self* parameter but when we access test.__get__\n427                 we get a new object which has two parameters, *self* and *type*.\n428                 \"\"\"\n429                 nonlocal func\n430                 arguments = astroid.Arguments(\n431                     parent=func.args.parent, vararg=None, kwarg=None\n432                 )\n433 \n434                 positional_or_keyword_params = func.args.args.copy()\n435                 positional_or_keyword_params.append(\n436                     astroid.AssignName(\n437                         name=\"type\",\n438                         lineno=0,\n439                         col_offset=0,\n440                         parent=arguments,\n441                         end_lineno=None,\n442                         end_col_offset=None,\n443                     )\n444                 )\n445 \n446                 positional_only_params = func.args.posonlyargs.copy()\n447 \n448                 arguments.postinit(\n449                     args=positional_or_keyword_params,\n450                     posonlyargs=positional_only_params,\n451                     defaults=[],\n452                     kwonlyargs=[],\n453                     kw_defaults=[],\n454                     annotations=[],\n455                     kwonlyargs_annotations=[],\n456                     posonlyargs_annotations=[],\n457                 )\n458                 return arguments\n459 \n460         return DescriptorBoundMethod(proxy=self._instance, bound=self._instance)\n461 \n462     # These are here just for completion.\n463     @property\n464     def attr___ne__(self):\n465         return node_classes.Unknown()\n466 \n467     attr___subclasshook__ = attr___ne__\n468     attr___str__ = attr___ne__\n469     attr___sizeof__ = attr___ne__\n470     attr___setattr___ = attr___ne__\n471     attr___repr__ = attr___ne__\n472     attr___reduce__ = attr___ne__\n473     attr___reduce_ex__ = attr___ne__\n474     attr___lt__ = attr___ne__\n475     attr___eq__ = attr___ne__\n476     attr___gt__ = attr___ne__\n477     attr___format__ = attr___ne__\n478     attr___delattr___ = attr___ne__\n479     attr___getattribute__ = attr___ne__\n480     attr___hash__ = attr___ne__\n481     attr___dir__ = attr___ne__\n482     attr___call__ = attr___ne__\n483     attr___class__ = attr___ne__\n484     attr___closure__ = attr___ne__\n485     attr___code__ = attr___ne__\n486 \n487 \n488 class ClassModel(ObjectModel):\n489     def __init__(self):\n490         # Add a context so that inferences called from an instance don't recurse endlessly\n491         self.context = InferenceContext()\n492 \n493         super().__init__()\n494 \n495     @property\n496     def attr___module__(self):\n497         return node_classes.Const(self._instance.root().qname())\n498 \n499     @property\n500     def attr___name__(self):\n501         return node_classes.Const(self._instance.name)\n502 \n503     @property\n504     def attr___qualname__(self):\n505         return node_classes.Const(self._instance.qname())\n506 \n507     @property\n508     def attr___doc__(self):\n509         return node_classes.Const(getattr(self._instance.doc_node, \"value\", None))\n510 \n511     @property\n512     def attr___mro__(self):\n513         if not self._instance.newstyle:\n514             raise AttributeInferenceError(target=self._instance, attribute=\"__mro__\")\n515 \n516         mro = self._instance.mro()\n517         obj = node_classes.Tuple(parent=self._instance)\n518         obj.postinit(mro)\n519         return obj\n520 \n521     @property\n522     def attr_mro(self):\n523         if not self._instance.newstyle:\n524             raise AttributeInferenceError(target=self._instance, attribute=\"mro\")\n525 \n526         other_self = self\n527 \n528         # Cls.mro is a method and we need to return one in order to have a proper inference.\n529         # The method we're returning is capable of inferring the underlying MRO though.\n530         class MroBoundMethod(bases.BoundMethod):\n531             def infer_call_result(\n532                 self,\n533                 caller: SuccessfulInferenceResult | None,\n534                 context: InferenceContext | None = None,\n535             ) -> Iterator[node_classes.Tuple]:\n536                 yield other_self.attr___mro__\n537 \n538         implicit_metaclass = self._instance.implicit_metaclass()\n539         mro_method = implicit_metaclass.locals[\"mro\"][0]\n540         return MroBoundMethod(proxy=mro_method, bound=implicit_metaclass)\n541 \n542     @property\n543     def attr___bases__(self):\n544         obj = node_classes.Tuple()\n545         context = InferenceContext()\n546         elts = list(self._instance._inferred_bases(context))\n547         obj.postinit(elts=elts)\n548         return obj\n549 \n550     @property\n551     def attr___class__(self):\n552         # pylint: disable=import-outside-toplevel; circular import\n553         from astroid import helpers\n554 \n555         return helpers.object_type(self._instance)\n556 \n557     @property\n558     def attr___subclasses__(self):\n559         \"\"\"Get the subclasses of the underlying class.\n560 \n561         This looks only in the current module for retrieving the subclasses,\n562         thus it might miss a couple of them.\n563         \"\"\"\n564         if not self._instance.newstyle:\n565             raise AttributeInferenceError(\n566                 target=self._instance, attribute=\"__subclasses__\"\n567             )\n568 \n569         qname = self._instance.qname()\n570         root = self._instance.root()\n571         classes = [\n572             cls\n573             for cls in root.nodes_of_class(nodes.ClassDef)\n574             if cls != self._instance and cls.is_subtype_of(qname, context=self.context)\n575         ]\n576 \n577         obj = node_classes.List(parent=self._instance)\n578         obj.postinit(classes)\n579 \n580         class SubclassesBoundMethod(bases.BoundMethod):\n581             def infer_call_result(\n582                 self,\n583                 caller: SuccessfulInferenceResult | None,\n584                 context: InferenceContext | None = None,\n585             ) -> Iterator[node_classes.List]:\n586                 yield obj\n587 \n588         implicit_metaclass = self._instance.implicit_metaclass()\n589         subclasses_method = implicit_metaclass.locals[\"__subclasses__\"][0]\n590         return SubclassesBoundMethod(proxy=subclasses_method, bound=implicit_metaclass)\n591 \n592     @property\n593     def attr___dict__(self):\n594         return node_classes.Dict(\n595             parent=self._instance,\n596             lineno=self._instance.lineno,\n597             col_offset=self._instance.col_offset,\n598             end_lineno=self._instance.end_lineno,\n599             end_col_offset=self._instance.end_col_offset,\n600         )\n601 \n602     @property\n603     def attr___call__(self):\n604         \"\"\"Calling a class A() returns an instance of A.\"\"\"\n605         return self._instance.instantiate_class()\n606 \n607 \n608 class SuperModel(ObjectModel):\n609     @property\n610     def attr___thisclass__(self):\n611         return self._instance.mro_pointer\n612 \n613     @property\n614     def attr___self_class__(self):\n615         return self._instance._self_class\n616 \n617     @property\n618     def attr___self__(self):\n619         return self._instance.type\n620 \n621     @property\n622     def attr___class__(self):\n623         return self._instance._proxied\n624 \n625 \n626 class UnboundMethodModel(ObjectModel):\n627     @property\n628     def attr___class__(self):\n629         # pylint: disable=import-outside-toplevel; circular import\n630         from astroid import helpers\n631 \n632         return helpers.object_type(self._instance)\n633 \n634     @property\n635     def attr___func__(self):\n636         return self._instance._proxied\n637 \n638     @property\n639     def attr___self__(self):\n640         return node_classes.Const(value=None, parent=self._instance)\n641 \n642     attr_im_func = attr___func__\n643     attr_im_class = attr___class__\n644     attr_im_self = attr___self__\n645 \n646 \n647 class ContextManagerModel(ObjectModel):\n648     \"\"\"Model for context managers.\n649 \n650     Based on 3.3.9 of the Data Model documentation:\n651     https://docs.python.org/3/reference/datamodel.html#with-statement-context-managers\n652     \"\"\"\n653 \n654     @property\n655     def attr___enter__(self) -> bases.BoundMethod:\n656         \"\"\"Representation of the base implementation of __enter__.\n657 \n658         As per Python documentation:\n659         Enter the runtime context related to this object. The with statement\n660         will bind this method's return value to the target(s) specified in the\n661         as clause of the statement, if any.\n662         \"\"\"\n663         from astroid import builder  # pylint: disable=import-outside-toplevel\n664 \n665         node: nodes.FunctionDef = builder.extract_node(\"\"\"def __enter__(self): ...\"\"\")\n666         # We set the parent as being the ClassDef of 'object' as that\n667         # is where this method originally comes from\n668         node.parent = AstroidManager().builtins_module[\"object\"]\n669 \n670         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n671 \n672     @property\n673     def attr___exit__(self) -> bases.BoundMethod:\n674         \"\"\"Representation of the base implementation of __exit__.\n675 \n676         As per Python documentation:\n677         Exit the runtime context related to this object. The parameters describe the\n678         exception that caused the context to be exited. If the context was exited\n679         without an exception, all three arguments will be None.\n680         \"\"\"\n681         from astroid import builder  # pylint: disable=import-outside-toplevel\n682 \n683         node: nodes.FunctionDef = builder.extract_node(\n684             \"\"\"def __exit__(self, exc_type, exc_value, traceback): ...\"\"\"\n685         )\n686         # We set the parent as being the ClassDef of 'object' as that\n687         # is where this method originally comes from\n688         node.parent = AstroidManager().builtins_module[\"object\"]\n689 \n690         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n691 \n692 \n693 class BoundMethodModel(FunctionModel):\n694     @property\n695     def attr___func__(self):\n696         return self._instance._proxied._proxied\n697 \n698     @property\n699     def attr___self__(self):\n700         return self._instance.bound\n701 \n702 \n703 class GeneratorModel(FunctionModel, ContextManagerModel):\n704     def __new__(cls, *args, **kwargs):\n705         # Append the values from the GeneratorType unto this object.\n706         ret = super().__new__(cls, *args, **kwargs)\n707         generator = AstroidManager().builtins_module[\"generator\"]\n708         for name, values in generator.locals.items():\n709             method = values[0]\n710 \n711             def patched(cls, meth=method):\n712                 return meth\n713 \n714             setattr(type(ret), IMPL_PREFIX + name, property(patched))\n715 \n716         return ret\n717 \n718     @property\n719     def attr___name__(self):\n720         return node_classes.Const(\n721             value=self._instance.parent.name, parent=self._instance\n722         )\n723 \n724     @property\n725     def attr___doc__(self):\n726         return node_classes.Const(\n727             value=getattr(self._instance.parent.doc_node, \"value\", None),\n728             parent=self._instance,\n729         )\n730 \n731 \n732 class AsyncGeneratorModel(GeneratorModel):\n733     def __new__(cls, *args, **kwargs):\n734         # Append the values from the AGeneratorType unto this object.\n735         ret = super().__new__(cls, *args, **kwargs)\n736         astroid_builtins = AstroidManager().builtins_module\n737         generator = astroid_builtins.get(\"async_generator\")\n738         if generator is None:\n739             # Make it backward compatible.\n740             generator = astroid_builtins.get(\"generator\")\n741 \n742         for name, values in generator.locals.items():\n743             method = values[0]\n744 \n745             def patched(cls, meth=method):\n746                 return meth\n747 \n748             setattr(type(ret), IMPL_PREFIX + name, property(patched))\n749 \n750         return ret\n751 \n752 \n753 class InstanceModel(ObjectModel):\n754     @property\n755     def attr___class__(self):\n756         return self._instance._proxied\n757 \n758     @property\n759     def attr___module__(self):\n760         return node_classes.Const(self._instance.root().qname())\n761 \n762     @property\n763     def attr___doc__(self):\n764         return node_classes.Const(getattr(self._instance.doc_node, \"value\", None))\n765 \n766     @property\n767     def attr___dict__(self):\n768         return _dunder_dict(self._instance, self._instance.instance_attrs)\n769 \n770 \n771 # Exception instances\n772 \n773 \n774 class ExceptionInstanceModel(InstanceModel):\n775     @property\n776     def attr_args(self) -> nodes.Tuple:\n777         return nodes.Tuple(parent=self._instance)\n778 \n779     @property\n780     def attr___traceback__(self):\n781         builtins_ast_module = AstroidManager().builtins_module\n782         traceback_type = builtins_ast_module[types.TracebackType.__name__]\n783         return traceback_type.instantiate_class()\n784 \n785 \n786 class SyntaxErrorInstanceModel(ExceptionInstanceModel):\n787     @property\n788     def attr_text(self):\n789         return node_classes.Const(\"\")\n790 \n791 \n792 class OSErrorInstanceModel(ExceptionInstanceModel):\n793     @property\n794     def attr_filename(self):\n795         return node_classes.Const(\"\")\n796 \n797     @property\n798     def attr_errno(self):\n799         return node_classes.Const(0)\n800 \n801     @property\n802     def attr_strerror(self):\n803         return node_classes.Const(\"\")\n804 \n805     attr_filename2 = attr_filename\n806 \n807 \n808 class ImportErrorInstanceModel(ExceptionInstanceModel):\n809     @property\n810     def attr_name(self):\n811         return node_classes.Const(\"\")\n812 \n813     @property\n814     def attr_path(self):\n815         return node_classes.Const(\"\")\n816 \n817 \n818 class UnicodeDecodeErrorInstanceModel(ExceptionInstanceModel):\n819     @property\n820     def attr_object(self):\n821         return node_classes.Const(\"\")\n822 \n823 \n824 BUILTIN_EXCEPTIONS = {\n825     \"builtins.SyntaxError\": SyntaxErrorInstanceModel,\n826     \"builtins.ImportError\": ImportErrorInstanceModel,\n827     \"builtins.UnicodeDecodeError\": UnicodeDecodeErrorInstanceModel,\n828     # These are all similar to OSError in terms of attributes\n829     \"builtins.OSError\": OSErrorInstanceModel,\n830     \"builtins.BlockingIOError\": OSErrorInstanceModel,\n831     \"builtins.BrokenPipeError\": OSErrorInstanceModel,\n832     \"builtins.ChildProcessError\": OSErrorInstanceModel,\n833     \"builtins.ConnectionAbortedError\": OSErrorInstanceModel,\n834     \"builtins.ConnectionError\": OSErrorInstanceModel,\n835     \"builtins.ConnectionRefusedError\": OSErrorInstanceModel,\n836     \"builtins.ConnectionResetError\": OSErrorInstanceModel,\n837     \"builtins.FileExistsError\": OSErrorInstanceModel,\n838     \"builtins.FileNotFoundError\": OSErrorInstanceModel,\n839     \"builtins.InterruptedError\": OSErrorInstanceModel,\n840     \"builtins.IsADirectoryError\": OSErrorInstanceModel,\n841     \"builtins.NotADirectoryError\": OSErrorInstanceModel,\n842     \"builtins.PermissionError\": OSErrorInstanceModel,\n843     \"builtins.ProcessLookupError\": OSErrorInstanceModel,\n844     \"builtins.TimeoutError\": OSErrorInstanceModel,\n845 }\n846 \n847 \n848 class DictModel(ObjectModel):\n849     @property\n850     def attr___class__(self):\n851         return self._instance._proxied\n852 \n853     def _generic_dict_attribute(self, obj, name):\n854         \"\"\"Generate a bound method that can infer the given *obj*.\"\"\"\n855 \n856         class DictMethodBoundMethod(astroid.BoundMethod):\n857             def infer_call_result(\n858                 self,\n859                 caller: SuccessfulInferenceResult | None,\n860                 context: InferenceContext | None = None,\n861             ) -> Iterator[InferenceResult]:\n862                 yield obj\n863 \n864         meth = next(self._instance._proxied.igetattr(name), None)\n865         return DictMethodBoundMethod(proxy=meth, bound=self._instance)\n866 \n867     @property\n868     def attr_items(self):\n869         from astroid import objects  # pylint: disable=import-outside-toplevel\n870 \n871         elems = []\n872         obj = node_classes.List(parent=self._instance)\n873         for key, value in self._instance.items:\n874             elem = node_classes.Tuple(parent=obj)\n875             elem.postinit((key, value))\n876             elems.append(elem)\n877         obj.postinit(elts=elems)\n878 \n879         items_obj = objects.DictItems(obj)\n880         return self._generic_dict_attribute(items_obj, \"items\")\n881 \n882     @property\n883     def attr_keys(self):\n884         from astroid import objects  # pylint: disable=import-outside-toplevel\n885 \n886         keys = [key for (key, _) in self._instance.items]\n887         obj = node_classes.List(parent=self._instance)\n888         obj.postinit(elts=keys)\n889 \n890         keys_obj = objects.DictKeys(obj)\n891         return self._generic_dict_attribute(keys_obj, \"keys\")\n892 \n893     @property\n894     def attr_values(self):\n895         from astroid import objects  # pylint: disable=import-outside-toplevel\n896 \n897         values = [value for (_, value) in self._instance.items]\n898         obj = node_classes.List(parent=self._instance)\n899         obj.postinit(values)\n900 \n901         values_obj = objects.DictValues(obj)\n902         return self._generic_dict_attribute(values_obj, \"values\")\n903 \n904 \n905 class PropertyModel(ObjectModel):\n906     \"\"\"Model for a builtin property.\"\"\"\n907 \n908     def _init_function(self, name):\n909         function = nodes.FunctionDef(\n910             name=name,\n911             parent=self._instance,\n912             lineno=self._instance.lineno,\n913             col_offset=self._instance.col_offset,\n914             end_lineno=self._instance.end_lineno,\n915             end_col_offset=self._instance.end_col_offset,\n916         )\n917 \n918         args = nodes.Arguments(parent=function, vararg=None, kwarg=None)\n919         args.postinit(\n920             args=[],\n921             defaults=[],\n922             kwonlyargs=[],\n923             kw_defaults=[],\n924             annotations=[],\n925             posonlyargs=[],\n926             posonlyargs_annotations=[],\n927             kwonlyargs_annotations=[],\n928         )\n929 \n930         function.postinit(args=args, body=[])\n931         return function\n932 \n933     @property\n934     def attr_fget(self):\n935         func = self._instance\n936 \n937         class PropertyFuncAccessor(nodes.FunctionDef):\n938             def infer_call_result(\n939                 self,\n940                 caller: SuccessfulInferenceResult | None,\n941                 context: InferenceContext | None = None,\n942             ) -> Iterator[InferenceResult]:\n943                 nonlocal func\n944                 if caller and len(caller.args) != 1:\n945                     raise InferenceError(\n946                         \"fget() needs a single argument\", target=self, context=context\n947                     )\n948 \n949                 yield from func.function.infer_call_result(\n950                     caller=caller, context=context\n951                 )\n952 \n953         property_accessor = PropertyFuncAccessor(\n954             name=\"fget\",\n955             parent=self._instance,\n956             lineno=self._instance.lineno,\n957             col_offset=self._instance.col_offset,\n958             end_lineno=self._instance.end_lineno,\n959             end_col_offset=self._instance.end_col_offset,\n960         )\n961         property_accessor.postinit(args=func.args, body=func.body)\n962         return property_accessor\n963 \n964     @property\n965     def attr_fset(self):\n966         func = self._instance\n967 \n968         def find_setter(func: Property) -> astroid.FunctionDef | None:\n969             \"\"\"\n970             Given a property, find the corresponding setter function and returns it.\n971 \n972             :param func: property for which the setter has to be found\n973             :return: the setter function or None\n974             \"\"\"\n975             for target in [\n976                 t for t in func.parent.get_children() if t.name == func.function.name\n977             ]:\n978                 for dec_name in target.decoratornames():\n979                     if dec_name.endswith(func.function.name + \".setter\"):\n980                         return target\n981             return None\n982 \n983         func_setter = find_setter(func)\n984         if not func_setter:\n985             raise InferenceError(\n986                 f\"Unable to find the setter of property {func.function.name}\"\n987             )\n988 \n989         class PropertyFuncAccessor(nodes.FunctionDef):\n990             def infer_call_result(\n991                 self,\n992                 caller: SuccessfulInferenceResult | None,\n993                 context: InferenceContext | None = None,\n994             ) -> Iterator[InferenceResult]:\n995                 nonlocal func_setter\n996                 if caller and len(caller.args) != 2:\n997                     raise InferenceError(\n998                         \"fset() needs two arguments\", target=self, context=context\n999                     )\n1000                 yield from func_setter.infer_call_result(caller=caller, context=context)\n1001 \n1002         property_accessor = PropertyFuncAccessor(\n1003             name=\"fset\",\n1004             parent=self._instance,\n1005             lineno=self._instance.lineno,\n1006             col_offset=self._instance.col_offset,\n1007             end_lineno=self._instance.end_lineno,\n1008             end_col_offset=self._instance.end_col_offset,\n1009         )\n1010         property_accessor.postinit(args=func_setter.args, body=func_setter.body)\n1011         return property_accessor\n1012 \n1013     @property\n1014     def attr_setter(self):\n1015         return self._init_function(\"setter\")\n1016 \n1017     @property\n1018     def attr_deleter(self):\n1019         return self._init_function(\"deleter\")\n1020 \n1021     @property\n1022     def attr_getter(self):\n1023         return self._init_function(\"getter\")\n1024 \n1025     # pylint: enable=import-outside-toplevel\n1026 \n[end of astroid/interpreter/objectmodel.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pylint-dev/astroid", "base_commit": "514991036806e9cda2b12cef8ab3184ac373bd6c", "problem_statement": "`.arguments` property ignores keyword-only args, *args, and **kwargs\n```python\r\n>>> from astroid import extract_node\r\n>>> node = extract_node(\"\"\"def a(*args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[]\r\n```\r\n\r\nExpected to find all the arguments from the function signature.\r\n\r\nThe wanted data can be found here:\r\n\r\n```python\r\n>>> node.args.vararg\r\n'args'\r\n>>> node.args.kwarg\r\n'kwargs'\r\n>>> node.args.kwonlyargs\r\n[<AssignName.b l.1 at 0x1048189b0>, <AssignName.c l.1 at 0x104818830>]\r\n```\r\n\r\nDiscussed at https://github.com/pylint-dev/pylint/pull/7577#discussion_r989000829.\r\n\r\nNotice that positional-only args are found for some reason \ud83e\udd37 \n", "hints_text": "Should the definition be changed as well? It states `args.arguments` returns required arguments, and AFAIK in the example none are required (I can call `a` without supplying any arguments).\r\n\r\nI tried running the following:\r\n\r\n```\r\n>>> node = extract_node(\"\"\"def a(kiwi, apple, *args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[<AssignName.kiwi l.1 at 0x7f5c55986b90>, <AssignName.apple l.1 at 0x7f5c55985a50>]\r\n```\r\n\r\nAnd it seems correct to me :thinking: \nhttps://github.com/pylint-dev/astroid/blob/fef38f2dd474b0dacd1dda3f15abbf61eb0e9a71/astroid/nodes/node_classes.py#L685-L688\r\n\r\nThe docstring seems to be correct?\nDepends on how you parse the language. \"positional and keyword\" could describe the argument `kiwi` and exclude keyword-only arguments.\r\n\r\nEssentially, the crux of this is whether we should\r\n- leave the function as is, and audit everywhere that uses it (given that we keep finding bugs)\r\n- change the function\r\n\r\n@crazybolillo have you happened to sample the places that use this function to be able to offer a view on that? I'd be eager to hear it!\nI think I got confused about the documentation :sob:. I was reading the docstring for `args` (`node.args.args` in the example):\r\n\r\nhttps://github.com/pylint-dev/astroid/blob/d4f4452fe089f600bf9144ffdcd8e698816df3c2/astroid/nodes/node_classes.py#L554-L555\r\n\r\n but we are dealing with `arguments` (`node.args.arguments`). I will review the code further to see if I can come up with something\r\n\r\n", "created_at": "2023-07-06T20:52:39Z", "patch": "<patch>\ndiff --git a/astroid/arguments.py b/astroid/arguments.py\n--- a/astroid/arguments.py\n+++ b/astroid/arguments.py\n@@ -181,7 +181,13 @@ def infer_argument(\n \n         positional = self.positional_arguments[: len(funcnode.args.args)]\n         vararg = self.positional_arguments[len(funcnode.args.args) :]\n-        argindex = funcnode.args.find_argname(name)[0]\n+\n+        # preserving previous behavior, when vararg and kwarg were not included in find_argname results\n+        if name in [funcnode.args.vararg, funcnode.args.kwarg]:\n+            argindex = None\n+        else:\n+            argindex = funcnode.args.find_argname(name)[0]\n+\n         kwonlyargs = {arg.name for arg in funcnode.args.kwonlyargs}\n         kwargs = {\n             key: value\ndiff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -605,7 +605,9 @@ def _infer(\n DEPRECATED_ARGUMENT_DEFAULT = \"DEPRECATED_ARGUMENT_DEFAULT\"\n \n \n-class Arguments(_base_nodes.AssignTypeNode):\n+class Arguments(\n+    _base_nodes.AssignTypeNode\n+):  # pylint: disable=too-many-instance-attributes\n     \"\"\"Class representing an :class:`ast.arguments` node.\n \n     An :class:`Arguments` node represents that arguments in a\n@@ -704,7 +706,20 @@ class Arguments(_base_nodes.AssignTypeNode):\n     kwargannotation: NodeNG | None\n     \"\"\"The type annotation for the variable length keyword arguments.\"\"\"\n \n-    def __init__(self, vararg: str | None, kwarg: str | None, parent: NodeNG) -> None:\n+    vararg_node: AssignName | None\n+    \"\"\"The node for variable length arguments\"\"\"\n+\n+    kwarg_node: AssignName | None\n+    \"\"\"The node for variable keyword arguments\"\"\"\n+\n+    def __init__(\n+        self,\n+        vararg: str | None,\n+        kwarg: str | None,\n+        parent: NodeNG,\n+        vararg_node: AssignName | None = None,\n+        kwarg_node: AssignName | None = None,\n+    ) -> None:\n         \"\"\"Almost all attributes can be None for living objects where introspection failed.\"\"\"\n         super().__init__(\n             parent=parent,\n@@ -720,6 +735,9 @@ def __init__(self, vararg: str | None, kwarg: str | None, parent: NodeNG) -> Non\n         self.kwarg = kwarg\n         \"\"\"The name of the variable length keyword arguments.\"\"\"\n \n+        self.vararg_node = vararg_node\n+        self.kwarg_node = kwarg_node\n+\n     # pylint: disable=too-many-arguments\n     def postinit(\n         self,\n@@ -780,8 +798,21 @@ def fromlineno(self) -> int:\n \n     @cached_property\n     def arguments(self):\n-        \"\"\"Get all the arguments for this node, including positional only and positional and keyword\"\"\"\n-        return list(itertools.chain((self.posonlyargs or ()), self.args or ()))\n+        \"\"\"Get all the arguments for this node. This includes:\n+        * Positional only arguments\n+        * Positional arguments\n+        * Keyword arguments\n+        * Variable arguments (.e.g *args)\n+        * Variable keyword arguments (e.g **kwargs)\n+        \"\"\"\n+        retval = list(itertools.chain((self.posonlyargs or ()), (self.args or ())))\n+        if self.vararg_node:\n+            retval.append(self.vararg_node)\n+        retval += self.kwonlyargs or ()\n+        if self.kwarg_node:\n+            retval.append(self.kwarg_node)\n+\n+        return retval\n \n     def format_args(self, *, skippable_names: set[str] | None = None) -> str:\n         \"\"\"Get the arguments formatted as string.\n@@ -911,15 +942,20 @@ def default_value(self, argname):\n         :raises NoDefault: If there is no default value defined for the\n             given argument.\n         \"\"\"\n-        args = self.arguments\n+        args = [\n+            arg for arg in self.arguments if arg.name not in [self.vararg, self.kwarg]\n+        ]\n+\n+        index = _find_arg(argname, self.kwonlyargs)[0]\n+        if index is not None and self.kw_defaults[index] is not None:\n+            return self.kw_defaults[index]\n+\n         index = _find_arg(argname, args)[0]\n         if index is not None:\n-            idx = index - (len(args) - len(self.defaults))\n+            idx = index - (len(args) - len(self.defaults) - len(self.kw_defaults))\n             if idx >= 0:\n                 return self.defaults[idx]\n-        index = _find_arg(argname, self.kwonlyargs)[0]\n-        if index is not None and self.kw_defaults[index] is not None:\n-            return self.kw_defaults[index]\n+\n         raise NoDefault(func=self.parent, name=argname)\n \n     def is_argument(self, name) -> bool:\n@@ -934,11 +970,7 @@ def is_argument(self, name) -> bool:\n             return True\n         if name == self.kwarg:\n             return True\n-        return (\n-            self.find_argname(name)[1] is not None\n-            or self.kwonlyargs\n-            and _find_arg(name, self.kwonlyargs)[1] is not None\n-        )\n+        return self.find_argname(name)[1] is not None\n \n     def find_argname(self, argname, rec=DEPRECATED_ARGUMENT_DEFAULT):\n         \"\"\"Get the index and :class:`AssignName` node for given name.\n@@ -956,7 +988,9 @@ def find_argname(self, argname, rec=DEPRECATED_ARGUMENT_DEFAULT):\n                 stacklevel=2,\n             )\n         if self.arguments:\n-            return _find_arg(argname, self.arguments)\n+            index, argument = _find_arg(argname, self.arguments)\n+            if argument:\n+                return index, argument\n         return None, None\n \n     def get_children(self):\ndiff --git a/astroid/nodes/scoped_nodes/scoped_nodes.py b/astroid/nodes/scoped_nodes/scoped_nodes.py\n--- a/astroid/nodes/scoped_nodes/scoped_nodes.py\n+++ b/astroid/nodes/scoped_nodes/scoped_nodes.py\n@@ -963,11 +963,7 @@ def argnames(self) -> list[str]:\n             names = [elt.name for elt in self.args.arguments]\n         else:\n             names = []\n-        if self.args.vararg:\n-            names.append(self.args.vararg)\n-        names += [elt.name for elt in self.args.kwonlyargs]\n-        if self.args.kwarg:\n-            names.append(self.args.kwarg)\n+\n         return names\n \n     def infer_call_result(\n@@ -1280,11 +1276,7 @@ def argnames(self) -> list[str]:\n             names = [elt.name for elt in self.args.arguments]\n         else:\n             names = []\n-        if self.args.vararg:\n-            names.append(self.args.vararg)\n-        names += [elt.name for elt in self.args.kwonlyargs]\n-        if self.args.kwarg:\n-            names.append(self.args.kwarg)\n+\n         return names\n \n     def getattr(\ndiff --git a/astroid/protocols.py b/astroid/protocols.py\n--- a/astroid/protocols.py\n+++ b/astroid/protocols.py\n@@ -352,14 +352,15 @@ def _arguments_infer_argname(\n     # more\n     from astroid import arguments  # pylint: disable=import-outside-toplevel\n \n-    if not (self.arguments or self.vararg or self.kwarg):\n+    if not self.arguments:\n         yield util.Uninferable\n         return\n \n+    args = [arg for arg in self.arguments if arg.name not in [self.vararg, self.kwarg]]\n     functype = self.parent.type\n     # first argument of instance/class method\n     if (\n-        self.arguments\n+        args\n         and getattr(self.arguments[0], \"name\", None) == name\n         and functype != \"staticmethod\"\n     ):\n@@ -388,7 +389,7 @@ def _arguments_infer_argname(\n     if name == self.vararg:\n         vararg = nodes.const_factory(())\n         vararg.parent = self\n-        if not self.arguments and self.parent.name == \"__init__\":\n+        if not args and self.parent.name == \"__init__\":\n             cls = self.parent.parent.scope()\n             vararg.elts = [cls.instantiate_class()]\n         yield vararg\ndiff --git a/astroid/rebuilder.py b/astroid/rebuilder.py\n--- a/astroid/rebuilder.py\n+++ b/astroid/rebuilder.py\n@@ -21,6 +21,7 @@\n from astroid.const import IS_PYPY, PY38, PY39_PLUS, PY312_PLUS, Context\n from astroid.manager import AstroidManager\n from astroid.nodes import NodeNG\n+from astroid.nodes.node_classes import AssignName\n from astroid.nodes.utils import Position\n from astroid.typing import InferenceResult\n \n@@ -561,10 +562,33 @@ def visit_arguments(self, node: ast.arguments, parent: NodeNG) -> nodes.Argument\n         \"\"\"Visit an Arguments node by returning a fresh instance of it.\"\"\"\n         vararg: str | None = None\n         kwarg: str | None = None\n+        vararg_node = node.vararg\n+        kwarg_node = node.kwarg\n+\n         newnode = nodes.Arguments(\n             node.vararg.arg if node.vararg else None,\n             node.kwarg.arg if node.kwarg else None,\n             parent,\n+            AssignName(\n+                vararg_node.arg,\n+                vararg_node.lineno,\n+                vararg_node.col_offset,\n+                parent,\n+                end_lineno=vararg_node.end_lineno,\n+                end_col_offset=vararg_node.end_col_offset,\n+            )\n+            if vararg_node\n+            else None,\n+            AssignName(\n+                kwarg_node.arg,\n+                kwarg_node.lineno,\n+                kwarg_node.col_offset,\n+                parent,\n+                end_lineno=kwarg_node.end_lineno,\n+                end_col_offset=kwarg_node.end_col_offset,\n+            )\n+            if kwarg_node\n+            else None,\n         )\n         args = [self.visit(child, newnode) for child in node.args]\n         defaults = [self.visit(child, newnode) for child in node.defaults]\n\n</patch>", "test_patch": "diff --git a/tests/test_nodes.py b/tests/test_nodes.py\n--- a/tests/test_nodes.py\n+++ b/tests/test_nodes.py\n@@ -22,6 +22,7 @@\n     Uninferable,\n     bases,\n     builder,\n+    extract_node,\n     nodes,\n     parse,\n     test_utils,\n@@ -1975,3 +1976,38 @@ def test_str_repr_no_warnings(node):\n     test_node = node(**args)\n     str(test_node)\n     repr(test_node)\n+\n+\n+def test_arguments_contains_all():\n+    \"\"\"Ensure Arguments.arguments actually returns all available arguments\"\"\"\n+\n+    def manually_get_args(arg_node) -> set:\n+        names = set()\n+        if arg_node.args.vararg:\n+            names.add(arg_node.args.vararg)\n+        if arg_node.args.kwarg:\n+            names.add(arg_node.args.kwarg)\n+\n+        names.update([x.name for x in arg_node.args.args])\n+        names.update([x.name for x in arg_node.args.kwonlyargs])\n+\n+        return names\n+\n+    node = extract_node(\"\"\"def a(fruit: str, *args, b=None, c=None, **kwargs): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+    node = extract_node(\"\"\"def a(mango: int, b=\"banana\", c=None, **kwargs): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+    node = extract_node(\"\"\"def a(self, num = 10, *args): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+\n+def test_arguments_default_value():\n+    node = extract_node(\n+        \"def fruit(eat='please', *, peel='no', trim='yes', **kwargs): ...\"\n+    )\n+    assert node.args.default_value(\"eat\").value == \"please\"\n+\n+    node = extract_node(\"def fruit(seeds, flavor='good', *, peel='maybe'): ...\")\n+    assert node.args.default_value(\"flavor\").value == \"good\"\n", "version": "3.0", "FAIL_TO_PASS": "[\"tests/test_nodes.py::test_arguments_contains_all\"]", "PASS_TO_PASS": "[\"tests/test_nodes.py::AsStringTest::test_3k_annotations_and_metaclass\", \"tests/test_nodes.py::AsStringTest::test_3k_as_string\", \"tests/test_nodes.py::AsStringTest::test_as_string\", \"tests/test_nodes.py::AsStringTest::test_as_string_for_list_containing_uninferable\", \"tests/test_nodes.py::AsStringTest::test_as_string_unknown\", \"tests/test_nodes.py::AsStringTest::test_class_def\", \"tests/test_nodes.py::AsStringTest::test_ellipsis\", \"tests/test_nodes.py::AsStringTest::test_f_strings\", \"tests/test_nodes.py::AsStringTest::test_frozenset_as_string\", \"tests/test_nodes.py::AsStringTest::test_func_signature_issue_185\", \"tests/test_nodes.py::AsStringTest::test_int_attribute\", \"tests/test_nodes.py::AsStringTest::test_module2_as_string\", \"tests/test_nodes.py::AsStringTest::test_module_as_string\", \"tests/test_nodes.py::AsStringTest::test_operator_precedence\", \"tests/test_nodes.py::AsStringTest::test_slice_and_subscripts\", \"tests/test_nodes.py::AsStringTest::test_slices\", \"tests/test_nodes.py::AsStringTest::test_tuple_as_string\", \"tests/test_nodes.py::AsStringTest::test_varargs_kwargs_as_string\", \"tests/test_nodes.py::IfNodeTest::test_block_range\", \"tests/test_nodes.py::IfNodeTest::test_if_elif_else_node\", \"tests/test_nodes.py::TryNodeTest::test_block_range\", \"tests/test_nodes.py::TryExceptNodeTest::test_block_range\", \"tests/test_nodes.py::TryFinallyNodeTest::test_block_range\", \"tests/test_nodes.py::TryExceptFinallyNodeTest::test_block_range\", \"tests/test_nodes.py::ImportNodeTest::test_absolute_import\", \"tests/test_nodes.py::ImportNodeTest::test_as_string\", \"tests/test_nodes.py::ImportNodeTest::test_bad_import_inference\", \"tests/test_nodes.py::ImportNodeTest::test_conditional\", \"tests/test_nodes.py::ImportNodeTest::test_conditional_import\", \"tests/test_nodes.py::ImportNodeTest::test_from_self_resolve\", \"tests/test_nodes.py::ImportNodeTest::test_import_self_resolve\", \"tests/test_nodes.py::ImportNodeTest::test_more_absolute_import\", \"tests/test_nodes.py::ImportNodeTest::test_real_name\", \"tests/test_nodes.py::CmpNodeTest::test_as_string\", \"tests/test_nodes.py::ConstNodeTest::test_bool\", \"tests/test_nodes.py::ConstNodeTest::test_complex\", \"tests/test_nodes.py::ConstNodeTest::test_copy\", \"tests/test_nodes.py::ConstNodeTest::test_float\", \"tests/test_nodes.py::ConstNodeTest::test_int\", \"tests/test_nodes.py::ConstNodeTest::test_none\", \"tests/test_nodes.py::ConstNodeTest::test_str\", \"tests/test_nodes.py::ConstNodeTest::test_str_kind\", \"tests/test_nodes.py::ConstNodeTest::test_unicode\", \"tests/test_nodes.py::NameNodeTest::test_assign_to_true\", \"tests/test_nodes.py::TestNamedExprNode::test_frame\", \"tests/test_nodes.py::TestNamedExprNode::test_scope\", \"tests/test_nodes.py::AnnAssignNodeTest::test_as_string\", \"tests/test_nodes.py::AnnAssignNodeTest::test_complex\", \"tests/test_nodes.py::AnnAssignNodeTest::test_primitive\", \"tests/test_nodes.py::AnnAssignNodeTest::test_primitive_without_initial_value\", \"tests/test_nodes.py::ArgumentsNodeTC::test_kwoargs\", \"tests/test_nodes.py::ArgumentsNodeTC::test_linenumbering\", \"tests/test_nodes.py::ArgumentsNodeTC::test_positional_only\", \"tests/test_nodes.py::UnboundMethodNodeTest::test_no_super_getattr\", \"tests/test_nodes.py::BoundMethodNodeTest::test_is_property\", \"tests/test_nodes.py::AliasesTest::test_aliases\", \"tests/test_nodes.py::Python35AsyncTest::test_async_await_keywords\", \"tests/test_nodes.py::Python35AsyncTest::test_asyncfor_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_asyncwith_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_await_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_decorated_async_def_as_string\", \"tests/test_nodes.py::ContextTest::test_list_del\", \"tests/test_nodes.py::ContextTest::test_list_load\", \"tests/test_nodes.py::ContextTest::test_list_store\", \"tests/test_nodes.py::ContextTest::test_starred_load\", \"tests/test_nodes.py::ContextTest::test_starred_store\", \"tests/test_nodes.py::ContextTest::test_subscript_del\", \"tests/test_nodes.py::ContextTest::test_subscript_load\", \"tests/test_nodes.py::ContextTest::test_subscript_store\", \"tests/test_nodes.py::ContextTest::test_tuple_load\", \"tests/test_nodes.py::ContextTest::test_tuple_store\", \"tests/test_nodes.py::test_unknown\", \"tests/test_nodes.py::test_type_comments_with\", \"tests/test_nodes.py::test_type_comments_for\", \"tests/test_nodes.py::test_type_coments_assign\", \"tests/test_nodes.py::test_type_comments_invalid_expression\", \"tests/test_nodes.py::test_type_comments_invalid_function_comments\", \"tests/test_nodes.py::test_type_comments_function\", \"tests/test_nodes.py::test_type_comments_arguments\", \"tests/test_nodes.py::test_type_comments_posonly_arguments\", \"tests/test_nodes.py::test_correct_function_type_comment_parent\", \"tests/test_nodes.py::test_is_generator_for_yield_assignments\", \"tests/test_nodes.py::test_f_string_correct_line_numbering\", \"tests/test_nodes.py::test_assignment_expression\", \"tests/test_nodes.py::test_assignment_expression_in_functiondef\", \"tests/test_nodes.py::test_get_doc\", \"tests/test_nodes.py::test_parse_fstring_debug_mode\", \"tests/test_nodes.py::test_parse_type_comments_with_proper_parent\", \"tests/test_nodes.py::test_const_itered\", \"tests/test_nodes.py::test_is_generator_for_yield_in_while\", \"tests/test_nodes.py::test_is_generator_for_yield_in_if\", \"tests/test_nodes.py::test_is_generator_for_yield_in_aug_assign\", \"tests/test_nodes.py::test_str_repr_no_warnings[AnnAssign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Arguments]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Assert]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Assign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AssignAttr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AssignName]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncFor]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncFunctionDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncWith]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Attribute]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AugAssign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Await]\", \"tests/test_nodes.py::test_str_repr_no_warnings[BinOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[BoolOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Break]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Call]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ClassDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Compare]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Comprehension]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ComprehensionScope]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Const]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Continue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Decorators]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DelAttr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Delete]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DelName]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Dict]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DictComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DictUnpack]\", \"tests/test_nodes.py::test_str_repr_no_warnings[EmptyNode]\", \"tests/test_nodes.py::test_str_repr_no_warnings[EvaluatedObject]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ExceptHandler]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Expr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[For]\", \"tests/test_nodes.py::test_str_repr_no_warnings[FormattedValue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[FunctionDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[GeneratorExp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Global]\", \"tests/test_nodes.py::test_str_repr_no_warnings[If]\", \"tests/test_nodes.py::test_str_repr_no_warnings[IfExp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Import]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ImportFrom]\", \"tests/test_nodes.py::test_str_repr_no_warnings[JoinedStr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Keyword]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Lambda]\", \"tests/test_nodes.py::test_str_repr_no_warnings[List]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ListComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[LocalsDictNodeNG]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Match]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchAs]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchCase]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchClass]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchMapping]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchOr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchSequence]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchSingleton]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchStar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchValue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Module]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Name]\", \"tests/test_nodes.py::test_str_repr_no_warnings[NamedExpr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Nonlocal]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ParamSpec]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Pass]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Pattern]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Raise]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Return]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Set]\", \"tests/test_nodes.py::test_str_repr_no_warnings[SetComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Slice]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Starred]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Subscript]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Try]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TryStar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Tuple]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeAlias]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeVar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeVarTuple]\", \"tests/test_nodes.py::test_str_repr_no_warnings[UnaryOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Unknown]\", \"tests/test_nodes.py::test_str_repr_no_warnings[While]\", \"tests/test_nodes.py::test_str_repr_no_warnings[With]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Yield]\", \"tests/test_nodes.py::test_str_repr_no_warnings[YieldFrom]\", \"tests/test_nodes.py::test_arguments_default_value\"]", "environment_setup_commit": "1113d490ec4a94cdc1b35f45abfdaca9f19fa31e"}
{"instance_id": "pylint-dev__astroid-2240_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n`.arguments` property ignores keyword-only args, *args, and **kwargs\n```python\r\n>>> from astroid import extract_node\r\n>>> node = extract_node(\"\"\"def a(*args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[]\r\n```\r\n\r\nExpected to find all the arguments from the function signature.\r\n\r\nThe wanted data can be found here:\r\n\r\n```python\r\n>>> node.args.vararg\r\n'args'\r\n>>> node.args.kwarg\r\n'kwargs'\r\n>>> node.args.kwonlyargs\r\n[<AssignName.b l.1 at 0x1048189b0>, <AssignName.c l.1 at 0x104818830>]\r\n```\r\n\r\nDiscussed at https://github.com/pylint-dev/pylint/pull/7577#discussion_r989000829.\r\n\r\nNotice that positional-only args are found for some reason \ud83e\udd37 \n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://codecov.io/gh/pylint-dev/astroid/branch/main/graph/badge.svg?token=Buxy4WptLb\n5     :target: https://codecov.io/gh/pylint-dev/astroid\n6     :alt: Coverage badge from codecov\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/pylint-dev/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/pylint-dev/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/pylint-dev/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest\n90 \n[end of README.rst]\n[start of astroid/arguments.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 from astroid import nodes\n8 from astroid.bases import Instance\n9 from astroid.context import CallContext, InferenceContext\n10 from astroid.exceptions import InferenceError, NoDefault\n11 from astroid.typing import InferenceResult\n12 from astroid.util import Uninferable, UninferableBase, safe_infer\n13 \n14 \n15 class CallSite:\n16     \"\"\"Class for understanding arguments passed into a call site.\n17 \n18     It needs a call context, which contains the arguments and the\n19     keyword arguments that were passed into a given call site.\n20     In order to infer what an argument represents, call :meth:`infer_argument`\n21     with the corresponding function node and the argument name.\n22 \n23     :param callcontext:\n24         An instance of :class:`astroid.context.CallContext`, that holds\n25         the arguments for the call site.\n26     :param argument_context_map:\n27         Additional contexts per node, passed in from :attr:`astroid.context.Context.extra_context`\n28     :param context:\n29         An instance of :class:`astroid.context.Context`.\n30     \"\"\"\n31 \n32     def __init__(\n33         self,\n34         callcontext: CallContext,\n35         argument_context_map=None,\n36         context: InferenceContext | None = None,\n37     ):\n38         if argument_context_map is None:\n39             argument_context_map = {}\n40         self.argument_context_map = argument_context_map\n41         args = callcontext.args\n42         keywords = callcontext.keywords\n43         self.duplicated_keywords: set[str] = set()\n44         self._unpacked_args = self._unpack_args(args, context=context)\n45         self._unpacked_kwargs = self._unpack_keywords(keywords, context=context)\n46 \n47         self.positional_arguments = [\n48             arg for arg in self._unpacked_args if not isinstance(arg, UninferableBase)\n49         ]\n50         self.keyword_arguments = {\n51             key: value\n52             for key, value in self._unpacked_kwargs.items()\n53             if not isinstance(value, UninferableBase)\n54         }\n55 \n56     @classmethod\n57     def from_call(cls, call_node, context: InferenceContext | None = None):\n58         \"\"\"Get a CallSite object from the given Call node.\n59 \n60         context will be used to force a single inference path.\n61         \"\"\"\n62 \n63         # Determine the callcontext from the given `context` object if any.\n64         context = context or InferenceContext()\n65         callcontext = CallContext(call_node.args, call_node.keywords)\n66         return cls(callcontext, context=context)\n67 \n68     def has_invalid_arguments(self):\n69         \"\"\"Check if in the current CallSite were passed *invalid* arguments.\n70 \n71         This can mean multiple things. For instance, if an unpacking\n72         of an invalid object was passed, then this method will return True.\n73         Other cases can be when the arguments can't be inferred by astroid,\n74         for example, by passing objects which aren't known statically.\n75         \"\"\"\n76         return len(self.positional_arguments) != len(self._unpacked_args)\n77 \n78     def has_invalid_keywords(self) -> bool:\n79         \"\"\"Check if in the current CallSite were passed *invalid* keyword arguments.\n80 \n81         For instance, unpacking a dictionary with integer keys is invalid\n82         (**{1:2}), because the keys must be strings, which will make this\n83         method to return True. Other cases where this might return True if\n84         objects which can't be inferred were passed.\n85         \"\"\"\n86         return len(self.keyword_arguments) != len(self._unpacked_kwargs)\n87 \n88     def _unpack_keywords(\n89         self,\n90         keywords: list[tuple[str | None, nodes.NodeNG]],\n91         context: InferenceContext | None = None,\n92     ):\n93         values: dict[str | None, InferenceResult] = {}\n94         context = context or InferenceContext()\n95         context.extra_context = self.argument_context_map\n96         for name, value in keywords:\n97             if name is None:\n98                 # Then it's an unpacking operation (**)\n99                 inferred = safe_infer(value, context=context)\n100                 if not isinstance(inferred, nodes.Dict):\n101                     # Not something we can work with.\n102                     values[name] = Uninferable\n103                     continue\n104 \n105                 for dict_key, dict_value in inferred.items:\n106                     dict_key = safe_infer(dict_key, context=context)\n107                     if not isinstance(dict_key, nodes.Const):\n108                         values[name] = Uninferable\n109                         continue\n110                     if not isinstance(dict_key.value, str):\n111                         values[name] = Uninferable\n112                         continue\n113                     if dict_key.value in values:\n114                         # The name is already in the dictionary\n115                         values[dict_key.value] = Uninferable\n116                         self.duplicated_keywords.add(dict_key.value)\n117                         continue\n118                     values[dict_key.value] = dict_value\n119             else:\n120                 values[name] = value\n121         return values\n122 \n123     def _unpack_args(self, args, context: InferenceContext | None = None):\n124         values = []\n125         context = context or InferenceContext()\n126         context.extra_context = self.argument_context_map\n127         for arg in args:\n128             if isinstance(arg, nodes.Starred):\n129                 inferred = safe_infer(arg.value, context=context)\n130                 if isinstance(inferred, UninferableBase):\n131                     values.append(Uninferable)\n132                     continue\n133                 if not hasattr(inferred, \"elts\"):\n134                     values.append(Uninferable)\n135                     continue\n136                 values.extend(inferred.elts)\n137             else:\n138                 values.append(arg)\n139         return values\n140 \n141     def infer_argument(\n142         self, funcnode: InferenceResult, name: str, context: InferenceContext\n143     ):  # noqa: C901\n144         \"\"\"Infer a function argument value according to the call context.\"\"\"\n145         if not isinstance(funcnode, (nodes.FunctionDef, nodes.Lambda)):\n146             raise InferenceError(\n147                 f\"Can not infer function argument value for non-function node {funcnode!r}.\",\n148                 call_site=self,\n149                 func=funcnode,\n150                 arg=name,\n151                 context=context,\n152             )\n153 \n154         if name in self.duplicated_keywords:\n155             raise InferenceError(\n156                 \"The arguments passed to {func!r} have duplicate keywords.\",\n157                 call_site=self,\n158                 func=funcnode,\n159                 arg=name,\n160                 context=context,\n161             )\n162 \n163         # Look into the keywords first, maybe it's already there.\n164         try:\n165             return self.keyword_arguments[name].infer(context)\n166         except KeyError:\n167             pass\n168 \n169         # Too many arguments given and no variable arguments.\n170         if len(self.positional_arguments) > len(funcnode.args.args):\n171             if not funcnode.args.vararg and not funcnode.args.posonlyargs:\n172                 raise InferenceError(\n173                     \"Too many positional arguments \"\n174                     \"passed to {func!r} that does \"\n175                     \"not have *args.\",\n176                     call_site=self,\n177                     func=funcnode,\n178                     arg=name,\n179                     context=context,\n180                 )\n181 \n182         positional = self.positional_arguments[: len(funcnode.args.args)]\n183         vararg = self.positional_arguments[len(funcnode.args.args) :]\n184         argindex = funcnode.args.find_argname(name)[0]\n185         kwonlyargs = {arg.name for arg in funcnode.args.kwonlyargs}\n186         kwargs = {\n187             key: value\n188             for key, value in self.keyword_arguments.items()\n189             if key not in kwonlyargs\n190         }\n191         # If there are too few positionals compared to\n192         # what the function expects to receive, check to see\n193         # if the missing positional arguments were passed\n194         # as keyword arguments and if so, place them into the\n195         # positional args list.\n196         if len(positional) < len(funcnode.args.args):\n197             for func_arg in funcnode.args.args:\n198                 if func_arg.name in kwargs:\n199                     arg = kwargs.pop(func_arg.name)\n200                     positional.append(arg)\n201 \n202         if argindex is not None:\n203             boundnode = context.boundnode\n204             # 2. first argument of instance/class method\n205             if argindex == 0 and funcnode.type in {\"method\", \"classmethod\"}:\n206                 # context.boundnode is None when an instance method is called with\n207                 # the class, e.g. MyClass.method(obj, ...). In this case, self\n208                 # is the first argument.\n209                 if boundnode is None and funcnode.type == \"method\" and positional:\n210                     return positional[0].infer(context=context)\n211                 if boundnode is None:\n212                     # XXX can do better ?\n213                     boundnode = funcnode.parent.frame()\n214 \n215                 if isinstance(boundnode, nodes.ClassDef):\n216                     # Verify that we're accessing a method\n217                     # of the metaclass through a class, as in\n218                     # `cls.metaclass_method`. In this case, the\n219                     # first argument is always the class.\n220                     method_scope = funcnode.parent.scope()\n221                     if method_scope is boundnode.metaclass(context=context):\n222                         return iter((boundnode,))\n223 \n224                 if funcnode.type == \"method\":\n225                     if not isinstance(boundnode, Instance):\n226                         boundnode = boundnode.instantiate_class()\n227                     return iter((boundnode,))\n228                 if funcnode.type == \"classmethod\":\n229                     return iter((boundnode,))\n230             # if we have a method, extract one position\n231             # from the index, so we'll take in account\n232             # the extra parameter represented by `self` or `cls`\n233             if funcnode.type in {\"method\", \"classmethod\"} and boundnode:\n234                 argindex -= 1\n235             # 2. search arg index\n236             try:\n237                 return self.positional_arguments[argindex].infer(context)\n238             except IndexError:\n239                 pass\n240 \n241         if funcnode.args.kwarg == name:\n242             # It wants all the keywords that were passed into\n243             # the call site.\n244             if self.has_invalid_keywords():\n245                 raise InferenceError(\n246                     \"Inference failed to find values for all keyword arguments \"\n247                     \"to {func!r}: {unpacked_kwargs!r} doesn't correspond to \"\n248                     \"{keyword_arguments!r}.\",\n249                     keyword_arguments=self.keyword_arguments,\n250                     unpacked_kwargs=self._unpacked_kwargs,\n251                     call_site=self,\n252                     func=funcnode,\n253                     arg=name,\n254                     context=context,\n255                 )\n256             kwarg = nodes.Dict(\n257                 lineno=funcnode.args.lineno,\n258                 col_offset=funcnode.args.col_offset,\n259                 parent=funcnode.args,\n260                 end_lineno=funcnode.args.end_lineno,\n261                 end_col_offset=funcnode.args.end_col_offset,\n262             )\n263             kwarg.postinit(\n264                 [(nodes.const_factory(key), value) for key, value in kwargs.items()]\n265             )\n266             return iter((kwarg,))\n267         if funcnode.args.vararg == name:\n268             # It wants all the args that were passed into\n269             # the call site.\n270             if self.has_invalid_arguments():\n271                 raise InferenceError(\n272                     \"Inference failed to find values for all positional \"\n273                     \"arguments to {func!r}: {unpacked_args!r} doesn't \"\n274                     \"correspond to {positional_arguments!r}.\",\n275                     positional_arguments=self.positional_arguments,\n276                     unpacked_args=self._unpacked_args,\n277                     call_site=self,\n278                     func=funcnode,\n279                     arg=name,\n280                     context=context,\n281                 )\n282             args = nodes.Tuple(\n283                 lineno=funcnode.args.lineno,\n284                 col_offset=funcnode.args.col_offset,\n285                 parent=funcnode.args,\n286             )\n287             args.postinit(vararg)\n288             return iter((args,))\n289 \n290         # Check if it's a default parameter.\n291         try:\n292             return funcnode.args.default_value(name).infer(context)\n293         except NoDefault:\n294             pass\n295         raise InferenceError(\n296             \"No value found for argument {arg} to {func!r}\",\n297             call_site=self,\n298             func=funcnode,\n299             arg=name,\n300             context=context,\n301         )\n302 \n[end of astroid/arguments.py]\n[start of astroid/interpreter/objectmodel.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"\n6 Data object model, as per https://docs.python.org/3/reference/datamodel.html.\n7 \n8 This module describes, at least partially, a data object model for some\n9 of astroid's nodes. The model contains special attributes that nodes such\n10 as functions, classes, modules etc have, such as __doc__, __class__,\n11 __module__ etc, being used when doing attribute lookups over nodes.\n12 \n13 For instance, inferring `obj.__class__` will first trigger an inference\n14 of the `obj` variable. If it was successfully inferred, then an attribute\n15 `__class__ will be looked for in the inferred object. This is the part\n16 where the data model occurs. The model is attached to those nodes\n17 and the lookup mechanism will try to see if attributes such as\n18 `__class__` are defined by the model or not. If they are defined,\n19 the model will be requested to return the corresponding value of that\n20 attribute. Thus the model can be viewed as a special part of the lookup\n21 mechanism.\n22 \"\"\"\n23 \n24 from __future__ import annotations\n25 \n26 import itertools\n27 import os\n28 import pprint\n29 import types\n30 from collections.abc import Iterator\n31 from functools import lru_cache\n32 from typing import TYPE_CHECKING, Any, Literal\n33 \n34 import astroid\n35 from astroid import bases, nodes, util\n36 from astroid.context import InferenceContext, copy_context\n37 from astroid.exceptions import AttributeInferenceError, InferenceError, NoDefault\n38 from astroid.manager import AstroidManager\n39 from astroid.nodes import node_classes\n40 from astroid.typing import InferenceResult, SuccessfulInferenceResult\n41 \n42 if TYPE_CHECKING:\n43     from astroid.objects import Property\n44 \n45 IMPL_PREFIX = \"attr_\"\n46 LEN_OF_IMPL_PREFIX = len(IMPL_PREFIX)\n47 \n48 \n49 def _dunder_dict(instance, attributes):\n50     obj = node_classes.Dict(\n51         parent=instance,\n52         lineno=instance.lineno,\n53         col_offset=instance.col_offset,\n54         end_lineno=instance.end_lineno,\n55         end_col_offset=instance.end_col_offset,\n56     )\n57 \n58     # Convert the keys to node strings\n59     keys = [\n60         node_classes.Const(value=value, parent=obj) for value in list(attributes.keys())\n61     ]\n62 \n63     # The original attribute has a list of elements for each key,\n64     # but that is not useful for retrieving the special attribute's value.\n65     # In this case, we're picking the last value from each list.\n66     values = [elem[-1] for elem in attributes.values()]\n67 \n68     obj.postinit(list(zip(keys, values)))\n69     return obj\n70 \n71 \n72 def _get_bound_node(model: ObjectModel) -> Any:\n73     # TODO: Use isinstance instead of try ... except after _instance has typing\n74     try:\n75         return model._instance._proxied\n76     except AttributeError:\n77         return model._instance\n78 \n79 \n80 class ObjectModel:\n81     def __init__(self):\n82         self._instance = None\n83 \n84     def __repr__(self):\n85         result = []\n86         cname = type(self).__name__\n87         string = \"%(cname)s(%(fields)s)\"\n88         alignment = len(cname) + 1\n89         for field in sorted(self.attributes()):\n90             width = 80 - len(field) - alignment\n91             lines = pprint.pformat(field, indent=2, width=width).splitlines(True)\n92 \n93             inner = [lines[0]]\n94             for line in lines[1:]:\n95                 inner.append(\" \" * alignment + line)\n96             result.append(field)\n97 \n98         return string % {\n99             \"cname\": cname,\n100             \"fields\": (\",\\n\" + \" \" * alignment).join(result),\n101         }\n102 \n103     def __call__(self, instance):\n104         self._instance = instance\n105         return self\n106 \n107     def __get__(self, instance, cls=None):\n108         # ObjectModel needs to be a descriptor so that just doing\n109         # `special_attributes = SomeObjectModel` should be enough in the body of a node.\n110         # But at the same time, node.special_attributes should return an object\n111         # which can be used for manipulating the special attributes. That's the reason\n112         # we pass the instance through which it got accessed to ObjectModel.__call__,\n113         # returning itself afterwards, so we can still have access to the\n114         # underlying data model and to the instance for which it got accessed.\n115         return self(instance)\n116 \n117     def __contains__(self, name) -> bool:\n118         return name in self.attributes()\n119 \n120     @lru_cache  # noqa\n121     def attributes(self) -> list[str]:\n122         \"\"\"Get the attributes which are exported by this object model.\"\"\"\n123         return [o[LEN_OF_IMPL_PREFIX:] for o in dir(self) if o.startswith(IMPL_PREFIX)]\n124 \n125     def lookup(self, name):\n126         \"\"\"Look up the given *name* in the current model.\n127 \n128         It should return an AST or an interpreter object,\n129         but if the name is not found, then an AttributeInferenceError will be raised.\n130         \"\"\"\n131         if name in self.attributes():\n132             return getattr(self, IMPL_PREFIX + name)\n133         raise AttributeInferenceError(target=self._instance, attribute=name)\n134 \n135     @property\n136     def attr___new__(self) -> bases.BoundMethod:\n137         \"\"\"Calling cls.__new__(type) on an object returns an instance of 'type'.\"\"\"\n138         from astroid import builder  # pylint: disable=import-outside-toplevel\n139 \n140         node: nodes.FunctionDef = builder.extract_node(\n141             \"\"\"def __new__(self, cls): return cls()\"\"\"\n142         )\n143         # We set the parent as being the ClassDef of 'object' as that\n144         # triggers correct inference as a call to __new__ in bases.py\n145         node.parent = AstroidManager().builtins_module[\"object\"]\n146 \n147         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n148 \n149     @property\n150     def attr___init__(self) -> bases.BoundMethod:\n151         \"\"\"Calling cls.__init__() normally returns None.\"\"\"\n152         from astroid import builder  # pylint: disable=import-outside-toplevel\n153 \n154         # The *args and **kwargs are necessary not to trigger warnings about missing\n155         # or extra parameters for '__init__' methods we don't infer correctly.\n156         # This BoundMethod is the fallback value for those.\n157         node: nodes.FunctionDef = builder.extract_node(\n158             \"\"\"def __init__(self, *args, **kwargs): return None\"\"\"\n159         )\n160         # We set the parent as being the ClassDef of 'object' as that\n161         # is where this method originally comes from\n162         node.parent = AstroidManager().builtins_module[\"object\"]\n163 \n164         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n165 \n166 \n167 class ModuleModel(ObjectModel):\n168     def _builtins(self):\n169         builtins_ast_module = AstroidManager().builtins_module\n170         return builtins_ast_module.special_attributes.lookup(\"__dict__\")\n171 \n172     @property\n173     def attr_builtins(self):\n174         return self._builtins()\n175 \n176     @property\n177     def attr___path__(self):\n178         if not self._instance.package:\n179             raise AttributeInferenceError(target=self._instance, attribute=\"__path__\")\n180 \n181         path_objs = [\n182             node_classes.Const(\n183                 value=path\n184                 if not path.endswith(\"__init__.py\")\n185                 else os.path.dirname(path),\n186                 parent=self._instance,\n187             )\n188             for path in self._instance.path\n189         ]\n190 \n191         container = node_classes.List(parent=self._instance)\n192         container.postinit(path_objs)\n193 \n194         return container\n195 \n196     @property\n197     def attr___name__(self):\n198         return node_classes.Const(value=self._instance.name, parent=self._instance)\n199 \n200     @property\n201     def attr___doc__(self):\n202         return node_classes.Const(\n203             value=getattr(self._instance.doc_node, \"value\", None),\n204             parent=self._instance,\n205         )\n206 \n207     @property\n208     def attr___file__(self):\n209         return node_classes.Const(value=self._instance.file, parent=self._instance)\n210 \n211     @property\n212     def attr___dict__(self):\n213         return _dunder_dict(self._instance, self._instance.globals)\n214 \n215     @property\n216     def attr___package__(self):\n217         if not self._instance.package:\n218             value = \"\"\n219         else:\n220             value = self._instance.name\n221 \n222         return node_classes.Const(value=value, parent=self._instance)\n223 \n224     # These are related to the Python 3 implementation of the\n225     # import system,\n226     # https://docs.python.org/3/reference/import.html#import-related-module-attributes\n227 \n228     @property\n229     def attr___spec__(self):\n230         # No handling for now.\n231         return node_classes.Unknown()\n232 \n233     @property\n234     def attr___loader__(self):\n235         # No handling for now.\n236         return node_classes.Unknown()\n237 \n238     @property\n239     def attr___cached__(self):\n240         # No handling for now.\n241         return node_classes.Unknown()\n242 \n243 \n244 class FunctionModel(ObjectModel):\n245     @property\n246     def attr___name__(self):\n247         return node_classes.Const(value=self._instance.name, parent=self._instance)\n248 \n249     @property\n250     def attr___doc__(self):\n251         return node_classes.Const(\n252             value=getattr(self._instance.doc_node, \"value\", None),\n253             parent=self._instance,\n254         )\n255 \n256     @property\n257     def attr___qualname__(self):\n258         return node_classes.Const(value=self._instance.qname(), parent=self._instance)\n259 \n260     @property\n261     def attr___defaults__(self):\n262         func = self._instance\n263         if not func.args.defaults:\n264             return node_classes.Const(value=None, parent=func)\n265 \n266         defaults_obj = node_classes.Tuple(parent=func)\n267         defaults_obj.postinit(func.args.defaults)\n268         return defaults_obj\n269 \n270     @property\n271     def attr___annotations__(self):\n272         obj = node_classes.Dict(\n273             parent=self._instance,\n274             lineno=self._instance.lineno,\n275             col_offset=self._instance.col_offset,\n276             end_lineno=self._instance.end_lineno,\n277             end_col_offset=self._instance.end_col_offset,\n278         )\n279 \n280         if not self._instance.returns:\n281             returns = None\n282         else:\n283             returns = self._instance.returns\n284 \n285         args = self._instance.args\n286         pair_annotations = itertools.chain(\n287             zip(args.args or [], args.annotations),\n288             zip(args.kwonlyargs, args.kwonlyargs_annotations),\n289             zip(args.posonlyargs or [], args.posonlyargs_annotations),\n290         )\n291 \n292         annotations = {\n293             arg.name: annotation for (arg, annotation) in pair_annotations if annotation\n294         }\n295         if args.varargannotation:\n296             annotations[args.vararg] = args.varargannotation\n297         if args.kwargannotation:\n298             annotations[args.kwarg] = args.kwargannotation\n299         if returns:\n300             annotations[\"return\"] = returns\n301 \n302         items = [\n303             (node_classes.Const(key, parent=obj), value)\n304             for (key, value) in annotations.items()\n305         ]\n306 \n307         obj.postinit(items)\n308         return obj\n309 \n310     @property\n311     def attr___dict__(self):\n312         return node_classes.Dict(\n313             parent=self._instance,\n314             lineno=self._instance.lineno,\n315             col_offset=self._instance.col_offset,\n316             end_lineno=self._instance.end_lineno,\n317             end_col_offset=self._instance.end_col_offset,\n318         )\n319 \n320     attr___globals__ = attr___dict__\n321 \n322     @property\n323     def attr___kwdefaults__(self):\n324         def _default_args(args, parent):\n325             for arg in args.kwonlyargs:\n326                 try:\n327                     default = args.default_value(arg.name)\n328                 except NoDefault:\n329                     continue\n330 \n331                 name = node_classes.Const(arg.name, parent=parent)\n332                 yield name, default\n333 \n334         args = self._instance.args\n335         obj = node_classes.Dict(\n336             parent=self._instance,\n337             lineno=self._instance.lineno,\n338             col_offset=self._instance.col_offset,\n339             end_lineno=self._instance.end_lineno,\n340             end_col_offset=self._instance.end_col_offset,\n341         )\n342         defaults = dict(_default_args(args, obj))\n343 \n344         obj.postinit(list(defaults.items()))\n345         return obj\n346 \n347     @property\n348     def attr___module__(self):\n349         return node_classes.Const(self._instance.root().qname())\n350 \n351     @property\n352     def attr___get__(self):\n353         func = self._instance\n354 \n355         class DescriptorBoundMethod(bases.BoundMethod):\n356             \"\"\"Bound method which knows how to understand calling descriptor\n357             binding.\n358             \"\"\"\n359 \n360             def implicit_parameters(self) -> Literal[0]:\n361                 # Different than BoundMethod since the signature\n362                 # is different.\n363                 return 0\n364 \n365             def infer_call_result(\n366                 self,\n367                 caller: SuccessfulInferenceResult | None,\n368                 context: InferenceContext | None = None,\n369             ) -> Iterator[bases.BoundMethod]:\n370                 if len(caller.args) > 2 or len(caller.args) < 1:\n371                     raise InferenceError(\n372                         \"Invalid arguments for descriptor binding\",\n373                         target=self,\n374                         context=context,\n375                     )\n376 \n377                 context = copy_context(context)\n378                 try:\n379                     cls = next(caller.args[0].infer(context=context))\n380                 except StopIteration as e:\n381                     raise InferenceError(context=context, node=caller.args[0]) from e\n382 \n383                 if isinstance(cls, util.UninferableBase):\n384                     raise InferenceError(\n385                         \"Invalid class inferred\", target=self, context=context\n386                     )\n387 \n388                 # For some reason func is a Node that the below\n389                 # code is not expecting\n390                 if isinstance(func, bases.BoundMethod):\n391                     yield func\n392                     return\n393 \n394                 # Rebuild the original value, but with the parent set as the\n395                 # class where it will be bound.\n396                 new_func = func.__class__(\n397                     name=func.name,\n398                     lineno=func.lineno,\n399                     col_offset=func.col_offset,\n400                     parent=func.parent,\n401                     end_lineno=func.end_lineno,\n402                     end_col_offset=func.end_col_offset,\n403                 )\n404                 # pylint: disable=no-member\n405                 new_func.postinit(\n406                     func.args,\n407                     func.body,\n408                     func.decorators,\n409                     func.returns,\n410                     doc_node=func.doc_node,\n411                 )\n412 \n413                 # Build a proper bound method that points to our newly built function.\n414                 proxy = bases.UnboundMethod(new_func)\n415                 yield bases.BoundMethod(proxy=proxy, bound=cls)\n416 \n417             @property\n418             def args(self):\n419                 \"\"\"Overwrite the underlying args to match those of the underlying func.\n420 \n421                 Usually the underlying *func* is a function/method, as in:\n422 \n423                     def test(self):\n424                         pass\n425 \n426                 This has only the *self* parameter but when we access test.__get__\n427                 we get a new object which has two parameters, *self* and *type*.\n428                 \"\"\"\n429                 nonlocal func\n430                 arguments = astroid.Arguments(\n431                     parent=func.args.parent, vararg=None, kwarg=None\n432                 )\n433 \n434                 positional_or_keyword_params = func.args.args.copy()\n435                 positional_or_keyword_params.append(\n436                     astroid.AssignName(\n437                         name=\"type\",\n438                         lineno=0,\n439                         col_offset=0,\n440                         parent=arguments,\n441                         end_lineno=None,\n442                         end_col_offset=None,\n443                     )\n444                 )\n445 \n446                 positional_only_params = func.args.posonlyargs.copy()\n447 \n448                 arguments.postinit(\n449                     args=positional_or_keyword_params,\n450                     posonlyargs=positional_only_params,\n451                     defaults=[],\n452                     kwonlyargs=[],\n453                     kw_defaults=[],\n454                     annotations=[],\n455                     kwonlyargs_annotations=[],\n456                     posonlyargs_annotations=[],\n457                 )\n458                 return arguments\n459 \n460         return DescriptorBoundMethod(proxy=self._instance, bound=self._instance)\n461 \n462     # These are here just for completion.\n463     @property\n464     def attr___ne__(self):\n465         return node_classes.Unknown()\n466 \n467     attr___subclasshook__ = attr___ne__\n468     attr___str__ = attr___ne__\n469     attr___sizeof__ = attr___ne__\n470     attr___setattr___ = attr___ne__\n471     attr___repr__ = attr___ne__\n472     attr___reduce__ = attr___ne__\n473     attr___reduce_ex__ = attr___ne__\n474     attr___lt__ = attr___ne__\n475     attr___eq__ = attr___ne__\n476     attr___gt__ = attr___ne__\n477     attr___format__ = attr___ne__\n478     attr___delattr___ = attr___ne__\n479     attr___getattribute__ = attr___ne__\n480     attr___hash__ = attr___ne__\n481     attr___dir__ = attr___ne__\n482     attr___call__ = attr___ne__\n483     attr___class__ = attr___ne__\n484     attr___closure__ = attr___ne__\n485     attr___code__ = attr___ne__\n486 \n487 \n488 class ClassModel(ObjectModel):\n489     def __init__(self):\n490         # Add a context so that inferences called from an instance don't recurse endlessly\n491         self.context = InferenceContext()\n492 \n493         super().__init__()\n494 \n495     @property\n496     def attr___module__(self):\n497         return node_classes.Const(self._instance.root().qname())\n498 \n499     @property\n500     def attr___name__(self):\n501         return node_classes.Const(self._instance.name)\n502 \n503     @property\n504     def attr___qualname__(self):\n505         return node_classes.Const(self._instance.qname())\n506 \n507     @property\n508     def attr___doc__(self):\n509         return node_classes.Const(getattr(self._instance.doc_node, \"value\", None))\n510 \n511     @property\n512     def attr___mro__(self):\n513         if not self._instance.newstyle:\n514             raise AttributeInferenceError(target=self._instance, attribute=\"__mro__\")\n515 \n516         mro = self._instance.mro()\n517         obj = node_classes.Tuple(parent=self._instance)\n518         obj.postinit(mro)\n519         return obj\n520 \n521     @property\n522     def attr_mro(self):\n523         if not self._instance.newstyle:\n524             raise AttributeInferenceError(target=self._instance, attribute=\"mro\")\n525 \n526         other_self = self\n527 \n528         # Cls.mro is a method and we need to return one in order to have a proper inference.\n529         # The method we're returning is capable of inferring the underlying MRO though.\n530         class MroBoundMethod(bases.BoundMethod):\n531             def infer_call_result(\n532                 self,\n533                 caller: SuccessfulInferenceResult | None,\n534                 context: InferenceContext | None = None,\n535             ) -> Iterator[node_classes.Tuple]:\n536                 yield other_self.attr___mro__\n537 \n538         implicit_metaclass = self._instance.implicit_metaclass()\n539         mro_method = implicit_metaclass.locals[\"mro\"][0]\n540         return MroBoundMethod(proxy=mro_method, bound=implicit_metaclass)\n541 \n542     @property\n543     def attr___bases__(self):\n544         obj = node_classes.Tuple()\n545         context = InferenceContext()\n546         elts = list(self._instance._inferred_bases(context))\n547         obj.postinit(elts=elts)\n548         return obj\n549 \n550     @property\n551     def attr___class__(self):\n552         # pylint: disable=import-outside-toplevel; circular import\n553         from astroid import helpers\n554 \n555         return helpers.object_type(self._instance)\n556 \n557     @property\n558     def attr___subclasses__(self):\n559         \"\"\"Get the subclasses of the underlying class.\n560 \n561         This looks only in the current module for retrieving the subclasses,\n562         thus it might miss a couple of them.\n563         \"\"\"\n564         if not self._instance.newstyle:\n565             raise AttributeInferenceError(\n566                 target=self._instance, attribute=\"__subclasses__\"\n567             )\n568 \n569         qname = self._instance.qname()\n570         root = self._instance.root()\n571         classes = [\n572             cls\n573             for cls in root.nodes_of_class(nodes.ClassDef)\n574             if cls != self._instance and cls.is_subtype_of(qname, context=self.context)\n575         ]\n576 \n577         obj = node_classes.List(parent=self._instance)\n578         obj.postinit(classes)\n579 \n580         class SubclassesBoundMethod(bases.BoundMethod):\n581             def infer_call_result(\n582                 self,\n583                 caller: SuccessfulInferenceResult | None,\n584                 context: InferenceContext | None = None,\n585             ) -> Iterator[node_classes.List]:\n586                 yield obj\n587 \n588         implicit_metaclass = self._instance.implicit_metaclass()\n589         subclasses_method = implicit_metaclass.locals[\"__subclasses__\"][0]\n590         return SubclassesBoundMethod(proxy=subclasses_method, bound=implicit_metaclass)\n591 \n592     @property\n593     def attr___dict__(self):\n594         return node_classes.Dict(\n595             parent=self._instance,\n596             lineno=self._instance.lineno,\n597             col_offset=self._instance.col_offset,\n598             end_lineno=self._instance.end_lineno,\n599             end_col_offset=self._instance.end_col_offset,\n600         )\n601 \n602     @property\n603     def attr___call__(self):\n604         \"\"\"Calling a class A() returns an instance of A.\"\"\"\n605         return self._instance.instantiate_class()\n606 \n607 \n608 class SuperModel(ObjectModel):\n609     @property\n610     def attr___thisclass__(self):\n611         return self._instance.mro_pointer\n612 \n613     @property\n614     def attr___self_class__(self):\n615         return self._instance._self_class\n616 \n617     @property\n618     def attr___self__(self):\n619         return self._instance.type\n620 \n621     @property\n622     def attr___class__(self):\n623         return self._instance._proxied\n624 \n625 \n626 class UnboundMethodModel(ObjectModel):\n627     @property\n628     def attr___class__(self):\n629         # pylint: disable=import-outside-toplevel; circular import\n630         from astroid import helpers\n631 \n632         return helpers.object_type(self._instance)\n633 \n634     @property\n635     def attr___func__(self):\n636         return self._instance._proxied\n637 \n638     @property\n639     def attr___self__(self):\n640         return node_classes.Const(value=None, parent=self._instance)\n641 \n642     attr_im_func = attr___func__\n643     attr_im_class = attr___class__\n644     attr_im_self = attr___self__\n645 \n646 \n647 class ContextManagerModel(ObjectModel):\n648     \"\"\"Model for context managers.\n649 \n650     Based on 3.3.9 of the Data Model documentation:\n651     https://docs.python.org/3/reference/datamodel.html#with-statement-context-managers\n652     \"\"\"\n653 \n654     @property\n655     def attr___enter__(self) -> bases.BoundMethod:\n656         \"\"\"Representation of the base implementation of __enter__.\n657 \n658         As per Python documentation:\n659         Enter the runtime context related to this object. The with statement\n660         will bind this method's return value to the target(s) specified in the\n661         as clause of the statement, if any.\n662         \"\"\"\n663         from astroid import builder  # pylint: disable=import-outside-toplevel\n664 \n665         node: nodes.FunctionDef = builder.extract_node(\"\"\"def __enter__(self): ...\"\"\")\n666         # We set the parent as being the ClassDef of 'object' as that\n667         # is where this method originally comes from\n668         node.parent = AstroidManager().builtins_module[\"object\"]\n669 \n670         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n671 \n672     @property\n673     def attr___exit__(self) -> bases.BoundMethod:\n674         \"\"\"Representation of the base implementation of __exit__.\n675 \n676         As per Python documentation:\n677         Exit the runtime context related to this object. The parameters describe the\n678         exception that caused the context to be exited. If the context was exited\n679         without an exception, all three arguments will be None.\n680         \"\"\"\n681         from astroid import builder  # pylint: disable=import-outside-toplevel\n682 \n683         node: nodes.FunctionDef = builder.extract_node(\n684             \"\"\"def __exit__(self, exc_type, exc_value, traceback): ...\"\"\"\n685         )\n686         # We set the parent as being the ClassDef of 'object' as that\n687         # is where this method originally comes from\n688         node.parent = AstroidManager().builtins_module[\"object\"]\n689 \n690         return bases.BoundMethod(proxy=node, bound=_get_bound_node(self))\n691 \n692 \n693 class BoundMethodModel(FunctionModel):\n694     @property\n695     def attr___func__(self):\n696         return self._instance._proxied._proxied\n697 \n698     @property\n699     def attr___self__(self):\n700         return self._instance.bound\n701 \n702 \n703 class GeneratorModel(FunctionModel, ContextManagerModel):\n704     def __new__(cls, *args, **kwargs):\n705         # Append the values from the GeneratorType unto this object.\n706         ret = super().__new__(cls, *args, **kwargs)\n707         generator = AstroidManager().builtins_module[\"generator\"]\n708         for name, values in generator.locals.items():\n709             method = values[0]\n710 \n711             def patched(cls, meth=method):\n712                 return meth\n713 \n714             setattr(type(ret), IMPL_PREFIX + name, property(patched))\n715 \n716         return ret\n717 \n718     @property\n719     def attr___name__(self):\n720         return node_classes.Const(\n721             value=self._instance.parent.name, parent=self._instance\n722         )\n723 \n724     @property\n725     def attr___doc__(self):\n726         return node_classes.Const(\n727             value=getattr(self._instance.parent.doc_node, \"value\", None),\n728             parent=self._instance,\n729         )\n730 \n731 \n732 class AsyncGeneratorModel(GeneratorModel):\n733     def __new__(cls, *args, **kwargs):\n734         # Append the values from the AGeneratorType unto this object.\n735         ret = super().__new__(cls, *args, **kwargs)\n736         astroid_builtins = AstroidManager().builtins_module\n737         generator = astroid_builtins.get(\"async_generator\")\n738         if generator is None:\n739             # Make it backward compatible.\n740             generator = astroid_builtins.get(\"generator\")\n741 \n742         for name, values in generator.locals.items():\n743             method = values[0]\n744 \n745             def patched(cls, meth=method):\n746                 return meth\n747 \n748             setattr(type(ret), IMPL_PREFIX + name, property(patched))\n749 \n750         return ret\n751 \n752 \n753 class InstanceModel(ObjectModel):\n754     @property\n755     def attr___class__(self):\n756         return self._instance._proxied\n757 \n758     @property\n759     def attr___module__(self):\n760         return node_classes.Const(self._instance.root().qname())\n761 \n762     @property\n763     def attr___doc__(self):\n764         return node_classes.Const(getattr(self._instance.doc_node, \"value\", None))\n765 \n766     @property\n767     def attr___dict__(self):\n768         return _dunder_dict(self._instance, self._instance.instance_attrs)\n769 \n770 \n771 # Exception instances\n772 \n773 \n774 class ExceptionInstanceModel(InstanceModel):\n775     @property\n776     def attr_args(self) -> nodes.Tuple:\n777         return nodes.Tuple(parent=self._instance)\n778 \n779     @property\n780     def attr___traceback__(self):\n781         builtins_ast_module = AstroidManager().builtins_module\n782         traceback_type = builtins_ast_module[types.TracebackType.__name__]\n783         return traceback_type.instantiate_class()\n784 \n785 \n786 class SyntaxErrorInstanceModel(ExceptionInstanceModel):\n787     @property\n788     def attr_text(self):\n789         return node_classes.Const(\"\")\n790 \n791 \n792 class OSErrorInstanceModel(ExceptionInstanceModel):\n793     @property\n794     def attr_filename(self):\n795         return node_classes.Const(\"\")\n796 \n797     @property\n798     def attr_errno(self):\n799         return node_classes.Const(0)\n800 \n801     @property\n802     def attr_strerror(self):\n803         return node_classes.Const(\"\")\n804 \n805     attr_filename2 = attr_filename\n806 \n807 \n808 class ImportErrorInstanceModel(ExceptionInstanceModel):\n809     @property\n810     def attr_name(self):\n811         return node_classes.Const(\"\")\n812 \n813     @property\n814     def attr_path(self):\n815         return node_classes.Const(\"\")\n816 \n817 \n818 class UnicodeDecodeErrorInstanceModel(ExceptionInstanceModel):\n819     @property\n820     def attr_object(self):\n821         return node_classes.Const(\"\")\n822 \n823 \n824 BUILTIN_EXCEPTIONS = {\n825     \"builtins.SyntaxError\": SyntaxErrorInstanceModel,\n826     \"builtins.ImportError\": ImportErrorInstanceModel,\n827     \"builtins.UnicodeDecodeError\": UnicodeDecodeErrorInstanceModel,\n828     # These are all similar to OSError in terms of attributes\n829     \"builtins.OSError\": OSErrorInstanceModel,\n830     \"builtins.BlockingIOError\": OSErrorInstanceModel,\n831     \"builtins.BrokenPipeError\": OSErrorInstanceModel,\n832     \"builtins.ChildProcessError\": OSErrorInstanceModel,\n833     \"builtins.ConnectionAbortedError\": OSErrorInstanceModel,\n834     \"builtins.ConnectionError\": OSErrorInstanceModel,\n835     \"builtins.ConnectionRefusedError\": OSErrorInstanceModel,\n836     \"builtins.ConnectionResetError\": OSErrorInstanceModel,\n837     \"builtins.FileExistsError\": OSErrorInstanceModel,\n838     \"builtins.FileNotFoundError\": OSErrorInstanceModel,\n839     \"builtins.InterruptedError\": OSErrorInstanceModel,\n840     \"builtins.IsADirectoryError\": OSErrorInstanceModel,\n841     \"builtins.NotADirectoryError\": OSErrorInstanceModel,\n842     \"builtins.PermissionError\": OSErrorInstanceModel,\n843     \"builtins.ProcessLookupError\": OSErrorInstanceModel,\n844     \"builtins.TimeoutError\": OSErrorInstanceModel,\n845 }\n846 \n847 \n848 class DictModel(ObjectModel):\n849     @property\n850     def attr___class__(self):\n851         return self._instance._proxied\n852 \n853     def _generic_dict_attribute(self, obj, name):\n854         \"\"\"Generate a bound method that can infer the given *obj*.\"\"\"\n855 \n856         class DictMethodBoundMethod(astroid.BoundMethod):\n857             def infer_call_result(\n858                 self,\n859                 caller: SuccessfulInferenceResult | None,\n860                 context: InferenceContext | None = None,\n861             ) -> Iterator[InferenceResult]:\n862                 yield obj\n863 \n864         meth = next(self._instance._proxied.igetattr(name), None)\n865         return DictMethodBoundMethod(proxy=meth, bound=self._instance)\n866 \n867     @property\n868     def attr_items(self):\n869         from astroid import objects  # pylint: disable=import-outside-toplevel\n870 \n871         elems = []\n872         obj = node_classes.List(parent=self._instance)\n873         for key, value in self._instance.items:\n874             elem = node_classes.Tuple(parent=obj)\n875             elem.postinit((key, value))\n876             elems.append(elem)\n877         obj.postinit(elts=elems)\n878 \n879         items_obj = objects.DictItems(obj)\n880         return self._generic_dict_attribute(items_obj, \"items\")\n881 \n882     @property\n883     def attr_keys(self):\n884         from astroid import objects  # pylint: disable=import-outside-toplevel\n885 \n886         keys = [key for (key, _) in self._instance.items]\n887         obj = node_classes.List(parent=self._instance)\n888         obj.postinit(elts=keys)\n889 \n890         keys_obj = objects.DictKeys(obj)\n891         return self._generic_dict_attribute(keys_obj, \"keys\")\n892 \n893     @property\n894     def attr_values(self):\n895         from astroid import objects  # pylint: disable=import-outside-toplevel\n896 \n897         values = [value for (_, value) in self._instance.items]\n898         obj = node_classes.List(parent=self._instance)\n899         obj.postinit(values)\n900 \n901         values_obj = objects.DictValues(obj)\n902         return self._generic_dict_attribute(values_obj, \"values\")\n903 \n904 \n905 class PropertyModel(ObjectModel):\n906     \"\"\"Model for a builtin property.\"\"\"\n907 \n908     def _init_function(self, name):\n909         function = nodes.FunctionDef(\n910             name=name,\n911             parent=self._instance,\n912             lineno=self._instance.lineno,\n913             col_offset=self._instance.col_offset,\n914             end_lineno=self._instance.end_lineno,\n915             end_col_offset=self._instance.end_col_offset,\n916         )\n917 \n918         args = nodes.Arguments(parent=function, vararg=None, kwarg=None)\n919         args.postinit(\n920             args=[],\n921             defaults=[],\n922             kwonlyargs=[],\n923             kw_defaults=[],\n924             annotations=[],\n925             posonlyargs=[],\n926             posonlyargs_annotations=[],\n927             kwonlyargs_annotations=[],\n928         )\n929 \n930         function.postinit(args=args, body=[])\n931         return function\n932 \n933     @property\n934     def attr_fget(self):\n935         func = self._instance\n936 \n937         class PropertyFuncAccessor(nodes.FunctionDef):\n938             def infer_call_result(\n939                 self,\n940                 caller: SuccessfulInferenceResult | None,\n941                 context: InferenceContext | None = None,\n942             ) -> Iterator[InferenceResult]:\n943                 nonlocal func\n944                 if caller and len(caller.args) != 1:\n945                     raise InferenceError(\n946                         \"fget() needs a single argument\", target=self, context=context\n947                     )\n948 \n949                 yield from func.function.infer_call_result(\n950                     caller=caller, context=context\n951                 )\n952 \n953         property_accessor = PropertyFuncAccessor(\n954             name=\"fget\",\n955             parent=self._instance,\n956             lineno=self._instance.lineno,\n957             col_offset=self._instance.col_offset,\n958             end_lineno=self._instance.end_lineno,\n959             end_col_offset=self._instance.end_col_offset,\n960         )\n961         property_accessor.postinit(args=func.args, body=func.body)\n962         return property_accessor\n963 \n964     @property\n965     def attr_fset(self):\n966         func = self._instance\n967 \n968         def find_setter(func: Property) -> astroid.FunctionDef | None:\n969             \"\"\"\n970             Given a property, find the corresponding setter function and returns it.\n971 \n972             :param func: property for which the setter has to be found\n973             :return: the setter function or None\n974             \"\"\"\n975             for target in [\n976                 t for t in func.parent.get_children() if t.name == func.function.name\n977             ]:\n978                 for dec_name in target.decoratornames():\n979                     if dec_name.endswith(func.function.name + \".setter\"):\n980                         return target\n981             return None\n982 \n983         func_setter = find_setter(func)\n984         if not func_setter:\n985             raise InferenceError(\n986                 f\"Unable to find the setter of property {func.function.name}\"\n987             )\n988 \n989         class PropertyFuncAccessor(nodes.FunctionDef):\n990             def infer_call_result(\n991                 self,\n992                 caller: SuccessfulInferenceResult | None,\n993                 context: InferenceContext | None = None,\n994             ) -> Iterator[InferenceResult]:\n995                 nonlocal func_setter\n996                 if caller and len(caller.args) != 2:\n997                     raise InferenceError(\n998                         \"fset() needs two arguments\", target=self, context=context\n999                     )\n1000                 yield from func_setter.infer_call_result(caller=caller, context=context)\n1001 \n1002         property_accessor = PropertyFuncAccessor(\n1003             name=\"fset\",\n1004             parent=self._instance,\n1005             lineno=self._instance.lineno,\n1006             col_offset=self._instance.col_offset,\n1007             end_lineno=self._instance.end_lineno,\n1008             end_col_offset=self._instance.end_col_offset,\n1009         )\n1010         property_accessor.postinit(args=func_setter.args, body=func_setter.body)\n1011         return property_accessor\n1012 \n1013     @property\n1014     def attr_setter(self):\n1015         return self._init_function(\"setter\")\n1016 \n1017     @property\n1018     def attr_deleter(self):\n1019         return self._init_function(\"deleter\")\n1020 \n1021     @property\n1022     def attr_getter(self):\n1023         return self._init_function(\"getter\")\n1024 \n1025     # pylint: enable=import-outside-toplevel\n1026 \n[end of astroid/interpreter/objectmodel.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pylint-dev/astroid", "base_commit": "514991036806e9cda2b12cef8ab3184ac373bd6c", "problem_statement": "`.arguments` property ignores keyword-only args, *args, and **kwargs\n```python\r\n>>> from astroid import extract_node\r\n>>> node = extract_node(\"\"\"def a(*args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[]\r\n```\r\n\r\nExpected to find all the arguments from the function signature.\r\n\r\nThe wanted data can be found here:\r\n\r\n```python\r\n>>> node.args.vararg\r\n'args'\r\n>>> node.args.kwarg\r\n'kwargs'\r\n>>> node.args.kwonlyargs\r\n[<AssignName.b l.1 at 0x1048189b0>, <AssignName.c l.1 at 0x104818830>]\r\n```\r\n\r\nDiscussed at https://github.com/pylint-dev/pylint/pull/7577#discussion_r989000829.\r\n\r\nNotice that positional-only args are found for some reason \ud83e\udd37 \n", "hints_text": "Should the definition be changed as well? It states `args.arguments` returns required arguments, and AFAIK in the example none are required (I can call `a` without supplying any arguments).\r\n\r\nI tried running the following:\r\n\r\n```\r\n>>> node = extract_node(\"\"\"def a(kiwi, apple, *args, b=None, c=None, **kwargs): ...\"\"\")\r\n>>> node.args.arguments\r\n[<AssignName.kiwi l.1 at 0x7f5c55986b90>, <AssignName.apple l.1 at 0x7f5c55985a50>]\r\n```\r\n\r\nAnd it seems correct to me :thinking: \nhttps://github.com/pylint-dev/astroid/blob/fef38f2dd474b0dacd1dda3f15abbf61eb0e9a71/astroid/nodes/node_classes.py#L685-L688\r\n\r\nThe docstring seems to be correct?\nDepends on how you parse the language. \"positional and keyword\" could describe the argument `kiwi` and exclude keyword-only arguments.\r\n\r\nEssentially, the crux of this is whether we should\r\n- leave the function as is, and audit everywhere that uses it (given that we keep finding bugs)\r\n- change the function\r\n\r\n@crazybolillo have you happened to sample the places that use this function to be able to offer a view on that? I'd be eager to hear it!\nI think I got confused about the documentation :sob:. I was reading the docstring for `args` (`node.args.args` in the example):\r\n\r\nhttps://github.com/pylint-dev/astroid/blob/d4f4452fe089f600bf9144ffdcd8e698816df3c2/astroid/nodes/node_classes.py#L554-L555\r\n\r\n but we are dealing with `arguments` (`node.args.arguments`). I will review the code further to see if I can come up with something\r\n\r\n", "created_at": "2023-07-06T20:52:39Z", "patch": "<patch>\ndiff --git a/astroid/arguments.py b/astroid/arguments.py\n--- a/astroid/arguments.py\n+++ b/astroid/arguments.py\n@@ -181,7 +181,13 @@ def infer_argument(\n \n         positional = self.positional_arguments[: len(funcnode.args.args)]\n         vararg = self.positional_arguments[len(funcnode.args.args) :]\n-        argindex = funcnode.args.find_argname(name)[0]\n+\n+        # preserving previous behavior, when vararg and kwarg were not included in find_argname results\n+        if name in [funcnode.args.vararg, funcnode.args.kwarg]:\n+            argindex = None\n+        else:\n+            argindex = funcnode.args.find_argname(name)[0]\n+\n         kwonlyargs = {arg.name for arg in funcnode.args.kwonlyargs}\n         kwargs = {\n             key: value\ndiff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -605,7 +605,9 @@ def _infer(\n DEPRECATED_ARGUMENT_DEFAULT = \"DEPRECATED_ARGUMENT_DEFAULT\"\n \n \n-class Arguments(_base_nodes.AssignTypeNode):\n+class Arguments(\n+    _base_nodes.AssignTypeNode\n+):  # pylint: disable=too-many-instance-attributes\n     \"\"\"Class representing an :class:`ast.arguments` node.\n \n     An :class:`Arguments` node represents that arguments in a\n@@ -704,7 +706,20 @@ class Arguments(_base_nodes.AssignTypeNode):\n     kwargannotation: NodeNG | None\n     \"\"\"The type annotation for the variable length keyword arguments.\"\"\"\n \n-    def __init__(self, vararg: str | None, kwarg: str | None, parent: NodeNG) -> None:\n+    vararg_node: AssignName | None\n+    \"\"\"The node for variable length arguments\"\"\"\n+\n+    kwarg_node: AssignName | None\n+    \"\"\"The node for variable keyword arguments\"\"\"\n+\n+    def __init__(\n+        self,\n+        vararg: str | None,\n+        kwarg: str | None,\n+        parent: NodeNG,\n+        vararg_node: AssignName | None = None,\n+        kwarg_node: AssignName | None = None,\n+    ) -> None:\n         \"\"\"Almost all attributes can be None for living objects where introspection failed.\"\"\"\n         super().__init__(\n             parent=parent,\n@@ -720,6 +735,9 @@ def __init__(self, vararg: str | None, kwarg: str | None, parent: NodeNG) -> Non\n         self.kwarg = kwarg\n         \"\"\"The name of the variable length keyword arguments.\"\"\"\n \n+        self.vararg_node = vararg_node\n+        self.kwarg_node = kwarg_node\n+\n     # pylint: disable=too-many-arguments\n     def postinit(\n         self,\n@@ -780,8 +798,21 @@ def fromlineno(self) -> int:\n \n     @cached_property\n     def arguments(self):\n-        \"\"\"Get all the arguments for this node, including positional only and positional and keyword\"\"\"\n-        return list(itertools.chain((self.posonlyargs or ()), self.args or ()))\n+        \"\"\"Get all the arguments for this node. This includes:\n+        * Positional only arguments\n+        * Positional arguments\n+        * Keyword arguments\n+        * Variable arguments (.e.g *args)\n+        * Variable keyword arguments (e.g **kwargs)\n+        \"\"\"\n+        retval = list(itertools.chain((self.posonlyargs or ()), (self.args or ())))\n+        if self.vararg_node:\n+            retval.append(self.vararg_node)\n+        retval += self.kwonlyargs or ()\n+        if self.kwarg_node:\n+            retval.append(self.kwarg_node)\n+\n+        return retval\n \n     def format_args(self, *, skippable_names: set[str] | None = None) -> str:\n         \"\"\"Get the arguments formatted as string.\n@@ -911,15 +942,20 @@ def default_value(self, argname):\n         :raises NoDefault: If there is no default value defined for the\n             given argument.\n         \"\"\"\n-        args = self.arguments\n+        args = [\n+            arg for arg in self.arguments if arg.name not in [self.vararg, self.kwarg]\n+        ]\n+\n+        index = _find_arg(argname, self.kwonlyargs)[0]\n+        if index is not None and self.kw_defaults[index] is not None:\n+            return self.kw_defaults[index]\n+\n         index = _find_arg(argname, args)[0]\n         if index is not None:\n-            idx = index - (len(args) - len(self.defaults))\n+            idx = index - (len(args) - len(self.defaults) - len(self.kw_defaults))\n             if idx >= 0:\n                 return self.defaults[idx]\n-        index = _find_arg(argname, self.kwonlyargs)[0]\n-        if index is not None and self.kw_defaults[index] is not None:\n-            return self.kw_defaults[index]\n+\n         raise NoDefault(func=self.parent, name=argname)\n \n     def is_argument(self, name) -> bool:\n@@ -934,11 +970,7 @@ def is_argument(self, name) -> bool:\n             return True\n         if name == self.kwarg:\n             return True\n-        return (\n-            self.find_argname(name)[1] is not None\n-            or self.kwonlyargs\n-            and _find_arg(name, self.kwonlyargs)[1] is not None\n-        )\n+        return self.find_argname(name)[1] is not None\n \n     def find_argname(self, argname, rec=DEPRECATED_ARGUMENT_DEFAULT):\n         \"\"\"Get the index and :class:`AssignName` node for given name.\n@@ -956,7 +988,9 @@ def find_argname(self, argname, rec=DEPRECATED_ARGUMENT_DEFAULT):\n                 stacklevel=2,\n             )\n         if self.arguments:\n-            return _find_arg(argname, self.arguments)\n+            index, argument = _find_arg(argname, self.arguments)\n+            if argument:\n+                return index, argument\n         return None, None\n \n     def get_children(self):\ndiff --git a/astroid/nodes/scoped_nodes/scoped_nodes.py b/astroid/nodes/scoped_nodes/scoped_nodes.py\n--- a/astroid/nodes/scoped_nodes/scoped_nodes.py\n+++ b/astroid/nodes/scoped_nodes/scoped_nodes.py\n@@ -963,11 +963,7 @@ def argnames(self) -> list[str]:\n             names = [elt.name for elt in self.args.arguments]\n         else:\n             names = []\n-        if self.args.vararg:\n-            names.append(self.args.vararg)\n-        names += [elt.name for elt in self.args.kwonlyargs]\n-        if self.args.kwarg:\n-            names.append(self.args.kwarg)\n+\n         return names\n \n     def infer_call_result(\n@@ -1280,11 +1276,7 @@ def argnames(self) -> list[str]:\n             names = [elt.name for elt in self.args.arguments]\n         else:\n             names = []\n-        if self.args.vararg:\n-            names.append(self.args.vararg)\n-        names += [elt.name for elt in self.args.kwonlyargs]\n-        if self.args.kwarg:\n-            names.append(self.args.kwarg)\n+\n         return names\n \n     def getattr(\ndiff --git a/astroid/protocols.py b/astroid/protocols.py\n--- a/astroid/protocols.py\n+++ b/astroid/protocols.py\n@@ -352,14 +352,15 @@ def _arguments_infer_argname(\n     # more\n     from astroid import arguments  # pylint: disable=import-outside-toplevel\n \n-    if not (self.arguments or self.vararg or self.kwarg):\n+    if not self.arguments:\n         yield util.Uninferable\n         return\n \n+    args = [arg for arg in self.arguments if arg.name not in [self.vararg, self.kwarg]]\n     functype = self.parent.type\n     # first argument of instance/class method\n     if (\n-        self.arguments\n+        args\n         and getattr(self.arguments[0], \"name\", None) == name\n         and functype != \"staticmethod\"\n     ):\n@@ -388,7 +389,7 @@ def _arguments_infer_argname(\n     if name == self.vararg:\n         vararg = nodes.const_factory(())\n         vararg.parent = self\n-        if not self.arguments and self.parent.name == \"__init__\":\n+        if not args and self.parent.name == \"__init__\":\n             cls = self.parent.parent.scope()\n             vararg.elts = [cls.instantiate_class()]\n         yield vararg\ndiff --git a/astroid/rebuilder.py b/astroid/rebuilder.py\n--- a/astroid/rebuilder.py\n+++ b/astroid/rebuilder.py\n@@ -21,6 +21,7 @@\n from astroid.const import IS_PYPY, PY38, PY39_PLUS, PY312_PLUS, Context\n from astroid.manager import AstroidManager\n from astroid.nodes import NodeNG\n+from astroid.nodes.node_classes import AssignName\n from astroid.nodes.utils import Position\n from astroid.typing import InferenceResult\n \n@@ -561,10 +562,33 @@ def visit_arguments(self, node: ast.arguments, parent: NodeNG) -> nodes.Argument\n         \"\"\"Visit an Arguments node by returning a fresh instance of it.\"\"\"\n         vararg: str | None = None\n         kwarg: str | None = None\n+        vararg_node = node.vararg\n+        kwarg_node = node.kwarg\n+\n         newnode = nodes.Arguments(\n             node.vararg.arg if node.vararg else None,\n             node.kwarg.arg if node.kwarg else None,\n             parent,\n+            AssignName(\n+                vararg_node.arg,\n+                vararg_node.lineno,\n+                vararg_node.col_offset,\n+                parent,\n+                end_lineno=vararg_node.end_lineno,\n+                end_col_offset=vararg_node.end_col_offset,\n+            )\n+            if vararg_node\n+            else None,\n+            AssignName(\n+                kwarg_node.arg,\n+                kwarg_node.lineno,\n+                kwarg_node.col_offset,\n+                parent,\n+                end_lineno=kwarg_node.end_lineno,\n+                end_col_offset=kwarg_node.end_col_offset,\n+            )\n+            if kwarg_node\n+            else None,\n         )\n         args = [self.visit(child, newnode) for child in node.args]\n         defaults = [self.visit(child, newnode) for child in node.defaults]\n\n</patch>", "test_patch": "diff --git a/tests/test_nodes.py b/tests/test_nodes.py\n--- a/tests/test_nodes.py\n+++ b/tests/test_nodes.py\n@@ -22,6 +22,7 @@\n     Uninferable,\n     bases,\n     builder,\n+    extract_node,\n     nodes,\n     parse,\n     test_utils,\n@@ -1975,3 +1976,38 @@ def test_str_repr_no_warnings(node):\n     test_node = node(**args)\n     str(test_node)\n     repr(test_node)\n+\n+\n+def test_arguments_contains_all():\n+    \"\"\"Ensure Arguments.arguments actually returns all available arguments\"\"\"\n+\n+    def manually_get_args(arg_node) -> set:\n+        names = set()\n+        if arg_node.args.vararg:\n+            names.add(arg_node.args.vararg)\n+        if arg_node.args.kwarg:\n+            names.add(arg_node.args.kwarg)\n+\n+        names.update([x.name for x in arg_node.args.args])\n+        names.update([x.name for x in arg_node.args.kwonlyargs])\n+\n+        return names\n+\n+    node = extract_node(\"\"\"def a(fruit: str, *args, b=None, c=None, **kwargs): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+    node = extract_node(\"\"\"def a(mango: int, b=\"banana\", c=None, **kwargs): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+    node = extract_node(\"\"\"def a(self, num = 10, *args): ...\"\"\")\n+    assert manually_get_args(node) == {x.name for x in node.args.arguments}\n+\n+\n+def test_arguments_default_value():\n+    node = extract_node(\n+        \"def fruit(eat='please', *, peel='no', trim='yes', **kwargs): ...\"\n+    )\n+    assert node.args.default_value(\"eat\").value == \"please\"\n+\n+    node = extract_node(\"def fruit(seeds, flavor='good', *, peel='maybe'): ...\")\n+    assert node.args.default_value(\"flavor\").value == \"good\"\n", "version": "3.0", "FAIL_TO_PASS": "[\"tests/test_nodes.py::test_arguments_contains_all\"]", "PASS_TO_PASS": "[\"tests/test_nodes.py::AsStringTest::test_3k_annotations_and_metaclass\", \"tests/test_nodes.py::AsStringTest::test_3k_as_string\", \"tests/test_nodes.py::AsStringTest::test_as_string\", \"tests/test_nodes.py::AsStringTest::test_as_string_for_list_containing_uninferable\", \"tests/test_nodes.py::AsStringTest::test_as_string_unknown\", \"tests/test_nodes.py::AsStringTest::test_class_def\", \"tests/test_nodes.py::AsStringTest::test_ellipsis\", \"tests/test_nodes.py::AsStringTest::test_f_strings\", \"tests/test_nodes.py::AsStringTest::test_frozenset_as_string\", \"tests/test_nodes.py::AsStringTest::test_func_signature_issue_185\", \"tests/test_nodes.py::AsStringTest::test_int_attribute\", \"tests/test_nodes.py::AsStringTest::test_module2_as_string\", \"tests/test_nodes.py::AsStringTest::test_module_as_string\", \"tests/test_nodes.py::AsStringTest::test_operator_precedence\", \"tests/test_nodes.py::AsStringTest::test_slice_and_subscripts\", \"tests/test_nodes.py::AsStringTest::test_slices\", \"tests/test_nodes.py::AsStringTest::test_tuple_as_string\", \"tests/test_nodes.py::AsStringTest::test_varargs_kwargs_as_string\", \"tests/test_nodes.py::IfNodeTest::test_block_range\", \"tests/test_nodes.py::IfNodeTest::test_if_elif_else_node\", \"tests/test_nodes.py::TryNodeTest::test_block_range\", \"tests/test_nodes.py::TryExceptNodeTest::test_block_range\", \"tests/test_nodes.py::TryFinallyNodeTest::test_block_range\", \"tests/test_nodes.py::TryExceptFinallyNodeTest::test_block_range\", \"tests/test_nodes.py::ImportNodeTest::test_absolute_import\", \"tests/test_nodes.py::ImportNodeTest::test_as_string\", \"tests/test_nodes.py::ImportNodeTest::test_bad_import_inference\", \"tests/test_nodes.py::ImportNodeTest::test_conditional\", \"tests/test_nodes.py::ImportNodeTest::test_conditional_import\", \"tests/test_nodes.py::ImportNodeTest::test_from_self_resolve\", \"tests/test_nodes.py::ImportNodeTest::test_import_self_resolve\", \"tests/test_nodes.py::ImportNodeTest::test_more_absolute_import\", \"tests/test_nodes.py::ImportNodeTest::test_real_name\", \"tests/test_nodes.py::CmpNodeTest::test_as_string\", \"tests/test_nodes.py::ConstNodeTest::test_bool\", \"tests/test_nodes.py::ConstNodeTest::test_complex\", \"tests/test_nodes.py::ConstNodeTest::test_copy\", \"tests/test_nodes.py::ConstNodeTest::test_float\", \"tests/test_nodes.py::ConstNodeTest::test_int\", \"tests/test_nodes.py::ConstNodeTest::test_none\", \"tests/test_nodes.py::ConstNodeTest::test_str\", \"tests/test_nodes.py::ConstNodeTest::test_str_kind\", \"tests/test_nodes.py::ConstNodeTest::test_unicode\", \"tests/test_nodes.py::NameNodeTest::test_assign_to_true\", \"tests/test_nodes.py::TestNamedExprNode::test_frame\", \"tests/test_nodes.py::TestNamedExprNode::test_scope\", \"tests/test_nodes.py::AnnAssignNodeTest::test_as_string\", \"tests/test_nodes.py::AnnAssignNodeTest::test_complex\", \"tests/test_nodes.py::AnnAssignNodeTest::test_primitive\", \"tests/test_nodes.py::AnnAssignNodeTest::test_primitive_without_initial_value\", \"tests/test_nodes.py::ArgumentsNodeTC::test_kwoargs\", \"tests/test_nodes.py::ArgumentsNodeTC::test_linenumbering\", \"tests/test_nodes.py::ArgumentsNodeTC::test_positional_only\", \"tests/test_nodes.py::UnboundMethodNodeTest::test_no_super_getattr\", \"tests/test_nodes.py::BoundMethodNodeTest::test_is_property\", \"tests/test_nodes.py::AliasesTest::test_aliases\", \"tests/test_nodes.py::Python35AsyncTest::test_async_await_keywords\", \"tests/test_nodes.py::Python35AsyncTest::test_asyncfor_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_asyncwith_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_await_as_string\", \"tests/test_nodes.py::Python35AsyncTest::test_decorated_async_def_as_string\", \"tests/test_nodes.py::ContextTest::test_list_del\", \"tests/test_nodes.py::ContextTest::test_list_load\", \"tests/test_nodes.py::ContextTest::test_list_store\", \"tests/test_nodes.py::ContextTest::test_starred_load\", \"tests/test_nodes.py::ContextTest::test_starred_store\", \"tests/test_nodes.py::ContextTest::test_subscript_del\", \"tests/test_nodes.py::ContextTest::test_subscript_load\", \"tests/test_nodes.py::ContextTest::test_subscript_store\", \"tests/test_nodes.py::ContextTest::test_tuple_load\", \"tests/test_nodes.py::ContextTest::test_tuple_store\", \"tests/test_nodes.py::test_unknown\", \"tests/test_nodes.py::test_type_comments_with\", \"tests/test_nodes.py::test_type_comments_for\", \"tests/test_nodes.py::test_type_coments_assign\", \"tests/test_nodes.py::test_type_comments_invalid_expression\", \"tests/test_nodes.py::test_type_comments_invalid_function_comments\", \"tests/test_nodes.py::test_type_comments_function\", \"tests/test_nodes.py::test_type_comments_arguments\", \"tests/test_nodes.py::test_type_comments_posonly_arguments\", \"tests/test_nodes.py::test_correct_function_type_comment_parent\", \"tests/test_nodes.py::test_is_generator_for_yield_assignments\", \"tests/test_nodes.py::test_f_string_correct_line_numbering\", \"tests/test_nodes.py::test_assignment_expression\", \"tests/test_nodes.py::test_assignment_expression_in_functiondef\", \"tests/test_nodes.py::test_get_doc\", \"tests/test_nodes.py::test_parse_fstring_debug_mode\", \"tests/test_nodes.py::test_parse_type_comments_with_proper_parent\", \"tests/test_nodes.py::test_const_itered\", \"tests/test_nodes.py::test_is_generator_for_yield_in_while\", \"tests/test_nodes.py::test_is_generator_for_yield_in_if\", \"tests/test_nodes.py::test_is_generator_for_yield_in_aug_assign\", \"tests/test_nodes.py::test_str_repr_no_warnings[AnnAssign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Arguments]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Assert]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Assign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AssignAttr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AssignName]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncFor]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncFunctionDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AsyncWith]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Attribute]\", \"tests/test_nodes.py::test_str_repr_no_warnings[AugAssign]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Await]\", \"tests/test_nodes.py::test_str_repr_no_warnings[BinOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[BoolOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Break]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Call]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ClassDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Compare]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Comprehension]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ComprehensionScope]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Const]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Continue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Decorators]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DelAttr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Delete]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DelName]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Dict]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DictComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[DictUnpack]\", \"tests/test_nodes.py::test_str_repr_no_warnings[EmptyNode]\", \"tests/test_nodes.py::test_str_repr_no_warnings[EvaluatedObject]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ExceptHandler]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Expr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[For]\", \"tests/test_nodes.py::test_str_repr_no_warnings[FormattedValue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[FunctionDef]\", \"tests/test_nodes.py::test_str_repr_no_warnings[GeneratorExp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Global]\", \"tests/test_nodes.py::test_str_repr_no_warnings[If]\", \"tests/test_nodes.py::test_str_repr_no_warnings[IfExp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Import]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ImportFrom]\", \"tests/test_nodes.py::test_str_repr_no_warnings[JoinedStr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Keyword]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Lambda]\", \"tests/test_nodes.py::test_str_repr_no_warnings[List]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ListComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[LocalsDictNodeNG]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Match]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchAs]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchCase]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchClass]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchMapping]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchOr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchSequence]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchSingleton]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchStar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[MatchValue]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Module]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Name]\", \"tests/test_nodes.py::test_str_repr_no_warnings[NamedExpr]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Nonlocal]\", \"tests/test_nodes.py::test_str_repr_no_warnings[ParamSpec]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Pass]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Pattern]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Raise]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Return]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Set]\", \"tests/test_nodes.py::test_str_repr_no_warnings[SetComp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Slice]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Starred]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Subscript]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Try]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TryStar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Tuple]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeAlias]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeVar]\", \"tests/test_nodes.py::test_str_repr_no_warnings[TypeVarTuple]\", \"tests/test_nodes.py::test_str_repr_no_warnings[UnaryOp]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Unknown]\", \"tests/test_nodes.py::test_str_repr_no_warnings[While]\", \"tests/test_nodes.py::test_str_repr_no_warnings[With]\", \"tests/test_nodes.py::test_str_repr_no_warnings[Yield]\", \"tests/test_nodes.py::test_str_repr_no_warnings[YieldFrom]\", \"tests/test_nodes.py::test_arguments_default_value\"]", "environment_setup_commit": "1113d490ec4a94cdc1b35f45abfdaca9f19fa31e"}
{"instance_id": "sqlfluff__sqlfluff-4151_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n\n</issue>\n<code>\n[start of README.md]\n1 ![SQLFluff](https://raw.githubusercontent.com/sqlfluff/sqlfluff/main/images/sqlfluff-wide.png)\n2 \n3 # The SQL Linter for Humans\n4 \n5 [![PyPi Version](https://img.shields.io/pypi/v/sqlfluff.svg?style=flat-square&logo=PyPi)](https://pypi.org/project/sqlfluff/)\n6 [![PyPi License](https://img.shields.io/pypi/l/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n7 [![PyPi Python Versions](https://img.shields.io/pypi/pyversions/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n8 [![PyPi Status](https://img.shields.io/pypi/status/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n9 [![PyPi Downloads](https://img.shields.io/pypi/dm/sqlfluff?style=flat-square)](https://pypi.org/project/sqlfluff/)\n10 \n11 [![codecov](https://img.shields.io/codecov/c/gh/sqlfluff/sqlfluff.svg?style=flat-square&logo=Codecov)](https://codecov.io/gh/sqlfluff/sqlfluff)\n12 [![GitHub Workflow Status](https://img.shields.io/github/workflow/status/sqlfluff/sqlfluff/CI%20Tests?logo=github&style=flat-square)](https://github.com/sqlfluff/sqlfluff/actions/workflows/ci-tests.yml?query=branch%3Amain)\n13 [![ReadTheDocs](https://img.shields.io/readthedocs/sqlfluff?style=flat-square&logo=Read%20the%20Docs)](https://sqlfluff.readthedocs.io)\n14 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/psf/black)\n15 [![Docker Pulls](https://img.shields.io/docker/pulls/sqlfluff/sqlfluff?logo=docker&style=flat-square)](https://hub.docker.com/r/sqlfluff/sqlfluff)\n16 \n17 **SQLFluff** is a dialect-flexible and configurable SQL linter. Designed with ELT applications in mind, **SQLFluff** also works with Jinja templating and dbt. **SQLFluff** will auto-fix most linting errors, allowing you to focus your time on what matters.\n18 \n19 ## Dialects Supported\n20 \n21 Although SQL is reasonably consistent in its implementations, there are several different dialects available with variations of syntax and grammar. **SQLFluff** currently supports the following SQL dialects (though perhaps not in full):\n22 \n23 - ANSI SQL - this is the base version and on occasion may not strictly follow the ANSI/ISO SQL definition\n24 - [Athena](https://aws.amazon.com/athena/)\n25 - [BigQuery](https://cloud.google.com/bigquery/)\n26 - [ClickHouse](https://clickhouse.com/)\n27 - [Databricks](https://databricks.com/) (note: currently this is just an alias for the `sparksql` dialect).\n28 - [Db2](https://www.ibm.com/analytics/db2)\n29 - [Exasol](https://www.exasol.com/)\n30 - [Hive](https://hive.apache.org/)\n31 - [Materialize](https://materialize.com/)\n32 - [MySQL](https://www.mysql.com/)\n33 - [Oracle](https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/index.html)\n34 - [PostgreSQL](https://www.postgresql.org/) (aka Postgres)\n35 - [Redshift](https://docs.aws.amazon.com/redshift/index.html)\n36 - [Snowflake](https://www.snowflake.com/)\n37 - [SOQL](https://developer.salesforce.com/docs/atlas.en-us.soql_sosl.meta/soql_sosl/sforce_api_calls_soql.htm)\n38 - [SparkSQL](https://spark.apache.org/docs/latest/)\n39 - [SQLite](https://www.sqlite.org/)\n40 - [Teradata](https://www.teradata.com/)\n41 - [Transact-SQL](https://docs.microsoft.com/en-us/sql/t-sql/language-reference) (aka T-SQL)\n42 \n43 We aim to make it easy to expand on the support of these dialects and also add other, currently unsupported, dialects. Please [raise issues](https://github.com/sqlfluff/sqlfluff/issues) (or upvote any existing issues) to let us know of demand for missing support.\n44 \n45 Pull requests from those that know the missing syntax or dialects are especially welcomed and are the question way for you to get support added. We are happy to work with any potential contributors on this to help them add this support. Please raise an issue first for any large feature change to ensure it is a good fit for this project before spending time on this work.\n46 \n47 ## Templates Supported\n48 \n49 SQL itself does not lend itself well to [modularity](https://docs.getdbt.com/docs/viewpoint#section-modularity), so to introduce some flexibility and reusability it is often [templated](https://en.wikipedia.org/wiki/Template_processor) as discussed more in [our modularity documentation](https://docs.sqlfluff.com/en/stable/realworld.html#modularity).\n50 \n51 **SQLFluff** supports the following templates:\n52 - [Jinja](https://jinja.palletsprojects.com/) (aka Jinja2)\n53 - [dbt](https://www.getdbt.com/)\n54 \n55 Again, please raise issues if you wish to support more templating languages/syntaxes.\n56 \n57 # Getting Started\n58 \n59 To get started, install the package and run `sqlfluff lint` or `sqlfluff fix`.\n60 \n61 ```shell\n62 $ pip install sqlfluff\n63 $ echo \"  SELECT a  +  b FROM tbl;  \" > test.sql\n64 $ sqlfluff lint test.sql --dialect ansi\n65 == [test.sql] FAIL\n66 L:   1 | P:   1 | L050 | Files must not begin with newlines or whitespace.\n67 L:   1 | P:   3 | L003 | First line has unexpected indent\n68 L:   1 | P:  11 | L039 | Unnecessary whitespace found.\n69 L:   1 | P:  14 | L039 | Unnecessary whitespace found.\n70 L:   1 | P:  27 | L001 | Unnecessary trailing whitespace.\n71 ```\n72 \n73 Alternatively, you can use the [**Official SQLFluff Docker Image**](https://hub.docker.com/r/sqlfluff/sqlfluff) or have a play using [**SQLFluff online**](https://online.sqlfluff.com/).\n74 \n75 For full [CLI usage](https://docs.sqlfluff.com/en/stable/cli.html) and [rules reference](https://docs.sqlfluff.com/en/stable/rules.html), see [the SQLFluff docs](https://docs.sqlfluff.com/en/stable/).\n76 \n77 # Documentation\n78 \n79 For full documentation visit [docs.sqlfluff.com](https://docs.sqlfluff.com/en/stable/). This documentation is generated from this repository so please raise [issues](https://github.com/sqlfluff/sqlfluff/issues) or pull requests for any additions, corrections, or clarifications.\n80 \n81 # Releases\n82 \n83 **SQLFluff** adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html), so breaking changes\n84 should be restricted to major versions releases. Some elements (such as the python API) are in a less\n85 stable state and may see more significant changes more often. See the [changelog](CHANGELOG.md) for more details.\n86 If you would like to join in please consider [contributing](CONTRIBUTING.md).\n87 \n88 New releases are made monthly. For more information, visit [Releases](https://github.com/sqlfluff/sqlfluff/releases).\n89 \n90 # SQLFluff on Slack\n91 \n92 We have a fast-growing community [on Slack](https://join.slack.com/t/sqlfluff/shared_invite/zt-o1f4x0e8-pZzarAIlQmKj_6ZwD16w0g), come and join us!\n93 \n94 # SQLFluff on Twitter\n95 \n96 Follow us [on Twitter @SQLFluff](https://twitter.com/SQLFluff) for announcements and other related posts.\n97 \n98 # Contributing\n99 \n100 We are grateful to all our [contributors](https://github.com/sqlfluff/sqlfluff/graphs/contributors). There is a lot to do in this project, and we are just getting started.\n101 \n102 If you want to understand more about the architecture of **SQLFluff**, you can\n103 find [more here](https://docs.sqlfluff.com/en/latest/internals.html#architecture).\n104 \n105 If you would like to contribute, check out the [open issues on GitHub](https://github.com/sqlfluff/sqlfluff/issues). You can also see the guide to [contributing](CONTRIBUTING.md).\n106 \n[end of README.md]\n[start of src/sqlfluff/core/config.py]\n1 \"\"\"Module for loading config.\"\"\"\n2 \n3 import logging\n4 import os\n5 import os.path\n6 import configparser\n7 from dataclasses import dataclass\n8 \n9 import pluggy\n10 from itertools import chain\n11 from typing import Dict, Iterator, List, Tuple, Any, Optional, Union, Iterable, Callable\n12 from pathlib import Path\n13 from sqlfluff.core.plugin.host import get_plugin_manager\n14 from sqlfluff.core.errors import SQLFluffUserError\n15 \n16 import appdirs\n17 \n18 import toml\n19 \n20 # Instantiate the config logger\n21 config_logger = logging.getLogger(\"sqlfluff.config\")\n22 \n23 global_loader = None\n24 \"\"\":obj:`ConfigLoader`: A variable to hold the single module loader when loaded.\n25 \n26 We define a global loader, so that between calls to load config, we\n27 can still cache appropriately\n28 \"\"\"\n29 \n30 ConfigElemType = Tuple[Tuple[str, ...], Any]\n31 \n32 \n33 @dataclass\n34 class _RemovedConfig:\n35     old_path: Tuple[str, ...]\n36     warning: str\n37     new_path: Optional[Tuple[str, ...]] = None\n38     translation_func: Optional[Callable[[str], str]] = None\n39 \n40 \n41 REMOVED_CONFIGS = [\n42     _RemovedConfig(\n43         (\"rules\", \"L007\", \"operator_new_lines\"),\n44         (\n45             \"Use the line_position config in the appropriate \"\n46             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n47             \":binary_operator).\"\n48         ),\n49         (\"layout\", \"type\", \"binary_operator\", \"line_position\"),\n50         (lambda x: \"trailing\" if x == \"before\" else \"leading\"),\n51     ),\n52     _RemovedConfig(\n53         (\"rules\", \"comma_style\"),\n54         (\n55             \"Use the line_position config in the appropriate \"\n56             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n57             \":comma).\"\n58         ),\n59         (\"layout\", \"type\", \"comma\", \"line_position\"),\n60         (lambda x: x),\n61     ),\n62     # L019 used to have a more specific version of the same /config itself.\n63     _RemovedConfig(\n64         (\"rules\", \"L019\", \"comma_style\"),\n65         (\n66             \"Use the line_position config in the appropriate \"\n67             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n68             \":comma).\"\n69         ),\n70         (\"layout\", \"type\", \"comma\", \"line_position\"),\n71         (lambda x: x),\n72     ),\n73     _RemovedConfig(\n74         (\"rules\", \"L003\", \"lint_templated_tokens\"),\n75         \"No longer used.\",\n76     ),\n77 ]\n78 \n79 \n80 def coerce_value(val: str) -> Any:\n81     \"\"\"Try to coerce to a more specific type.\"\"\"\n82     # Try to coerce it to a more specific type,\n83     # otherwise just make it a string.\n84     try:\n85         v: Any = int(val)\n86     except ValueError:\n87         try:\n88             v = float(val)\n89         except ValueError:\n90             cleaned_val = val.strip().lower()\n91             if cleaned_val in [\"true\"]:\n92                 v = True\n93             elif cleaned_val in [\"false\"]:\n94                 v = False\n95             elif cleaned_val in [\"none\"]:\n96                 v = None\n97             else:\n98                 v = val\n99     return v\n100 \n101 \n102 def nested_combine(*dicts: dict) -> dict:\n103     \"\"\"Combine an iterable of dictionaries.\n104 \n105     Each dictionary is combined into a result dictionary. For\n106     each key in the first dictionary, it will be overwritten\n107     by any same-named key in any later dictionaries in the\n108     iterable. If the element at that key is a dictionary, rather\n109     than just overwriting we use the same function to combine\n110     those dictionaries.\n111 \n112     Args:\n113         *dicts: An iterable of dictionaries to be combined.\n114 \n115     Returns:\n116         `dict`: A combined dictionary from the input dictionaries.\n117 \n118     A simple example:\n119     >>> nested_combine({\"a\": {\"b\": \"c\"}}, {\"a\": {\"d\": \"e\"}})\n120     {'a': {'b': 'c', 'd': 'e'}}\n121 \n122     Keys overwrite left to right:\n123     >>> nested_combine({\"a\": {\"b\": \"c\"}}, {\"a\": {\"b\": \"e\"}})\n124     {'a': {'b': 'e'}}\n125     \"\"\"\n126     r: dict = {}\n127     for d in dicts:\n128         for k in d:\n129             if k in r and isinstance(r[k], dict):\n130                 if isinstance(d[k], dict):\n131                     r[k] = nested_combine(r[k], d[k])\n132                 else:  # pragma: no cover\n133                     raise ValueError(\n134                         \"Key {!r} is a dict in one config but not another! PANIC: \"\n135                         \"{!r}\".format(k, d[k])\n136                     )\n137             else:\n138                 r[k] = d[k]\n139     return r\n140 \n141 \n142 def dict_diff(left: dict, right: dict, ignore: Optional[List[str]] = None) -> dict:\n143     \"\"\"Work out the difference between to dictionaries.\n144 \n145     Returns a dictionary which represents elements in the `left`\n146     dictionary which aren't in the `right` or are different to\n147     those in the `right`. If the element is a dictionary, we\n148     recursively look for differences in those dictionaries,\n149     likewise only returning the differing elements.\n150 \n151     NOTE: If an element is in the `right` but not in the `left`\n152     at all (i.e. an element has been *removed*) then it will\n153     not show up in the comparison.\n154 \n155     Args:\n156         left (:obj:`dict`): The object containing the *new* elements\n157             which will be compared against the other.\n158         right (:obj:`dict`): The object to compare against.\n159         ignore (:obj:`list` of `str`, optional): Keys to ignore.\n160 \n161     Returns:\n162         `dict`: A dictionary representing the difference.\n163 \n164     Basic functionality shown, especially returning the left as:\n165     >>> dict_diff({\"a\": \"b\", \"c\": \"d\"}, {\"a\": \"b\", \"c\": \"e\"})\n166     {'c': 'd'}\n167 \n168     Ignoring works on a key basis:\n169     >>> dict_diff({\"a\": \"b\"}, {\"a\": \"c\"})\n170     {'a': 'b'}\n171     >>> dict_diff({\"a\": \"b\"}, {\"a\": \"c\"}, [\"a\"])\n172     {}\n173     \"\"\"\n174     buff: dict = {}\n175     for k in left:\n176         if ignore and k in ignore:\n177             continue\n178         # Is the key there at all?\n179         if k not in right:\n180             buff[k] = left[k]\n181         # Is the content the same?\n182         elif left[k] == right[k]:\n183             continue\n184         # If it's not the same but both are dicts, then compare\n185         elif isinstance(left[k], dict) and isinstance(right[k], dict):\n186             diff = dict_diff(left[k], right[k], ignore=ignore)\n187             # Only include the difference if non-null.\n188             if diff:\n189                 buff[k] = diff\n190         # It's just different\n191         else:\n192             buff[k] = left[k]\n193     return buff\n194 \n195 \n196 def _split_comma_separated_string(raw_str: str) -> List[str]:\n197     return [s.strip() for s in raw_str.split(\",\") if s.strip()]\n198 \n199 \n200 class ConfigLoader:\n201     \"\"\"The class for loading config files.\n202 \n203     Note:\n204         Unlike most cfg file readers, sqlfluff is case-sensitive in how\n205         it reads config files. This is to ensure we support the case\n206         sensitivity of jinja.\n207 \n208     \"\"\"\n209 \n210     def __init__(self) -> None:\n211         # TODO: check that this cache implementation is actually useful\n212         self._config_cache: dict = {}\n213 \n214     @classmethod\n215     def get_global(cls) -> \"ConfigLoader\":\n216         \"\"\"Get the singleton loader.\"\"\"\n217         global global_loader\n218         if not global_loader:\n219             global_loader = cls()\n220         return global_loader\n221 \n222     @classmethod\n223     def _walk_toml(cls, config: Dict[str, Any], base_key=()):\n224         \"\"\"Recursively walk the nested config inside a TOML file.\"\"\"\n225         buff: List[tuple] = []\n226         for k, v in config.items():\n227             key = base_key + (k,)\n228             if isinstance(v, dict):\n229                 buff.extend(cls._walk_toml(v, key))\n230             else:\n231                 buff.append((key, v))\n232 \n233         return buff\n234 \n235     @classmethod\n236     def _iter_config_elems_from_dict(cls, configs: dict) -> Iterator[ConfigElemType]:\n237         \"\"\"Walk a config dict and get config elements.\n238 \n239         >>> list(\n240         ...    ConfigLoader._iter_config_elems_from_dict(\n241         ...        {\"foo\":{\"bar\":{\"baz\": \"a\", \"biz\": \"b\"}}}\n242         ...    )\n243         ... )\n244         [(('foo', 'bar', 'baz'), 'a'), (('foo', 'bar', 'biz'), 'b')]\n245         \"\"\"\n246         for key, val in configs.items():\n247             if isinstance(val, dict):\n248                 for partial_key, sub_val in cls._iter_config_elems_from_dict(val):\n249                     yield (key,) + partial_key, sub_val\n250             else:\n251                 yield (key,), val\n252 \n253     @classmethod\n254     def _config_elems_to_dict(cls, configs: Iterable[ConfigElemType]) -> dict:\n255         \"\"\"Reconstruct config elements into a dict.\n256 \n257         >>> ConfigLoader._config_elems_to_dict(\n258         ...     [((\"foo\", \"bar\", \"baz\"), \"a\"), ((\"foo\", \"bar\", \"biz\"), \"b\")]\n259         ... )\n260         {'foo': {'bar': {'baz': 'a', 'biz': 'b'}}}\n261         \"\"\"\n262         result: Dict[str, Union[dict, str]] = {}\n263         for key, val in configs:\n264             ref = result\n265             for step in key[:-1]:\n266                 if step not in ref:\n267                     ref[step] = {}\n268                 ref = ref[step]  # type: ignore\n269             ref[key[-1]] = val\n270         return result\n271 \n272     @classmethod\n273     def _get_config_elems_from_toml(cls, fpath: str) -> List[ConfigElemType]:\n274         \"\"\"Load a config from a TOML file and return a list of tuples.\n275 \n276         The return value is a list of tuples, were each tuple has two elements,\n277         the first is a tuple of paths, the second is the value at that path.\n278         \"\"\"\n279         config = toml.load(fpath)\n280         tool = config.get(\"tool\", {}).get(\"sqlfluff\", {})\n281 \n282         return cls._walk_toml(tool)\n283 \n284     @classmethod\n285     def _get_config_elems_from_file(cls, fpath: str) -> List[ConfigElemType]:\n286         \"\"\"Load a config from a file and return a list of tuples.\n287 \n288         The return value is a list of tuples, were each tuple has two elements,\n289         the first is a tuple of paths, the second is the value at that path.\n290 \n291         Note:\n292             Unlike most cfg file readers, sqlfluff is case-sensitive in how\n293             it reads config files.\n294 \n295         Note:\n296             Any variable names ending with `_path` or `_dir`, will be attempted to be\n297             resolved as relative paths to this config file. If that fails the\n298             string value will remain.\n299 \n300         \"\"\"\n301         buff: List[Tuple[tuple, Any]] = []\n302         # Disable interpolation so we can load macros\n303         kw: Dict = {}\n304         kw[\"interpolation\"] = None\n305         config = configparser.ConfigParser(delimiters=\"=\", **kw)\n306         # NB: We want to be case sensitive in how we read from files,\n307         # because jinja is also case sensitive. To do this we override\n308         # the optionxform attribute.\n309         config.optionxform = lambda option: option  # type: ignore\n310         config.read(fpath)\n311         for k in config.sections():\n312             if k == \"sqlfluff\":\n313                 key: Tuple = (\"core\",)\n314             elif k.startswith(\"sqlfluff:\"):\n315                 # Return a tuple of nested values\n316                 key = tuple(k[len(\"sqlfluff:\") :].split(\":\"))\n317             else:  # pragma: no cover\n318                 # if it doesn't start with sqlfluff, then don't go\n319                 # further on this iteration\n320                 continue\n321 \n322             for name, val in config.items(section=k):\n323                 # Try to coerce it to a more specific type,\n324                 # otherwise just make it a string.\n325                 v = coerce_value(val)\n326 \n327                 # Attempt to resolve paths\n328                 if name.lower() == \"load_macros_from_path\":\n329                     # Comma-separated list of paths.\n330                     paths = _split_comma_separated_string(val)\n331                     v_temp = []\n332                     for path in paths:\n333                         v_temp.append(cls._resolve_path(fpath, path))\n334                     v = \",\".join(v_temp)\n335                 elif name.lower().endswith((\"_path\", \"_dir\")):\n336                     # One path\n337                     v = cls._resolve_path(fpath, val)\n338                 # Add the name to the end of the key\n339                 buff.append((key + (name,), v))\n340         return buff\n341 \n342     @classmethod\n343     def _resolve_path(cls, fpath, val):\n344         \"\"\"Try to resolve a path.\"\"\"\n345         # Make the referenced path.\n346         ref_path = os.path.join(os.path.dirname(fpath), val)\n347         # Check if it exists, and if it does, replace the value with the path.\n348         return ref_path if os.path.exists(ref_path) else val\n349 \n350     @staticmethod\n351     def _incorporate_vals(ctx: dict, vals: List[ConfigElemType]) -> dict:\n352         \"\"\"Take a list of tuples and incorporate it into a dictionary.\n353 \n354         >>> ConfigLoader._incorporate_vals({}, [((\"a\", \"b\"), \"c\")])\n355         {'a': {'b': 'c'}}\n356         >>> ConfigLoader._incorporate_vals({\"a\": {\"b\": \"c\"}}, [((\"a\", \"d\"), \"e\")])\n357         {'a': {'b': 'c', 'd': 'e'}}\n358         \"\"\"\n359         for k, v in vals:\n360             # Keep a ref we can use for recursion\n361             r = ctx\n362             # Get the name of the variable\n363             n = k[-1]\n364             # Get the path\n365             pth = k[:-1]\n366             for dp in pth:\n367                 # Does this path exist?\n368                 if dp in r:\n369                     if isinstance(r[dp], dict):\n370                         r = r[dp]\n371                     else:  # pragma: no cover\n372                         raise ValueError(f\"Overriding config value with section! [{k}]\")\n373                 else:\n374                     r[dp] = {}\n375                     r = r[dp]\n376             # Deal with the value itself\n377             r[n] = v\n378         return ctx\n379 \n380     @staticmethod\n381     def _validate_configs(\n382         configs: Iterable[ConfigElemType], file_path\n383     ) -> List[ConfigElemType]:\n384         \"\"\"Validate config elements against removed list.\"\"\"\n385         config_map = {cfg.old_path: cfg for cfg in REMOVED_CONFIGS}\n386         # Materialise the configs into a list to we can iterate twice.\n387         new_configs = list(configs)\n388         defined_keys = {k for k, _ in new_configs}\n389         validated_configs = []\n390         for k, v in new_configs:\n391             if k in config_map.keys():\n392                 formatted_key = \":\".join(k)\n393                 removed_option = config_map[k]\n394                 # Is there a mapping option?\n395                 if removed_option.translation_func and removed_option.new_path:\n396                     formatted_new_key = \":\".join(removed_option.new_path)\n397                     # Before mutating, check we haven't _also_ set the new value.\n398                     if removed_option.new_path in defined_keys:\n399                         # Raise an warning.\n400                         config_logger.warning(\n401                             f\"\\nWARNING: Config file {file_path} set a deprecated \"\n402                             f\"config value `{formatted_key}` (which can be migrated) \"\n403                             f\"but ALSO set the value it would be migrated to. The new \"\n404                             f\"value (`{removed_option.new_path}`) takes precedence. \"\n405                             \"Please update your configuration to remove this warning. \"\n406                             f\"\\n\\n{removed_option.warning}\\n\\n\"\n407                             \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n408                             \" for more details.\\n\"\n409                         )\n410                         # continue to NOT add this value in the set\n411                         continue\n412 \n413                     # Mutate and warn.\n414                     v = removed_option.translation_func(v)\n415                     k = removed_option.new_path\n416                     # NOTE: At the stage of emitting this warning, we may not yet\n417                     # have set up red logging because we haven't yet loaded the config\n418                     # file. For that reason, this error message has a bit more padding.\n419                     config_logger.warning(\n420                         f\"\\nWARNING: Config file {file_path} set a deprecated config \"\n421                         f\"value `{formatted_key}`. This will be removed in a later \"\n422                         \"release. This has been mapped to \"\n423                         f\"`{formatted_new_key}` set to a value of `{v}` for this run. \"\n424                         \"Please update your configuration to remove this warning. \"\n425                         f\"\\n\\n{removed_option.warning}\\n\\n\"\n426                         \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n427                         \" for more details.\\n\"\n428                     )\n429                 else:\n430                     # Raise an error.\n431                     raise SQLFluffUserError(\n432                         f\"Config file {file_path} set an outdated config \"\n433                         f\"value {formatted_key}.\\n\\n{removed_option.warning}\\n\\n\"\n434                         \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n435                         \" for more details.\"\n436                     )\n437 \n438             validated_configs.append((k, v))\n439         return validated_configs\n440 \n441     def load_config_file(\n442         self, file_dir: str, file_name: str, configs: Optional[dict] = None\n443     ) -> dict:\n444         \"\"\"Load the default config file.\"\"\"\n445         file_path = os.path.join(file_dir, file_name)\n446         if file_name == \"pyproject.toml\":\n447             elems = self._get_config_elems_from_toml(file_path)\n448         else:\n449             elems = self._get_config_elems_from_file(file_path)\n450         elems = self._validate_configs(elems, file_path)\n451         return self._incorporate_vals(configs or {}, elems)\n452 \n453     def load_config_at_path(self, path: str) -> dict:\n454         \"\"\"Load config from a given path.\"\"\"\n455         # First check the cache\n456         if str(path) in self._config_cache:\n457             return self._config_cache[str(path)]\n458 \n459         # The potential filenames we would look for at this path.\n460         # NB: later in this list overwrites earlier\n461         filename_options = [\n462             \"setup.cfg\",\n463             \"tox.ini\",\n464             \"pep8.ini\",\n465             \".sqlfluff\",\n466             \"pyproject.toml\",\n467         ]\n468 \n469         configs: dict = {}\n470 \n471         if os.path.isdir(path):\n472             p = path\n473         else:\n474             p = os.path.dirname(path)\n475 \n476         d = os.listdir(os.path.expanduser(p))\n477         # iterate this way round to make sure things overwrite is the right direction\n478         for fname in filename_options:\n479             if fname in d:\n480                 configs = self.load_config_file(p, fname, configs=configs)\n481 \n482         # Store in the cache\n483         self._config_cache[str(path)] = configs\n484         return configs\n485 \n486     def load_extra_config(self, extra_config_path: str) -> dict:\n487         \"\"\"Load specified extra config.\"\"\"\n488         if not os.path.exists(extra_config_path):\n489             raise SQLFluffUserError(\n490                 f\"Extra config '{extra_config_path}' does not exist.\"\n491             )\n492 \n493         # First check the cache\n494         if str(extra_config_path) in self._config_cache:\n495             return self._config_cache[str(extra_config_path)]\n496 \n497         configs: dict = {}\n498         if extra_config_path.endswith(\"pyproject.toml\"):\n499             elems = self._get_config_elems_from_toml(extra_config_path)\n500         else:\n501             elems = self._get_config_elems_from_file(extra_config_path)\n502         configs = self._incorporate_vals(configs, elems)\n503 \n504         # Store in the cache\n505         self._config_cache[str(extra_config_path)] = configs\n506         return configs\n507 \n508     @staticmethod\n509     def _get_user_config_dir_path() -> str:\n510         appname = \"sqlfluff\"\n511         appauthor = \"sqlfluff\"\n512 \n513         # On Mac OSX follow Linux XDG base dirs\n514         # https://github.com/sqlfluff/sqlfluff/issues/889\n515         user_config_dir_path = os.path.expanduser(\"~/.config/sqlfluff\")\n516         if appdirs.system == \"darwin\":\n517             appdirs.system = \"linux2\"\n518             user_config_dir_path = appdirs.user_config_dir(appname, appauthor)\n519             appdirs.system = \"darwin\"\n520 \n521         if not os.path.exists(user_config_dir_path):\n522             user_config_dir_path = appdirs.user_config_dir(appname, appauthor)\n523 \n524         return user_config_dir_path\n525 \n526     def load_user_appdir_config(self) -> dict:\n527         \"\"\"Load the config from the user's OS specific appdir config directory.\"\"\"\n528         user_config_dir_path = self._get_user_config_dir_path()\n529         if os.path.exists(user_config_dir_path):\n530             return self.load_config_at_path(user_config_dir_path)\n531         else:\n532             return {}\n533 \n534     def load_user_config(self) -> dict:\n535         \"\"\"Load the config from the user's home directory.\"\"\"\n536         user_home_path = os.path.expanduser(\"~\")\n537         return self.load_config_at_path(user_home_path)\n538 \n539     def load_config_up_to_path(\n540         self,\n541         path: str,\n542         extra_config_path: Optional[str] = None,\n543         ignore_local_config: bool = False,\n544     ) -> dict:\n545         \"\"\"Loads a selection of config files from both the path and its parent paths.\"\"\"\n546         user_appdir_config = (\n547             self.load_user_appdir_config() if not ignore_local_config else {}\n548         )\n549         user_config = self.load_user_config() if not ignore_local_config else {}\n550         config_paths = (\n551             self.iter_config_locations_up_to_path(path)\n552             if not ignore_local_config\n553             else {}\n554         )\n555         config_stack = (\n556             [self.load_config_at_path(p) for p in config_paths]\n557             if not ignore_local_config\n558             else []\n559         )\n560         extra_config = (\n561             self.load_extra_config(extra_config_path) if extra_config_path else {}\n562         )\n563         return nested_combine(\n564             user_appdir_config, user_config, *config_stack, extra_config\n565         )\n566 \n567     @classmethod\n568     def find_ignore_config_files(\n569         cls, path, working_path=Path.cwd(), ignore_file_name=\".sqlfluffignore\"\n570     ):\n571         \"\"\"Finds sqlfluff ignore files from both the path and its parent paths.\"\"\"\n572         return set(\n573             filter(\n574                 os.path.isfile,\n575                 map(\n576                     lambda x: os.path.join(x, ignore_file_name),\n577                     cls.iter_config_locations_up_to_path(\n578                         path=path, working_path=working_path\n579                     ),\n580                 ),\n581             )\n582         )\n583 \n584     @staticmethod\n585     def iter_config_locations_up_to_path(path, working_path=Path.cwd()):\n586         \"\"\"Finds config locations from both the path and its parent paths.\n587 \n588         The lowest priority is the user appdir, then home dir, then increasingly\n589         the configs closest to the file being directly linted.\n590         \"\"\"\n591         given_path = Path(path).absolute()\n592         working_path = Path(working_path).absolute()\n593 \n594         # If we've been passed a file and not a directory,\n595         # then go straight to the directory.\n596         if not given_path.is_dir():\n597             given_path = given_path.parent\n598 \n599         common_path = Path(os.path.commonpath([working_path, given_path]))\n600 \n601         # we have a sub path! We can load nested paths\n602         path_to_visit = common_path\n603         while path_to_visit != given_path:\n604             yield str(path_to_visit.resolve())\n605             next_path_to_visit = (\n606                 path_to_visit / given_path.relative_to(path_to_visit).parts[0]\n607             )\n608             if next_path_to_visit == path_to_visit:  # pragma: no cover\n609                 # we're not making progress...\n610                 # [prevent infinite loop]\n611                 break\n612             path_to_visit = next_path_to_visit\n613 \n614         yield str(given_path.resolve())\n615 \n616 \n617 class FluffConfig:\n618     \"\"\"The class that actually gets passed around as a config object.\"\"\"\n619 \n620     private_vals = \"rule_denylist\", \"rule_allowlist\", \"dialect_obj\", \"templater_obj\"\n621 \n622     def __init__(\n623         self,\n624         configs: Optional[dict] = None,\n625         extra_config_path: Optional[str] = None,\n626         ignore_local_config: bool = False,\n627         overrides: Optional[dict] = None,\n628         plugin_manager: Optional[pluggy.PluginManager] = None,\n629         # Ideally a dialect should be set when config is read but sometimes\n630         # it might only be set in nested .sqlfluff config files, so allow it\n631         # to be not required.\n632         require_dialect: bool = True,\n633     ):\n634         self._extra_config_path = (\n635             extra_config_path  # We only store this for child configs\n636         )\n637         self._ignore_local_config = (\n638             ignore_local_config  # We only store this for child configs\n639         )\n640         # If overrides are provided, validate them early.\n641         if overrides:\n642             overrides = ConfigLoader._config_elems_to_dict(\n643                 ConfigLoader._validate_configs(\n644                     [\n645                         ((\"core\",) + k, v)\n646                         for k, v in ConfigLoader._iter_config_elems_from_dict(overrides)\n647                     ],\n648                     \"<provided overrides>\",\n649                 )\n650             )[\"core\"]\n651         self._overrides = overrides  # We only store this for child configs\n652 \n653         # Fetch a fresh plugin manager if we weren't provided with one\n654         self._plugin_manager = plugin_manager or get_plugin_manager()\n655 \n656         defaults = nested_combine(*self._plugin_manager.hook.load_default_config())\n657         # If any existing configs are provided. Validate them:\n658         if configs:\n659             configs = ConfigLoader._config_elems_to_dict(\n660                 ConfigLoader._validate_configs(\n661                     ConfigLoader._iter_config_elems_from_dict(configs),\n662                     \"<provided configs>\",\n663                 )\n664             )\n665         self._configs = nested_combine(\n666             defaults, configs or {\"core\": {}}, {\"core\": overrides or {}}\n667         )\n668         # Some configs require special treatment\n669         self._configs[\"core\"][\"color\"] = (\n670             False if self._configs[\"core\"].get(\"nocolor\", False) else None\n671         )\n672         # Handle inputs which are potentially comma separated strings\n673         for in_key, out_key in [\n674             # Deal with potential ignore & warning parameters\n675             (\"ignore\", \"ignore\"),\n676             (\"warnings\", \"warnings\"),\n677             (\"rules\", \"rule_allowlist\"),\n678             # Allowlists and denylists\n679             (\"exclude_rules\", \"rule_denylist\"),\n680         ]:\n681             if self._configs[\"core\"].get(in_key, None):\n682                 self._configs[\"core\"][out_key] = _split_comma_separated_string(\n683                     self._configs[\"core\"][in_key]\n684                 )\n685             else:\n686                 self._configs[\"core\"][out_key] = []\n687         # Configure Recursion\n688         if self._configs[\"core\"].get(\"recurse\", 0) == 0:\n689             self._configs[\"core\"][\"recurse\"] = True\n690 \n691         # Dialect and Template selection.\n692         # NB: We import here to avoid a circular references.\n693         from sqlfluff.core.dialects import dialect_selector\n694 \n695         dialect: Optional[str] = self._configs[\"core\"][\"dialect\"]\n696         if dialect is not None:\n697             self._configs[\"core\"][\"dialect_obj\"] = dialect_selector(\n698                 self._configs[\"core\"][\"dialect\"]\n699             )\n700         elif require_dialect:\n701             self.verify_dialect_specified()\n702         self._configs[\"core\"][\"templater_obj\"] = self.get_templater(\n703             self._configs[\"core\"][\"templater\"]\n704         )\n705 \n706     def verify_dialect_specified(self) -> None:\n707         \"\"\"Check if the config specifies a dialect, raising an error if not.\"\"\"\n708         dialect: Optional[str] = self._configs[\"core\"][\"dialect\"]\n709         if dialect is None:\n710             # Get list of available dialects for the error message. We must\n711             # import here rather than at file scope in order to avoid a circular\n712             # import.\n713             from sqlfluff.core.dialects import dialect_readout\n714 \n715             raise SQLFluffUserError(\n716                 \"No dialect was specified. You must configure a dialect or \"\n717                 \"specify one on the command line using --dialect after the \"\n718                 \"command. Available dialects:\\n\"\n719                 f\"{', '.join([d.label for d in dialect_readout()])}\"\n720             )\n721 \n722     def __getstate__(self):\n723         # Copy the object's state from self.__dict__ which contains\n724         # all our instance attributes. Always use the dict.copy()\n725         # method to avoid modifying the original state.\n726         state = self.__dict__.copy()\n727         # Remove the unpicklable entries.\n728         del state[\"_plugin_manager\"]\n729         return state\n730 \n731     def __setstate__(self, state):  # pragma: no cover\n732         # Restore instance attributes\n733         self.__dict__.update(state)\n734         # NB: We don't reinstate the plugin manager, but this should only\n735         # be happening between processes where the plugin manager should\n736         # probably be fresh in any case.\n737         # NOTE: This means that registering user plugins directly will only\n738         # work if those plugins are used in the main process (i.e. templaters).\n739         # User registered linting rules either must be \"installed\" and therefore\n740         # available to all processes - or their use is limited to only single\n741         # process invocations of sqlfluff. In the event that user registered\n742         # rules are used in a multi-process invocation, they will not be applied\n743         # in the child processes.\n744 \n745     @classmethod\n746     def from_root(\n747         cls,\n748         extra_config_path: Optional[str] = None,\n749         ignore_local_config: bool = False,\n750         overrides: Optional[dict] = None,\n751         **kw,\n752     ) -> \"FluffConfig\":\n753         \"\"\"Loads a config object just based on the root directory.\"\"\"\n754         loader = ConfigLoader.get_global()\n755         c = loader.load_config_up_to_path(\n756             path=\".\",\n757             extra_config_path=extra_config_path,\n758             ignore_local_config=ignore_local_config,\n759         )\n760         return cls(\n761             configs=c,\n762             extra_config_path=extra_config_path,\n763             ignore_local_config=ignore_local_config,\n764             overrides=overrides,\n765             **kw,\n766         )\n767 \n768     @classmethod\n769     def from_path(\n770         cls,\n771         path: str,\n772         extra_config_path: Optional[str] = None,\n773         ignore_local_config: bool = False,\n774         overrides: Optional[dict] = None,\n775         plugin_manager: Optional[pluggy.PluginManager] = None,\n776     ) -> \"FluffConfig\":\n777         \"\"\"Loads a config object given a particular path.\"\"\"\n778         loader = ConfigLoader.get_global()\n779         c = loader.load_config_up_to_path(\n780             path=path,\n781             extra_config_path=extra_config_path,\n782             ignore_local_config=ignore_local_config,\n783         )\n784         return cls(\n785             configs=c,\n786             extra_config_path=extra_config_path,\n787             ignore_local_config=ignore_local_config,\n788             overrides=overrides,\n789             plugin_manager=plugin_manager,\n790         )\n791 \n792     @classmethod\n793     def from_kwargs(\n794         cls,\n795         config: Optional[\"FluffConfig\"] = None,\n796         dialect: Optional[str] = None,\n797         rules: Optional[List[str]] = None,\n798         exclude_rules: Optional[List[str]] = None,\n799         require_dialect: bool = True,\n800     ) -> \"FluffConfig\":\n801         \"\"\"Instantiate a config from either an existing config or kwargs.\n802 \n803         This is a convenience method for the ways that the public classes\n804         like Linter(), Parser() and Lexer() can be instantiated with a\n805         FluffConfig or with the convenience kwargs: dialect & rules.\n806         \"\"\"\n807         if (dialect or rules) and config:  # pragma: no cover\n808             raise ValueError(\n809                 \"Cannot specify `config` with `dialect` or `rules`. Any config object \"\n810                 \"specifies its own dialect and rules.\"\n811             )\n812         elif config:\n813             return config\n814 \n815         overrides = {}\n816         if dialect:\n817             overrides[\"dialect\"] = dialect\n818         if rules:\n819             # Make a comma separated string to pass in as override\n820             overrides[\"rules\"] = \",\".join(rules)\n821         if exclude_rules:\n822             # Make a comma separated string to pass in as override\n823             overrides[\"exclude_rules\"] = \",\".join(exclude_rules)\n824         return cls(overrides=overrides, require_dialect=require_dialect)\n825 \n826     def get_templater(self, templater_name=\"jinja\", **kwargs):\n827         \"\"\"Fetch a templater by name.\"\"\"\n828         templater_lookup = {\n829             templater.name: templater\n830             for templater in chain.from_iterable(\n831                 self._plugin_manager.hook.get_templaters()\n832             )\n833         }\n834         try:\n835             cls = templater_lookup[templater_name]\n836             # Instantiate here, optionally with kwargs\n837             return cls(**kwargs)\n838         except KeyError:\n839             if templater_name == \"dbt\":  # pragma: no cover\n840                 config_logger.warning(\n841                     \"Starting in sqlfluff version 0.7.0 the dbt templater is \"\n842                     \"distributed as a separate python package. Please pip install \"\n843                     \"sqlfluff-templater-dbt to use it.\"\n844                 )\n845             raise SQLFluffUserError(\n846                 \"Requested templater {!r} which is not currently available. Try one of \"\n847                 \"{}\".format(templater_name, \", \".join(templater_lookup.keys()))\n848             )\n849 \n850     def make_child_from_path(self, path: str) -> \"FluffConfig\":\n851         \"\"\"Make a child config at a path but pass on overrides and extra_config_path.\"\"\"\n852         return self.from_path(\n853             path,\n854             extra_config_path=self._extra_config_path,\n855             ignore_local_config=self._ignore_local_config,\n856             overrides=self._overrides,\n857             plugin_manager=self._plugin_manager,\n858         )\n859 \n860     def diff_to(self, other: \"FluffConfig\") -> dict:\n861         \"\"\"Compare this config to another.\n862 \n863         Args:\n864             other (:obj:`FluffConfig`): Another config object to compare\n865                 against. We will return keys from *this* object that are\n866                 not in `other` or are different to those in `other`.\n867 \n868         Returns:\n869             A filtered dict of items in this config that are not in the other\n870             or are different to the other.\n871 \n872         \"\"\"\n873         # We ignore some objects which are not meaningful in the comparison\n874         # e.g. dialect_obj, which is generated on the fly.\n875         return dict_diff(self._configs, other._configs, ignore=[\"dialect_obj\"])\n876 \n877     def get(\n878         self, val: str, section: Union[str, Iterable[str]] = \"core\", default: Any = None\n879     ):\n880         \"\"\"Get a particular value from the config.\"\"\"\n881         section_dict = self.get_section(section)\n882         if section_dict is None:\n883             return default\n884 \n885         return section_dict.get(val, default)\n886 \n887     def get_section(self, section: Union[str, Iterable[str]]) -> Any:\n888         \"\"\"Return a whole section of config as a dict.\n889 \n890         If the element found at the address is a value and not\n891         a section, it is still returned and so this can be used\n892         as a more advanced from of the basic `get` method.\n893 \n894         Args:\n895             section: An iterable or string. If it's a string\n896                 we load that root section. If it's an iterable\n897                 of strings, then we treat it as a path within\n898                 the dictionary structure.\n899 \n900         \"\"\"\n901         if isinstance(section, str):\n902             return self._configs.get(section, None)\n903         else:\n904             # Try iterating\n905             buff = self._configs\n906             for sec in section:\n907                 buff = buff.get(sec, None)\n908                 if buff is None:\n909                     return None\n910             return buff\n911 \n912     def set_value(self, config_path: Iterable[str], val: Any):\n913         \"\"\"Set a value at a given path.\"\"\"\n914         # Make the path a list so we can index on it\n915         config_path = list(config_path)\n916         # Coerce the value into something more useful.\n917         config_val = coerce_value(val)\n918         # Sort out core if not there\n919         if len(config_path) == 1:  # pragma: no cover TODO?\n920             config_path = [\"core\"] + config_path\n921         # Current section:\n922         dict_buff = [self._configs]\n923         for elem in config_path[:-1]:\n924             dict_buff.append(dict_buff[-1][elem])\n925         # Set the value\n926         dict_buff[-1][config_path[-1]] = config_val\n927         # Rebuild the config\n928         for elem in reversed(config_path[:-1]):\n929             dict_elem = dict_buff.pop()\n930             dict_buff[-1][elem] = dict_elem\n931         self._configs = dict_buff[0]\n932 \n933     def iter_vals(self, cfg: Optional[dict] = None) -> Iterable[tuple]:\n934         \"\"\"Return an iterable of tuples representing keys.\n935 \n936         We show values before dicts, the tuple contains an indent\n937         value to know what level of the dict we're in. Dict labels\n938         will be returned as a blank value before their content.\n939         \"\"\"\n940         cfg = cfg or self._configs\n941 \n942         # Get keys and sort\n943         keys = sorted(cfg.keys())\n944         # First iterate values (alphabetically):\n945         for k in keys:\n946             if (\n947                 not isinstance(cfg[k], dict)\n948                 and cfg[k] is not None\n949                 and k not in self.private_vals\n950             ):\n951                 yield (0, k, cfg[k])\n952 \n953         # Then iterate dicts (alphabetically (but `core` comes first if it exists))\n954         for k in keys:\n955             if isinstance(cfg[k], dict):\n956                 # First yield the dict label\n957                 yield (0, k, \"\")\n958                 # Then yield its content\n959                 for idnt, key, val in self.iter_vals(cfg=cfg[k]):\n960                     yield (idnt + 1, key, val)\n961 \n962     def process_inline_config(self, config_line: str):\n963         \"\"\"Process an inline config command and update self.\"\"\"\n964         # Strip preceding comment marks\n965         if config_line.startswith(\"--\"):\n966             config_line = config_line[2:].strip()\n967         # Strip preceding sqlfluff line.\n968         if not config_line.startswith(\"sqlfluff:\"):  # pragma: no cover\n969             config_logger.warning(\n970                 \"Unable to process inline config statement: %r\", config_line\n971             )\n972             return\n973         config_line = config_line[9:].strip()\n974         # Divide on colons\n975         config_path = [elem.strip() for elem in config_line.split(\":\")]\n976         # Set the value\n977         self.set_value(config_path[:-1], config_path[-1])\n978 \n979     def process_raw_file_for_config(self, raw_str: str):\n980         \"\"\"Process a full raw file for inline config and update self.\"\"\"\n981         # Scan the raw file for config commands.\n982         for raw_line in raw_str.splitlines():\n983             if raw_line.startswith(\"-- sqlfluff\"):\n984                 # Found a in-file config command\n985                 self.process_inline_config(raw_line)\n986 \n987 \n988 class ProgressBarConfiguration:\n989     \"\"\"Singleton-esque progress bar configuration.\n990 \n991     It's expected to be set during starting with parameters coming from commands\n992     parameters, then to be just utilized as just\n993     ```\n994     from sqlfluff.core.config import progress_bar_configuration\n995     is_progressbar_disabled = progress_bar_configuration.disable_progress_bar\n996     ```\n997     \"\"\"\n998 \n999     _disable_progress_bar: Optional[bool] = True\n1000 \n1001     @property\n1002     def disable_progress_bar(self) -> Optional[bool]:  # noqa: D102\n1003         return self._disable_progress_bar\n1004 \n1005     @disable_progress_bar.setter\n1006     def disable_progress_bar(self, value: Optional[bool]) -> None:\n1007         \"\"\"`disable_progress_bar` setter.\n1008 \n1009         `True` means that progress bar should be always hidden, `False` fallbacks\n1010         into `None` which is an automatic mode.\n1011         From tqdm documentation: 'If set to None, disable on non-TTY.'\n1012         \"\"\"\n1013         self._disable_progress_bar = value or None\n1014 \n1015 \n1016 progress_bar_configuration = ProgressBarConfiguration()\n1017 \n[end of src/sqlfluff/core/config.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "sqlfluff/sqlfluff", "base_commit": "dc59c2a5672aacedaf91f0e6129b467eefad331b", "problem_statement": "--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n", "hints_text": "Looks like #3904 made `lint` work with both but updated `fix` to only accept `--disable-progress-bar`. I assume that was by accident. Should be relatively straightforward to fix by updating to match `lint`. \nLooks like #3904 made `lint` work with both but updated `fix` to only accept `--disable-progress-bar`. I assume that was by accident. Should be relatively straightforward to fix by updating to match `lint`. ", "created_at": "2022-12-11T16:33:31Z", "patch": "<patch>\ndiff --git a/src/sqlfluff/cli/commands.py b/src/sqlfluff/cli/commands.py\n--- a/src/sqlfluff/cli/commands.py\n+++ b/src/sqlfluff/cli/commands.py\n@@ -680,7 +680,7 @@ def do_fixes(lnt, result, formatter=None, **kwargs):\n     return False  # pragma: no cover\n \n \n-@cli.command()\n+@cli.command(cls=DeprecatedOptionsCommand)\n @common_options\n @core_options\n @click.option(\n@@ -710,9 +710,12 @@ def do_fixes(lnt, result, formatter=None, **kwargs):\n     ),\n )\n @click.option(\n+    \"--disable_progress_bar\",\n     \"--disable-progress-bar\",\n     is_flag=True,\n     help=\"Disables progress bars.\",\n+    cls=DeprecatedOption,\n+    deprecated=[\"--disable_progress_bar\"],\n )\n @click.option(\n     \"--FIX-EVEN-UNPARSABLE\",\n\n</patch>", "test_patch": "diff --git a/test/cli/commands_test.py b/test/cli/commands_test.py\n--- a/test/cli/commands_test.py\n+++ b/test/cli/commands_test.py\n@@ -1775,6 +1775,46 @@ def test_cli_lint_enabled_progress_bar_multiple_files(\n         assert r\"\\rrule L001:\" in raw_output\n         assert r\"\\rrule L049:\" in raw_output\n \n+    def test_cli_fix_disabled_progress_bar(\n+        self, mock_disable_progress_bar: MagicMock\n+    ) -> None:\n+        \"\"\"When progress bar is disabled, nothing should be printed into output.\"\"\"\n+        result = invoke_assert_code(\n+            args=[\n+                fix,\n+                [\n+                    \"--disable-progress-bar\",\n+                    \"test/fixtures/linter/passing.sql\",\n+                ],\n+            ],\n+        )\n+        raw_output = repr(result.output)\n+\n+        assert (\n+            \"DeprecationWarning: The option '--disable_progress_bar' is deprecated, \"\n+            \"use '--disable-progress-bar'\"\n+        ) not in raw_output\n+\n+    def test_cli_fix_disabled_progress_bar_deprecated_option(\n+        self, mock_disable_progress_bar: MagicMock\n+    ) -> None:\n+        \"\"\"Same as above but checks additionally if deprecation warning is printed.\"\"\"\n+        result = invoke_assert_code(\n+            args=[\n+                fix,\n+                [\n+                    \"--disable_progress_bar\",\n+                    \"test/fixtures/linter/passing.sql\",\n+                ],\n+            ],\n+        )\n+        raw_output = repr(result.output)\n+\n+        assert (\n+            \"DeprecationWarning: The option '--disable_progress_bar' is deprecated, \"\n+            \"use '--disable-progress-bar'\"\n+        ) in raw_output\n+\n \n multiple_expected_output = \"\"\"==== finding fixable violations ====\n == [test/fixtures/linter/multiple_sql_errors.sql] FAIL\n", "version": "1.3", "FAIL_TO_PASS": "[\"test/cli/commands_test.py::TestProgressBars::test_cli_fix_disabled_progress_bar_deprecated_option\"]", "PASS_TO_PASS": "[\"test/cli/commands_test.py::test__cli__command_directed\", \"test/cli/commands_test.py::test__cli__command_dialect\", \"test/cli/commands_test.py::test__cli__command_no_dialect\", \"test/cli/commands_test.py::test__cli__command_parse_error_dialect_explicit_warning\", \"test/cli/commands_test.py::test__cli__command_parse_error_dialect_implicit_warning\", \"test/cli/commands_test.py::test__cli__command_dialect_legacy\", \"test/cli/commands_test.py::test__cli__command_extra_config_fail\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command3]\", \"test/cli/commands_test.py::test__cli__command_render_stdin\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command3]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command4]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command5]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command6]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command7]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command8]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command9]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command10]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command11]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command12]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command13]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command14]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command15]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command16]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command17]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command18]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command19]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command20]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command21]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command22]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command23]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command24]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command25]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command0-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command1-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command2-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command3-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command4-1]\", \"test/cli/commands_test.py::test__cli__command_lint_warning_explicit_file_ignored\", \"test/cli/commands_test.py::test__cli__command_lint_skip_ignore_files\", \"test/cli/commands_test.py::test__cli__command_lint_ignore_local_config\", \"test/cli/commands_test.py::test__cli__command_lint_warning\", \"test/cli/commands_test.py::test__cli__command_versioning\", \"test/cli/commands_test.py::test__cli__command_version\", \"test/cli/commands_test.py::test__cli__command_rules\", \"test/cli/commands_test.py::test__cli__command_dialects\", \"test/cli/commands_test.py::test__cli__command__fix[L001-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/whitespace_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L003-test/fixtures/linter/indentation_error_hard.sql]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_templating_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_suppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[0_lint_errors_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[0_lint_errors_1_suppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_parse_error_FIX_EVEN_UNPARSABLE]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[2_files_with_lint_errors_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[command-line-False]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[command-line-True]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[config-file-False]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[config-file-True]\", \"test/cli/commands_test.py::test__cli__fix_loop_limit_behavior[--\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[select\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[SELECT\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_logging_to_stderr\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_safety\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[create\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[select\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-y-0-0]\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-n-1-1]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[None-yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[None-json]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[outfile-yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[outfile-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[select\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[SElect\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command0]\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_nocolor\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-human]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-github-annotation-native]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-human]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-github-annotation-native]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation_native\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_annotation_level_error_failure_equivalent[github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_annotation_level_error_failure_equivalent[github-annotation-native]\", \"test/cli/commands_test.py::test___main___help\", \"test/cli/commands_test.py::test_encoding[utf-8-ascii]\", \"test/cli/commands_test.py::test_encoding[utf-8-sig-UTF-8-SIG]\", \"test/cli/commands_test.py::test_encoding[utf-32-UTF-32]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-command-line-False]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-SIG-command-line-True]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-config-file-False]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-SIG-config-file-True]\", \"test/cli/commands_test.py::test_cli_no_disable_noqa_flag\", \"test/cli/commands_test.py::test_cli_disable_noqa_flag\", \"test/cli/commands_test.py::test_cli_get_default_config\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_disabled_progress_bar\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_disabled_progress_bar_deprecated_option\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar_multiple_paths\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar_multiple_files\", \"test/cli/commands_test.py::TestProgressBars::test_cli_fix_disabled_progress_bar\", \"test/cli/commands_test.py::test__cli__fix_multiple_errors_no_show_errors\", \"test/cli/commands_test.py::test__cli__fix_multiple_errors_show_errors\", \"test/cli/commands_test.py::test__cli__multiple_files__fix_multiple_errors_show_errors\", \"test/cli/commands_test.py::test__cli__render_fail\", \"test/cli/commands_test.py::test__cli__render_pass\"]", "environment_setup_commit": "dc59c2a5672aacedaf91f0e6129b467eefad331b"}
{"instance_id": "sqlfluff__sqlfluff-4151_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n\n</issue>\n<code>\n[start of README.md]\n1 ![SQLFluff](https://raw.githubusercontent.com/sqlfluff/sqlfluff/main/images/sqlfluff-wide.png)\n2 \n3 # The SQL Linter for Humans\n4 \n5 [![PyPi Version](https://img.shields.io/pypi/v/sqlfluff.svg?style=flat-square&logo=PyPi)](https://pypi.org/project/sqlfluff/)\n6 [![PyPi License](https://img.shields.io/pypi/l/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n7 [![PyPi Python Versions](https://img.shields.io/pypi/pyversions/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n8 [![PyPi Status](https://img.shields.io/pypi/status/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n9 [![PyPi Downloads](https://img.shields.io/pypi/dm/sqlfluff?style=flat-square)](https://pypi.org/project/sqlfluff/)\n10 \n11 [![codecov](https://img.shields.io/codecov/c/gh/sqlfluff/sqlfluff.svg?style=flat-square&logo=Codecov)](https://codecov.io/gh/sqlfluff/sqlfluff)\n12 [![GitHub Workflow Status](https://img.shields.io/github/workflow/status/sqlfluff/sqlfluff/CI%20Tests?logo=github&style=flat-square)](https://github.com/sqlfluff/sqlfluff/actions/workflows/ci-tests.yml?query=branch%3Amain)\n13 [![ReadTheDocs](https://img.shields.io/readthedocs/sqlfluff?style=flat-square&logo=Read%20the%20Docs)](https://sqlfluff.readthedocs.io)\n14 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/psf/black)\n15 [![Docker Pulls](https://img.shields.io/docker/pulls/sqlfluff/sqlfluff?logo=docker&style=flat-square)](https://hub.docker.com/r/sqlfluff/sqlfluff)\n16 \n17 **SQLFluff** is a dialect-flexible and configurable SQL linter. Designed with ELT applications in mind, **SQLFluff** also works with Jinja templating and dbt. **SQLFluff** will auto-fix most linting errors, allowing you to focus your time on what matters.\n18 \n19 ## Dialects Supported\n20 \n21 Although SQL is reasonably consistent in its implementations, there are several different dialects available with variations of syntax and grammar. **SQLFluff** currently supports the following SQL dialects (though perhaps not in full):\n22 \n23 - ANSI SQL - this is the base version and on occasion may not strictly follow the ANSI/ISO SQL definition\n24 - [Athena](https://aws.amazon.com/athena/)\n25 - [BigQuery](https://cloud.google.com/bigquery/)\n26 - [ClickHouse](https://clickhouse.com/)\n27 - [Databricks](https://databricks.com/) (note: currently this is just an alias for the `sparksql` dialect).\n28 - [Db2](https://www.ibm.com/analytics/db2)\n29 - [Exasol](https://www.exasol.com/)\n30 - [Hive](https://hive.apache.org/)\n31 - [Materialize](https://materialize.com/)\n32 - [MySQL](https://www.mysql.com/)\n33 - [Oracle](https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/index.html)\n34 - [PostgreSQL](https://www.postgresql.org/) (aka Postgres)\n35 - [Redshift](https://docs.aws.amazon.com/redshift/index.html)\n36 - [Snowflake](https://www.snowflake.com/)\n37 - [SOQL](https://developer.salesforce.com/docs/atlas.en-us.soql_sosl.meta/soql_sosl/sforce_api_calls_soql.htm)\n38 - [SparkSQL](https://spark.apache.org/docs/latest/)\n39 - [SQLite](https://www.sqlite.org/)\n40 - [Teradata](https://www.teradata.com/)\n41 - [Transact-SQL](https://docs.microsoft.com/en-us/sql/t-sql/language-reference) (aka T-SQL)\n42 \n43 We aim to make it easy to expand on the support of these dialects and also add other, currently unsupported, dialects. Please [raise issues](https://github.com/sqlfluff/sqlfluff/issues) (or upvote any existing issues) to let us know of demand for missing support.\n44 \n45 Pull requests from those that know the missing syntax or dialects are especially welcomed and are the question way for you to get support added. We are happy to work with any potential contributors on this to help them add this support. Please raise an issue first for any large feature change to ensure it is a good fit for this project before spending time on this work.\n46 \n47 ## Templates Supported\n48 \n49 SQL itself does not lend itself well to [modularity](https://docs.getdbt.com/docs/viewpoint#section-modularity), so to introduce some flexibility and reusability it is often [templated](https://en.wikipedia.org/wiki/Template_processor) as discussed more in [our modularity documentation](https://docs.sqlfluff.com/en/stable/realworld.html#modularity).\n50 \n51 **SQLFluff** supports the following templates:\n52 - [Jinja](https://jinja.palletsprojects.com/) (aka Jinja2)\n53 - [dbt](https://www.getdbt.com/)\n54 \n55 Again, please raise issues if you wish to support more templating languages/syntaxes.\n56 \n57 # Getting Started\n58 \n59 To get started, install the package and run `sqlfluff lint` or `sqlfluff fix`.\n60 \n61 ```shell\n62 $ pip install sqlfluff\n63 $ echo \"  SELECT a  +  b FROM tbl;  \" > test.sql\n64 $ sqlfluff lint test.sql --dialect ansi\n65 == [test.sql] FAIL\n66 L:   1 | P:   1 | L050 | Files must not begin with newlines or whitespace.\n67 L:   1 | P:   3 | L003 | First line has unexpected indent\n68 L:   1 | P:  11 | L039 | Unnecessary whitespace found.\n69 L:   1 | P:  14 | L039 | Unnecessary whitespace found.\n70 L:   1 | P:  27 | L001 | Unnecessary trailing whitespace.\n71 ```\n72 \n73 Alternatively, you can use the [**Official SQLFluff Docker Image**](https://hub.docker.com/r/sqlfluff/sqlfluff) or have a play using [**SQLFluff online**](https://online.sqlfluff.com/).\n74 \n75 For full [CLI usage](https://docs.sqlfluff.com/en/stable/cli.html) and [rules reference](https://docs.sqlfluff.com/en/stable/rules.html), see [the SQLFluff docs](https://docs.sqlfluff.com/en/stable/).\n76 \n77 # Documentation\n78 \n79 For full documentation visit [docs.sqlfluff.com](https://docs.sqlfluff.com/en/stable/). This documentation is generated from this repository so please raise [issues](https://github.com/sqlfluff/sqlfluff/issues) or pull requests for any additions, corrections, or clarifications.\n80 \n81 # Releases\n82 \n83 **SQLFluff** adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html), so breaking changes\n84 should be restricted to major versions releases. Some elements (such as the python API) are in a less\n85 stable state and may see more significant changes more often. See the [changelog](CHANGELOG.md) for more details.\n86 If you would like to join in please consider [contributing](CONTRIBUTING.md).\n87 \n88 New releases are made monthly. For more information, visit [Releases](https://github.com/sqlfluff/sqlfluff/releases).\n89 \n90 # SQLFluff on Slack\n91 \n92 We have a fast-growing community [on Slack](https://join.slack.com/t/sqlfluff/shared_invite/zt-o1f4x0e8-pZzarAIlQmKj_6ZwD16w0g), come and join us!\n93 \n94 # SQLFluff on Twitter\n95 \n96 Follow us [on Twitter @SQLFluff](https://twitter.com/SQLFluff) for announcements and other related posts.\n97 \n98 # Contributing\n99 \n100 We are grateful to all our [contributors](https://github.com/sqlfluff/sqlfluff/graphs/contributors). There is a lot to do in this project, and we are just getting started.\n101 \n102 If you want to understand more about the architecture of **SQLFluff**, you can\n103 find [more here](https://docs.sqlfluff.com/en/latest/internals.html#architecture).\n104 \n105 If you would like to contribute, check out the [open issues on GitHub](https://github.com/sqlfluff/sqlfluff/issues). You can also see the guide to [contributing](CONTRIBUTING.md).\n106 \n[end of README.md]\n[start of src/sqlfluff/core/config.py]\n1 \"\"\"Module for loading config.\"\"\"\n2 \n3 import logging\n4 import os\n5 import os.path\n6 import configparser\n7 from dataclasses import dataclass\n8 \n9 import pluggy\n10 from itertools import chain\n11 from typing import Dict, Iterator, List, Tuple, Any, Optional, Union, Iterable, Callable\n12 from pathlib import Path\n13 from sqlfluff.core.plugin.host import get_plugin_manager\n14 from sqlfluff.core.errors import SQLFluffUserError\n15 \n16 import appdirs\n17 \n18 import toml\n19 \n20 # Instantiate the config logger\n21 config_logger = logging.getLogger(\"sqlfluff.config\")\n22 \n23 global_loader = None\n24 \"\"\":obj:`ConfigLoader`: A variable to hold the single module loader when loaded.\n25 \n26 We define a global loader, so that between calls to load config, we\n27 can still cache appropriately\n28 \"\"\"\n29 \n30 ConfigElemType = Tuple[Tuple[str, ...], Any]\n31 \n32 \n33 @dataclass\n34 class _RemovedConfig:\n35     old_path: Tuple[str, ...]\n36     warning: str\n37     new_path: Optional[Tuple[str, ...]] = None\n38     translation_func: Optional[Callable[[str], str]] = None\n39 \n40 \n41 REMOVED_CONFIGS = [\n42     _RemovedConfig(\n43         (\"rules\", \"L007\", \"operator_new_lines\"),\n44         (\n45             \"Use the line_position config in the appropriate \"\n46             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n47             \":binary_operator).\"\n48         ),\n49         (\"layout\", \"type\", \"binary_operator\", \"line_position\"),\n50         (lambda x: \"trailing\" if x == \"before\" else \"leading\"),\n51     ),\n52     _RemovedConfig(\n53         (\"rules\", \"comma_style\"),\n54         (\n55             \"Use the line_position config in the appropriate \"\n56             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n57             \":comma).\"\n58         ),\n59         (\"layout\", \"type\", \"comma\", \"line_position\"),\n60         (lambda x: x),\n61     ),\n62     # L019 used to have a more specific version of the same /config itself.\n63     _RemovedConfig(\n64         (\"rules\", \"L019\", \"comma_style\"),\n65         (\n66             \"Use the line_position config in the appropriate \"\n67             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n68             \":comma).\"\n69         ),\n70         (\"layout\", \"type\", \"comma\", \"line_position\"),\n71         (lambda x: x),\n72     ),\n73     _RemovedConfig(\n74         (\"rules\", \"L003\", \"lint_templated_tokens\"),\n75         \"No longer used.\",\n76     ),\n77 ]\n78 \n79 \n80 def coerce_value(val: str) -> Any:\n81     \"\"\"Try to coerce to a more specific type.\"\"\"\n82     # Try to coerce it to a more specific type,\n83     # otherwise just make it a string.\n84     try:\n85         v: Any = int(val)\n86     except ValueError:\n87         try:\n88             v = float(val)\n89         except ValueError:\n90             cleaned_val = val.strip().lower()\n91             if cleaned_val in [\"true\"]:\n92                 v = True\n93             elif cleaned_val in [\"false\"]:\n94                 v = False\n95             elif cleaned_val in [\"none\"]:\n96                 v = None\n97             else:\n98                 v = val\n99     return v\n100 \n101 \n102 def nested_combine(*dicts: dict) -> dict:\n103     \"\"\"Combine an iterable of dictionaries.\n104 \n105     Each dictionary is combined into a result dictionary. For\n106     each key in the first dictionary, it will be overwritten\n107     by any same-named key in any later dictionaries in the\n108     iterable. If the element at that key is a dictionary, rather\n109     than just overwriting we use the same function to combine\n110     those dictionaries.\n111 \n112     Args:\n113         *dicts: An iterable of dictionaries to be combined.\n114 \n115     Returns:\n116         `dict`: A combined dictionary from the input dictionaries.\n117 \n118     A simple example:\n119     >>> nested_combine({\"a\": {\"b\": \"c\"}}, {\"a\": {\"d\": \"e\"}})\n120     {'a': {'b': 'c', 'd': 'e'}}\n121 \n122     Keys overwrite left to right:\n123     >>> nested_combine({\"a\": {\"b\": \"c\"}}, {\"a\": {\"b\": \"e\"}})\n124     {'a': {'b': 'e'}}\n125     \"\"\"\n126     r: dict = {}\n127     for d in dicts:\n128         for k in d:\n129             if k in r and isinstance(r[k], dict):\n130                 if isinstance(d[k], dict):\n131                     r[k] = nested_combine(r[k], d[k])\n132                 else:  # pragma: no cover\n133                     raise ValueError(\n134                         \"Key {!r} is a dict in one config but not another! PANIC: \"\n135                         \"{!r}\".format(k, d[k])\n136                     )\n137             else:\n138                 r[k] = d[k]\n139     return r\n140 \n141 \n142 def dict_diff(left: dict, right: dict, ignore: Optional[List[str]] = None) -> dict:\n143     \"\"\"Work out the difference between to dictionaries.\n144 \n145     Returns a dictionary which represents elements in the `left`\n146     dictionary which aren't in the `right` or are different to\n147     those in the `right`. If the element is a dictionary, we\n148     recursively look for differences in those dictionaries,\n149     likewise only returning the differing elements.\n150 \n151     NOTE: If an element is in the `right` but not in the `left`\n152     at all (i.e. an element has been *removed*) then it will\n153     not show up in the comparison.\n154 \n155     Args:\n156         left (:obj:`dict`): The object containing the *new* elements\n157             which will be compared against the other.\n158         right (:obj:`dict`): The object to compare against.\n159         ignore (:obj:`list` of `str`, optional): Keys to ignore.\n160 \n161     Returns:\n162         `dict`: A dictionary representing the difference.\n163 \n164     Basic functionality shown, especially returning the left as:\n165     >>> dict_diff({\"a\": \"b\", \"c\": \"d\"}, {\"a\": \"b\", \"c\": \"e\"})\n166     {'c': 'd'}\n167 \n168     Ignoring works on a key basis:\n169     >>> dict_diff({\"a\": \"b\"}, {\"a\": \"c\"})\n170     {'a': 'b'}\n171     >>> dict_diff({\"a\": \"b\"}, {\"a\": \"c\"}, [\"a\"])\n172     {}\n173     \"\"\"\n174     buff: dict = {}\n175     for k in left:\n176         if ignore and k in ignore:\n177             continue\n178         # Is the key there at all?\n179         if k not in right:\n180             buff[k] = left[k]\n181         # Is the content the same?\n182         elif left[k] == right[k]:\n183             continue\n184         # If it's not the same but both are dicts, then compare\n185         elif isinstance(left[k], dict) and isinstance(right[k], dict):\n186             diff = dict_diff(left[k], right[k], ignore=ignore)\n187             # Only include the difference if non-null.\n188             if diff:\n189                 buff[k] = diff\n190         # It's just different\n191         else:\n192             buff[k] = left[k]\n193     return buff\n194 \n195 \n196 def _split_comma_separated_string(raw_str: str) -> List[str]:\n197     return [s.strip() for s in raw_str.split(\",\") if s.strip()]\n198 \n199 \n200 class ConfigLoader:\n201     \"\"\"The class for loading config files.\n202 \n203     Note:\n204         Unlike most cfg file readers, sqlfluff is case-sensitive in how\n205         it reads config files. This is to ensure we support the case\n206         sensitivity of jinja.\n207 \n208     \"\"\"\n209 \n210     def __init__(self) -> None:\n211         # TODO: check that this cache implementation is actually useful\n212         self._config_cache: dict = {}\n213 \n214     @classmethod\n215     def get_global(cls) -> \"ConfigLoader\":\n216         \"\"\"Get the singleton loader.\"\"\"\n217         global global_loader\n218         if not global_loader:\n219             global_loader = cls()\n220         return global_loader\n221 \n222     @classmethod\n223     def _walk_toml(cls, config: Dict[str, Any], base_key=()):\n224         \"\"\"Recursively walk the nested config inside a TOML file.\"\"\"\n225         buff: List[tuple] = []\n226         for k, v in config.items():\n227             key = base_key + (k,)\n228             if isinstance(v, dict):\n229                 buff.extend(cls._walk_toml(v, key))\n230             else:\n231                 buff.append((key, v))\n232 \n233         return buff\n234 \n235     @classmethod\n236     def _iter_config_elems_from_dict(cls, configs: dict) -> Iterator[ConfigElemType]:\n237         \"\"\"Walk a config dict and get config elements.\n238 \n239         >>> list(\n240         ...    ConfigLoader._iter_config_elems_from_dict(\n241         ...        {\"foo\":{\"bar\":{\"baz\": \"a\", \"biz\": \"b\"}}}\n242         ...    )\n243         ... )\n244         [(('foo', 'bar', 'baz'), 'a'), (('foo', 'bar', 'biz'), 'b')]\n245         \"\"\"\n246         for key, val in configs.items():\n247             if isinstance(val, dict):\n248                 for partial_key, sub_val in cls._iter_config_elems_from_dict(val):\n249                     yield (key,) + partial_key, sub_val\n250             else:\n251                 yield (key,), val\n252 \n253     @classmethod\n254     def _config_elems_to_dict(cls, configs: Iterable[ConfigElemType]) -> dict:\n255         \"\"\"Reconstruct config elements into a dict.\n256 \n257         >>> ConfigLoader._config_elems_to_dict(\n258         ...     [((\"foo\", \"bar\", \"baz\"), \"a\"), ((\"foo\", \"bar\", \"biz\"), \"b\")]\n259         ... )\n260         {'foo': {'bar': {'baz': 'a', 'biz': 'b'}}}\n261         \"\"\"\n262         result: Dict[str, Union[dict, str]] = {}\n263         for key, val in configs:\n264             ref = result\n265             for step in key[:-1]:\n266                 if step not in ref:\n267                     ref[step] = {}\n268                 ref = ref[step]  # type: ignore\n269             ref[key[-1]] = val\n270         return result\n271 \n272     @classmethod\n273     def _get_config_elems_from_toml(cls, fpath: str) -> List[ConfigElemType]:\n274         \"\"\"Load a config from a TOML file and return a list of tuples.\n275 \n276         The return value is a list of tuples, were each tuple has two elements,\n277         the first is a tuple of paths, the second is the value at that path.\n278         \"\"\"\n279         config = toml.load(fpath)\n280         tool = config.get(\"tool\", {}).get(\"sqlfluff\", {})\n281 \n282         return cls._walk_toml(tool)\n283 \n284     @classmethod\n285     def _get_config_elems_from_file(cls, fpath: str) -> List[ConfigElemType]:\n286         \"\"\"Load a config from a file and return a list of tuples.\n287 \n288         The return value is a list of tuples, were each tuple has two elements,\n289         the first is a tuple of paths, the second is the value at that path.\n290 \n291         Note:\n292             Unlike most cfg file readers, sqlfluff is case-sensitive in how\n293             it reads config files.\n294 \n295         Note:\n296             Any variable names ending with `_path` or `_dir`, will be attempted to be\n297             resolved as relative paths to this config file. If that fails the\n298             string value will remain.\n299 \n300         \"\"\"\n301         buff: List[Tuple[tuple, Any]] = []\n302         # Disable interpolation so we can load macros\n303         kw: Dict = {}\n304         kw[\"interpolation\"] = None\n305         config = configparser.ConfigParser(delimiters=\"=\", **kw)\n306         # NB: We want to be case sensitive in how we read from files,\n307         # because jinja is also case sensitive. To do this we override\n308         # the optionxform attribute.\n309         config.optionxform = lambda option: option  # type: ignore\n310         config.read(fpath)\n311         for k in config.sections():\n312             if k == \"sqlfluff\":\n313                 key: Tuple = (\"core\",)\n314             elif k.startswith(\"sqlfluff:\"):\n315                 # Return a tuple of nested values\n316                 key = tuple(k[len(\"sqlfluff:\") :].split(\":\"))\n317             else:  # pragma: no cover\n318                 # if it doesn't start with sqlfluff, then don't go\n319                 # further on this iteration\n320                 continue\n321 \n322             for name, val in config.items(section=k):\n323                 # Try to coerce it to a more specific type,\n324                 # otherwise just make it a string.\n325                 v = coerce_value(val)\n326 \n327                 # Attempt to resolve paths\n328                 if name.lower() == \"load_macros_from_path\":\n329                     # Comma-separated list of paths.\n330                     paths = _split_comma_separated_string(val)\n331                     v_temp = []\n332                     for path in paths:\n333                         v_temp.append(cls._resolve_path(fpath, path))\n334                     v = \",\".join(v_temp)\n335                 elif name.lower().endswith((\"_path\", \"_dir\")):\n336                     # One path\n337                     v = cls._resolve_path(fpath, val)\n338                 # Add the name to the end of the key\n339                 buff.append((key + (name,), v))\n340         return buff\n341 \n342     @classmethod\n343     def _resolve_path(cls, fpath, val):\n344         \"\"\"Try to resolve a path.\"\"\"\n345         # Make the referenced path.\n346         ref_path = os.path.join(os.path.dirname(fpath), val)\n347         # Check if it exists, and if it does, replace the value with the path.\n348         return ref_path if os.path.exists(ref_path) else val\n349 \n350     @staticmethod\n351     def _incorporate_vals(ctx: dict, vals: List[ConfigElemType]) -> dict:\n352         \"\"\"Take a list of tuples and incorporate it into a dictionary.\n353 \n354         >>> ConfigLoader._incorporate_vals({}, [((\"a\", \"b\"), \"c\")])\n355         {'a': {'b': 'c'}}\n356         >>> ConfigLoader._incorporate_vals({\"a\": {\"b\": \"c\"}}, [((\"a\", \"d\"), \"e\")])\n357         {'a': {'b': 'c', 'd': 'e'}}\n358         \"\"\"\n359         for k, v in vals:\n360             # Keep a ref we can use for recursion\n361             r = ctx\n362             # Get the name of the variable\n363             n = k[-1]\n364             # Get the path\n365             pth = k[:-1]\n366             for dp in pth:\n367                 # Does this path exist?\n368                 if dp in r:\n369                     if isinstance(r[dp], dict):\n370                         r = r[dp]\n371                     else:  # pragma: no cover\n372                         raise ValueError(f\"Overriding config value with section! [{k}]\")\n373                 else:\n374                     r[dp] = {}\n375                     r = r[dp]\n376             # Deal with the value itself\n377             r[n] = v\n378         return ctx\n379 \n380     @staticmethod\n381     def _validate_configs(\n382         configs: Iterable[ConfigElemType], file_path\n383     ) -> List[ConfigElemType]:\n384         \"\"\"Validate config elements against removed list.\"\"\"\n385         config_map = {cfg.old_path: cfg for cfg in REMOVED_CONFIGS}\n386         # Materialise the configs into a list to we can iterate twice.\n387         new_configs = list(configs)\n388         defined_keys = {k for k, _ in new_configs}\n389         validated_configs = []\n390         for k, v in new_configs:\n391             if k in config_map.keys():\n392                 formatted_key = \":\".join(k)\n393                 removed_option = config_map[k]\n394                 # Is there a mapping option?\n395                 if removed_option.translation_func and removed_option.new_path:\n396                     formatted_new_key = \":\".join(removed_option.new_path)\n397                     # Before mutating, check we haven't _also_ set the new value.\n398                     if removed_option.new_path in defined_keys:\n399                         # Raise an warning.\n400                         config_logger.warning(\n401                             f\"\\nWARNING: Config file {file_path} set a deprecated \"\n402                             f\"config value `{formatted_key}` (which can be migrated) \"\n403                             f\"but ALSO set the value it would be migrated to. The new \"\n404                             f\"value (`{removed_option.new_path}`) takes precedence. \"\n405                             \"Please update your configuration to remove this warning. \"\n406                             f\"\\n\\n{removed_option.warning}\\n\\n\"\n407                             \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n408                             \" for more details.\\n\"\n409                         )\n410                         # continue to NOT add this value in the set\n411                         continue\n412 \n413                     # Mutate and warn.\n414                     v = removed_option.translation_func(v)\n415                     k = removed_option.new_path\n416                     # NOTE: At the stage of emitting this warning, we may not yet\n417                     # have set up red logging because we haven't yet loaded the config\n418                     # file. For that reason, this error message has a bit more padding.\n419                     config_logger.warning(\n420                         f\"\\nWARNING: Config file {file_path} set a deprecated config \"\n421                         f\"value `{formatted_key}`. This will be removed in a later \"\n422                         \"release. This has been mapped to \"\n423                         f\"`{formatted_new_key}` set to a value of `{v}` for this run. \"\n424                         \"Please update your configuration to remove this warning. \"\n425                         f\"\\n\\n{removed_option.warning}\\n\\n\"\n426                         \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n427                         \" for more details.\\n\"\n428                     )\n429                 else:\n430                     # Raise an error.\n431                     raise SQLFluffUserError(\n432                         f\"Config file {file_path} set an outdated config \"\n433                         f\"value {formatted_key}.\\n\\n{removed_option.warning}\\n\\n\"\n434                         \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n435                         \" for more details.\"\n436                     )\n437 \n438             validated_configs.append((k, v))\n439         return validated_configs\n440 \n441     def load_config_file(\n442         self, file_dir: str, file_name: str, configs: Optional[dict] = None\n443     ) -> dict:\n444         \"\"\"Load the default config file.\"\"\"\n445         file_path = os.path.join(file_dir, file_name)\n446         if file_name == \"pyproject.toml\":\n447             elems = self._get_config_elems_from_toml(file_path)\n448         else:\n449             elems = self._get_config_elems_from_file(file_path)\n450         elems = self._validate_configs(elems, file_path)\n451         return self._incorporate_vals(configs or {}, elems)\n452 \n453     def load_config_at_path(self, path: str) -> dict:\n454         \"\"\"Load config from a given path.\"\"\"\n455         # First check the cache\n456         if str(path) in self._config_cache:\n457             return self._config_cache[str(path)]\n458 \n459         # The potential filenames we would look for at this path.\n460         # NB: later in this list overwrites earlier\n461         filename_options = [\n462             \"setup.cfg\",\n463             \"tox.ini\",\n464             \"pep8.ini\",\n465             \".sqlfluff\",\n466             \"pyproject.toml\",\n467         ]\n468 \n469         configs: dict = {}\n470 \n471         if os.path.isdir(path):\n472             p = path\n473         else:\n474             p = os.path.dirname(path)\n475 \n476         d = os.listdir(os.path.expanduser(p))\n477         # iterate this way round to make sure things overwrite is the right direction\n478         for fname in filename_options:\n479             if fname in d:\n480                 configs = self.load_config_file(p, fname, configs=configs)\n481 \n482         # Store in the cache\n483         self._config_cache[str(path)] = configs\n484         return configs\n485 \n486     def load_extra_config(self, extra_config_path: str) -> dict:\n487         \"\"\"Load specified extra config.\"\"\"\n488         if not os.path.exists(extra_config_path):\n489             raise SQLFluffUserError(\n490                 f\"Extra config '{extra_config_path}' does not exist.\"\n491             )\n492 \n493         # First check the cache\n494         if str(extra_config_path) in self._config_cache:\n495             return self._config_cache[str(extra_config_path)]\n496 \n497         configs: dict = {}\n498         if extra_config_path.endswith(\"pyproject.toml\"):\n499             elems = self._get_config_elems_from_toml(extra_config_path)\n500         else:\n501             elems = self._get_config_elems_from_file(extra_config_path)\n502         configs = self._incorporate_vals(configs, elems)\n503 \n504         # Store in the cache\n505         self._config_cache[str(extra_config_path)] = configs\n506         return configs\n507 \n508     @staticmethod\n509     def _get_user_config_dir_path() -> str:\n510         appname = \"sqlfluff\"\n511         appauthor = \"sqlfluff\"\n512 \n513         # On Mac OSX follow Linux XDG base dirs\n514         # https://github.com/sqlfluff/sqlfluff/issues/889\n515         user_config_dir_path = os.path.expanduser(\"~/.config/sqlfluff\")\n516         if appdirs.system == \"darwin\":\n517             appdirs.system = \"linux2\"\n518             user_config_dir_path = appdirs.user_config_dir(appname, appauthor)\n519             appdirs.system = \"darwin\"\n520 \n521         if not os.path.exists(user_config_dir_path):\n522             user_config_dir_path = appdirs.user_config_dir(appname, appauthor)\n523 \n524         return user_config_dir_path\n525 \n526     def load_user_appdir_config(self) -> dict:\n527         \"\"\"Load the config from the user's OS specific appdir config directory.\"\"\"\n528         user_config_dir_path = self._get_user_config_dir_path()\n529         if os.path.exists(user_config_dir_path):\n530             return self.load_config_at_path(user_config_dir_path)\n531         else:\n532             return {}\n533 \n534     def load_user_config(self) -> dict:\n535         \"\"\"Load the config from the user's home directory.\"\"\"\n536         user_home_path = os.path.expanduser(\"~\")\n537         return self.load_config_at_path(user_home_path)\n538 \n539     def load_config_up_to_path(\n540         self,\n541         path: str,\n542         extra_config_path: Optional[str] = None,\n543         ignore_local_config: bool = False,\n544     ) -> dict:\n545         \"\"\"Loads a selection of config files from both the path and its parent paths.\"\"\"\n546         user_appdir_config = (\n547             self.load_user_appdir_config() if not ignore_local_config else {}\n548         )\n549         user_config = self.load_user_config() if not ignore_local_config else {}\n550         config_paths = (\n551             self.iter_config_locations_up_to_path(path)\n552             if not ignore_local_config\n553             else {}\n554         )\n555         config_stack = (\n556             [self.load_config_at_path(p) for p in config_paths]\n557             if not ignore_local_config\n558             else []\n559         )\n560         extra_config = (\n561             self.load_extra_config(extra_config_path) if extra_config_path else {}\n562         )\n563         return nested_combine(\n564             user_appdir_config, user_config, *config_stack, extra_config\n565         )\n566 \n567     @classmethod\n568     def find_ignore_config_files(\n569         cls, path, working_path=Path.cwd(), ignore_file_name=\".sqlfluffignore\"\n570     ):\n571         \"\"\"Finds sqlfluff ignore files from both the path and its parent paths.\"\"\"\n572         return set(\n573             filter(\n574                 os.path.isfile,\n575                 map(\n576                     lambda x: os.path.join(x, ignore_file_name),\n577                     cls.iter_config_locations_up_to_path(\n578                         path=path, working_path=working_path\n579                     ),\n580                 ),\n581             )\n582         )\n583 \n584     @staticmethod\n585     def iter_config_locations_up_to_path(path, working_path=Path.cwd()):\n586         \"\"\"Finds config locations from both the path and its parent paths.\n587 \n588         The lowest priority is the user appdir, then home dir, then increasingly\n589         the configs closest to the file being directly linted.\n590         \"\"\"\n591         given_path = Path(path).absolute()\n592         working_path = Path(working_path).absolute()\n593 \n594         # If we've been passed a file and not a directory,\n595         # then go straight to the directory.\n596         if not given_path.is_dir():\n597             given_path = given_path.parent\n598 \n599         common_path = Path(os.path.commonpath([working_path, given_path]))\n600 \n601         # we have a sub path! We can load nested paths\n602         path_to_visit = common_path\n603         while path_to_visit != given_path:\n604             yield str(path_to_visit.resolve())\n605             next_path_to_visit = (\n606                 path_to_visit / given_path.relative_to(path_to_visit).parts[0]\n607             )\n608             if next_path_to_visit == path_to_visit:  # pragma: no cover\n609                 # we're not making progress...\n610                 # [prevent infinite loop]\n611                 break\n612             path_to_visit = next_path_to_visit\n613 \n614         yield str(given_path.resolve())\n615 \n616 \n617 class FluffConfig:\n618     \"\"\"The class that actually gets passed around as a config object.\"\"\"\n619 \n620     private_vals = \"rule_denylist\", \"rule_allowlist\", \"dialect_obj\", \"templater_obj\"\n621 \n622     def __init__(\n623         self,\n624         configs: Optional[dict] = None,\n625         extra_config_path: Optional[str] = None,\n626         ignore_local_config: bool = False,\n627         overrides: Optional[dict] = None,\n628         plugin_manager: Optional[pluggy.PluginManager] = None,\n629         # Ideally a dialect should be set when config is read but sometimes\n630         # it might only be set in nested .sqlfluff config files, so allow it\n631         # to be not required.\n632         require_dialect: bool = True,\n633     ):\n634         self._extra_config_path = (\n635             extra_config_path  # We only store this for child configs\n636         )\n637         self._ignore_local_config = (\n638             ignore_local_config  # We only store this for child configs\n639         )\n640         # If overrides are provided, validate them early.\n641         if overrides:\n642             overrides = ConfigLoader._config_elems_to_dict(\n643                 ConfigLoader._validate_configs(\n644                     [\n645                         ((\"core\",) + k, v)\n646                         for k, v in ConfigLoader._iter_config_elems_from_dict(overrides)\n647                     ],\n648                     \"<provided overrides>\",\n649                 )\n650             )[\"core\"]\n651         self._overrides = overrides  # We only store this for child configs\n652 \n653         # Fetch a fresh plugin manager if we weren't provided with one\n654         self._plugin_manager = plugin_manager or get_plugin_manager()\n655 \n656         defaults = nested_combine(*self._plugin_manager.hook.load_default_config())\n657         # If any existing configs are provided. Validate them:\n658         if configs:\n659             configs = ConfigLoader._config_elems_to_dict(\n660                 ConfigLoader._validate_configs(\n661                     ConfigLoader._iter_config_elems_from_dict(configs),\n662                     \"<provided configs>\",\n663                 )\n664             )\n665         self._configs = nested_combine(\n666             defaults, configs or {\"core\": {}}, {\"core\": overrides or {}}\n667         )\n668         # Some configs require special treatment\n669         self._configs[\"core\"][\"color\"] = (\n670             False if self._configs[\"core\"].get(\"nocolor\", False) else None\n671         )\n672         # Handle inputs which are potentially comma separated strings\n673         for in_key, out_key in [\n674             # Deal with potential ignore & warning parameters\n675             (\"ignore\", \"ignore\"),\n676             (\"warnings\", \"warnings\"),\n677             (\"rules\", \"rule_allowlist\"),\n678             # Allowlists and denylists\n679             (\"exclude_rules\", \"rule_denylist\"),\n680         ]:\n681             if self._configs[\"core\"].get(in_key, None):\n682                 self._configs[\"core\"][out_key] = _split_comma_separated_string(\n683                     self._configs[\"core\"][in_key]\n684                 )\n685             else:\n686                 self._configs[\"core\"][out_key] = []\n687         # Configure Recursion\n688         if self._configs[\"core\"].get(\"recurse\", 0) == 0:\n689             self._configs[\"core\"][\"recurse\"] = True\n690 \n691         # Dialect and Template selection.\n692         # NB: We import here to avoid a circular references.\n693         from sqlfluff.core.dialects import dialect_selector\n694 \n695         dialect: Optional[str] = self._configs[\"core\"][\"dialect\"]\n696         if dialect is not None:\n697             self._configs[\"core\"][\"dialect_obj\"] = dialect_selector(\n698                 self._configs[\"core\"][\"dialect\"]\n699             )\n700         elif require_dialect:\n701             self.verify_dialect_specified()\n702         self._configs[\"core\"][\"templater_obj\"] = self.get_templater(\n703             self._configs[\"core\"][\"templater\"]\n704         )\n705 \n706     def verify_dialect_specified(self) -> None:\n707         \"\"\"Check if the config specifies a dialect, raising an error if not.\"\"\"\n708         dialect: Optional[str] = self._configs[\"core\"][\"dialect\"]\n709         if dialect is None:\n710             # Get list of available dialects for the error message. We must\n711             # import here rather than at file scope in order to avoid a circular\n712             # import.\n713             from sqlfluff.core.dialects import dialect_readout\n714 \n715             raise SQLFluffUserError(\n716                 \"No dialect was specified. You must configure a dialect or \"\n717                 \"specify one on the command line using --dialect after the \"\n718                 \"command. Available dialects:\\n\"\n719                 f\"{', '.join([d.label for d in dialect_readout()])}\"\n720             )\n721 \n722     def __getstate__(self):\n723         # Copy the object's state from self.__dict__ which contains\n724         # all our instance attributes. Always use the dict.copy()\n725         # method to avoid modifying the original state.\n726         state = self.__dict__.copy()\n727         # Remove the unpicklable entries.\n728         del state[\"_plugin_manager\"]\n729         return state\n730 \n731     def __setstate__(self, state):  # pragma: no cover\n732         # Restore instance attributes\n733         self.__dict__.update(state)\n734         # NB: We don't reinstate the plugin manager, but this should only\n735         # be happening between processes where the plugin manager should\n736         # probably be fresh in any case.\n737         # NOTE: This means that registering user plugins directly will only\n738         # work if those plugins are used in the main process (i.e. templaters).\n739         # User registered linting rules either must be \"installed\" and therefore\n740         # available to all processes - or their use is limited to only single\n741         # process invocations of sqlfluff. In the event that user registered\n742         # rules are used in a multi-process invocation, they will not be applied\n743         # in the child processes.\n744 \n745     @classmethod\n746     def from_root(\n747         cls,\n748         extra_config_path: Optional[str] = None,\n749         ignore_local_config: bool = False,\n750         overrides: Optional[dict] = None,\n751         **kw,\n752     ) -> \"FluffConfig\":\n753         \"\"\"Loads a config object just based on the root directory.\"\"\"\n754         loader = ConfigLoader.get_global()\n755         c = loader.load_config_up_to_path(\n756             path=\".\",\n757             extra_config_path=extra_config_path,\n758             ignore_local_config=ignore_local_config,\n759         )\n760         return cls(\n761             configs=c,\n762             extra_config_path=extra_config_path,\n763             ignore_local_config=ignore_local_config,\n764             overrides=overrides,\n765             **kw,\n766         )\n767 \n768     @classmethod\n769     def from_path(\n770         cls,\n771         path: str,\n772         extra_config_path: Optional[str] = None,\n773         ignore_local_config: bool = False,\n774         overrides: Optional[dict] = None,\n775         plugin_manager: Optional[pluggy.PluginManager] = None,\n776     ) -> \"FluffConfig\":\n777         \"\"\"Loads a config object given a particular path.\"\"\"\n778         loader = ConfigLoader.get_global()\n779         c = loader.load_config_up_to_path(\n780             path=path,\n781             extra_config_path=extra_config_path,\n782             ignore_local_config=ignore_local_config,\n783         )\n784         return cls(\n785             configs=c,\n786             extra_config_path=extra_config_path,\n787             ignore_local_config=ignore_local_config,\n788             overrides=overrides,\n789             plugin_manager=plugin_manager,\n790         )\n791 \n792     @classmethod\n793     def from_kwargs(\n794         cls,\n795         config: Optional[\"FluffConfig\"] = None,\n796         dialect: Optional[str] = None,\n797         rules: Optional[List[str]] = None,\n798         exclude_rules: Optional[List[str]] = None,\n799         require_dialect: bool = True,\n800     ) -> \"FluffConfig\":\n801         \"\"\"Instantiate a config from either an existing config or kwargs.\n802 \n803         This is a convenience method for the ways that the public classes\n804         like Linter(), Parser() and Lexer() can be instantiated with a\n805         FluffConfig or with the convenience kwargs: dialect & rules.\n806         \"\"\"\n807         if (dialect or rules) and config:  # pragma: no cover\n808             raise ValueError(\n809                 \"Cannot specify `config` with `dialect` or `rules`. Any config object \"\n810                 \"specifies its own dialect and rules.\"\n811             )\n812         elif config:\n813             return config\n814 \n815         overrides = {}\n816         if dialect:\n817             overrides[\"dialect\"] = dialect\n818         if rules:\n819             # Make a comma separated string to pass in as override\n820             overrides[\"rules\"] = \",\".join(rules)\n821         if exclude_rules:\n822             # Make a comma separated string to pass in as override\n823             overrides[\"exclude_rules\"] = \",\".join(exclude_rules)\n824         return cls(overrides=overrides, require_dialect=require_dialect)\n825 \n826     def get_templater(self, templater_name=\"jinja\", **kwargs):\n827         \"\"\"Fetch a templater by name.\"\"\"\n828         templater_lookup = {\n829             templater.name: templater\n830             for templater in chain.from_iterable(\n831                 self._plugin_manager.hook.get_templaters()\n832             )\n833         }\n834         try:\n835             cls = templater_lookup[templater_name]\n836             # Instantiate here, optionally with kwargs\n837             return cls(**kwargs)\n838         except KeyError:\n839             if templater_name == \"dbt\":  # pragma: no cover\n840                 config_logger.warning(\n841                     \"Starting in sqlfluff version 0.7.0 the dbt templater is \"\n842                     \"distributed as a separate python package. Please pip install \"\n843                     \"sqlfluff-templater-dbt to use it.\"\n844                 )\n845             raise SQLFluffUserError(\n846                 \"Requested templater {!r} which is not currently available. Try one of \"\n847                 \"{}\".format(templater_name, \", \".join(templater_lookup.keys()))\n848             )\n849 \n850     def make_child_from_path(self, path: str) -> \"FluffConfig\":\n851         \"\"\"Make a child config at a path but pass on overrides and extra_config_path.\"\"\"\n852         return self.from_path(\n853             path,\n854             extra_config_path=self._extra_config_path,\n855             ignore_local_config=self._ignore_local_config,\n856             overrides=self._overrides,\n857             plugin_manager=self._plugin_manager,\n858         )\n859 \n860     def diff_to(self, other: \"FluffConfig\") -> dict:\n861         \"\"\"Compare this config to another.\n862 \n863         Args:\n864             other (:obj:`FluffConfig`): Another config object to compare\n865                 against. We will return keys from *this* object that are\n866                 not in `other` or are different to those in `other`.\n867 \n868         Returns:\n869             A filtered dict of items in this config that are not in the other\n870             or are different to the other.\n871 \n872         \"\"\"\n873         # We ignore some objects which are not meaningful in the comparison\n874         # e.g. dialect_obj, which is generated on the fly.\n875         return dict_diff(self._configs, other._configs, ignore=[\"dialect_obj\"])\n876 \n877     def get(\n878         self, val: str, section: Union[str, Iterable[str]] = \"core\", default: Any = None\n879     ):\n880         \"\"\"Get a particular value from the config.\"\"\"\n881         section_dict = self.get_section(section)\n882         if section_dict is None:\n883             return default\n884 \n885         return section_dict.get(val, default)\n886 \n887     def get_section(self, section: Union[str, Iterable[str]]) -> Any:\n888         \"\"\"Return a whole section of config as a dict.\n889 \n890         If the element found at the address is a value and not\n891         a section, it is still returned and so this can be used\n892         as a more advanced from of the basic `get` method.\n893 \n894         Args:\n895             section: An iterable or string. If it's a string\n896                 we load that root section. If it's an iterable\n897                 of strings, then we treat it as a path within\n898                 the dictionary structure.\n899 \n900         \"\"\"\n901         if isinstance(section, str):\n902             return self._configs.get(section, None)\n903         else:\n904             # Try iterating\n905             buff = self._configs\n906             for sec in section:\n907                 buff = buff.get(sec, None)\n908                 if buff is None:\n909                     return None\n910             return buff\n911 \n912     def set_value(self, config_path: Iterable[str], val: Any):\n913         \"\"\"Set a value at a given path.\"\"\"\n914         # Make the path a list so we can index on it\n915         config_path = list(config_path)\n916         # Coerce the value into something more useful.\n917         config_val = coerce_value(val)\n918         # Sort out core if not there\n919         if len(config_path) == 1:  # pragma: no cover TODO?\n920             config_path = [\"core\"] + config_path\n921         # Current section:\n922         dict_buff = [self._configs]\n923         for elem in config_path[:-1]:\n924             dict_buff.append(dict_buff[-1][elem])\n925         # Set the value\n926         dict_buff[-1][config_path[-1]] = config_val\n927         # Rebuild the config\n928         for elem in reversed(config_path[:-1]):\n929             dict_elem = dict_buff.pop()\n930             dict_buff[-1][elem] = dict_elem\n931         self._configs = dict_buff[0]\n932 \n933     def iter_vals(self, cfg: Optional[dict] = None) -> Iterable[tuple]:\n934         \"\"\"Return an iterable of tuples representing keys.\n935 \n936         We show values before dicts, the tuple contains an indent\n937         value to know what level of the dict we're in. Dict labels\n938         will be returned as a blank value before their content.\n939         \"\"\"\n940         cfg = cfg or self._configs\n941 \n942         # Get keys and sort\n943         keys = sorted(cfg.keys())\n944         # First iterate values (alphabetically):\n945         for k in keys:\n946             if (\n947                 not isinstance(cfg[k], dict)\n948                 and cfg[k] is not None\n949                 and k not in self.private_vals\n950             ):\n951                 yield (0, k, cfg[k])\n952 \n953         # Then iterate dicts (alphabetically (but `core` comes first if it exists))\n954         for k in keys:\n955             if isinstance(cfg[k], dict):\n956                 # First yield the dict label\n957                 yield (0, k, \"\")\n958                 # Then yield its content\n959                 for idnt, key, val in self.iter_vals(cfg=cfg[k]):\n960                     yield (idnt + 1, key, val)\n961 \n962     def process_inline_config(self, config_line: str):\n963         \"\"\"Process an inline config command and update self.\"\"\"\n964         # Strip preceding comment marks\n965         if config_line.startswith(\"--\"):\n966             config_line = config_line[2:].strip()\n967         # Strip preceding sqlfluff line.\n968         if not config_line.startswith(\"sqlfluff:\"):  # pragma: no cover\n969             config_logger.warning(\n970                 \"Unable to process inline config statement: %r\", config_line\n971             )\n972             return\n973         config_line = config_line[9:].strip()\n974         # Divide on colons\n975         config_path = [elem.strip() for elem in config_line.split(\":\")]\n976         # Set the value\n977         self.set_value(config_path[:-1], config_path[-1])\n978 \n979     def process_raw_file_for_config(self, raw_str: str):\n980         \"\"\"Process a full raw file for inline config and update self.\"\"\"\n981         # Scan the raw file for config commands.\n982         for raw_line in raw_str.splitlines():\n983             if raw_line.startswith(\"-- sqlfluff\"):\n984                 # Found a in-file config command\n985                 self.process_inline_config(raw_line)\n986 \n987 \n988 class ProgressBarConfiguration:\n989     \"\"\"Singleton-esque progress bar configuration.\n990 \n991     It's expected to be set during starting with parameters coming from commands\n992     parameters, then to be just utilized as just\n993     ```\n994     from sqlfluff.core.config import progress_bar_configuration\n995     is_progressbar_disabled = progress_bar_configuration.disable_progress_bar\n996     ```\n997     \"\"\"\n998 \n999     _disable_progress_bar: Optional[bool] = True\n1000 \n1001     @property\n1002     def disable_progress_bar(self) -> Optional[bool]:  # noqa: D102\n1003         return self._disable_progress_bar\n1004 \n1005     @disable_progress_bar.setter\n1006     def disable_progress_bar(self, value: Optional[bool]) -> None:\n1007         \"\"\"`disable_progress_bar` setter.\n1008 \n1009         `True` means that progress bar should be always hidden, `False` fallbacks\n1010         into `None` which is an automatic mode.\n1011         From tqdm documentation: 'If set to None, disable on non-TTY.'\n1012         \"\"\"\n1013         self._disable_progress_bar = value or None\n1014 \n1015 \n1016 progress_bar_configuration = ProgressBarConfiguration()\n1017 \n[end of src/sqlfluff/core/config.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "sqlfluff/sqlfluff", "base_commit": "dc59c2a5672aacedaf91f0e6129b467eefad331b", "problem_statement": "--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n", "hints_text": "Looks like #3904 made `lint` work with both but updated `fix` to only accept `--disable-progress-bar`. I assume that was by accident. Should be relatively straightforward to fix by updating to match `lint`. \nLooks like #3904 made `lint` work with both but updated `fix` to only accept `--disable-progress-bar`. I assume that was by accident. Should be relatively straightforward to fix by updating to match `lint`. ", "created_at": "2022-12-11T16:33:31Z", "patch": "<patch>\ndiff --git a/src/sqlfluff/cli/commands.py b/src/sqlfluff/cli/commands.py\n--- a/src/sqlfluff/cli/commands.py\n+++ b/src/sqlfluff/cli/commands.py\n@@ -680,7 +680,7 @@ def do_fixes(lnt, result, formatter=None, **kwargs):\n     return False  # pragma: no cover\n \n \n-@cli.command()\n+@cli.command(cls=DeprecatedOptionsCommand)\n @common_options\n @core_options\n @click.option(\n@@ -710,9 +710,12 @@ def do_fixes(lnt, result, formatter=None, **kwargs):\n     ),\n )\n @click.option(\n+    \"--disable_progress_bar\",\n     \"--disable-progress-bar\",\n     is_flag=True,\n     help=\"Disables progress bars.\",\n+    cls=DeprecatedOption,\n+    deprecated=[\"--disable_progress_bar\"],\n )\n @click.option(\n     \"--FIX-EVEN-UNPARSABLE\",\n\n</patch>", "test_patch": "diff --git a/test/cli/commands_test.py b/test/cli/commands_test.py\n--- a/test/cli/commands_test.py\n+++ b/test/cli/commands_test.py\n@@ -1775,6 +1775,46 @@ def test_cli_lint_enabled_progress_bar_multiple_files(\n         assert r\"\\rrule L001:\" in raw_output\n         assert r\"\\rrule L049:\" in raw_output\n \n+    def test_cli_fix_disabled_progress_bar(\n+        self, mock_disable_progress_bar: MagicMock\n+    ) -> None:\n+        \"\"\"When progress bar is disabled, nothing should be printed into output.\"\"\"\n+        result = invoke_assert_code(\n+            args=[\n+                fix,\n+                [\n+                    \"--disable-progress-bar\",\n+                    \"test/fixtures/linter/passing.sql\",\n+                ],\n+            ],\n+        )\n+        raw_output = repr(result.output)\n+\n+        assert (\n+            \"DeprecationWarning: The option '--disable_progress_bar' is deprecated, \"\n+            \"use '--disable-progress-bar'\"\n+        ) not in raw_output\n+\n+    def test_cli_fix_disabled_progress_bar_deprecated_option(\n+        self, mock_disable_progress_bar: MagicMock\n+    ) -> None:\n+        \"\"\"Same as above but checks additionally if deprecation warning is printed.\"\"\"\n+        result = invoke_assert_code(\n+            args=[\n+                fix,\n+                [\n+                    \"--disable_progress_bar\",\n+                    \"test/fixtures/linter/passing.sql\",\n+                ],\n+            ],\n+        )\n+        raw_output = repr(result.output)\n+\n+        assert (\n+            \"DeprecationWarning: The option '--disable_progress_bar' is deprecated, \"\n+            \"use '--disable-progress-bar'\"\n+        ) in raw_output\n+\n \n multiple_expected_output = \"\"\"==== finding fixable violations ====\n == [test/fixtures/linter/multiple_sql_errors.sql] FAIL\n", "version": "1.3", "FAIL_TO_PASS": "[\"test/cli/commands_test.py::TestProgressBars::test_cli_fix_disabled_progress_bar_deprecated_option\"]", "PASS_TO_PASS": "[\"test/cli/commands_test.py::test__cli__command_directed\", \"test/cli/commands_test.py::test__cli__command_dialect\", \"test/cli/commands_test.py::test__cli__command_no_dialect\", \"test/cli/commands_test.py::test__cli__command_parse_error_dialect_explicit_warning\", \"test/cli/commands_test.py::test__cli__command_parse_error_dialect_implicit_warning\", \"test/cli/commands_test.py::test__cli__command_dialect_legacy\", \"test/cli/commands_test.py::test__cli__command_extra_config_fail\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command3]\", \"test/cli/commands_test.py::test__cli__command_render_stdin\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command3]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command4]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command5]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command6]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command7]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command8]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command9]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command10]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command11]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command12]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command13]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command14]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command15]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command16]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command17]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command18]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command19]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command20]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command21]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command22]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command23]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command24]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command25]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command0-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command1-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command2-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command3-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command4-1]\", \"test/cli/commands_test.py::test__cli__command_lint_warning_explicit_file_ignored\", \"test/cli/commands_test.py::test__cli__command_lint_skip_ignore_files\", \"test/cli/commands_test.py::test__cli__command_lint_ignore_local_config\", \"test/cli/commands_test.py::test__cli__command_lint_warning\", \"test/cli/commands_test.py::test__cli__command_versioning\", \"test/cli/commands_test.py::test__cli__command_version\", \"test/cli/commands_test.py::test__cli__command_rules\", \"test/cli/commands_test.py::test__cli__command_dialects\", \"test/cli/commands_test.py::test__cli__command__fix[L001-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/whitespace_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L003-test/fixtures/linter/indentation_error_hard.sql]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_templating_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_suppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[0_lint_errors_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[0_lint_errors_1_suppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_parse_error_FIX_EVEN_UNPARSABLE]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[2_files_with_lint_errors_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[command-line-False]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[command-line-True]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[config-file-False]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[config-file-True]\", \"test/cli/commands_test.py::test__cli__fix_loop_limit_behavior[--\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[select\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[SELECT\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_logging_to_stderr\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_safety\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[create\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[select\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-y-0-0]\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-n-1-1]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[None-yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[None-json]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[outfile-yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[outfile-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[select\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[SElect\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command0]\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_nocolor\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-human]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-github-annotation-native]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-human]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-github-annotation-native]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation_native\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_annotation_level_error_failure_equivalent[github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_annotation_level_error_failure_equivalent[github-annotation-native]\", \"test/cli/commands_test.py::test___main___help\", \"test/cli/commands_test.py::test_encoding[utf-8-ascii]\", \"test/cli/commands_test.py::test_encoding[utf-8-sig-UTF-8-SIG]\", \"test/cli/commands_test.py::test_encoding[utf-32-UTF-32]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-command-line-False]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-SIG-command-line-True]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-config-file-False]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-SIG-config-file-True]\", \"test/cli/commands_test.py::test_cli_no_disable_noqa_flag\", \"test/cli/commands_test.py::test_cli_disable_noqa_flag\", \"test/cli/commands_test.py::test_cli_get_default_config\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_disabled_progress_bar\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_disabled_progress_bar_deprecated_option\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar_multiple_paths\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar_multiple_files\", \"test/cli/commands_test.py::TestProgressBars::test_cli_fix_disabled_progress_bar\", \"test/cli/commands_test.py::test__cli__fix_multiple_errors_no_show_errors\", \"test/cli/commands_test.py::test__cli__fix_multiple_errors_show_errors\", \"test/cli/commands_test.py::test__cli__multiple_files__fix_multiple_errors_show_errors\", \"test/cli/commands_test.py::test__cli__render_fail\", \"test/cli/commands_test.py::test__cli__render_pass\"]", "environment_setup_commit": "dc59c2a5672aacedaf91f0e6129b467eefad331b"}
{"instance_id": "sqlfluff__sqlfluff-4151_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n\n</issue>\n<code>\n[start of README.md]\n1 ![SQLFluff](https://raw.githubusercontent.com/sqlfluff/sqlfluff/main/images/sqlfluff-wide.png)\n2 \n3 # The SQL Linter for Humans\n4 \n5 [![PyPi Version](https://img.shields.io/pypi/v/sqlfluff.svg?style=flat-square&logo=PyPi)](https://pypi.org/project/sqlfluff/)\n6 [![PyPi License](https://img.shields.io/pypi/l/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n7 [![PyPi Python Versions](https://img.shields.io/pypi/pyversions/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n8 [![PyPi Status](https://img.shields.io/pypi/status/sqlfluff.svg?style=flat-square)](https://pypi.org/project/sqlfluff/)\n9 [![PyPi Downloads](https://img.shields.io/pypi/dm/sqlfluff?style=flat-square)](https://pypi.org/project/sqlfluff/)\n10 \n11 [![codecov](https://img.shields.io/codecov/c/gh/sqlfluff/sqlfluff.svg?style=flat-square&logo=Codecov)](https://codecov.io/gh/sqlfluff/sqlfluff)\n12 [![GitHub Workflow Status](https://img.shields.io/github/workflow/status/sqlfluff/sqlfluff/CI%20Tests?logo=github&style=flat-square)](https://github.com/sqlfluff/sqlfluff/actions/workflows/ci-tests.yml?query=branch%3Amain)\n13 [![ReadTheDocs](https://img.shields.io/readthedocs/sqlfluff?style=flat-square&logo=Read%20the%20Docs)](https://sqlfluff.readthedocs.io)\n14 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/psf/black)\n15 [![Docker Pulls](https://img.shields.io/docker/pulls/sqlfluff/sqlfluff?logo=docker&style=flat-square)](https://hub.docker.com/r/sqlfluff/sqlfluff)\n16 \n17 **SQLFluff** is a dialect-flexible and configurable SQL linter. Designed with ELT applications in mind, **SQLFluff** also works with Jinja templating and dbt. **SQLFluff** will auto-fix most linting errors, allowing you to focus your time on what matters.\n18 \n19 ## Dialects Supported\n20 \n21 Although SQL is reasonably consistent in its implementations, there are several different dialects available with variations of syntax and grammar. **SQLFluff** currently supports the following SQL dialects (though perhaps not in full):\n22 \n23 - ANSI SQL - this is the base version and on occasion may not strictly follow the ANSI/ISO SQL definition\n24 - [Athena](https://aws.amazon.com/athena/)\n25 - [BigQuery](https://cloud.google.com/bigquery/)\n26 - [ClickHouse](https://clickhouse.com/)\n27 - [Databricks](https://databricks.com/) (note: currently this is just an alias for the `sparksql` dialect).\n28 - [Db2](https://www.ibm.com/analytics/db2)\n29 - [Exasol](https://www.exasol.com/)\n30 - [Hive](https://hive.apache.org/)\n31 - [Materialize](https://materialize.com/)\n32 - [MySQL](https://www.mysql.com/)\n33 - [Oracle](https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/index.html)\n34 - [PostgreSQL](https://www.postgresql.org/) (aka Postgres)\n35 - [Redshift](https://docs.aws.amazon.com/redshift/index.html)\n36 - [Snowflake](https://www.snowflake.com/)\n37 - [SOQL](https://developer.salesforce.com/docs/atlas.en-us.soql_sosl.meta/soql_sosl/sforce_api_calls_soql.htm)\n38 - [SparkSQL](https://spark.apache.org/docs/latest/)\n39 - [SQLite](https://www.sqlite.org/)\n40 - [Teradata](https://www.teradata.com/)\n41 - [Transact-SQL](https://docs.microsoft.com/en-us/sql/t-sql/language-reference) (aka T-SQL)\n42 \n43 We aim to make it easy to expand on the support of these dialects and also add other, currently unsupported, dialects. Please [raise issues](https://github.com/sqlfluff/sqlfluff/issues) (or upvote any existing issues) to let us know of demand for missing support.\n44 \n45 Pull requests from those that know the missing syntax or dialects are especially welcomed and are the question way for you to get support added. We are happy to work with any potential contributors on this to help them add this support. Please raise an issue first for any large feature change to ensure it is a good fit for this project before spending time on this work.\n46 \n47 ## Templates Supported\n48 \n49 SQL itself does not lend itself well to [modularity](https://docs.getdbt.com/docs/viewpoint#section-modularity), so to introduce some flexibility and reusability it is often [templated](https://en.wikipedia.org/wiki/Template_processor) as discussed more in [our modularity documentation](https://docs.sqlfluff.com/en/stable/realworld.html#modularity).\n50 \n51 **SQLFluff** supports the following templates:\n52 - [Jinja](https://jinja.palletsprojects.com/) (aka Jinja2)\n53 - [dbt](https://www.getdbt.com/)\n54 \n55 Again, please raise issues if you wish to support more templating languages/syntaxes.\n56 \n57 # Getting Started\n58 \n59 To get started, install the package and run `sqlfluff lint` or `sqlfluff fix`.\n60 \n61 ```shell\n62 $ pip install sqlfluff\n63 $ echo \"  SELECT a  +  b FROM tbl;  \" > test.sql\n64 $ sqlfluff lint test.sql --dialect ansi\n65 == [test.sql] FAIL\n66 L:   1 | P:   1 | L050 | Files must not begin with newlines or whitespace.\n67 L:   1 | P:   3 | L003 | First line has unexpected indent\n68 L:   1 | P:  11 | L039 | Unnecessary whitespace found.\n69 L:   1 | P:  14 | L039 | Unnecessary whitespace found.\n70 L:   1 | P:  27 | L001 | Unnecessary trailing whitespace.\n71 ```\n72 \n73 Alternatively, you can use the [**Official SQLFluff Docker Image**](https://hub.docker.com/r/sqlfluff/sqlfluff) or have a play using [**SQLFluff online**](https://online.sqlfluff.com/).\n74 \n75 For full [CLI usage](https://docs.sqlfluff.com/en/stable/cli.html) and [rules reference](https://docs.sqlfluff.com/en/stable/rules.html), see [the SQLFluff docs](https://docs.sqlfluff.com/en/stable/).\n76 \n77 # Documentation\n78 \n79 For full documentation visit [docs.sqlfluff.com](https://docs.sqlfluff.com/en/stable/). This documentation is generated from this repository so please raise [issues](https://github.com/sqlfluff/sqlfluff/issues) or pull requests for any additions, corrections, or clarifications.\n80 \n81 # Releases\n82 \n83 **SQLFluff** adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html), so breaking changes\n84 should be restricted to major versions releases. Some elements (such as the python API) are in a less\n85 stable state and may see more significant changes more often. See the [changelog](CHANGELOG.md) for more details.\n86 If you would like to join in please consider [contributing](CONTRIBUTING.md).\n87 \n88 New releases are made monthly. For more information, visit [Releases](https://github.com/sqlfluff/sqlfluff/releases).\n89 \n90 # SQLFluff on Slack\n91 \n92 We have a fast-growing community [on Slack](https://join.slack.com/t/sqlfluff/shared_invite/zt-o1f4x0e8-pZzarAIlQmKj_6ZwD16w0g), come and join us!\n93 \n94 # SQLFluff on Twitter\n95 \n96 Follow us [on Twitter @SQLFluff](https://twitter.com/SQLFluff) for announcements and other related posts.\n97 \n98 # Contributing\n99 \n100 We are grateful to all our [contributors](https://github.com/sqlfluff/sqlfluff/graphs/contributors). There is a lot to do in this project, and we are just getting started.\n101 \n102 If you want to understand more about the architecture of **SQLFluff**, you can\n103 find [more here](https://docs.sqlfluff.com/en/latest/internals.html#architecture).\n104 \n105 If you would like to contribute, check out the [open issues on GitHub](https://github.com/sqlfluff/sqlfluff/issues). You can also see the guide to [contributing](CONTRIBUTING.md).\n106 \n[end of README.md]\n[start of src/sqlfluff/core/config.py]\n1 \"\"\"Module for loading config.\"\"\"\n2 \n3 import logging\n4 import os\n5 import os.path\n6 import configparser\n7 from dataclasses import dataclass\n8 \n9 import pluggy\n10 from itertools import chain\n11 from typing import Dict, Iterator, List, Tuple, Any, Optional, Union, Iterable, Callable\n12 from pathlib import Path\n13 from sqlfluff.core.plugin.host import get_plugin_manager\n14 from sqlfluff.core.errors import SQLFluffUserError\n15 \n16 import appdirs\n17 \n18 import toml\n19 \n20 # Instantiate the config logger\n21 config_logger = logging.getLogger(\"sqlfluff.config\")\n22 \n23 global_loader = None\n24 \"\"\":obj:`ConfigLoader`: A variable to hold the single module loader when loaded.\n25 \n26 We define a global loader, so that between calls to load config, we\n27 can still cache appropriately\n28 \"\"\"\n29 \n30 ConfigElemType = Tuple[Tuple[str, ...], Any]\n31 \n32 \n33 @dataclass\n34 class _RemovedConfig:\n35     old_path: Tuple[str, ...]\n36     warning: str\n37     new_path: Optional[Tuple[str, ...]] = None\n38     translation_func: Optional[Callable[[str], str]] = None\n39 \n40 \n41 REMOVED_CONFIGS = [\n42     _RemovedConfig(\n43         (\"rules\", \"L007\", \"operator_new_lines\"),\n44         (\n45             \"Use the line_position config in the appropriate \"\n46             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n47             \":binary_operator).\"\n48         ),\n49         (\"layout\", \"type\", \"binary_operator\", \"line_position\"),\n50         (lambda x: \"trailing\" if x == \"before\" else \"leading\"),\n51     ),\n52     _RemovedConfig(\n53         (\"rules\", \"comma_style\"),\n54         (\n55             \"Use the line_position config in the appropriate \"\n56             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n57             \":comma).\"\n58         ),\n59         (\"layout\", \"type\", \"comma\", \"line_position\"),\n60         (lambda x: x),\n61     ),\n62     # L019 used to have a more specific version of the same /config itself.\n63     _RemovedConfig(\n64         (\"rules\", \"L019\", \"comma_style\"),\n65         (\n66             \"Use the line_position config in the appropriate \"\n67             \"sqlfluff:layout section (e.g. sqlfluff:layout:type\"\n68             \":comma).\"\n69         ),\n70         (\"layout\", \"type\", \"comma\", \"line_position\"),\n71         (lambda x: x),\n72     ),\n73     _RemovedConfig(\n74         (\"rules\", \"L003\", \"lint_templated_tokens\"),\n75         \"No longer used.\",\n76     ),\n77 ]\n78 \n79 \n80 def coerce_value(val: str) -> Any:\n81     \"\"\"Try to coerce to a more specific type.\"\"\"\n82     # Try to coerce it to a more specific type,\n83     # otherwise just make it a string.\n84     try:\n85         v: Any = int(val)\n86     except ValueError:\n87         try:\n88             v = float(val)\n89         except ValueError:\n90             cleaned_val = val.strip().lower()\n91             if cleaned_val in [\"true\"]:\n92                 v = True\n93             elif cleaned_val in [\"false\"]:\n94                 v = False\n95             elif cleaned_val in [\"none\"]:\n96                 v = None\n97             else:\n98                 v = val\n99     return v\n100 \n101 \n102 def nested_combine(*dicts: dict) -> dict:\n103     \"\"\"Combine an iterable of dictionaries.\n104 \n105     Each dictionary is combined into a result dictionary. For\n106     each key in the first dictionary, it will be overwritten\n107     by any same-named key in any later dictionaries in the\n108     iterable. If the element at that key is a dictionary, rather\n109     than just overwriting we use the same function to combine\n110     those dictionaries.\n111 \n112     Args:\n113         *dicts: An iterable of dictionaries to be combined.\n114 \n115     Returns:\n116         `dict`: A combined dictionary from the input dictionaries.\n117 \n118     A simple example:\n119     >>> nested_combine({\"a\": {\"b\": \"c\"}}, {\"a\": {\"d\": \"e\"}})\n120     {'a': {'b': 'c', 'd': 'e'}}\n121 \n122     Keys overwrite left to right:\n123     >>> nested_combine({\"a\": {\"b\": \"c\"}}, {\"a\": {\"b\": \"e\"}})\n124     {'a': {'b': 'e'}}\n125     \"\"\"\n126     r: dict = {}\n127     for d in dicts:\n128         for k in d:\n129             if k in r and isinstance(r[k], dict):\n130                 if isinstance(d[k], dict):\n131                     r[k] = nested_combine(r[k], d[k])\n132                 else:  # pragma: no cover\n133                     raise ValueError(\n134                         \"Key {!r} is a dict in one config but not another! PANIC: \"\n135                         \"{!r}\".format(k, d[k])\n136                     )\n137             else:\n138                 r[k] = d[k]\n139     return r\n140 \n141 \n142 def dict_diff(left: dict, right: dict, ignore: Optional[List[str]] = None) -> dict:\n143     \"\"\"Work out the difference between to dictionaries.\n144 \n145     Returns a dictionary which represents elements in the `left`\n146     dictionary which aren't in the `right` or are different to\n147     those in the `right`. If the element is a dictionary, we\n148     recursively look for differences in those dictionaries,\n149     likewise only returning the differing elements.\n150 \n151     NOTE: If an element is in the `right` but not in the `left`\n152     at all (i.e. an element has been *removed*) then it will\n153     not show up in the comparison.\n154 \n155     Args:\n156         left (:obj:`dict`): The object containing the *new* elements\n157             which will be compared against the other.\n158         right (:obj:`dict`): The object to compare against.\n159         ignore (:obj:`list` of `str`, optional): Keys to ignore.\n160 \n161     Returns:\n162         `dict`: A dictionary representing the difference.\n163 \n164     Basic functionality shown, especially returning the left as:\n165     >>> dict_diff({\"a\": \"b\", \"c\": \"d\"}, {\"a\": \"b\", \"c\": \"e\"})\n166     {'c': 'd'}\n167 \n168     Ignoring works on a key basis:\n169     >>> dict_diff({\"a\": \"b\"}, {\"a\": \"c\"})\n170     {'a': 'b'}\n171     >>> dict_diff({\"a\": \"b\"}, {\"a\": \"c\"}, [\"a\"])\n172     {}\n173     \"\"\"\n174     buff: dict = {}\n175     for k in left:\n176         if ignore and k in ignore:\n177             continue\n178         # Is the key there at all?\n179         if k not in right:\n180             buff[k] = left[k]\n181         # Is the content the same?\n182         elif left[k] == right[k]:\n183             continue\n184         # If it's not the same but both are dicts, then compare\n185         elif isinstance(left[k], dict) and isinstance(right[k], dict):\n186             diff = dict_diff(left[k], right[k], ignore=ignore)\n187             # Only include the difference if non-null.\n188             if diff:\n189                 buff[k] = diff\n190         # It's just different\n191         else:\n192             buff[k] = left[k]\n193     return buff\n194 \n195 \n196 def _split_comma_separated_string(raw_str: str) -> List[str]:\n197     return [s.strip() for s in raw_str.split(\",\") if s.strip()]\n198 \n199 \n200 class ConfigLoader:\n201     \"\"\"The class for loading config files.\n202 \n203     Note:\n204         Unlike most cfg file readers, sqlfluff is case-sensitive in how\n205         it reads config files. This is to ensure we support the case\n206         sensitivity of jinja.\n207 \n208     \"\"\"\n209 \n210     def __init__(self) -> None:\n211         # TODO: check that this cache implementation is actually useful\n212         self._config_cache: dict = {}\n213 \n214     @classmethod\n215     def get_global(cls) -> \"ConfigLoader\":\n216         \"\"\"Get the singleton loader.\"\"\"\n217         global global_loader\n218         if not global_loader:\n219             global_loader = cls()\n220         return global_loader\n221 \n222     @classmethod\n223     def _walk_toml(cls, config: Dict[str, Any], base_key=()):\n224         \"\"\"Recursively walk the nested config inside a TOML file.\"\"\"\n225         buff: List[tuple] = []\n226         for k, v in config.items():\n227             key = base_key + (k,)\n228             if isinstance(v, dict):\n229                 buff.extend(cls._walk_toml(v, key))\n230             else:\n231                 buff.append((key, v))\n232 \n233         return buff\n234 \n235     @classmethod\n236     def _iter_config_elems_from_dict(cls, configs: dict) -> Iterator[ConfigElemType]:\n237         \"\"\"Walk a config dict and get config elements.\n238 \n239         >>> list(\n240         ...    ConfigLoader._iter_config_elems_from_dict(\n241         ...        {\"foo\":{\"bar\":{\"baz\": \"a\", \"biz\": \"b\"}}}\n242         ...    )\n243         ... )\n244         [(('foo', 'bar', 'baz'), 'a'), (('foo', 'bar', 'biz'), 'b')]\n245         \"\"\"\n246         for key, val in configs.items():\n247             if isinstance(val, dict):\n248                 for partial_key, sub_val in cls._iter_config_elems_from_dict(val):\n249                     yield (key,) + partial_key, sub_val\n250             else:\n251                 yield (key,), val\n252 \n253     @classmethod\n254     def _config_elems_to_dict(cls, configs: Iterable[ConfigElemType]) -> dict:\n255         \"\"\"Reconstruct config elements into a dict.\n256 \n257         >>> ConfigLoader._config_elems_to_dict(\n258         ...     [((\"foo\", \"bar\", \"baz\"), \"a\"), ((\"foo\", \"bar\", \"biz\"), \"b\")]\n259         ... )\n260         {'foo': {'bar': {'baz': 'a', 'biz': 'b'}}}\n261         \"\"\"\n262         result: Dict[str, Union[dict, str]] = {}\n263         for key, val in configs:\n264             ref = result\n265             for step in key[:-1]:\n266                 if step not in ref:\n267                     ref[step] = {}\n268                 ref = ref[step]  # type: ignore\n269             ref[key[-1]] = val\n270         return result\n271 \n272     @classmethod\n273     def _get_config_elems_from_toml(cls, fpath: str) -> List[ConfigElemType]:\n274         \"\"\"Load a config from a TOML file and return a list of tuples.\n275 \n276         The return value is a list of tuples, were each tuple has two elements,\n277         the first is a tuple of paths, the second is the value at that path.\n278         \"\"\"\n279         config = toml.load(fpath)\n280         tool = config.get(\"tool\", {}).get(\"sqlfluff\", {})\n281 \n282         return cls._walk_toml(tool)\n283 \n284     @classmethod\n285     def _get_config_elems_from_file(cls, fpath: str) -> List[ConfigElemType]:\n286         \"\"\"Load a config from a file and return a list of tuples.\n287 \n288         The return value is a list of tuples, were each tuple has two elements,\n289         the first is a tuple of paths, the second is the value at that path.\n290 \n291         Note:\n292             Unlike most cfg file readers, sqlfluff is case-sensitive in how\n293             it reads config files.\n294 \n295         Note:\n296             Any variable names ending with `_path` or `_dir`, will be attempted to be\n297             resolved as relative paths to this config file. If that fails the\n298             string value will remain.\n299 \n300         \"\"\"\n301         buff: List[Tuple[tuple, Any]] = []\n302         # Disable interpolation so we can load macros\n303         kw: Dict = {}\n304         kw[\"interpolation\"] = None\n305         config = configparser.ConfigParser(delimiters=\"=\", **kw)\n306         # NB: We want to be case sensitive in how we read from files,\n307         # because jinja is also case sensitive. To do this we override\n308         # the optionxform attribute.\n309         config.optionxform = lambda option: option  # type: ignore\n310         config.read(fpath)\n311         for k in config.sections():\n312             if k == \"sqlfluff\":\n313                 key: Tuple = (\"core\",)\n314             elif k.startswith(\"sqlfluff:\"):\n315                 # Return a tuple of nested values\n316                 key = tuple(k[len(\"sqlfluff:\") :].split(\":\"))\n317             else:  # pragma: no cover\n318                 # if it doesn't start with sqlfluff, then don't go\n319                 # further on this iteration\n320                 continue\n321 \n322             for name, val in config.items(section=k):\n323                 # Try to coerce it to a more specific type,\n324                 # otherwise just make it a string.\n325                 v = coerce_value(val)\n326 \n327                 # Attempt to resolve paths\n328                 if name.lower() == \"load_macros_from_path\":\n329                     # Comma-separated list of paths.\n330                     paths = _split_comma_separated_string(val)\n331                     v_temp = []\n332                     for path in paths:\n333                         v_temp.append(cls._resolve_path(fpath, path))\n334                     v = \",\".join(v_temp)\n335                 elif name.lower().endswith((\"_path\", \"_dir\")):\n336                     # One path\n337                     v = cls._resolve_path(fpath, val)\n338                 # Add the name to the end of the key\n339                 buff.append((key + (name,), v))\n340         return buff\n341 \n342     @classmethod\n343     def _resolve_path(cls, fpath, val):\n344         \"\"\"Try to resolve a path.\"\"\"\n345         # Make the referenced path.\n346         ref_path = os.path.join(os.path.dirname(fpath), val)\n347         # Check if it exists, and if it does, replace the value with the path.\n348         return ref_path if os.path.exists(ref_path) else val\n349 \n350     @staticmethod\n351     def _incorporate_vals(ctx: dict, vals: List[ConfigElemType]) -> dict:\n352         \"\"\"Take a list of tuples and incorporate it into a dictionary.\n353 \n354         >>> ConfigLoader._incorporate_vals({}, [((\"a\", \"b\"), \"c\")])\n355         {'a': {'b': 'c'}}\n356         >>> ConfigLoader._incorporate_vals({\"a\": {\"b\": \"c\"}}, [((\"a\", \"d\"), \"e\")])\n357         {'a': {'b': 'c', 'd': 'e'}}\n358         \"\"\"\n359         for k, v in vals:\n360             # Keep a ref we can use for recursion\n361             r = ctx\n362             # Get the name of the variable\n363             n = k[-1]\n364             # Get the path\n365             pth = k[:-1]\n366             for dp in pth:\n367                 # Does this path exist?\n368                 if dp in r:\n369                     if isinstance(r[dp], dict):\n370                         r = r[dp]\n371                     else:  # pragma: no cover\n372                         raise ValueError(f\"Overriding config value with section! [{k}]\")\n373                 else:\n374                     r[dp] = {}\n375                     r = r[dp]\n376             # Deal with the value itself\n377             r[n] = v\n378         return ctx\n379 \n380     @staticmethod\n381     def _validate_configs(\n382         configs: Iterable[ConfigElemType], file_path\n383     ) -> List[ConfigElemType]:\n384         \"\"\"Validate config elements against removed list.\"\"\"\n385         config_map = {cfg.old_path: cfg for cfg in REMOVED_CONFIGS}\n386         # Materialise the configs into a list to we can iterate twice.\n387         new_configs = list(configs)\n388         defined_keys = {k for k, _ in new_configs}\n389         validated_configs = []\n390         for k, v in new_configs:\n391             if k in config_map.keys():\n392                 formatted_key = \":\".join(k)\n393                 removed_option = config_map[k]\n394                 # Is there a mapping option?\n395                 if removed_option.translation_func and removed_option.new_path:\n396                     formatted_new_key = \":\".join(removed_option.new_path)\n397                     # Before mutating, check we haven't _also_ set the new value.\n398                     if removed_option.new_path in defined_keys:\n399                         # Raise an warning.\n400                         config_logger.warning(\n401                             f\"\\nWARNING: Config file {file_path} set a deprecated \"\n402                             f\"config value `{formatted_key}` (which can be migrated) \"\n403                             f\"but ALSO set the value it would be migrated to. The new \"\n404                             f\"value (`{removed_option.new_path}`) takes precedence. \"\n405                             \"Please update your configuration to remove this warning. \"\n406                             f\"\\n\\n{removed_option.warning}\\n\\n\"\n407                             \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n408                             \" for more details.\\n\"\n409                         )\n410                         # continue to NOT add this value in the set\n411                         continue\n412 \n413                     # Mutate and warn.\n414                     v = removed_option.translation_func(v)\n415                     k = removed_option.new_path\n416                     # NOTE: At the stage of emitting this warning, we may not yet\n417                     # have set up red logging because we haven't yet loaded the config\n418                     # file. For that reason, this error message has a bit more padding.\n419                     config_logger.warning(\n420                         f\"\\nWARNING: Config file {file_path} set a deprecated config \"\n421                         f\"value `{formatted_key}`. This will be removed in a later \"\n422                         \"release. This has been mapped to \"\n423                         f\"`{formatted_new_key}` set to a value of `{v}` for this run. \"\n424                         \"Please update your configuration to remove this warning. \"\n425                         f\"\\n\\n{removed_option.warning}\\n\\n\"\n426                         \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n427                         \" for more details.\\n\"\n428                     )\n429                 else:\n430                     # Raise an error.\n431                     raise SQLFluffUserError(\n432                         f\"Config file {file_path} set an outdated config \"\n433                         f\"value {formatted_key}.\\n\\n{removed_option.warning}\\n\\n\"\n434                         \"See https://docs.sqlfluff.com/en/stable/configuration.html\"\n435                         \" for more details.\"\n436                     )\n437 \n438             validated_configs.append((k, v))\n439         return validated_configs\n440 \n441     def load_config_file(\n442         self, file_dir: str, file_name: str, configs: Optional[dict] = None\n443     ) -> dict:\n444         \"\"\"Load the default config file.\"\"\"\n445         file_path = os.path.join(file_dir, file_name)\n446         if file_name == \"pyproject.toml\":\n447             elems = self._get_config_elems_from_toml(file_path)\n448         else:\n449             elems = self._get_config_elems_from_file(file_path)\n450         elems = self._validate_configs(elems, file_path)\n451         return self._incorporate_vals(configs or {}, elems)\n452 \n453     def load_config_at_path(self, path: str) -> dict:\n454         \"\"\"Load config from a given path.\"\"\"\n455         # First check the cache\n456         if str(path) in self._config_cache:\n457             return self._config_cache[str(path)]\n458 \n459         # The potential filenames we would look for at this path.\n460         # NB: later in this list overwrites earlier\n461         filename_options = [\n462             \"setup.cfg\",\n463             \"tox.ini\",\n464             \"pep8.ini\",\n465             \".sqlfluff\",\n466             \"pyproject.toml\",\n467         ]\n468 \n469         configs: dict = {}\n470 \n471         if os.path.isdir(path):\n472             p = path\n473         else:\n474             p = os.path.dirname(path)\n475 \n476         d = os.listdir(os.path.expanduser(p))\n477         # iterate this way round to make sure things overwrite is the right direction\n478         for fname in filename_options:\n479             if fname in d:\n480                 configs = self.load_config_file(p, fname, configs=configs)\n481 \n482         # Store in the cache\n483         self._config_cache[str(path)] = configs\n484         return configs\n485 \n486     def load_extra_config(self, extra_config_path: str) -> dict:\n487         \"\"\"Load specified extra config.\"\"\"\n488         if not os.path.exists(extra_config_path):\n489             raise SQLFluffUserError(\n490                 f\"Extra config '{extra_config_path}' does not exist.\"\n491             )\n492 \n493         # First check the cache\n494         if str(extra_config_path) in self._config_cache:\n495             return self._config_cache[str(extra_config_path)]\n496 \n497         configs: dict = {}\n498         if extra_config_path.endswith(\"pyproject.toml\"):\n499             elems = self._get_config_elems_from_toml(extra_config_path)\n500         else:\n501             elems = self._get_config_elems_from_file(extra_config_path)\n502         configs = self._incorporate_vals(configs, elems)\n503 \n504         # Store in the cache\n505         self._config_cache[str(extra_config_path)] = configs\n506         return configs\n507 \n508     @staticmethod\n509     def _get_user_config_dir_path() -> str:\n510         appname = \"sqlfluff\"\n511         appauthor = \"sqlfluff\"\n512 \n513         # On Mac OSX follow Linux XDG base dirs\n514         # https://github.com/sqlfluff/sqlfluff/issues/889\n515         user_config_dir_path = os.path.expanduser(\"~/.config/sqlfluff\")\n516         if appdirs.system == \"darwin\":\n517             appdirs.system = \"linux2\"\n518             user_config_dir_path = appdirs.user_config_dir(appname, appauthor)\n519             appdirs.system = \"darwin\"\n520 \n521         if not os.path.exists(user_config_dir_path):\n522             user_config_dir_path = appdirs.user_config_dir(appname, appauthor)\n523 \n524         return user_config_dir_path\n525 \n526     def load_user_appdir_config(self) -> dict:\n527         \"\"\"Load the config from the user's OS specific appdir config directory.\"\"\"\n528         user_config_dir_path = self._get_user_config_dir_path()\n529         if os.path.exists(user_config_dir_path):\n530             return self.load_config_at_path(user_config_dir_path)\n531         else:\n532             return {}\n533 \n534     def load_user_config(self) -> dict:\n535         \"\"\"Load the config from the user's home directory.\"\"\"\n536         user_home_path = os.path.expanduser(\"~\")\n537         return self.load_config_at_path(user_home_path)\n538 \n539     def load_config_up_to_path(\n540         self,\n541         path: str,\n542         extra_config_path: Optional[str] = None,\n543         ignore_local_config: bool = False,\n544     ) -> dict:\n545         \"\"\"Loads a selection of config files from both the path and its parent paths.\"\"\"\n546         user_appdir_config = (\n547             self.load_user_appdir_config() if not ignore_local_config else {}\n548         )\n549         user_config = self.load_user_config() if not ignore_local_config else {}\n550         config_paths = (\n551             self.iter_config_locations_up_to_path(path)\n552             if not ignore_local_config\n553             else {}\n554         )\n555         config_stack = (\n556             [self.load_config_at_path(p) for p in config_paths]\n557             if not ignore_local_config\n558             else []\n559         )\n560         extra_config = (\n561             self.load_extra_config(extra_config_path) if extra_config_path else {}\n562         )\n563         return nested_combine(\n564             user_appdir_config, user_config, *config_stack, extra_config\n565         )\n566 \n567     @classmethod\n568     def find_ignore_config_files(\n569         cls, path, working_path=Path.cwd(), ignore_file_name=\".sqlfluffignore\"\n570     ):\n571         \"\"\"Finds sqlfluff ignore files from both the path and its parent paths.\"\"\"\n572         return set(\n573             filter(\n574                 os.path.isfile,\n575                 map(\n576                     lambda x: os.path.join(x, ignore_file_name),\n577                     cls.iter_config_locations_up_to_path(\n578                         path=path, working_path=working_path\n579                     ),\n580                 ),\n581             )\n582         )\n583 \n584     @staticmethod\n585     def iter_config_locations_up_to_path(path, working_path=Path.cwd()):\n586         \"\"\"Finds config locations from both the path and its parent paths.\n587 \n588         The lowest priority is the user appdir, then home dir, then increasingly\n589         the configs closest to the file being directly linted.\n590         \"\"\"\n591         given_path = Path(path).absolute()\n592         working_path = Path(working_path).absolute()\n593 \n594         # If we've been passed a file and not a directory,\n595         # then go straight to the directory.\n596         if not given_path.is_dir():\n597             given_path = given_path.parent\n598 \n599         common_path = Path(os.path.commonpath([working_path, given_path]))\n600 \n601         # we have a sub path! We can load nested paths\n602         path_to_visit = common_path\n603         while path_to_visit != given_path:\n604             yield str(path_to_visit.resolve())\n605             next_path_to_visit = (\n606                 path_to_visit / given_path.relative_to(path_to_visit).parts[0]\n607             )\n608             if next_path_to_visit == path_to_visit:  # pragma: no cover\n609                 # we're not making progress...\n610                 # [prevent infinite loop]\n611                 break\n612             path_to_visit = next_path_to_visit\n613 \n614         yield str(given_path.resolve())\n615 \n616 \n617 class FluffConfig:\n618     \"\"\"The class that actually gets passed around as a config object.\"\"\"\n619 \n620     private_vals = \"rule_denylist\", \"rule_allowlist\", \"dialect_obj\", \"templater_obj\"\n621 \n622     def __init__(\n623         self,\n624         configs: Optional[dict] = None,\n625         extra_config_path: Optional[str] = None,\n626         ignore_local_config: bool = False,\n627         overrides: Optional[dict] = None,\n628         plugin_manager: Optional[pluggy.PluginManager] = None,\n629         # Ideally a dialect should be set when config is read but sometimes\n630         # it might only be set in nested .sqlfluff config files, so allow it\n631         # to be not required.\n632         require_dialect: bool = True,\n633     ):\n634         self._extra_config_path = (\n635             extra_config_path  # We only store this for child configs\n636         )\n637         self._ignore_local_config = (\n638             ignore_local_config  # We only store this for child configs\n639         )\n640         # If overrides are provided, validate them early.\n641         if overrides:\n642             overrides = ConfigLoader._config_elems_to_dict(\n643                 ConfigLoader._validate_configs(\n644                     [\n645                         ((\"core\",) + k, v)\n646                         for k, v in ConfigLoader._iter_config_elems_from_dict(overrides)\n647                     ],\n648                     \"<provided overrides>\",\n649                 )\n650             )[\"core\"]\n651         self._overrides = overrides  # We only store this for child configs\n652 \n653         # Fetch a fresh plugin manager if we weren't provided with one\n654         self._plugin_manager = plugin_manager or get_plugin_manager()\n655 \n656         defaults = nested_combine(*self._plugin_manager.hook.load_default_config())\n657         # If any existing configs are provided. Validate them:\n658         if configs:\n659             configs = ConfigLoader._config_elems_to_dict(\n660                 ConfigLoader._validate_configs(\n661                     ConfigLoader._iter_config_elems_from_dict(configs),\n662                     \"<provided configs>\",\n663                 )\n664             )\n665         self._configs = nested_combine(\n666             defaults, configs or {\"core\": {}}, {\"core\": overrides or {}}\n667         )\n668         # Some configs require special treatment\n669         self._configs[\"core\"][\"color\"] = (\n670             False if self._configs[\"core\"].get(\"nocolor\", False) else None\n671         )\n672         # Handle inputs which are potentially comma separated strings\n673         for in_key, out_key in [\n674             # Deal with potential ignore & warning parameters\n675             (\"ignore\", \"ignore\"),\n676             (\"warnings\", \"warnings\"),\n677             (\"rules\", \"rule_allowlist\"),\n678             # Allowlists and denylists\n679             (\"exclude_rules\", \"rule_denylist\"),\n680         ]:\n681             if self._configs[\"core\"].get(in_key, None):\n682                 self._configs[\"core\"][out_key] = _split_comma_separated_string(\n683                     self._configs[\"core\"][in_key]\n684                 )\n685             else:\n686                 self._configs[\"core\"][out_key] = []\n687         # Configure Recursion\n688         if self._configs[\"core\"].get(\"recurse\", 0) == 0:\n689             self._configs[\"core\"][\"recurse\"] = True\n690 \n691         # Dialect and Template selection.\n692         # NB: We import here to avoid a circular references.\n693         from sqlfluff.core.dialects import dialect_selector\n694 \n695         dialect: Optional[str] = self._configs[\"core\"][\"dialect\"]\n696         if dialect is not None:\n697             self._configs[\"core\"][\"dialect_obj\"] = dialect_selector(\n698                 self._configs[\"core\"][\"dialect\"]\n699             )\n700         elif require_dialect:\n701             self.verify_dialect_specified()\n702         self._configs[\"core\"][\"templater_obj\"] = self.get_templater(\n703             self._configs[\"core\"][\"templater\"]\n704         )\n705 \n706     def verify_dialect_specified(self) -> None:\n707         \"\"\"Check if the config specifies a dialect, raising an error if not.\"\"\"\n708         dialect: Optional[str] = self._configs[\"core\"][\"dialect\"]\n709         if dialect is None:\n710             # Get list of available dialects for the error message. We must\n711             # import here rather than at file scope in order to avoid a circular\n712             # import.\n713             from sqlfluff.core.dialects import dialect_readout\n714 \n715             raise SQLFluffUserError(\n716                 \"No dialect was specified. You must configure a dialect or \"\n717                 \"specify one on the command line using --dialect after the \"\n718                 \"command. Available dialects:\\n\"\n719                 f\"{', '.join([d.label for d in dialect_readout()])}\"\n720             )\n721 \n722     def __getstate__(self):\n723         # Copy the object's state from self.__dict__ which contains\n724         # all our instance attributes. Always use the dict.copy()\n725         # method to avoid modifying the original state.\n726         state = self.__dict__.copy()\n727         # Remove the unpicklable entries.\n728         del state[\"_plugin_manager\"]\n729         return state\n730 \n731     def __setstate__(self, state):  # pragma: no cover\n732         # Restore instance attributes\n733         self.__dict__.update(state)\n734         # NB: We don't reinstate the plugin manager, but this should only\n735         # be happening between processes where the plugin manager should\n736         # probably be fresh in any case.\n737         # NOTE: This means that registering user plugins directly will only\n738         # work if those plugins are used in the main process (i.e. templaters).\n739         # User registered linting rules either must be \"installed\" and therefore\n740         # available to all processes - or their use is limited to only single\n741         # process invocations of sqlfluff. In the event that user registered\n742         # rules are used in a multi-process invocation, they will not be applied\n743         # in the child processes.\n744 \n745     @classmethod\n746     def from_root(\n747         cls,\n748         extra_config_path: Optional[str] = None,\n749         ignore_local_config: bool = False,\n750         overrides: Optional[dict] = None,\n751         **kw,\n752     ) -> \"FluffConfig\":\n753         \"\"\"Loads a config object just based on the root directory.\"\"\"\n754         loader = ConfigLoader.get_global()\n755         c = loader.load_config_up_to_path(\n756             path=\".\",\n757             extra_config_path=extra_config_path,\n758             ignore_local_config=ignore_local_config,\n759         )\n760         return cls(\n761             configs=c,\n762             extra_config_path=extra_config_path,\n763             ignore_local_config=ignore_local_config,\n764             overrides=overrides,\n765             **kw,\n766         )\n767 \n768     @classmethod\n769     def from_path(\n770         cls,\n771         path: str,\n772         extra_config_path: Optional[str] = None,\n773         ignore_local_config: bool = False,\n774         overrides: Optional[dict] = None,\n775         plugin_manager: Optional[pluggy.PluginManager] = None,\n776     ) -> \"FluffConfig\":\n777         \"\"\"Loads a config object given a particular path.\"\"\"\n778         loader = ConfigLoader.get_global()\n779         c = loader.load_config_up_to_path(\n780             path=path,\n781             extra_config_path=extra_config_path,\n782             ignore_local_config=ignore_local_config,\n783         )\n784         return cls(\n785             configs=c,\n786             extra_config_path=extra_config_path,\n787             ignore_local_config=ignore_local_config,\n788             overrides=overrides,\n789             plugin_manager=plugin_manager,\n790         )\n791 \n792     @classmethod\n793     def from_kwargs(\n794         cls,\n795         config: Optional[\"FluffConfig\"] = None,\n796         dialect: Optional[str] = None,\n797         rules: Optional[List[str]] = None,\n798         exclude_rules: Optional[List[str]] = None,\n799         require_dialect: bool = True,\n800     ) -> \"FluffConfig\":\n801         \"\"\"Instantiate a config from either an existing config or kwargs.\n802 \n803         This is a convenience method for the ways that the public classes\n804         like Linter(), Parser() and Lexer() can be instantiated with a\n805         FluffConfig or with the convenience kwargs: dialect & rules.\n806         \"\"\"\n807         if (dialect or rules) and config:  # pragma: no cover\n808             raise ValueError(\n809                 \"Cannot specify `config` with `dialect` or `rules`. Any config object \"\n810                 \"specifies its own dialect and rules.\"\n811             )\n812         elif config:\n813             return config\n814 \n815         overrides = {}\n816         if dialect:\n817             overrides[\"dialect\"] = dialect\n818         if rules:\n819             # Make a comma separated string to pass in as override\n820             overrides[\"rules\"] = \",\".join(rules)\n821         if exclude_rules:\n822             # Make a comma separated string to pass in as override\n823             overrides[\"exclude_rules\"] = \",\".join(exclude_rules)\n824         return cls(overrides=overrides, require_dialect=require_dialect)\n825 \n826     def get_templater(self, templater_name=\"jinja\", **kwargs):\n827         \"\"\"Fetch a templater by name.\"\"\"\n828         templater_lookup = {\n829             templater.name: templater\n830             for templater in chain.from_iterable(\n831                 self._plugin_manager.hook.get_templaters()\n832             )\n833         }\n834         try:\n835             cls = templater_lookup[templater_name]\n836             # Instantiate here, optionally with kwargs\n837             return cls(**kwargs)\n838         except KeyError:\n839             if templater_name == \"dbt\":  # pragma: no cover\n840                 config_logger.warning(\n841                     \"Starting in sqlfluff version 0.7.0 the dbt templater is \"\n842                     \"distributed as a separate python package. Please pip install \"\n843                     \"sqlfluff-templater-dbt to use it.\"\n844                 )\n845             raise SQLFluffUserError(\n846                 \"Requested templater {!r} which is not currently available. Try one of \"\n847                 \"{}\".format(templater_name, \", \".join(templater_lookup.keys()))\n848             )\n849 \n850     def make_child_from_path(self, path: str) -> \"FluffConfig\":\n851         \"\"\"Make a child config at a path but pass on overrides and extra_config_path.\"\"\"\n852         return self.from_path(\n853             path,\n854             extra_config_path=self._extra_config_path,\n855             ignore_local_config=self._ignore_local_config,\n856             overrides=self._overrides,\n857             plugin_manager=self._plugin_manager,\n858         )\n859 \n860     def diff_to(self, other: \"FluffConfig\") -> dict:\n861         \"\"\"Compare this config to another.\n862 \n863         Args:\n864             other (:obj:`FluffConfig`): Another config object to compare\n865                 against. We will return keys from *this* object that are\n866                 not in `other` or are different to those in `other`.\n867 \n868         Returns:\n869             A filtered dict of items in this config that are not in the other\n870             or are different to the other.\n871 \n872         \"\"\"\n873         # We ignore some objects which are not meaningful in the comparison\n874         # e.g. dialect_obj, which is generated on the fly.\n875         return dict_diff(self._configs, other._configs, ignore=[\"dialect_obj\"])\n876 \n877     def get(\n878         self, val: str, section: Union[str, Iterable[str]] = \"core\", default: Any = None\n879     ):\n880         \"\"\"Get a particular value from the config.\"\"\"\n881         section_dict = self.get_section(section)\n882         if section_dict is None:\n883             return default\n884 \n885         return section_dict.get(val, default)\n886 \n887     def get_section(self, section: Union[str, Iterable[str]]) -> Any:\n888         \"\"\"Return a whole section of config as a dict.\n889 \n890         If the element found at the address is a value and not\n891         a section, it is still returned and so this can be used\n892         as a more advanced from of the basic `get` method.\n893 \n894         Args:\n895             section: An iterable or string. If it's a string\n896                 we load that root section. If it's an iterable\n897                 of strings, then we treat it as a path within\n898                 the dictionary structure.\n899 \n900         \"\"\"\n901         if isinstance(section, str):\n902             return self._configs.get(section, None)\n903         else:\n904             # Try iterating\n905             buff = self._configs\n906             for sec in section:\n907                 buff = buff.get(sec, None)\n908                 if buff is None:\n909                     return None\n910             return buff\n911 \n912     def set_value(self, config_path: Iterable[str], val: Any):\n913         \"\"\"Set a value at a given path.\"\"\"\n914         # Make the path a list so we can index on it\n915         config_path = list(config_path)\n916         # Coerce the value into something more useful.\n917         config_val = coerce_value(val)\n918         # Sort out core if not there\n919         if len(config_path) == 1:  # pragma: no cover TODO?\n920             config_path = [\"core\"] + config_path\n921         # Current section:\n922         dict_buff = [self._configs]\n923         for elem in config_path[:-1]:\n924             dict_buff.append(dict_buff[-1][elem])\n925         # Set the value\n926         dict_buff[-1][config_path[-1]] = config_val\n927         # Rebuild the config\n928         for elem in reversed(config_path[:-1]):\n929             dict_elem = dict_buff.pop()\n930             dict_buff[-1][elem] = dict_elem\n931         self._configs = dict_buff[0]\n932 \n933     def iter_vals(self, cfg: Optional[dict] = None) -> Iterable[tuple]:\n934         \"\"\"Return an iterable of tuples representing keys.\n935 \n936         We show values before dicts, the tuple contains an indent\n937         value to know what level of the dict we're in. Dict labels\n938         will be returned as a blank value before their content.\n939         \"\"\"\n940         cfg = cfg or self._configs\n941 \n942         # Get keys and sort\n943         keys = sorted(cfg.keys())\n944         # First iterate values (alphabetically):\n945         for k in keys:\n946             if (\n947                 not isinstance(cfg[k], dict)\n948                 and cfg[k] is not None\n949                 and k not in self.private_vals\n950             ):\n951                 yield (0, k, cfg[k])\n952 \n953         # Then iterate dicts (alphabetically (but `core` comes first if it exists))\n954         for k in keys:\n955             if isinstance(cfg[k], dict):\n956                 # First yield the dict label\n957                 yield (0, k, \"\")\n958                 # Then yield its content\n959                 for idnt, key, val in self.iter_vals(cfg=cfg[k]):\n960                     yield (idnt + 1, key, val)\n961 \n962     def process_inline_config(self, config_line: str):\n963         \"\"\"Process an inline config command and update self.\"\"\"\n964         # Strip preceding comment marks\n965         if config_line.startswith(\"--\"):\n966             config_line = config_line[2:].strip()\n967         # Strip preceding sqlfluff line.\n968         if not config_line.startswith(\"sqlfluff:\"):  # pragma: no cover\n969             config_logger.warning(\n970                 \"Unable to process inline config statement: %r\", config_line\n971             )\n972             return\n973         config_line = config_line[9:].strip()\n974         # Divide on colons\n975         config_path = [elem.strip() for elem in config_line.split(\":\")]\n976         # Set the value\n977         self.set_value(config_path[:-1], config_path[-1])\n978 \n979     def process_raw_file_for_config(self, raw_str: str):\n980         \"\"\"Process a full raw file for inline config and update self.\"\"\"\n981         # Scan the raw file for config commands.\n982         for raw_line in raw_str.splitlines():\n983             if raw_line.startswith(\"-- sqlfluff\"):\n984                 # Found a in-file config command\n985                 self.process_inline_config(raw_line)\n986 \n987 \n988 class ProgressBarConfiguration:\n989     \"\"\"Singleton-esque progress bar configuration.\n990 \n991     It's expected to be set during starting with parameters coming from commands\n992     parameters, then to be just utilized as just\n993     ```\n994     from sqlfluff.core.config import progress_bar_configuration\n995     is_progressbar_disabled = progress_bar_configuration.disable_progress_bar\n996     ```\n997     \"\"\"\n998 \n999     _disable_progress_bar: Optional[bool] = True\n1000 \n1001     @property\n1002     def disable_progress_bar(self) -> Optional[bool]:  # noqa: D102\n1003         return self._disable_progress_bar\n1004 \n1005     @disable_progress_bar.setter\n1006     def disable_progress_bar(self, value: Optional[bool]) -> None:\n1007         \"\"\"`disable_progress_bar` setter.\n1008 \n1009         `True` means that progress bar should be always hidden, `False` fallbacks\n1010         into `None` which is an automatic mode.\n1011         From tqdm documentation: 'If set to None, disable on non-TTY.'\n1012         \"\"\"\n1013         self._disable_progress_bar = value or None\n1014 \n1015 \n1016 progress_bar_configuration = ProgressBarConfiguration()\n1017 \n[end of src/sqlfluff/core/config.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "sqlfluff/sqlfluff", "base_commit": "dc59c2a5672aacedaf91f0e6129b467eefad331b", "problem_statement": "--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n--disable_progress_bar Flag Broken for Fix\n### Search before asking\n\n- [X] I searched the [issues](https://github.com/sqlfluff/sqlfluff/issues) and found no similar issues.\n\n\n### What Happened\n\nI ran `sqlfluff fix ${target} --dialect ansi --disable_progress_bar --force` on version 1.4.0 and got an error with exit code 2. Running with `--disable-progress-bar` appears to work fine, but it appears that compatibility with underscores was broken in version 1.4.0.\n\n### Expected Behaviour\n\nShould run as expected, with no error and no progress bar.\n\n### Observed Behaviour\n\nExit code 2 and stderr:\r\n```\r\nUsage: sqlfluff fix [OPTIONS] [PATHS]...\r\n        Try 'sqlfluff fix -h' for help.\r\n\r\n        Error: No such option: --disable_progress_bar (Possible options: --disable-noqa, --disable-progress-bar)\r\n```\n\n### How to reproduce\n\nSql file:\r\n```\r\nSELECT foo FROM bar;\r\n```\r\n\r\nCommand:\r\n```\r\nsqlfluff fix ${target} --dialect ansi --disable_progress_bar --force\r\n```\n\n### Dialect\n\nansi\n\n### Version\n\npython 3.10.3\r\nsqlfluff 1.4.0 and up appears to have this problem (tested through 1.4.2)\n\n### Configuration\n\nNo special configuration. Ran hermetically with `trunk`.\n\n### Are you willing to work on and submit a PR to address the issue?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/sqlfluff/sqlfluff/blob/main/CODE_OF_CONDUCT.md)\n\n", "hints_text": "Looks like #3904 made `lint` work with both but updated `fix` to only accept `--disable-progress-bar`. I assume that was by accident. Should be relatively straightforward to fix by updating to match `lint`. \nLooks like #3904 made `lint` work with both but updated `fix` to only accept `--disable-progress-bar`. I assume that was by accident. Should be relatively straightforward to fix by updating to match `lint`. ", "created_at": "2022-12-11T16:33:31Z", "patch": "<patch>\ndiff --git a/src/sqlfluff/cli/commands.py b/src/sqlfluff/cli/commands.py\n--- a/src/sqlfluff/cli/commands.py\n+++ b/src/sqlfluff/cli/commands.py\n@@ -680,7 +680,7 @@ def do_fixes(lnt, result, formatter=None, **kwargs):\n     return False  # pragma: no cover\n \n \n-@cli.command()\n+@cli.command(cls=DeprecatedOptionsCommand)\n @common_options\n @core_options\n @click.option(\n@@ -710,9 +710,12 @@ def do_fixes(lnt, result, formatter=None, **kwargs):\n     ),\n )\n @click.option(\n+    \"--disable_progress_bar\",\n     \"--disable-progress-bar\",\n     is_flag=True,\n     help=\"Disables progress bars.\",\n+    cls=DeprecatedOption,\n+    deprecated=[\"--disable_progress_bar\"],\n )\n @click.option(\n     \"--FIX-EVEN-UNPARSABLE\",\n\n</patch>", "test_patch": "diff --git a/test/cli/commands_test.py b/test/cli/commands_test.py\n--- a/test/cli/commands_test.py\n+++ b/test/cli/commands_test.py\n@@ -1775,6 +1775,46 @@ def test_cli_lint_enabled_progress_bar_multiple_files(\n         assert r\"\\rrule L001:\" in raw_output\n         assert r\"\\rrule L049:\" in raw_output\n \n+    def test_cli_fix_disabled_progress_bar(\n+        self, mock_disable_progress_bar: MagicMock\n+    ) -> None:\n+        \"\"\"When progress bar is disabled, nothing should be printed into output.\"\"\"\n+        result = invoke_assert_code(\n+            args=[\n+                fix,\n+                [\n+                    \"--disable-progress-bar\",\n+                    \"test/fixtures/linter/passing.sql\",\n+                ],\n+            ],\n+        )\n+        raw_output = repr(result.output)\n+\n+        assert (\n+            \"DeprecationWarning: The option '--disable_progress_bar' is deprecated, \"\n+            \"use '--disable-progress-bar'\"\n+        ) not in raw_output\n+\n+    def test_cli_fix_disabled_progress_bar_deprecated_option(\n+        self, mock_disable_progress_bar: MagicMock\n+    ) -> None:\n+        \"\"\"Same as above but checks additionally if deprecation warning is printed.\"\"\"\n+        result = invoke_assert_code(\n+            args=[\n+                fix,\n+                [\n+                    \"--disable_progress_bar\",\n+                    \"test/fixtures/linter/passing.sql\",\n+                ],\n+            ],\n+        )\n+        raw_output = repr(result.output)\n+\n+        assert (\n+            \"DeprecationWarning: The option '--disable_progress_bar' is deprecated, \"\n+            \"use '--disable-progress-bar'\"\n+        ) in raw_output\n+\n \n multiple_expected_output = \"\"\"==== finding fixable violations ====\n == [test/fixtures/linter/multiple_sql_errors.sql] FAIL\n", "version": "1.3", "FAIL_TO_PASS": "[\"test/cli/commands_test.py::TestProgressBars::test_cli_fix_disabled_progress_bar_deprecated_option\"]", "PASS_TO_PASS": "[\"test/cli/commands_test.py::test__cli__command_directed\", \"test/cli/commands_test.py::test__cli__command_dialect\", \"test/cli/commands_test.py::test__cli__command_no_dialect\", \"test/cli/commands_test.py::test__cli__command_parse_error_dialect_explicit_warning\", \"test/cli/commands_test.py::test__cli__command_parse_error_dialect_implicit_warning\", \"test/cli/commands_test.py::test__cli__command_dialect_legacy\", \"test/cli/commands_test.py::test__cli__command_extra_config_fail\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_stdin[command3]\", \"test/cli/commands_test.py::test__cli__command_render_stdin\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command0]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command2]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command3]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command4]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command5]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command6]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command7]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command8]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command9]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command10]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command11]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command12]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command13]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command14]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command15]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command16]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command17]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command18]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command19]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command20]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command21]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command22]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command23]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command24]\", \"test/cli/commands_test.py::test__cli__command_lint_parse[command25]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command0-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command1-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command2-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command3-1]\", \"test/cli/commands_test.py::test__cli__command_lint_parse_with_retcode[command4-1]\", \"test/cli/commands_test.py::test__cli__command_lint_warning_explicit_file_ignored\", \"test/cli/commands_test.py::test__cli__command_lint_skip_ignore_files\", \"test/cli/commands_test.py::test__cli__command_lint_ignore_local_config\", \"test/cli/commands_test.py::test__cli__command_lint_warning\", \"test/cli/commands_test.py::test__cli__command_versioning\", \"test/cli/commands_test.py::test__cli__command_version\", \"test/cli/commands_test.py::test__cli__command_rules\", \"test/cli/commands_test.py::test__cli__command_dialects\", \"test/cli/commands_test.py::test__cli__command__fix[L001-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/whitespace_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L008-test/fixtures/linter/indentation_errors.sql]\", \"test/cli/commands_test.py::test__cli__command__fix[L003-test/fixtures/linter/indentation_error_hard.sql]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_templating_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_suppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[0_lint_errors_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[0_lint_errors_1_suppressed_parse_error]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[1_lint_error_1_unsuppressed_parse_error_FIX_EVEN_UNPARSABLE]\", \"test/cli/commands_test.py::test__cli__fix_error_handling_behavior[2_files_with_lint_errors_1_unsuppressed_parse_error]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[command-line-False]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[command-line-True]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[config-file-False]\", \"test/cli/commands_test.py::test_cli_fix_even_unparsable[config-file-True]\", \"test/cli/commands_test.py::test__cli__fix_loop_limit_behavior[--\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[select\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[\", \"test/cli/commands_test.py::test__cli__command_fix_stdin[SELECT\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_logging_to_stderr\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_safety\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[create\", \"test/cli/commands_test.py::test__cli__command_fix_stdin_error_exit_code[select\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-y-0-0]\", \"test/cli/commands_test.py::test__cli__command__fix_no_force[L001-test/fixtures/linter/indentation_errors.sql-n-1-1]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[None-yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[None-json]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[outfile-yaml]\", \"test/cli/commands_test.py::test__cli__command_parse_serialize_from_stdin[outfile-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[select\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_from_stdin[SElect\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command0]\", \"test/cli/commands_test.py::test__cli__command_fail_nice_not_found[command1]\", \"test/cli/commands_test.py::test__cli__command_lint_nocolor\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-human]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[None-github-annotation-native]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-human]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-yaml]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-json]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_multiple_files[outfile-github-annotation-native]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_github_annotation_native\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_annotation_level_error_failure_equivalent[github-annotation]\", \"test/cli/commands_test.py::test__cli__command_lint_serialize_annotation_level_error_failure_equivalent[github-annotation-native]\", \"test/cli/commands_test.py::test___main___help\", \"test/cli/commands_test.py::test_encoding[utf-8-ascii]\", \"test/cli/commands_test.py::test_encoding[utf-8-sig-UTF-8-SIG]\", \"test/cli/commands_test.py::test_encoding[utf-32-UTF-32]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-command-line-False]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-SIG-command-line-True]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-config-file-False]\", \"test/cli/commands_test.py::test_cli_encoding[utf-8-SIG-config-file-True]\", \"test/cli/commands_test.py::test_cli_no_disable_noqa_flag\", \"test/cli/commands_test.py::test_cli_disable_noqa_flag\", \"test/cli/commands_test.py::test_cli_get_default_config\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_disabled_progress_bar\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_disabled_progress_bar_deprecated_option\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar_multiple_paths\", \"test/cli/commands_test.py::TestProgressBars::test_cli_lint_enabled_progress_bar_multiple_files\", \"test/cli/commands_test.py::TestProgressBars::test_cli_fix_disabled_progress_bar\", \"test/cli/commands_test.py::test__cli__fix_multiple_errors_no_show_errors\", \"test/cli/commands_test.py::test__cli__fix_multiple_errors_show_errors\", \"test/cli/commands_test.py::test__cli__multiple_files__fix_multiple_errors_show_errors\", \"test/cli/commands_test.py::test__cli__render_fail\", \"test/cli/commands_test.py::test__cli__render_pass\"]", "environment_setup_commit": "dc59c2a5672aacedaf91f0e6129b467eefad331b"}
{"instance_id": "pvlib__pvlib-python-1026_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nmake read_crn accomodate bad files\nA couple of issues with our `read_crn` function. \r\n\r\nFirst, the character sequence '\\x00\\x00\\x00\\x00\\x00\\x00' occasionally shows up and trips up pandas. This can be fixed by adding `na_values=['\\x00\\x00\\x00\\x00\\x00\\x00']` to the reader.\r\n\r\nSecond, we try to set the `CRX_VN` column to dtype int, but it occasionally has floats that cannot be coerced. The [documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/subhourly01/README.txt) says it should be treated like a string.\r\n\r\nExample below shows both issues in `'CRNS0101-05-2020-FL_Titusville_7_E.txt'`\r\n\r\n```\r\n92821 20200706 1145 20200706 0645      3  -80.69   28.62    24.5     0.0    151 0    24.7 C 0    94 0 -99.000 -9999.0   990 0   1.23 0\r\n92821 20200706 1150 20200706 0650      3  -80.69   28.62    24.7     0.0    168 0    25.0 C 0    94 0 -99.000 -9999.0   990 0   1.28 0\r\n92821 20200706 1155 20200706 0655      3  -80.69   28.62    24.9     0.0    173 0    25.3 C 0    93 0 -99.000 -9999.0   990 0   1.48 0\r\n92821 20200706 1200 20200706 0700      3  -80.69   28.62    24.9     0.0    190 0    25.5 C 0    93 0 -99.000 -9999.0   990 0   1.57 0\r\n\\x00\\x00\\x00\\x00\\x00\\x00 repeated\r\n92821 20200706 1305 20200706 0805  2.623  -80.69   28.62    26.8     0.0    409 0    30.0 C 0    87 0 -99.000 -9999.0   988 0   1.44 0\r\n92821 20200706 1310 20200706 0810  2.623  -80.69   28.62    26.9     0.0    430 0    30.2 C 0    87 0 -99.000 -9999.0   989 0   1.64 0\r\n92821 20200706 1315 20200706 0815  2.623  -80.69   28.62    27.0     0.0    445 0    30.4 C 0    86 0 -99.000 -9999.0   989 0   1.94 0\r\n92821 20200706 1320 20200706 0820  2.623  -80.69   28.62    27.3     0.0    463 0    30.8 C 0    86 0 -99.000 -9999.0   988 0   1.50 0\r\n92821 20200706 1325 20200706 0825  2.623  -80.69   28.62    27.6     0.0    478 0    31.1 C 0    85 0 -99.000 -9999.0   988 0   1.54 0\r\n92821 20200706 1330 20200706 0830  2.623  -80.69   28.62    27.6     0.0    496 0    31.5 C 0    84 0 -99.000 -9999.0   988 0   1.48 0\r\n```\r\n\r\nfyi @lboeman \n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of docs/examples/plot_partial_module_shading_simple.py]\n1 \"\"\"\n2 Calculating power loss from partial module shading\n3 ==================================================\n4 \n5 Example of modeling cell-to-cell mismatch loss from partial module shading.\n6 \"\"\"\n7 \n8 # %%\n9 # Even though the PV cell is the primary power generation unit, PV modeling is\n10 # often done at the module level for simplicity because module-level parameters\n11 # are much more available and it significantly reduces the computational scope\n12 # of the simulation.  However, module-level simulations are too coarse to be\n13 # able to model effects like cell to cell mismatch or partial shading.  This\n14 # example calculates cell-level IV curves and combines them to reconstruct\n15 # the module-level IV curve.  It uses this approach to find the maximum power\n16 # under various shading and irradiance conditions.\n17 #\n18 # The primary functions used here are:\n19 #\n20 # - :py:meth:`pvlib.pvsystem.calcparams_desoto` to estimate the single\n21 #   diode equation parameters at some specified operating conditions.\n22 # - :py:meth:`pvlib.singlediode.bishop88` to calculate the full cell IV curve,\n23 #   including the reverse bias region.\n24 #\n25 # .. note::\n26 #\n27 #     This example requires the reverse bias functionality added in pvlib 0.7.2\n28 #\n29 # .. warning::\n30 #\n31 #     Modeling partial module shading is complicated and depends significantly\n32 #     on the module's electrical topology.  This example makes some simplifying\n33 #     assumptions that are not generally applicable.  For instance, it assumes\n34 #     that shading only applies to beam irradiance (*i.e.* all cells receive\n35 #     the same amount of diffuse irradiance) and cell temperature is uniform\n36 #     and not affected by cell-level irradiance variation.\n37 \n38 from pvlib import pvsystem, singlediode\n39 import pandas as pd\n40 import numpy as np\n41 from scipy.interpolate import interp1d\n42 import matplotlib.pyplot as plt\n43 \n44 from scipy.constants import e as qe, k as kB\n45 \n46 # For simplicity, use cell temperature of 25C for all calculations.\n47 # kB is J/K, qe is C=J/V\n48 # kB * T / qe -> V\n49 Vth = kB * (273.15+25) / qe\n50 \n51 cell_parameters = {\n52     'I_L_ref': 8.24,\n53     'I_o_ref': 2.36e-9,\n54     'a_ref': 1.3*Vth,\n55     'R_sh_ref': 1000,\n56     'R_s': 0.00181,\n57     'alpha_sc': 0.0042,\n58     'breakdown_factor': 2e-3,\n59     'breakdown_exp': 3,\n60     'breakdown_voltage': -15,\n61 }\n62 \n63 # %%\n64 # Simulating a cell IV curve\n65 # --------------------------\n66 #\n67 # First, calculate IV curves for individual cells.  The process is as follows:\n68 #\n69 # 1) Given a set of cell parameters at reference conditions and the operating\n70 #    conditions of interest (irradiance and temperature), use a single-diode\n71 #    model to calculate the single diode equation parameters for the cell at\n72 #    the operating conditions.  Here we use the De Soto model via\n73 #    :py:func:`pvlib.pvsystem.calcparams_desoto`.\n74 # 2) The single diode equation cannot be solved analytically, so pvlib has\n75 #    implemented a couple methods of solving it for us.  However, currently\n76 #    only the Bishop '88 method (:py:func:`pvlib.singlediode.bishop88`) has\n77 #    the ability to model the reverse bias characteristic in addition to the\n78 #    forward characteristic.  Depending on the nature of the shadow, it is\n79 #    sometimes necessary to model the reverse bias portion of the IV curve,\n80 #    so we use the Bishop '88 method here.  This gives us a set of (V, I)\n81 #    points on the cell's IV curve.\n82 \n83 \n84 def simulate_full_curve(parameters, Geff, Tcell, ivcurve_pnts=1000):\n85     \"\"\"\n86     Use De Soto and Bishop to simulate a full IV curve with both\n87     forward and reverse bias regions.\n88     \"\"\"\n89     # adjust the reference parameters according to the operating\n90     # conditions using the De Soto model:\n91     sde_args = pvsystem.calcparams_desoto(\n92         Geff,\n93         Tcell,\n94         alpha_sc=parameters['alpha_sc'],\n95         a_ref=parameters['a_ref'],\n96         I_L_ref=parameters['I_L_ref'],\n97         I_o_ref=parameters['I_o_ref'],\n98         R_sh_ref=parameters['R_sh_ref'],\n99         R_s=parameters['R_s'],\n100     )\n101     # sde_args has values:\n102     # (photocurrent, saturation_current, resistance_series,\n103     # resistance_shunt, nNsVth)\n104 \n105     # Use Bishop's method to calculate points on the IV curve with V ranging\n106     # from the reverse breakdown voltage to open circuit\n107     kwargs = {\n108         'breakdown_factor': parameters['breakdown_factor'],\n109         'breakdown_exp': parameters['breakdown_exp'],\n110         'breakdown_voltage': parameters['breakdown_voltage'],\n111     }\n112     v_oc = singlediode.bishop88_v_from_i(\n113         0.0, *sde_args, **kwargs\n114     )\n115     # ideally would use some intelligent log-spacing to concentrate points\n116     # around the forward- and reverse-bias knees, but this is good enough:\n117     vd = np.linspace(0.99*kwargs['breakdown_voltage'], v_oc, ivcurve_pnts)\n118 \n119     ivcurve_i, ivcurve_v, _ = singlediode.bishop88(vd, *sde_args, **kwargs)\n120     return pd.DataFrame({\n121         'i': ivcurve_i,\n122         'v': ivcurve_v,\n123     })\n124 \n125 \n126 # %%\n127 # Now that we can calculate cell-level IV curves, let's compare a\n128 # fully-illuminated cell's curve to a shaded cell's curve.  Note that shading\n129 # typically does not reduce a cell's illumination to zero -- tree shading and\n130 # row-to-row shading block the beam portion of irradiance but leave the diffuse\n131 # portion largely intact.  In this example plot, we choose :math:`200 W/m^2`\n132 # as the amount of irradiance received by a shaded cell.\n133 \n134 def plot_curves(dfs, labels, title):\n135     \"\"\"plot the forward- and reverse-bias portions of an IV curve\"\"\"\n136     fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5, 3))\n137     for df, label in zip(dfs, labels):\n138         df.plot('v', 'i', label=label, ax=axes[0])\n139         df.plot('v', 'i', label=label, ax=axes[1])\n140         axes[0].set_xlim(right=0)\n141         axes[0].set_ylim([0, 25])\n142         axes[1].set_xlim([0, df['v'].max()*1.5])\n143     axes[0].set_ylabel('current [A]')\n144     axes[0].set_xlabel('voltage [V]')\n145     axes[1].set_xlabel('voltage [V]')\n146     fig.suptitle(title)\n147     fig.tight_layout()\n148     return axes\n149 \n150 \n151 cell_curve_full_sun = simulate_full_curve(cell_parameters, Geff=1000, Tcell=25)\n152 cell_curve_shaded = simulate_full_curve(cell_parameters, Geff=200, Tcell=25)\n153 ax = plot_curves([cell_curve_full_sun, cell_curve_shaded],\n154                  labels=['Full Sun', 'Shaded'],\n155                  title='Cell-level reverse- and forward-biased IV curves')\n156 \n157 # %%\n158 # This figure shows how a cell's current decreases roughly in proportion to\n159 # the irradiance reduction from shading, but voltage changes much less.\n160 # At the cell level, the effect of shading is essentially to shift the I-V\n161 # curve down to lower currents rather than change the curve's shape.\n162 #\n163 # Note that the forward and reverse curves are plotted separately to\n164 # accommodate the different voltage scales involved -- a normal crystalline\n165 # silicon cell reaches only ~0.6V in forward bias, but can get to -10 to -20V\n166 # in reverse bias.\n167 #\n168 # Combining cell IV curves to create a module IV curve\n169 # ----------------------------------------------------\n170 #\n171 # To combine the individual cell IV curves and form a module's IV curve,\n172 # the cells in each substring must be added in series.  The substrings are\n173 # in series as well, but with parallel bypass diodes to protect from reverse\n174 # bias voltages.  To add in series, the voltages for a given current are\n175 # added.  However, because each cell's curve is discretized and the currents\n176 # might not line up, we align each curve to a common set of current values\n177 # with interpolation.\n178 \n179 \n180 def interpolate(df, i):\n181     \"\"\"convenience wrapper around scipy.interpolate.interp1d\"\"\"\n182     f_interp = interp1d(np.flipud(df['i']), np.flipud(df['v']), kind='linear',\n183                         fill_value='extrapolate')\n184     return f_interp(i)\n185 \n186 \n187 def combine_series(dfs):\n188     \"\"\"\n189     Combine IV curves in series by aligning currents and summing voltages.\n190     The current range is based on the first curve's current range.\n191     \"\"\"\n192     df1 = dfs[0]\n193     imin = df1['i'].min()\n194     imax = df1['i'].max()\n195     i = np.linspace(imin, imax, 1000)\n196     v = 0\n197     for df2 in dfs:\n198         v_cell = interpolate(df2, i)\n199         v += v_cell\n200     return pd.DataFrame({'i': i, 'v': v})\n201 \n202 \n203 # %%\n204 # Rather than simulate all 72 cells in the module, we'll assume that there\n205 # are only three types of cells (fully illuminated, fully shaded, and\n206 # partially shaded), and within each type all cells behave identically.  This\n207 # means that simulating one cell from each type (for three cell simulations\n208 # total) is sufficient to model the module as a whole.\n209 #\n210 # This function also models the effect of bypass diodes in parallel with each\n211 # substring.  Bypass diodes are normally inactive but conduct when substring\n212 # voltage becomes sufficiently negative, presumably due to the substring\n213 # entering reverse bias from mismatch between substrings.  In that case the\n214 # substring's voltage is clamped to the diode's trigger voltage (assumed to\n215 # be 0.5V here).\n216 \n217 def simulate_module(cell_parameters, poa_direct, poa_diffuse, Tcell,\n218                     shaded_fraction, cells_per_string=24, strings=3):\n219     \"\"\"\n220     Simulate the IV curve for a partially shaded module.\n221     The shade is assumed to be coming up from the bottom of the module when in\n222     portrait orientation, so it affects all substrings equally.\n223     For simplicity, cell temperature is assumed to be uniform across the\n224     module, regardless of variation in cell-level illumination.\n225     Substrings are assumed to be \"down and back\", so the number of cells per\n226     string is divided between two columns of cells.\n227     \"\"\"\n228     # find the number of cells per column that are in full shadow\n229     nrow = cells_per_string // 2\n230     nrow_full_shade = int(shaded_fraction * nrow)\n231     # find the fraction of shade in the border row\n232     partial_shade_fraction = 1 - (shaded_fraction * nrow - nrow_full_shade)\n233 \n234     df_lit = simulate_full_curve(\n235         cell_parameters,\n236         poa_diffuse + poa_direct,\n237         Tcell)\n238     df_partial = simulate_full_curve(\n239         cell_parameters,\n240         poa_diffuse + partial_shade_fraction * poa_direct,\n241         Tcell)\n242     df_shaded = simulate_full_curve(\n243         cell_parameters,\n244         poa_diffuse,\n245         Tcell)\n246     # build a list of IV curves for a single column of cells (half a substring)\n247     include_partial_cell = (shaded_fraction < 1)\n248     half_substring_curves = (\n249         [df_lit] * (nrow - nrow_full_shade - 1)\n250         + ([df_partial] if include_partial_cell else [])  # noqa: W503\n251         + [df_shaded] * nrow_full_shade  # noqa: W503\n252     )\n253     substring_curve = combine_series(half_substring_curves)\n254     substring_curve['v'] *= 2  # turn half strings into whole strings\n255     # bypass diode:\n256     substring_curve['v'] = substring_curve['v'].clip(lower=-0.5)\n257     # no need to interpolate since we're just scaling voltage directly:\n258     substring_curve['v'] *= strings\n259     return substring_curve\n260 \n261 # %%\n262 # Now let's see how shade affects the IV curves at the module level.  For this\n263 # example, the bottom 10% of the module is shaded.  Assuming 12 cells per\n264 # column, that means one row of cells is fully shaded and another row is\n265 # partially shaded.  Even though only 10% of the module is shaded, the\n266 # maximum power is decreased by roughly 80%!\n267 #\n268 # Note the effect of the bypass diodes.  Without bypass diodes, operating the\n269 # shaded module at the same current as the fully illuminated module would\n270 # create a reverse-bias voltage of several hundred volts!  However, the diodes\n271 # prevent the reverse voltage from exceeding 1.5V (three diodes at 0.5V each).\n272 \n273 \n274 kwargs = {\n275     'cell_parameters': cell_parameters,\n276     'poa_direct': 800,\n277     'poa_diffuse': 200,\n278     'Tcell': 25\n279 }\n280 module_curve_full_sun = simulate_module(shaded_fraction=0, **kwargs)\n281 module_curve_shaded = simulate_module(shaded_fraction=0.1, **kwargs)\n282 ax = plot_curves([module_curve_full_sun, module_curve_shaded],\n283                  labels=['Full Sun', 'Shaded'],\n284                  title='Module-level reverse- and forward-biased IV curves')\n285 \n286 # %%\n287 # Calculating shading loss across shading scenarios\n288 # -------------------------------------------------\n289 #\n290 # Clearly the module-level IV-curve is strongly affected by partial shading.\n291 # This heatmap shows the module maximum power under a range of partial shade\n292 # conditions, where \"diffuse fraction\" refers to the ratio\n293 # :math:`poa_{diffuse} / poa_{global}` and \"shaded fraction\" refers to the\n294 # fraction of the module that receives only diffuse irradiance.\n295 \n296 \n297 def find_pmp(df):\n298     \"\"\"simple function to find Pmp on an IV curve\"\"\"\n299     return df.product(axis=1).max()\n300 \n301 \n302 # find Pmp under different shading conditions\n303 data = []\n304 for diffuse_fraction in np.linspace(0, 1, 11):\n305     for shaded_fraction in np.linspace(0, 1, 51):\n306 \n307         df = simulate_module(cell_parameters,\n308                              poa_direct=(1-diffuse_fraction)*1000,\n309                              poa_diffuse=diffuse_fraction*1000,\n310                              Tcell=25,\n311                              shaded_fraction=shaded_fraction)\n312         data.append({\n313             'fd': diffuse_fraction,\n314             'fs': shaded_fraction,\n315             'pmp': find_pmp(df)\n316         })\n317 \n318 results = pd.DataFrame(data)\n319 results['pmp'] /= results['pmp'].max()  # normalize power to 0-1\n320 results_pivot = results.pivot('fd', 'fs', 'pmp')\n321 plt.figure()\n322 plt.imshow(results_pivot, origin='lower', aspect='auto')\n323 plt.xlabel('shaded fraction')\n324 plt.ylabel('diffuse fraction')\n325 xlabels = [\"{:0.02f}\".format(fs) for fs in results_pivot.columns[::5]]\n326 ylabels = [\"{:0.02f}\".format(fd) for fd in results_pivot.index]\n327 plt.xticks(range(0, 5*len(xlabels), 5), xlabels)\n328 plt.yticks(range(0, len(ylabels)), ylabels)\n329 plt.title('Module P_mp across shading conditions')\n330 plt.colorbar()\n331 plt.show()\n332 # use this figure as the thumbnail:\n333 # sphinx_gallery_thumbnail_number = 3\n334 \n335 # %%\n336 # The heatmap makes a few things evident:\n337 #\n338 # - When diffuse fraction is equal to 1, there is no beam irradiance to lose,\n339 #   so shading has no effect on production.\n340 # - When shaded fraction is equal to 0, no irradiance is blocked, so module\n341 #   output does not change with the diffuse fraction.\n342 # - Under sunny conditions (diffuse fraction < 0.5), module output is\n343 #   significantly reduced after just the first cell is shaded\n344 #   (1/12 = ~8% shaded fraction).\n345 \n[end of docs/examples/plot_partial_module_shading_simple.py]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 \n8 \n9 TEMPERATURE_MODEL_PARAMETERS = {\n10     'sapm': {\n11         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n12         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n13         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n14         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n15     },\n16     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n17                'insulated': {'u_c': 15.0, 'u_v': 0}}\n18 }\n19 \n20 \n21 def _temperature_model_params(model, parameter_set):\n22     try:\n23         params = TEMPERATURE_MODEL_PARAMETERS[model]\n24         return params[parameter_set]\n25     except KeyError:\n26         msg = ('{} is not a named set of parameters for the {} cell'\n27                ' temperature model.'\n28                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n29                ' for names'.format(parameter_set, model))\n30         raise KeyError(msg)\n31 \n32 \n33 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n34               irrad_ref=1000):\n35     r'''\n36     Calculate cell temperature per the Sandia Array Performance Model.\n37 \n38     See [1]_ for details on the Sandia Array Performance Model.\n39 \n40     Parameters\n41     ----------\n42     poa_global : numeric\n43         Total incident irradiance [W/m^2].\n44 \n45     temp_air : numeric\n46         Ambient dry bulb temperature [C].\n47 \n48     wind_speed : numeric\n49         Wind speed at a height of 10 meters [m/s].\n50 \n51     a : float\n52         Parameter :math:`a` in :eq:`sapm1`.\n53 \n54     b : float\n55         Parameter :math:`b` in :eq:`sapm1`.\n56 \n57     deltaT : float\n58         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n59 \n60     irrad_ref : float, default 1000\n61         Reference irradiance, parameter :math:`E_{0}` in\n62         :eq:`sapm2` [W/m^2].\n63 \n64     Returns\n65     -------\n66     numeric, values in degrees C.\n67 \n68     Notes\n69     -----\n70     The model for cell temperature :math:`T_{C}` is given by a pair of\n71     equations (Eq. 11 and 12 in [1]_).\n72 \n73     .. math::\n74        :label: sapm1\n75 \n76        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n77 \n78     .. math::\n79        :label: sapm2\n80 \n81        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n82 \n83     The module back surface temperature :math:`T_{m}` is implemented in\n84     :py:func:`~pvlib.temperature.sapm_module`.\n85 \n86     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n87     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n88     the module construction and its mounting. Parameter sets are provided in\n89     [1]_ for representative modules and mounting, and are coded for convenience\n90     in ``pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS``.\n91 \n92     +---------------+----------------+-------+---------+---------------------+\n93     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n94     +===============+================+=======+=========+=====================+\n95     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n96     +---------------+----------------+-------+---------+---------------------+\n97     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n98     +---------------+----------------+-------+---------+---------------------+\n99     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n100     +---------------+----------------+-------+---------+---------------------+\n101     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n102     +---------------+----------------+-------+---------+---------------------+\n103 \n104     References\n105     ----------\n106     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n107        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n108        NM.\n109 \n110     See also\n111     --------\n112     sapm_cell_from_module\n113     sapm_module\n114 \n115     Examples\n116     --------\n117     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n118     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n119     >>> sapm_cell(1000, 10, 0, **params)\n120     44.11703066106086\n121     '''\n122     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n123                                      a, b)\n124     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n125                                  irrad_ref)\n126 \n127 \n128 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n129     r'''\n130     Calculate module back surface temperature per the Sandia Array\n131     Performance Model.\n132 \n133     See [1]_ for details on the Sandia Array Performance Model.\n134 \n135     Parameters\n136     ----------\n137     poa_global : numeric\n138         Total incident irradiance [W/m^2].\n139 \n140     temp_air : numeric\n141         Ambient dry bulb temperature [C].\n142 \n143     wind_speed : numeric\n144         Wind speed at a height of 10 meters [m/s].\n145 \n146     a : float\n147         Parameter :math:`a` in :eq:`sapm1mod`.\n148 \n149     b : float\n150         Parameter :math:`b` in :eq:`sapm1mod`.\n151 \n152     Returns\n153     -------\n154     numeric, values in degrees C.\n155 \n156     Notes\n157     -----\n158     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n159 \n160     .. math::\n161        :label: sapm1mod\n162 \n163        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n164 \n165     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n166     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n167     temperature at the back of the module :math:`T_{m}` and cell temperature\n168     :math:`T_{C}`. Model parameters depend both on the module construction and\n169     its mounting. Parameter sets are provided in [1]_ for representative\n170     modules and mounting, and are coded for convenience in\n171     ``temperature.TEMPERATURE_MODEL_PARAMETERS``.\n172 \n173     +---------------+----------------+-------+---------+---------------------+\n174     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n175     +===============+================+=======+=========+=====================+\n176     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n177     +---------------+----------------+-------+---------+---------------------+\n178     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n179     +---------------+----------------+-------+---------+---------------------+\n180     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n181     +---------------+----------------+-------+---------+---------------------+\n182     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n183     +---------------+----------------+-------+---------+---------------------+\n184 \n185     References\n186     ----------\n187     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n188        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n189        NM.\n190 \n191     See also\n192     --------\n193     sapm_cell\n194     sapm_cell_from_module\n195     '''\n196     return poa_global * np.exp(a + b * wind_speed) + temp_air\n197 \n198 \n199 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n200                           irrad_ref=1000):\n201     r'''\n202     Calculate cell temperature from module temperature using the Sandia Array\n203     Performance Model.\n204 \n205     See [1]_ for details on the Sandia Array Performance Model.\n206 \n207     Parameters\n208     ----------\n209     module_temperature : numeric\n210         Temperature of back of module surface [C].\n211 \n212     poa_global : numeric\n213         Total incident irradiance [W/m^2].\n214 \n215     deltaT : float\n216         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n217 \n218     irrad_ref : float, default 1000\n219         Reference irradiance, parameter :math:`E_{0}` in\n220         :eq:`sapm2` [W/m^2].\n221 \n222     Returns\n223     -------\n224     numeric, values in degrees C.\n225 \n226     Notes\n227     -----\n228     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n229 \n230     .. math::\n231        :label: sapm2_cell_from_mod\n232 \n233        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n234 \n235     The module back surface temperature :math:`T_{m}` is implemented in\n236     :py:func:`~pvlib.temperature.sapm_module`.\n237 \n238     Model parameters depend both on the module construction and its mounting.\n239     Parameter sets are provided in [1]_ for representative modules and\n240     mounting, and are coded for convenience in\n241     ``pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS``.\n242 \n243     +---------------+----------------+-------+---------+---------------------+\n244     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n245     +===============+================+=======+=========+=====================+\n246     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n247     +---------------+----------------+-------+---------+---------------------+\n248     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n249     +---------------+----------------+-------+---------+---------------------+\n250     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n251     +---------------+----------------+-------+---------+---------------------+\n252     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n253     +---------------+----------------+-------+---------+---------------------+\n254 \n255     References\n256     ----------\n257     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n258        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n259        NM.\n260 \n261     See also\n262     --------\n263     sapm_cell\n264     sapm_module\n265     '''\n266     return module_temperature + (poa_global / irrad_ref) * deltaT\n267 \n268 \n269 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n270                 eta_m=0.1, alpha_absorption=0.9):\n271     r\"\"\"\n272     Calculate cell temperature using an empirical heat loss factor model\n273     as implemented in PVsyst.\n274 \n275     Parameters\n276     ----------\n277     poa_global : numeric\n278         Total incident irradiance [W/m^2].\n279 \n280     temp_air : numeric\n281         Ambient dry bulb temperature [C].\n282 \n283     wind_speed : numeric, default 1.0\n284         Wind speed in m/s measured at the same height for which the wind loss\n285         factor was determined.  The default value 1.0 m/2 is the wind\n286         speed at module height used to determine NOCT. [m/s]\n287 \n288     u_c : float, default 29.0\n289         Combined heat loss factor coefficient. The default value is\n290         representative of freestanding modules with the rear surfaces exposed\n291         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n292         :eq:`pvsyst`.\n293         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n294 \n295     u_v : float, default 0.0\n296         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n297         in :eq:`pvsyst`.\n298         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n299 \n300     eta_m : numeric, default 0.1\n301         Module external efficiency as a fraction, i.e., DC power / poa_global.\n302         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n303 \n304     alpha_absorption : numeric, default 0.9\n305         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n306 \n307     Returns\n308     -------\n309     numeric, values in degrees Celsius\n310 \n311     Notes\n312     -----\n313     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n314 \n315     .. math::\n316        :label: pvsyst\n317 \n318         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n319 \n320     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n321     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n322     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n323     the module construction and its mounting. Parameters are provided in\n324     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n325     , and are coded for convenience in\n326     ``temperature.TEMPERATURE_MODEL_PARAMETERS``. The heat loss factors\n327     provided represent the combined effect of convection, radiation and\n328     conduction, and their values are experimentally determined.\n329 \n330     +--------------+---------------+---------------+\n331     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n332     +==============+===============+===============+\n333     | freestanding | 29.0          | 0.0           |\n334     +--------------+---------------+---------------+\n335     | insulated    | 15.0          | 0.0           |\n336     +--------------+---------------+---------------+\n337 \n338     References\n339     ----------\n340     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n341        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n342 \n343     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n344        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n345 \n346     Examples\n347     --------\n348     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n349     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n350     >>> pvsyst_cell(1000, 10, **params)\n351     37.93103448275862\n352     \"\"\"\n353 \n354     total_loss_factor = u_c + u_v * wind_speed\n355     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n356     temp_difference = heat_input / total_loss_factor\n357     return temp_air + temp_difference\n358 \n359 \n360 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n361     r'''\n362     Calculate cell or module temperature using the Faiman model.  The Faiman\n363     model uses an empirical heat loss factor model [1]_ and is adopted in the\n364     IEC 61853 standards [2]_ and [3]_.\n365 \n366     Usage of this model in the IEC 61853 standard does not distinguish\n367     between cell and module temperature.\n368 \n369     Parameters\n370     ----------\n371     poa_global : numeric\n372         Total incident irradiance [W/m^2].\n373 \n374     temp_air : numeric\n375         Ambient dry bulb temperature [C].\n376 \n377     wind_speed : numeric, default 1.0\n378         Wind speed in m/s measured at the same height for which the wind loss\n379         factor was determined.  The default value 1.0 m/s is the wind\n380         speed at module height used to determine NOCT. [m/s]\n381 \n382     u0 : numeric, default 25.0\n383         Combined heat loss factor coefficient. The default value is one\n384         determined by Faiman for 7 silicon modules.\n385         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n386 \n387     u1 : numeric, default 6.84\n388         Combined heat loss factor influenced by wind. The default value is one\n389         determined by Faiman for 7 silicon modules.\n390         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n391 \n392     Returns\n393     -------\n394     numeric, values in degrees Celsius\n395 \n396     Notes\n397     -----\n398     All arguments may be scalars or vectors. If multiple arguments\n399     are vectors they must be the same length.\n400 \n401     References\n402     ----------\n403     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n404        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n405 \n406     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n407        rating - Part 2: Spectral responsivity, incidence angle and module\n408        operating temperature measurements\". IEC, Geneva, 2018.\n409 \n410     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n411        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n412 \n413     '''\n414     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n415 \n416     # The following lines may seem odd since u0 & u1 are probably scalar,\n417     # but it serves an indirect and easy way of allowing lists and\n418     # tuples for the other function arguments.\n419     u0 = np.asanyarray(u0)\n420     u1 = np.asanyarray(u1)\n421 \n422     total_loss_factor = u0 + u1 * wind_speed\n423     heat_input = poa_global\n424     temp_difference = heat_input / total_loss_factor\n425     return temp_air + temp_difference\n426 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "27872b83b0932cc419116f79e442963cced935bb", "problem_statement": "make read_crn accomodate bad files\nA couple of issues with our `read_crn` function. \r\n\r\nFirst, the character sequence '\\x00\\x00\\x00\\x00\\x00\\x00' occasionally shows up and trips up pandas. This can be fixed by adding `na_values=['\\x00\\x00\\x00\\x00\\x00\\x00']` to the reader.\r\n\r\nSecond, we try to set the `CRX_VN` column to dtype int, but it occasionally has floats that cannot be coerced. The [documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/subhourly01/README.txt) says it should be treated like a string.\r\n\r\nExample below shows both issues in `'CRNS0101-05-2020-FL_Titusville_7_E.txt'`\r\n\r\n```\r\n92821 20200706 1145 20200706 0645      3  -80.69   28.62    24.5     0.0    151 0    24.7 C 0    94 0 -99.000 -9999.0   990 0   1.23 0\r\n92821 20200706 1150 20200706 0650      3  -80.69   28.62    24.7     0.0    168 0    25.0 C 0    94 0 -99.000 -9999.0   990 0   1.28 0\r\n92821 20200706 1155 20200706 0655      3  -80.69   28.62    24.9     0.0    173 0    25.3 C 0    93 0 -99.000 -9999.0   990 0   1.48 0\r\n92821 20200706 1200 20200706 0700      3  -80.69   28.62    24.9     0.0    190 0    25.5 C 0    93 0 -99.000 -9999.0   990 0   1.57 0\r\n\\x00\\x00\\x00\\x00\\x00\\x00 repeated\r\n92821 20200706 1305 20200706 0805  2.623  -80.69   28.62    26.8     0.0    409 0    30.0 C 0    87 0 -99.000 -9999.0   988 0   1.44 0\r\n92821 20200706 1310 20200706 0810  2.623  -80.69   28.62    26.9     0.0    430 0    30.2 C 0    87 0 -99.000 -9999.0   989 0   1.64 0\r\n92821 20200706 1315 20200706 0815  2.623  -80.69   28.62    27.0     0.0    445 0    30.4 C 0    86 0 -99.000 -9999.0   989 0   1.94 0\r\n92821 20200706 1320 20200706 0820  2.623  -80.69   28.62    27.3     0.0    463 0    30.8 C 0    86 0 -99.000 -9999.0   988 0   1.50 0\r\n92821 20200706 1325 20200706 0825  2.623  -80.69   28.62    27.6     0.0    478 0    31.1 C 0    85 0 -99.000 -9999.0   988 0   1.54 0\r\n92821 20200706 1330 20200706 0830  2.623  -80.69   28.62    27.6     0.0    496 0    31.5 C 0    84 0 -99.000 -9999.0   988 0   1.48 0\r\n```\r\n\r\nfyi @lboeman \n", "hints_text": "", "created_at": "2020-08-21T16:27:41Z", "patch": "<patch>\ndiff --git a/pvlib/iotools/crn.py b/pvlib/iotools/crn.py\n--- a/pvlib/iotools/crn.py\n+++ b/pvlib/iotools/crn.py\n@@ -33,7 +33,7 @@\n \n # specify dtypes for potentially problematic values\n DTYPES = [\n-    'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', 'float64',\n+    'int64', 'int64', 'int64', 'int64', 'int64', 'str', 'float64', 'float64',\n     'float64', 'float64', 'float64', 'int64', 'float64', 'O', 'int64',\n     'float64', 'int64', 'float64', 'float64', 'int64', 'int64', 'float64',\n     'int64'\n@@ -67,6 +67,13 @@ def read_crn(filename):\n     e.g. `SOLAR_RADIATION` becomes `ghi`. See the\n     `pvlib.iotools.crn.VARIABLE_MAP` dict for the complete mapping.\n \n+    CRN files occasionally have a set of null characters on a line\n+    instead of valid data. This function drops those lines. Sometimes\n+    these null characters appear on a line of their own and sometimes\n+    they occur on the same line as valid data. In the latter case, the\n+    valid data will not be returned. Users may manually remove the null\n+    characters and reparse the file if they need that line.\n+\n     References\n     ----------\n     .. [1] U.S. Climate Reference Network\n@@ -78,9 +85,13 @@ def read_crn(filename):\n        Amer. Meteor. Soc., 94, 489-498. :doi:`10.1175/BAMS-D-12-00170.1`\n     \"\"\"\n \n-    # read in data\n+    # read in data. set fields with NUL characters to NaN\n     data = pd.read_fwf(filename, header=None, names=HEADERS.split(' '),\n-                       widths=WIDTHS)\n+                       widths=WIDTHS, na_values=['\\x00\\x00\\x00\\x00\\x00\\x00'])\n+    # at this point we only have NaNs from NUL characters, not -999 etc.\n+    # these bad rows need to be removed so that dtypes can be set.\n+    # NaNs require float dtype so we run into errors if we don't do this.\n+    data = data.dropna(axis=0)\n     # loop here because dtype kwarg not supported in read_fwf until 0.20\n     for (col, _dtype) in zip(data.columns, DTYPES):\n         data[col] = data[col].astype(_dtype)\n@@ -98,8 +109,11 @@ def read_crn(filename):\n     except TypeError:\n         pass\n \n-    # set nans\n+    # Now we can set nans. This could be done a per column basis to be\n+    # safer, since in principle a real -99 value could occur in a -9999\n+    # column. Very unlikely to see that in the real world.\n     for val in [-99, -999, -9999]:\n+        # consider replacing with .replace([-99, -999, -9999])\n         data = data.where(data != val, np.nan)\n \n     data = data.rename(columns=VARIABLE_MAP)\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/iotools/test_crn.py b/pvlib/tests/iotools/test_crn.py\n--- a/pvlib/tests/iotools/test_crn.py\n+++ b/pvlib/tests/iotools/test_crn.py\n@@ -8,18 +8,39 @@\n \n \n @pytest.fixture\n-def testfile():\n-    return DATA_DIR / 'CRNS0101-05-2019-AZ_Tucson_11_W.txt'\n-\n-\n-def test_read_crn(testfile):\n-    columns = [\n+def columns():\n+    return [\n         'WBANNO', 'UTC_DATE', 'UTC_TIME', 'LST_DATE', 'LST_TIME', 'CRX_VN',\n         'longitude', 'latitude', 'temp_air', 'PRECIPITATION', 'ghi',\n         'ghi_flag',\n         'SURFACE_TEMPERATURE', 'ST_TYPE', 'ST_FLAG', 'relative_humidity',\n         'relative_humidity_flag', 'SOIL_MOISTURE_5', 'SOIL_TEMPERATURE_5',\n         'WETNESS', 'WET_FLAG', 'wind_speed', 'wind_speed_flag']\n+\n+\n+@pytest.fixture\n+def dtypes():\n+    return [\n+        dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n+        dtype('int64'), dtype('O'), dtype('float64'), dtype('float64'),\n+        dtype('float64'), dtype('float64'), dtype('float64'),\n+        dtype('int64'), dtype('float64'), dtype('O'), dtype('int64'),\n+        dtype('float64'), dtype('int64'), dtype('float64'),\n+        dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'),\n+        dtype('int64')]\n+\n+\n+@pytest.fixture\n+def testfile():\n+    return DATA_DIR / 'CRNS0101-05-2019-AZ_Tucson_11_W.txt'\n+\n+\n+@pytest.fixture\n+def testfile_problems():\n+    return DATA_DIR / 'CRN_with_problems.txt'\n+\n+\n+def test_read_crn(testfile, columns, dtypes):\n     index = pd.DatetimeIndex(['2019-01-01 16:10:00',\n                               '2019-01-01 16:15:00',\n                               '2019-01-01 16:20:00',\n@@ -34,16 +55,26 @@ def test_read_crn(testfile):\n          0.0, 340.0, 0, 4.3, 'C', 0, 83.0, 0, nan, nan, 1183, 0, 0.53, 0],\n         [53131, 20190101, 1625, 20190101, 925, 3, -111.17, 32.24, 4.0,\n          0.0, 393.0, 0, 4.8, 'C', 0, 81.0, 0, nan, nan, 1223, 0, 0.64, 0]])\n-    dtypes = [\n-        dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n-        dtype('int64'), dtype('int64'), dtype('float64'), dtype('float64'),\n-        dtype('float64'), dtype('float64'), dtype('float64'),\n-        dtype('int64'), dtype('float64'), dtype('O'), dtype('int64'),\n-        dtype('float64'), dtype('int64'), dtype('float64'),\n-        dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'),\n-        dtype('int64')]\n     expected = pd.DataFrame(values, columns=columns, index=index)\n     for (col, _dtype) in zip(expected.columns, dtypes):\n         expected[col] = expected[col].astype(_dtype)\n     out = crn.read_crn(testfile)\n     assert_frame_equal(out, expected)\n+\n+\n+def test_read_crn_problems(testfile_problems, columns, dtypes):\n+    # GH1025\n+    index = pd.DatetimeIndex(['2020-07-06 12:00:00',\n+                              '2020-07-06 13:10:00'],\n+                             freq=None).tz_localize('UTC')\n+    values = np.array([\n+        [92821, 20200706, 1200, 20200706, 700, '3', -80.69, 28.62, 24.9,\n+         0.0, 190.0, 0, 25.5, 'C', 0, 93.0, 0, nan, nan, 990, 0, 1.57, 0],\n+        [92821, 20200706, 1310, 20200706, 810, '2.623', -80.69, 28.62,\n+         26.9, 0.0, 430.0, 0, 30.2, 'C', 0, 87.0, 0, nan, nan, 989, 0,\n+         1.64, 0]])\n+    expected = pd.DataFrame(values, columns=columns, index=index)\n+    for (col, _dtype) in zip(expected.columns, dtypes):\n+        expected[col] = expected[col].astype(_dtype)\n+    out = crn.read_crn(testfile_problems)\n+    assert_frame_equal(out, expected)\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/iotools/test_crn.py::test_read_crn\"]", "PASS_TO_PASS": "[]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-1026_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nmake read_crn accomodate bad files\nA couple of issues with our `read_crn` function. \r\n\r\nFirst, the character sequence '\\x00\\x00\\x00\\x00\\x00\\x00' occasionally shows up and trips up pandas. This can be fixed by adding `na_values=['\\x00\\x00\\x00\\x00\\x00\\x00']` to the reader.\r\n\r\nSecond, we try to set the `CRX_VN` column to dtype int, but it occasionally has floats that cannot be coerced. The [documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/subhourly01/README.txt) says it should be treated like a string.\r\n\r\nExample below shows both issues in `'CRNS0101-05-2020-FL_Titusville_7_E.txt'`\r\n\r\n```\r\n92821 20200706 1145 20200706 0645      3  -80.69   28.62    24.5     0.0    151 0    24.7 C 0    94 0 -99.000 -9999.0   990 0   1.23 0\r\n92821 20200706 1150 20200706 0650      3  -80.69   28.62    24.7     0.0    168 0    25.0 C 0    94 0 -99.000 -9999.0   990 0   1.28 0\r\n92821 20200706 1155 20200706 0655      3  -80.69   28.62    24.9     0.0    173 0    25.3 C 0    93 0 -99.000 -9999.0   990 0   1.48 0\r\n92821 20200706 1200 20200706 0700      3  -80.69   28.62    24.9     0.0    190 0    25.5 C 0    93 0 -99.000 -9999.0   990 0   1.57 0\r\n\\x00\\x00\\x00\\x00\\x00\\x00 repeated\r\n92821 20200706 1305 20200706 0805  2.623  -80.69   28.62    26.8     0.0    409 0    30.0 C 0    87 0 -99.000 -9999.0   988 0   1.44 0\r\n92821 20200706 1310 20200706 0810  2.623  -80.69   28.62    26.9     0.0    430 0    30.2 C 0    87 0 -99.000 -9999.0   989 0   1.64 0\r\n92821 20200706 1315 20200706 0815  2.623  -80.69   28.62    27.0     0.0    445 0    30.4 C 0    86 0 -99.000 -9999.0   989 0   1.94 0\r\n92821 20200706 1320 20200706 0820  2.623  -80.69   28.62    27.3     0.0    463 0    30.8 C 0    86 0 -99.000 -9999.0   988 0   1.50 0\r\n92821 20200706 1325 20200706 0825  2.623  -80.69   28.62    27.6     0.0    478 0    31.1 C 0    85 0 -99.000 -9999.0   988 0   1.54 0\r\n92821 20200706 1330 20200706 0830  2.623  -80.69   28.62    27.6     0.0    496 0    31.5 C 0    84 0 -99.000 -9999.0   988 0   1.48 0\r\n```\r\n\r\nfyi @lboeman \n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of docs/examples/plot_partial_module_shading_simple.py]\n1 \"\"\"\n2 Calculating power loss from partial module shading\n3 ==================================================\n4 \n5 Example of modeling cell-to-cell mismatch loss from partial module shading.\n6 \"\"\"\n7 \n8 # %%\n9 # Even though the PV cell is the primary power generation unit, PV modeling is\n10 # often done at the module level for simplicity because module-level parameters\n11 # are much more available and it significantly reduces the computational scope\n12 # of the simulation.  However, module-level simulations are too coarse to be\n13 # able to model effects like cell to cell mismatch or partial shading.  This\n14 # example calculates cell-level IV curves and combines them to reconstruct\n15 # the module-level IV curve.  It uses this approach to find the maximum power\n16 # under various shading and irradiance conditions.\n17 #\n18 # The primary functions used here are:\n19 #\n20 # - :py:meth:`pvlib.pvsystem.calcparams_desoto` to estimate the single\n21 #   diode equation parameters at some specified operating conditions.\n22 # - :py:meth:`pvlib.singlediode.bishop88` to calculate the full cell IV curve,\n23 #   including the reverse bias region.\n24 #\n25 # .. note::\n26 #\n27 #     This example requires the reverse bias functionality added in pvlib 0.7.2\n28 #\n29 # .. warning::\n30 #\n31 #     Modeling partial module shading is complicated and depends significantly\n32 #     on the module's electrical topology.  This example makes some simplifying\n33 #     assumptions that are not generally applicable.  For instance, it assumes\n34 #     that shading only applies to beam irradiance (*i.e.* all cells receive\n35 #     the same amount of diffuse irradiance) and cell temperature is uniform\n36 #     and not affected by cell-level irradiance variation.\n37 \n38 from pvlib import pvsystem, singlediode\n39 import pandas as pd\n40 import numpy as np\n41 from scipy.interpolate import interp1d\n42 import matplotlib.pyplot as plt\n43 \n44 from scipy.constants import e as qe, k as kB\n45 \n46 # For simplicity, use cell temperature of 25C for all calculations.\n47 # kB is J/K, qe is C=J/V\n48 # kB * T / qe -> V\n49 Vth = kB * (273.15+25) / qe\n50 \n51 cell_parameters = {\n52     'I_L_ref': 8.24,\n53     'I_o_ref': 2.36e-9,\n54     'a_ref': 1.3*Vth,\n55     'R_sh_ref': 1000,\n56     'R_s': 0.00181,\n57     'alpha_sc': 0.0042,\n58     'breakdown_factor': 2e-3,\n59     'breakdown_exp': 3,\n60     'breakdown_voltage': -15,\n61 }\n62 \n63 # %%\n64 # Simulating a cell IV curve\n65 # --------------------------\n66 #\n67 # First, calculate IV curves for individual cells.  The process is as follows:\n68 #\n69 # 1) Given a set of cell parameters at reference conditions and the operating\n70 #    conditions of interest (irradiance and temperature), use a single-diode\n71 #    model to calculate the single diode equation parameters for the cell at\n72 #    the operating conditions.  Here we use the De Soto model via\n73 #    :py:func:`pvlib.pvsystem.calcparams_desoto`.\n74 # 2) The single diode equation cannot be solved analytically, so pvlib has\n75 #    implemented a couple methods of solving it for us.  However, currently\n76 #    only the Bishop '88 method (:py:func:`pvlib.singlediode.bishop88`) has\n77 #    the ability to model the reverse bias characteristic in addition to the\n78 #    forward characteristic.  Depending on the nature of the shadow, it is\n79 #    sometimes necessary to model the reverse bias portion of the IV curve,\n80 #    so we use the Bishop '88 method here.  This gives us a set of (V, I)\n81 #    points on the cell's IV curve.\n82 \n83 \n84 def simulate_full_curve(parameters, Geff, Tcell, ivcurve_pnts=1000):\n85     \"\"\"\n86     Use De Soto and Bishop to simulate a full IV curve with both\n87     forward and reverse bias regions.\n88     \"\"\"\n89     # adjust the reference parameters according to the operating\n90     # conditions using the De Soto model:\n91     sde_args = pvsystem.calcparams_desoto(\n92         Geff,\n93         Tcell,\n94         alpha_sc=parameters['alpha_sc'],\n95         a_ref=parameters['a_ref'],\n96         I_L_ref=parameters['I_L_ref'],\n97         I_o_ref=parameters['I_o_ref'],\n98         R_sh_ref=parameters['R_sh_ref'],\n99         R_s=parameters['R_s'],\n100     )\n101     # sde_args has values:\n102     # (photocurrent, saturation_current, resistance_series,\n103     # resistance_shunt, nNsVth)\n104 \n105     # Use Bishop's method to calculate points on the IV curve with V ranging\n106     # from the reverse breakdown voltage to open circuit\n107     kwargs = {\n108         'breakdown_factor': parameters['breakdown_factor'],\n109         'breakdown_exp': parameters['breakdown_exp'],\n110         'breakdown_voltage': parameters['breakdown_voltage'],\n111     }\n112     v_oc = singlediode.bishop88_v_from_i(\n113         0.0, *sde_args, **kwargs\n114     )\n115     # ideally would use some intelligent log-spacing to concentrate points\n116     # around the forward- and reverse-bias knees, but this is good enough:\n117     vd = np.linspace(0.99*kwargs['breakdown_voltage'], v_oc, ivcurve_pnts)\n118 \n119     ivcurve_i, ivcurve_v, _ = singlediode.bishop88(vd, *sde_args, **kwargs)\n120     return pd.DataFrame({\n121         'i': ivcurve_i,\n122         'v': ivcurve_v,\n123     })\n124 \n125 \n126 # %%\n127 # Now that we can calculate cell-level IV curves, let's compare a\n128 # fully-illuminated cell's curve to a shaded cell's curve.  Note that shading\n129 # typically does not reduce a cell's illumination to zero -- tree shading and\n130 # row-to-row shading block the beam portion of irradiance but leave the diffuse\n131 # portion largely intact.  In this example plot, we choose :math:`200 W/m^2`\n132 # as the amount of irradiance received by a shaded cell.\n133 \n134 def plot_curves(dfs, labels, title):\n135     \"\"\"plot the forward- and reverse-bias portions of an IV curve\"\"\"\n136     fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5, 3))\n137     for df, label in zip(dfs, labels):\n138         df.plot('v', 'i', label=label, ax=axes[0])\n139         df.plot('v', 'i', label=label, ax=axes[1])\n140         axes[0].set_xlim(right=0)\n141         axes[0].set_ylim([0, 25])\n142         axes[1].set_xlim([0, df['v'].max()*1.5])\n143     axes[0].set_ylabel('current [A]')\n144     axes[0].set_xlabel('voltage [V]')\n145     axes[1].set_xlabel('voltage [V]')\n146     fig.suptitle(title)\n147     fig.tight_layout()\n148     return axes\n149 \n150 \n151 cell_curve_full_sun = simulate_full_curve(cell_parameters, Geff=1000, Tcell=25)\n152 cell_curve_shaded = simulate_full_curve(cell_parameters, Geff=200, Tcell=25)\n153 ax = plot_curves([cell_curve_full_sun, cell_curve_shaded],\n154                  labels=['Full Sun', 'Shaded'],\n155                  title='Cell-level reverse- and forward-biased IV curves')\n156 \n157 # %%\n158 # This figure shows how a cell's current decreases roughly in proportion to\n159 # the irradiance reduction from shading, but voltage changes much less.\n160 # At the cell level, the effect of shading is essentially to shift the I-V\n161 # curve down to lower currents rather than change the curve's shape.\n162 #\n163 # Note that the forward and reverse curves are plotted separately to\n164 # accommodate the different voltage scales involved -- a normal crystalline\n165 # silicon cell reaches only ~0.6V in forward bias, but can get to -10 to -20V\n166 # in reverse bias.\n167 #\n168 # Combining cell IV curves to create a module IV curve\n169 # ----------------------------------------------------\n170 #\n171 # To combine the individual cell IV curves and form a module's IV curve,\n172 # the cells in each substring must be added in series.  The substrings are\n173 # in series as well, but with parallel bypass diodes to protect from reverse\n174 # bias voltages.  To add in series, the voltages for a given current are\n175 # added.  However, because each cell's curve is discretized and the currents\n176 # might not line up, we align each curve to a common set of current values\n177 # with interpolation.\n178 \n179 \n180 def interpolate(df, i):\n181     \"\"\"convenience wrapper around scipy.interpolate.interp1d\"\"\"\n182     f_interp = interp1d(np.flipud(df['i']), np.flipud(df['v']), kind='linear',\n183                         fill_value='extrapolate')\n184     return f_interp(i)\n185 \n186 \n187 def combine_series(dfs):\n188     \"\"\"\n189     Combine IV curves in series by aligning currents and summing voltages.\n190     The current range is based on the first curve's current range.\n191     \"\"\"\n192     df1 = dfs[0]\n193     imin = df1['i'].min()\n194     imax = df1['i'].max()\n195     i = np.linspace(imin, imax, 1000)\n196     v = 0\n197     for df2 in dfs:\n198         v_cell = interpolate(df2, i)\n199         v += v_cell\n200     return pd.DataFrame({'i': i, 'v': v})\n201 \n202 \n203 # %%\n204 # Rather than simulate all 72 cells in the module, we'll assume that there\n205 # are only three types of cells (fully illuminated, fully shaded, and\n206 # partially shaded), and within each type all cells behave identically.  This\n207 # means that simulating one cell from each type (for three cell simulations\n208 # total) is sufficient to model the module as a whole.\n209 #\n210 # This function also models the effect of bypass diodes in parallel with each\n211 # substring.  Bypass diodes are normally inactive but conduct when substring\n212 # voltage becomes sufficiently negative, presumably due to the substring\n213 # entering reverse bias from mismatch between substrings.  In that case the\n214 # substring's voltage is clamped to the diode's trigger voltage (assumed to\n215 # be 0.5V here).\n216 \n217 def simulate_module(cell_parameters, poa_direct, poa_diffuse, Tcell,\n218                     shaded_fraction, cells_per_string=24, strings=3):\n219     \"\"\"\n220     Simulate the IV curve for a partially shaded module.\n221     The shade is assumed to be coming up from the bottom of the module when in\n222     portrait orientation, so it affects all substrings equally.\n223     For simplicity, cell temperature is assumed to be uniform across the\n224     module, regardless of variation in cell-level illumination.\n225     Substrings are assumed to be \"down and back\", so the number of cells per\n226     string is divided between two columns of cells.\n227     \"\"\"\n228     # find the number of cells per column that are in full shadow\n229     nrow = cells_per_string // 2\n230     nrow_full_shade = int(shaded_fraction * nrow)\n231     # find the fraction of shade in the border row\n232     partial_shade_fraction = 1 - (shaded_fraction * nrow - nrow_full_shade)\n233 \n234     df_lit = simulate_full_curve(\n235         cell_parameters,\n236         poa_diffuse + poa_direct,\n237         Tcell)\n238     df_partial = simulate_full_curve(\n239         cell_parameters,\n240         poa_diffuse + partial_shade_fraction * poa_direct,\n241         Tcell)\n242     df_shaded = simulate_full_curve(\n243         cell_parameters,\n244         poa_diffuse,\n245         Tcell)\n246     # build a list of IV curves for a single column of cells (half a substring)\n247     include_partial_cell = (shaded_fraction < 1)\n248     half_substring_curves = (\n249         [df_lit] * (nrow - nrow_full_shade - 1)\n250         + ([df_partial] if include_partial_cell else [])  # noqa: W503\n251         + [df_shaded] * nrow_full_shade  # noqa: W503\n252     )\n253     substring_curve = combine_series(half_substring_curves)\n254     substring_curve['v'] *= 2  # turn half strings into whole strings\n255     # bypass diode:\n256     substring_curve['v'] = substring_curve['v'].clip(lower=-0.5)\n257     # no need to interpolate since we're just scaling voltage directly:\n258     substring_curve['v'] *= strings\n259     return substring_curve\n260 \n261 # %%\n262 # Now let's see how shade affects the IV curves at the module level.  For this\n263 # example, the bottom 10% of the module is shaded.  Assuming 12 cells per\n264 # column, that means one row of cells is fully shaded and another row is\n265 # partially shaded.  Even though only 10% of the module is shaded, the\n266 # maximum power is decreased by roughly 80%!\n267 #\n268 # Note the effect of the bypass diodes.  Without bypass diodes, operating the\n269 # shaded module at the same current as the fully illuminated module would\n270 # create a reverse-bias voltage of several hundred volts!  However, the diodes\n271 # prevent the reverse voltage from exceeding 1.5V (three diodes at 0.5V each).\n272 \n273 \n274 kwargs = {\n275     'cell_parameters': cell_parameters,\n276     'poa_direct': 800,\n277     'poa_diffuse': 200,\n278     'Tcell': 25\n279 }\n280 module_curve_full_sun = simulate_module(shaded_fraction=0, **kwargs)\n281 module_curve_shaded = simulate_module(shaded_fraction=0.1, **kwargs)\n282 ax = plot_curves([module_curve_full_sun, module_curve_shaded],\n283                  labels=['Full Sun', 'Shaded'],\n284                  title='Module-level reverse- and forward-biased IV curves')\n285 \n286 # %%\n287 # Calculating shading loss across shading scenarios\n288 # -------------------------------------------------\n289 #\n290 # Clearly the module-level IV-curve is strongly affected by partial shading.\n291 # This heatmap shows the module maximum power under a range of partial shade\n292 # conditions, where \"diffuse fraction\" refers to the ratio\n293 # :math:`poa_{diffuse} / poa_{global}` and \"shaded fraction\" refers to the\n294 # fraction of the module that receives only diffuse irradiance.\n295 \n296 \n297 def find_pmp(df):\n298     \"\"\"simple function to find Pmp on an IV curve\"\"\"\n299     return df.product(axis=1).max()\n300 \n301 \n302 # find Pmp under different shading conditions\n303 data = []\n304 for diffuse_fraction in np.linspace(0, 1, 11):\n305     for shaded_fraction in np.linspace(0, 1, 51):\n306 \n307         df = simulate_module(cell_parameters,\n308                              poa_direct=(1-diffuse_fraction)*1000,\n309                              poa_diffuse=diffuse_fraction*1000,\n310                              Tcell=25,\n311                              shaded_fraction=shaded_fraction)\n312         data.append({\n313             'fd': diffuse_fraction,\n314             'fs': shaded_fraction,\n315             'pmp': find_pmp(df)\n316         })\n317 \n318 results = pd.DataFrame(data)\n319 results['pmp'] /= results['pmp'].max()  # normalize power to 0-1\n320 results_pivot = results.pivot('fd', 'fs', 'pmp')\n321 plt.figure()\n322 plt.imshow(results_pivot, origin='lower', aspect='auto')\n323 plt.xlabel('shaded fraction')\n324 plt.ylabel('diffuse fraction')\n325 xlabels = [\"{:0.02f}\".format(fs) for fs in results_pivot.columns[::5]]\n326 ylabels = [\"{:0.02f}\".format(fd) for fd in results_pivot.index]\n327 plt.xticks(range(0, 5*len(xlabels), 5), xlabels)\n328 plt.yticks(range(0, len(ylabels)), ylabels)\n329 plt.title('Module P_mp across shading conditions')\n330 plt.colorbar()\n331 plt.show()\n332 # use this figure as the thumbnail:\n333 # sphinx_gallery_thumbnail_number = 3\n334 \n335 # %%\n336 # The heatmap makes a few things evident:\n337 #\n338 # - When diffuse fraction is equal to 1, there is no beam irradiance to lose,\n339 #   so shading has no effect on production.\n340 # - When shaded fraction is equal to 0, no irradiance is blocked, so module\n341 #   output does not change with the diffuse fraction.\n342 # - Under sunny conditions (diffuse fraction < 0.5), module output is\n343 #   significantly reduced after just the first cell is shaded\n344 #   (1/12 = ~8% shaded fraction).\n345 \n[end of docs/examples/plot_partial_module_shading_simple.py]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 \n8 \n9 TEMPERATURE_MODEL_PARAMETERS = {\n10     'sapm': {\n11         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n12         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n13         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n14         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n15     },\n16     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n17                'insulated': {'u_c': 15.0, 'u_v': 0}}\n18 }\n19 \n20 \n21 def _temperature_model_params(model, parameter_set):\n22     try:\n23         params = TEMPERATURE_MODEL_PARAMETERS[model]\n24         return params[parameter_set]\n25     except KeyError:\n26         msg = ('{} is not a named set of parameters for the {} cell'\n27                ' temperature model.'\n28                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n29                ' for names'.format(parameter_set, model))\n30         raise KeyError(msg)\n31 \n32 \n33 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n34               irrad_ref=1000):\n35     r'''\n36     Calculate cell temperature per the Sandia Array Performance Model.\n37 \n38     See [1]_ for details on the Sandia Array Performance Model.\n39 \n40     Parameters\n41     ----------\n42     poa_global : numeric\n43         Total incident irradiance [W/m^2].\n44 \n45     temp_air : numeric\n46         Ambient dry bulb temperature [C].\n47 \n48     wind_speed : numeric\n49         Wind speed at a height of 10 meters [m/s].\n50 \n51     a : float\n52         Parameter :math:`a` in :eq:`sapm1`.\n53 \n54     b : float\n55         Parameter :math:`b` in :eq:`sapm1`.\n56 \n57     deltaT : float\n58         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n59 \n60     irrad_ref : float, default 1000\n61         Reference irradiance, parameter :math:`E_{0}` in\n62         :eq:`sapm2` [W/m^2].\n63 \n64     Returns\n65     -------\n66     numeric, values in degrees C.\n67 \n68     Notes\n69     -----\n70     The model for cell temperature :math:`T_{C}` is given by a pair of\n71     equations (Eq. 11 and 12 in [1]_).\n72 \n73     .. math::\n74        :label: sapm1\n75 \n76        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n77 \n78     .. math::\n79        :label: sapm2\n80 \n81        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n82 \n83     The module back surface temperature :math:`T_{m}` is implemented in\n84     :py:func:`~pvlib.temperature.sapm_module`.\n85 \n86     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n87     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n88     the module construction and its mounting. Parameter sets are provided in\n89     [1]_ for representative modules and mounting, and are coded for convenience\n90     in ``pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS``.\n91 \n92     +---------------+----------------+-------+---------+---------------------+\n93     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n94     +===============+================+=======+=========+=====================+\n95     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n96     +---------------+----------------+-------+---------+---------------------+\n97     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n98     +---------------+----------------+-------+---------+---------------------+\n99     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n100     +---------------+----------------+-------+---------+---------------------+\n101     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n102     +---------------+----------------+-------+---------+---------------------+\n103 \n104     References\n105     ----------\n106     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n107        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n108        NM.\n109 \n110     See also\n111     --------\n112     sapm_cell_from_module\n113     sapm_module\n114 \n115     Examples\n116     --------\n117     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n118     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n119     >>> sapm_cell(1000, 10, 0, **params)\n120     44.11703066106086\n121     '''\n122     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n123                                      a, b)\n124     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n125                                  irrad_ref)\n126 \n127 \n128 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n129     r'''\n130     Calculate module back surface temperature per the Sandia Array\n131     Performance Model.\n132 \n133     See [1]_ for details on the Sandia Array Performance Model.\n134 \n135     Parameters\n136     ----------\n137     poa_global : numeric\n138         Total incident irradiance [W/m^2].\n139 \n140     temp_air : numeric\n141         Ambient dry bulb temperature [C].\n142 \n143     wind_speed : numeric\n144         Wind speed at a height of 10 meters [m/s].\n145 \n146     a : float\n147         Parameter :math:`a` in :eq:`sapm1mod`.\n148 \n149     b : float\n150         Parameter :math:`b` in :eq:`sapm1mod`.\n151 \n152     Returns\n153     -------\n154     numeric, values in degrees C.\n155 \n156     Notes\n157     -----\n158     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n159 \n160     .. math::\n161        :label: sapm1mod\n162 \n163        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n164 \n165     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n166     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n167     temperature at the back of the module :math:`T_{m}` and cell temperature\n168     :math:`T_{C}`. Model parameters depend both on the module construction and\n169     its mounting. Parameter sets are provided in [1]_ for representative\n170     modules and mounting, and are coded for convenience in\n171     ``temperature.TEMPERATURE_MODEL_PARAMETERS``.\n172 \n173     +---------------+----------------+-------+---------+---------------------+\n174     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n175     +===============+================+=======+=========+=====================+\n176     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n177     +---------------+----------------+-------+---------+---------------------+\n178     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n179     +---------------+----------------+-------+---------+---------------------+\n180     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n181     +---------------+----------------+-------+---------+---------------------+\n182     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n183     +---------------+----------------+-------+---------+---------------------+\n184 \n185     References\n186     ----------\n187     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n188        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n189        NM.\n190 \n191     See also\n192     --------\n193     sapm_cell\n194     sapm_cell_from_module\n195     '''\n196     return poa_global * np.exp(a + b * wind_speed) + temp_air\n197 \n198 \n199 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n200                           irrad_ref=1000):\n201     r'''\n202     Calculate cell temperature from module temperature using the Sandia Array\n203     Performance Model.\n204 \n205     See [1]_ for details on the Sandia Array Performance Model.\n206 \n207     Parameters\n208     ----------\n209     module_temperature : numeric\n210         Temperature of back of module surface [C].\n211 \n212     poa_global : numeric\n213         Total incident irradiance [W/m^2].\n214 \n215     deltaT : float\n216         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n217 \n218     irrad_ref : float, default 1000\n219         Reference irradiance, parameter :math:`E_{0}` in\n220         :eq:`sapm2` [W/m^2].\n221 \n222     Returns\n223     -------\n224     numeric, values in degrees C.\n225 \n226     Notes\n227     -----\n228     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n229 \n230     .. math::\n231        :label: sapm2_cell_from_mod\n232 \n233        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n234 \n235     The module back surface temperature :math:`T_{m}` is implemented in\n236     :py:func:`~pvlib.temperature.sapm_module`.\n237 \n238     Model parameters depend both on the module construction and its mounting.\n239     Parameter sets are provided in [1]_ for representative modules and\n240     mounting, and are coded for convenience in\n241     ``pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS``.\n242 \n243     +---------------+----------------+-------+---------+---------------------+\n244     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n245     +===============+================+=======+=========+=====================+\n246     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n247     +---------------+----------------+-------+---------+---------------------+\n248     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n249     +---------------+----------------+-------+---------+---------------------+\n250     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n251     +---------------+----------------+-------+---------+---------------------+\n252     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n253     +---------------+----------------+-------+---------+---------------------+\n254 \n255     References\n256     ----------\n257     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n258        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n259        NM.\n260 \n261     See also\n262     --------\n263     sapm_cell\n264     sapm_module\n265     '''\n266     return module_temperature + (poa_global / irrad_ref) * deltaT\n267 \n268 \n269 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n270                 eta_m=0.1, alpha_absorption=0.9):\n271     r\"\"\"\n272     Calculate cell temperature using an empirical heat loss factor model\n273     as implemented in PVsyst.\n274 \n275     Parameters\n276     ----------\n277     poa_global : numeric\n278         Total incident irradiance [W/m^2].\n279 \n280     temp_air : numeric\n281         Ambient dry bulb temperature [C].\n282 \n283     wind_speed : numeric, default 1.0\n284         Wind speed in m/s measured at the same height for which the wind loss\n285         factor was determined.  The default value 1.0 m/2 is the wind\n286         speed at module height used to determine NOCT. [m/s]\n287 \n288     u_c : float, default 29.0\n289         Combined heat loss factor coefficient. The default value is\n290         representative of freestanding modules with the rear surfaces exposed\n291         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n292         :eq:`pvsyst`.\n293         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n294 \n295     u_v : float, default 0.0\n296         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n297         in :eq:`pvsyst`.\n298         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n299 \n300     eta_m : numeric, default 0.1\n301         Module external efficiency as a fraction, i.e., DC power / poa_global.\n302         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n303 \n304     alpha_absorption : numeric, default 0.9\n305         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n306 \n307     Returns\n308     -------\n309     numeric, values in degrees Celsius\n310 \n311     Notes\n312     -----\n313     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n314 \n315     .. math::\n316        :label: pvsyst\n317 \n318         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n319 \n320     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n321     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n322     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n323     the module construction and its mounting. Parameters are provided in\n324     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n325     , and are coded for convenience in\n326     ``temperature.TEMPERATURE_MODEL_PARAMETERS``. The heat loss factors\n327     provided represent the combined effect of convection, radiation and\n328     conduction, and their values are experimentally determined.\n329 \n330     +--------------+---------------+---------------+\n331     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n332     +==============+===============+===============+\n333     | freestanding | 29.0          | 0.0           |\n334     +--------------+---------------+---------------+\n335     | insulated    | 15.0          | 0.0           |\n336     +--------------+---------------+---------------+\n337 \n338     References\n339     ----------\n340     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n341        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n342 \n343     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n344        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n345 \n346     Examples\n347     --------\n348     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n349     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n350     >>> pvsyst_cell(1000, 10, **params)\n351     37.93103448275862\n352     \"\"\"\n353 \n354     total_loss_factor = u_c + u_v * wind_speed\n355     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n356     temp_difference = heat_input / total_loss_factor\n357     return temp_air + temp_difference\n358 \n359 \n360 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n361     r'''\n362     Calculate cell or module temperature using the Faiman model.  The Faiman\n363     model uses an empirical heat loss factor model [1]_ and is adopted in the\n364     IEC 61853 standards [2]_ and [3]_.\n365 \n366     Usage of this model in the IEC 61853 standard does not distinguish\n367     between cell and module temperature.\n368 \n369     Parameters\n370     ----------\n371     poa_global : numeric\n372         Total incident irradiance [W/m^2].\n373 \n374     temp_air : numeric\n375         Ambient dry bulb temperature [C].\n376 \n377     wind_speed : numeric, default 1.0\n378         Wind speed in m/s measured at the same height for which the wind loss\n379         factor was determined.  The default value 1.0 m/s is the wind\n380         speed at module height used to determine NOCT. [m/s]\n381 \n382     u0 : numeric, default 25.0\n383         Combined heat loss factor coefficient. The default value is one\n384         determined by Faiman for 7 silicon modules.\n385         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n386 \n387     u1 : numeric, default 6.84\n388         Combined heat loss factor influenced by wind. The default value is one\n389         determined by Faiman for 7 silicon modules.\n390         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n391 \n392     Returns\n393     -------\n394     numeric, values in degrees Celsius\n395 \n396     Notes\n397     -----\n398     All arguments may be scalars or vectors. If multiple arguments\n399     are vectors they must be the same length.\n400 \n401     References\n402     ----------\n403     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n404        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n405 \n406     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n407        rating - Part 2: Spectral responsivity, incidence angle and module\n408        operating temperature measurements\". IEC, Geneva, 2018.\n409 \n410     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n411        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n412 \n413     '''\n414     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n415 \n416     # The following lines may seem odd since u0 & u1 are probably scalar,\n417     # but it serves an indirect and easy way of allowing lists and\n418     # tuples for the other function arguments.\n419     u0 = np.asanyarray(u0)\n420     u1 = np.asanyarray(u1)\n421 \n422     total_loss_factor = u0 + u1 * wind_speed\n423     heat_input = poa_global\n424     temp_difference = heat_input / total_loss_factor\n425     return temp_air + temp_difference\n426 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "27872b83b0932cc419116f79e442963cced935bb", "problem_statement": "make read_crn accomodate bad files\nA couple of issues with our `read_crn` function. \r\n\r\nFirst, the character sequence '\\x00\\x00\\x00\\x00\\x00\\x00' occasionally shows up and trips up pandas. This can be fixed by adding `na_values=['\\x00\\x00\\x00\\x00\\x00\\x00']` to the reader.\r\n\r\nSecond, we try to set the `CRX_VN` column to dtype int, but it occasionally has floats that cannot be coerced. The [documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/subhourly01/README.txt) says it should be treated like a string.\r\n\r\nExample below shows both issues in `'CRNS0101-05-2020-FL_Titusville_7_E.txt'`\r\n\r\n```\r\n92821 20200706 1145 20200706 0645      3  -80.69   28.62    24.5     0.0    151 0    24.7 C 0    94 0 -99.000 -9999.0   990 0   1.23 0\r\n92821 20200706 1150 20200706 0650      3  -80.69   28.62    24.7     0.0    168 0    25.0 C 0    94 0 -99.000 -9999.0   990 0   1.28 0\r\n92821 20200706 1155 20200706 0655      3  -80.69   28.62    24.9     0.0    173 0    25.3 C 0    93 0 -99.000 -9999.0   990 0   1.48 0\r\n92821 20200706 1200 20200706 0700      3  -80.69   28.62    24.9     0.0    190 0    25.5 C 0    93 0 -99.000 -9999.0   990 0   1.57 0\r\n\\x00\\x00\\x00\\x00\\x00\\x00 repeated\r\n92821 20200706 1305 20200706 0805  2.623  -80.69   28.62    26.8     0.0    409 0    30.0 C 0    87 0 -99.000 -9999.0   988 0   1.44 0\r\n92821 20200706 1310 20200706 0810  2.623  -80.69   28.62    26.9     0.0    430 0    30.2 C 0    87 0 -99.000 -9999.0   989 0   1.64 0\r\n92821 20200706 1315 20200706 0815  2.623  -80.69   28.62    27.0     0.0    445 0    30.4 C 0    86 0 -99.000 -9999.0   989 0   1.94 0\r\n92821 20200706 1320 20200706 0820  2.623  -80.69   28.62    27.3     0.0    463 0    30.8 C 0    86 0 -99.000 -9999.0   988 0   1.50 0\r\n92821 20200706 1325 20200706 0825  2.623  -80.69   28.62    27.6     0.0    478 0    31.1 C 0    85 0 -99.000 -9999.0   988 0   1.54 0\r\n92821 20200706 1330 20200706 0830  2.623  -80.69   28.62    27.6     0.0    496 0    31.5 C 0    84 0 -99.000 -9999.0   988 0   1.48 0\r\n```\r\n\r\nfyi @lboeman \n", "hints_text": "", "created_at": "2020-08-21T16:27:41Z", "patch": "<patch>\ndiff --git a/pvlib/iotools/crn.py b/pvlib/iotools/crn.py\n--- a/pvlib/iotools/crn.py\n+++ b/pvlib/iotools/crn.py\n@@ -33,7 +33,7 @@\n \n # specify dtypes for potentially problematic values\n DTYPES = [\n-    'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', 'float64',\n+    'int64', 'int64', 'int64', 'int64', 'int64', 'str', 'float64', 'float64',\n     'float64', 'float64', 'float64', 'int64', 'float64', 'O', 'int64',\n     'float64', 'int64', 'float64', 'float64', 'int64', 'int64', 'float64',\n     'int64'\n@@ -67,6 +67,13 @@ def read_crn(filename):\n     e.g. `SOLAR_RADIATION` becomes `ghi`. See the\n     `pvlib.iotools.crn.VARIABLE_MAP` dict for the complete mapping.\n \n+    CRN files occasionally have a set of null characters on a line\n+    instead of valid data. This function drops those lines. Sometimes\n+    these null characters appear on a line of their own and sometimes\n+    they occur on the same line as valid data. In the latter case, the\n+    valid data will not be returned. Users may manually remove the null\n+    characters and reparse the file if they need that line.\n+\n     References\n     ----------\n     .. [1] U.S. Climate Reference Network\n@@ -78,9 +85,13 @@ def read_crn(filename):\n        Amer. Meteor. Soc., 94, 489-498. :doi:`10.1175/BAMS-D-12-00170.1`\n     \"\"\"\n \n-    # read in data\n+    # read in data. set fields with NUL characters to NaN\n     data = pd.read_fwf(filename, header=None, names=HEADERS.split(' '),\n-                       widths=WIDTHS)\n+                       widths=WIDTHS, na_values=['\\x00\\x00\\x00\\x00\\x00\\x00'])\n+    # at this point we only have NaNs from NUL characters, not -999 etc.\n+    # these bad rows need to be removed so that dtypes can be set.\n+    # NaNs require float dtype so we run into errors if we don't do this.\n+    data = data.dropna(axis=0)\n     # loop here because dtype kwarg not supported in read_fwf until 0.20\n     for (col, _dtype) in zip(data.columns, DTYPES):\n         data[col] = data[col].astype(_dtype)\n@@ -98,8 +109,11 @@ def read_crn(filename):\n     except TypeError:\n         pass\n \n-    # set nans\n+    # Now we can set nans. This could be done a per column basis to be\n+    # safer, since in principle a real -99 value could occur in a -9999\n+    # column. Very unlikely to see that in the real world.\n     for val in [-99, -999, -9999]:\n+        # consider replacing with .replace([-99, -999, -9999])\n         data = data.where(data != val, np.nan)\n \n     data = data.rename(columns=VARIABLE_MAP)\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/iotools/test_crn.py b/pvlib/tests/iotools/test_crn.py\n--- a/pvlib/tests/iotools/test_crn.py\n+++ b/pvlib/tests/iotools/test_crn.py\n@@ -8,18 +8,39 @@\n \n \n @pytest.fixture\n-def testfile():\n-    return DATA_DIR / 'CRNS0101-05-2019-AZ_Tucson_11_W.txt'\n-\n-\n-def test_read_crn(testfile):\n-    columns = [\n+def columns():\n+    return [\n         'WBANNO', 'UTC_DATE', 'UTC_TIME', 'LST_DATE', 'LST_TIME', 'CRX_VN',\n         'longitude', 'latitude', 'temp_air', 'PRECIPITATION', 'ghi',\n         'ghi_flag',\n         'SURFACE_TEMPERATURE', 'ST_TYPE', 'ST_FLAG', 'relative_humidity',\n         'relative_humidity_flag', 'SOIL_MOISTURE_5', 'SOIL_TEMPERATURE_5',\n         'WETNESS', 'WET_FLAG', 'wind_speed', 'wind_speed_flag']\n+\n+\n+@pytest.fixture\n+def dtypes():\n+    return [\n+        dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n+        dtype('int64'), dtype('O'), dtype('float64'), dtype('float64'),\n+        dtype('float64'), dtype('float64'), dtype('float64'),\n+        dtype('int64'), dtype('float64'), dtype('O'), dtype('int64'),\n+        dtype('float64'), dtype('int64'), dtype('float64'),\n+        dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'),\n+        dtype('int64')]\n+\n+\n+@pytest.fixture\n+def testfile():\n+    return DATA_DIR / 'CRNS0101-05-2019-AZ_Tucson_11_W.txt'\n+\n+\n+@pytest.fixture\n+def testfile_problems():\n+    return DATA_DIR / 'CRN_with_problems.txt'\n+\n+\n+def test_read_crn(testfile, columns, dtypes):\n     index = pd.DatetimeIndex(['2019-01-01 16:10:00',\n                               '2019-01-01 16:15:00',\n                               '2019-01-01 16:20:00',\n@@ -34,16 +55,26 @@ def test_read_crn(testfile):\n          0.0, 340.0, 0, 4.3, 'C', 0, 83.0, 0, nan, nan, 1183, 0, 0.53, 0],\n         [53131, 20190101, 1625, 20190101, 925, 3, -111.17, 32.24, 4.0,\n          0.0, 393.0, 0, 4.8, 'C', 0, 81.0, 0, nan, nan, 1223, 0, 0.64, 0]])\n-    dtypes = [\n-        dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n-        dtype('int64'), dtype('int64'), dtype('float64'), dtype('float64'),\n-        dtype('float64'), dtype('float64'), dtype('float64'),\n-        dtype('int64'), dtype('float64'), dtype('O'), dtype('int64'),\n-        dtype('float64'), dtype('int64'), dtype('float64'),\n-        dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'),\n-        dtype('int64')]\n     expected = pd.DataFrame(values, columns=columns, index=index)\n     for (col, _dtype) in zip(expected.columns, dtypes):\n         expected[col] = expected[col].astype(_dtype)\n     out = crn.read_crn(testfile)\n     assert_frame_equal(out, expected)\n+\n+\n+def test_read_crn_problems(testfile_problems, columns, dtypes):\n+    # GH1025\n+    index = pd.DatetimeIndex(['2020-07-06 12:00:00',\n+                              '2020-07-06 13:10:00'],\n+                             freq=None).tz_localize('UTC')\n+    values = np.array([\n+        [92821, 20200706, 1200, 20200706, 700, '3', -80.69, 28.62, 24.9,\n+         0.0, 190.0, 0, 25.5, 'C', 0, 93.0, 0, nan, nan, 990, 0, 1.57, 0],\n+        [92821, 20200706, 1310, 20200706, 810, '2.623', -80.69, 28.62,\n+         26.9, 0.0, 430.0, 0, 30.2, 'C', 0, 87.0, 0, nan, nan, 989, 0,\n+         1.64, 0]])\n+    expected = pd.DataFrame(values, columns=columns, index=index)\n+    for (col, _dtype) in zip(expected.columns, dtypes):\n+        expected[col] = expected[col].astype(_dtype)\n+    out = crn.read_crn(testfile_problems)\n+    assert_frame_equal(out, expected)\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/iotools/test_crn.py::test_read_crn\"]", "PASS_TO_PASS": "[]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-1026_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nmake read_crn accomodate bad files\nA couple of issues with our `read_crn` function. \r\n\r\nFirst, the character sequence '\\x00\\x00\\x00\\x00\\x00\\x00' occasionally shows up and trips up pandas. This can be fixed by adding `na_values=['\\x00\\x00\\x00\\x00\\x00\\x00']` to the reader.\r\n\r\nSecond, we try to set the `CRX_VN` column to dtype int, but it occasionally has floats that cannot be coerced. The [documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/subhourly01/README.txt) says it should be treated like a string.\r\n\r\nExample below shows both issues in `'CRNS0101-05-2020-FL_Titusville_7_E.txt'`\r\n\r\n```\r\n92821 20200706 1145 20200706 0645      3  -80.69   28.62    24.5     0.0    151 0    24.7 C 0    94 0 -99.000 -9999.0   990 0   1.23 0\r\n92821 20200706 1150 20200706 0650      3  -80.69   28.62    24.7     0.0    168 0    25.0 C 0    94 0 -99.000 -9999.0   990 0   1.28 0\r\n92821 20200706 1155 20200706 0655      3  -80.69   28.62    24.9     0.0    173 0    25.3 C 0    93 0 -99.000 -9999.0   990 0   1.48 0\r\n92821 20200706 1200 20200706 0700      3  -80.69   28.62    24.9     0.0    190 0    25.5 C 0    93 0 -99.000 -9999.0   990 0   1.57 0\r\n\\x00\\x00\\x00\\x00\\x00\\x00 repeated\r\n92821 20200706 1305 20200706 0805  2.623  -80.69   28.62    26.8     0.0    409 0    30.0 C 0    87 0 -99.000 -9999.0   988 0   1.44 0\r\n92821 20200706 1310 20200706 0810  2.623  -80.69   28.62    26.9     0.0    430 0    30.2 C 0    87 0 -99.000 -9999.0   989 0   1.64 0\r\n92821 20200706 1315 20200706 0815  2.623  -80.69   28.62    27.0     0.0    445 0    30.4 C 0    86 0 -99.000 -9999.0   989 0   1.94 0\r\n92821 20200706 1320 20200706 0820  2.623  -80.69   28.62    27.3     0.0    463 0    30.8 C 0    86 0 -99.000 -9999.0   988 0   1.50 0\r\n92821 20200706 1325 20200706 0825  2.623  -80.69   28.62    27.6     0.0    478 0    31.1 C 0    85 0 -99.000 -9999.0   988 0   1.54 0\r\n92821 20200706 1330 20200706 0830  2.623  -80.69   28.62    27.6     0.0    496 0    31.5 C 0    84 0 -99.000 -9999.0   988 0   1.48 0\r\n```\r\n\r\nfyi @lboeman \n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of docs/examples/plot_partial_module_shading_simple.py]\n1 \"\"\"\n2 Calculating power loss from partial module shading\n3 ==================================================\n4 \n5 Example of modeling cell-to-cell mismatch loss from partial module shading.\n6 \"\"\"\n7 \n8 # %%\n9 # Even though the PV cell is the primary power generation unit, PV modeling is\n10 # often done at the module level for simplicity because module-level parameters\n11 # are much more available and it significantly reduces the computational scope\n12 # of the simulation.  However, module-level simulations are too coarse to be\n13 # able to model effects like cell to cell mismatch or partial shading.  This\n14 # example calculates cell-level IV curves and combines them to reconstruct\n15 # the module-level IV curve.  It uses this approach to find the maximum power\n16 # under various shading and irradiance conditions.\n17 #\n18 # The primary functions used here are:\n19 #\n20 # - :py:meth:`pvlib.pvsystem.calcparams_desoto` to estimate the single\n21 #   diode equation parameters at some specified operating conditions.\n22 # - :py:meth:`pvlib.singlediode.bishop88` to calculate the full cell IV curve,\n23 #   including the reverse bias region.\n24 #\n25 # .. note::\n26 #\n27 #     This example requires the reverse bias functionality added in pvlib 0.7.2\n28 #\n29 # .. warning::\n30 #\n31 #     Modeling partial module shading is complicated and depends significantly\n32 #     on the module's electrical topology.  This example makes some simplifying\n33 #     assumptions that are not generally applicable.  For instance, it assumes\n34 #     that shading only applies to beam irradiance (*i.e.* all cells receive\n35 #     the same amount of diffuse irradiance) and cell temperature is uniform\n36 #     and not affected by cell-level irradiance variation.\n37 \n38 from pvlib import pvsystem, singlediode\n39 import pandas as pd\n40 import numpy as np\n41 from scipy.interpolate import interp1d\n42 import matplotlib.pyplot as plt\n43 \n44 from scipy.constants import e as qe, k as kB\n45 \n46 # For simplicity, use cell temperature of 25C for all calculations.\n47 # kB is J/K, qe is C=J/V\n48 # kB * T / qe -> V\n49 Vth = kB * (273.15+25) / qe\n50 \n51 cell_parameters = {\n52     'I_L_ref': 8.24,\n53     'I_o_ref': 2.36e-9,\n54     'a_ref': 1.3*Vth,\n55     'R_sh_ref': 1000,\n56     'R_s': 0.00181,\n57     'alpha_sc': 0.0042,\n58     'breakdown_factor': 2e-3,\n59     'breakdown_exp': 3,\n60     'breakdown_voltage': -15,\n61 }\n62 \n63 # %%\n64 # Simulating a cell IV curve\n65 # --------------------------\n66 #\n67 # First, calculate IV curves for individual cells.  The process is as follows:\n68 #\n69 # 1) Given a set of cell parameters at reference conditions and the operating\n70 #    conditions of interest (irradiance and temperature), use a single-diode\n71 #    model to calculate the single diode equation parameters for the cell at\n72 #    the operating conditions.  Here we use the De Soto model via\n73 #    :py:func:`pvlib.pvsystem.calcparams_desoto`.\n74 # 2) The single diode equation cannot be solved analytically, so pvlib has\n75 #    implemented a couple methods of solving it for us.  However, currently\n76 #    only the Bishop '88 method (:py:func:`pvlib.singlediode.bishop88`) has\n77 #    the ability to model the reverse bias characteristic in addition to the\n78 #    forward characteristic.  Depending on the nature of the shadow, it is\n79 #    sometimes necessary to model the reverse bias portion of the IV curve,\n80 #    so we use the Bishop '88 method here.  This gives us a set of (V, I)\n81 #    points on the cell's IV curve.\n82 \n83 \n84 def simulate_full_curve(parameters, Geff, Tcell, ivcurve_pnts=1000):\n85     \"\"\"\n86     Use De Soto and Bishop to simulate a full IV curve with both\n87     forward and reverse bias regions.\n88     \"\"\"\n89     # adjust the reference parameters according to the operating\n90     # conditions using the De Soto model:\n91     sde_args = pvsystem.calcparams_desoto(\n92         Geff,\n93         Tcell,\n94         alpha_sc=parameters['alpha_sc'],\n95         a_ref=parameters['a_ref'],\n96         I_L_ref=parameters['I_L_ref'],\n97         I_o_ref=parameters['I_o_ref'],\n98         R_sh_ref=parameters['R_sh_ref'],\n99         R_s=parameters['R_s'],\n100     )\n101     # sde_args has values:\n102     # (photocurrent, saturation_current, resistance_series,\n103     # resistance_shunt, nNsVth)\n104 \n105     # Use Bishop's method to calculate points on the IV curve with V ranging\n106     # from the reverse breakdown voltage to open circuit\n107     kwargs = {\n108         'breakdown_factor': parameters['breakdown_factor'],\n109         'breakdown_exp': parameters['breakdown_exp'],\n110         'breakdown_voltage': parameters['breakdown_voltage'],\n111     }\n112     v_oc = singlediode.bishop88_v_from_i(\n113         0.0, *sde_args, **kwargs\n114     )\n115     # ideally would use some intelligent log-spacing to concentrate points\n116     # around the forward- and reverse-bias knees, but this is good enough:\n117     vd = np.linspace(0.99*kwargs['breakdown_voltage'], v_oc, ivcurve_pnts)\n118 \n119     ivcurve_i, ivcurve_v, _ = singlediode.bishop88(vd, *sde_args, **kwargs)\n120     return pd.DataFrame({\n121         'i': ivcurve_i,\n122         'v': ivcurve_v,\n123     })\n124 \n125 \n126 # %%\n127 # Now that we can calculate cell-level IV curves, let's compare a\n128 # fully-illuminated cell's curve to a shaded cell's curve.  Note that shading\n129 # typically does not reduce a cell's illumination to zero -- tree shading and\n130 # row-to-row shading block the beam portion of irradiance but leave the diffuse\n131 # portion largely intact.  In this example plot, we choose :math:`200 W/m^2`\n132 # as the amount of irradiance received by a shaded cell.\n133 \n134 def plot_curves(dfs, labels, title):\n135     \"\"\"plot the forward- and reverse-bias portions of an IV curve\"\"\"\n136     fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5, 3))\n137     for df, label in zip(dfs, labels):\n138         df.plot('v', 'i', label=label, ax=axes[0])\n139         df.plot('v', 'i', label=label, ax=axes[1])\n140         axes[0].set_xlim(right=0)\n141         axes[0].set_ylim([0, 25])\n142         axes[1].set_xlim([0, df['v'].max()*1.5])\n143     axes[0].set_ylabel('current [A]')\n144     axes[0].set_xlabel('voltage [V]')\n145     axes[1].set_xlabel('voltage [V]')\n146     fig.suptitle(title)\n147     fig.tight_layout()\n148     return axes\n149 \n150 \n151 cell_curve_full_sun = simulate_full_curve(cell_parameters, Geff=1000, Tcell=25)\n152 cell_curve_shaded = simulate_full_curve(cell_parameters, Geff=200, Tcell=25)\n153 ax = plot_curves([cell_curve_full_sun, cell_curve_shaded],\n154                  labels=['Full Sun', 'Shaded'],\n155                  title='Cell-level reverse- and forward-biased IV curves')\n156 \n157 # %%\n158 # This figure shows how a cell's current decreases roughly in proportion to\n159 # the irradiance reduction from shading, but voltage changes much less.\n160 # At the cell level, the effect of shading is essentially to shift the I-V\n161 # curve down to lower currents rather than change the curve's shape.\n162 #\n163 # Note that the forward and reverse curves are plotted separately to\n164 # accommodate the different voltage scales involved -- a normal crystalline\n165 # silicon cell reaches only ~0.6V in forward bias, but can get to -10 to -20V\n166 # in reverse bias.\n167 #\n168 # Combining cell IV curves to create a module IV curve\n169 # ----------------------------------------------------\n170 #\n171 # To combine the individual cell IV curves and form a module's IV curve,\n172 # the cells in each substring must be added in series.  The substrings are\n173 # in series as well, but with parallel bypass diodes to protect from reverse\n174 # bias voltages.  To add in series, the voltages for a given current are\n175 # added.  However, because each cell's curve is discretized and the currents\n176 # might not line up, we align each curve to a common set of current values\n177 # with interpolation.\n178 \n179 \n180 def interpolate(df, i):\n181     \"\"\"convenience wrapper around scipy.interpolate.interp1d\"\"\"\n182     f_interp = interp1d(np.flipud(df['i']), np.flipud(df['v']), kind='linear',\n183                         fill_value='extrapolate')\n184     return f_interp(i)\n185 \n186 \n187 def combine_series(dfs):\n188     \"\"\"\n189     Combine IV curves in series by aligning currents and summing voltages.\n190     The current range is based on the first curve's current range.\n191     \"\"\"\n192     df1 = dfs[0]\n193     imin = df1['i'].min()\n194     imax = df1['i'].max()\n195     i = np.linspace(imin, imax, 1000)\n196     v = 0\n197     for df2 in dfs:\n198         v_cell = interpolate(df2, i)\n199         v += v_cell\n200     return pd.DataFrame({'i': i, 'v': v})\n201 \n202 \n203 # %%\n204 # Rather than simulate all 72 cells in the module, we'll assume that there\n205 # are only three types of cells (fully illuminated, fully shaded, and\n206 # partially shaded), and within each type all cells behave identically.  This\n207 # means that simulating one cell from each type (for three cell simulations\n208 # total) is sufficient to model the module as a whole.\n209 #\n210 # This function also models the effect of bypass diodes in parallel with each\n211 # substring.  Bypass diodes are normally inactive but conduct when substring\n212 # voltage becomes sufficiently negative, presumably due to the substring\n213 # entering reverse bias from mismatch between substrings.  In that case the\n214 # substring's voltage is clamped to the diode's trigger voltage (assumed to\n215 # be 0.5V here).\n216 \n217 def simulate_module(cell_parameters, poa_direct, poa_diffuse, Tcell,\n218                     shaded_fraction, cells_per_string=24, strings=3):\n219     \"\"\"\n220     Simulate the IV curve for a partially shaded module.\n221     The shade is assumed to be coming up from the bottom of the module when in\n222     portrait orientation, so it affects all substrings equally.\n223     For simplicity, cell temperature is assumed to be uniform across the\n224     module, regardless of variation in cell-level illumination.\n225     Substrings are assumed to be \"down and back\", so the number of cells per\n226     string is divided between two columns of cells.\n227     \"\"\"\n228     # find the number of cells per column that are in full shadow\n229     nrow = cells_per_string // 2\n230     nrow_full_shade = int(shaded_fraction * nrow)\n231     # find the fraction of shade in the border row\n232     partial_shade_fraction = 1 - (shaded_fraction * nrow - nrow_full_shade)\n233 \n234     df_lit = simulate_full_curve(\n235         cell_parameters,\n236         poa_diffuse + poa_direct,\n237         Tcell)\n238     df_partial = simulate_full_curve(\n239         cell_parameters,\n240         poa_diffuse + partial_shade_fraction * poa_direct,\n241         Tcell)\n242     df_shaded = simulate_full_curve(\n243         cell_parameters,\n244         poa_diffuse,\n245         Tcell)\n246     # build a list of IV curves for a single column of cells (half a substring)\n247     include_partial_cell = (shaded_fraction < 1)\n248     half_substring_curves = (\n249         [df_lit] * (nrow - nrow_full_shade - 1)\n250         + ([df_partial] if include_partial_cell else [])  # noqa: W503\n251         + [df_shaded] * nrow_full_shade  # noqa: W503\n252     )\n253     substring_curve = combine_series(half_substring_curves)\n254     substring_curve['v'] *= 2  # turn half strings into whole strings\n255     # bypass diode:\n256     substring_curve['v'] = substring_curve['v'].clip(lower=-0.5)\n257     # no need to interpolate since we're just scaling voltage directly:\n258     substring_curve['v'] *= strings\n259     return substring_curve\n260 \n261 # %%\n262 # Now let's see how shade affects the IV curves at the module level.  For this\n263 # example, the bottom 10% of the module is shaded.  Assuming 12 cells per\n264 # column, that means one row of cells is fully shaded and another row is\n265 # partially shaded.  Even though only 10% of the module is shaded, the\n266 # maximum power is decreased by roughly 80%!\n267 #\n268 # Note the effect of the bypass diodes.  Without bypass diodes, operating the\n269 # shaded module at the same current as the fully illuminated module would\n270 # create a reverse-bias voltage of several hundred volts!  However, the diodes\n271 # prevent the reverse voltage from exceeding 1.5V (three diodes at 0.5V each).\n272 \n273 \n274 kwargs = {\n275     'cell_parameters': cell_parameters,\n276     'poa_direct': 800,\n277     'poa_diffuse': 200,\n278     'Tcell': 25\n279 }\n280 module_curve_full_sun = simulate_module(shaded_fraction=0, **kwargs)\n281 module_curve_shaded = simulate_module(shaded_fraction=0.1, **kwargs)\n282 ax = plot_curves([module_curve_full_sun, module_curve_shaded],\n283                  labels=['Full Sun', 'Shaded'],\n284                  title='Module-level reverse- and forward-biased IV curves')\n285 \n286 # %%\n287 # Calculating shading loss across shading scenarios\n288 # -------------------------------------------------\n289 #\n290 # Clearly the module-level IV-curve is strongly affected by partial shading.\n291 # This heatmap shows the module maximum power under a range of partial shade\n292 # conditions, where \"diffuse fraction\" refers to the ratio\n293 # :math:`poa_{diffuse} / poa_{global}` and \"shaded fraction\" refers to the\n294 # fraction of the module that receives only diffuse irradiance.\n295 \n296 \n297 def find_pmp(df):\n298     \"\"\"simple function to find Pmp on an IV curve\"\"\"\n299     return df.product(axis=1).max()\n300 \n301 \n302 # find Pmp under different shading conditions\n303 data = []\n304 for diffuse_fraction in np.linspace(0, 1, 11):\n305     for shaded_fraction in np.linspace(0, 1, 51):\n306 \n307         df = simulate_module(cell_parameters,\n308                              poa_direct=(1-diffuse_fraction)*1000,\n309                              poa_diffuse=diffuse_fraction*1000,\n310                              Tcell=25,\n311                              shaded_fraction=shaded_fraction)\n312         data.append({\n313             'fd': diffuse_fraction,\n314             'fs': shaded_fraction,\n315             'pmp': find_pmp(df)\n316         })\n317 \n318 results = pd.DataFrame(data)\n319 results['pmp'] /= results['pmp'].max()  # normalize power to 0-1\n320 results_pivot = results.pivot('fd', 'fs', 'pmp')\n321 plt.figure()\n322 plt.imshow(results_pivot, origin='lower', aspect='auto')\n323 plt.xlabel('shaded fraction')\n324 plt.ylabel('diffuse fraction')\n325 xlabels = [\"{:0.02f}\".format(fs) for fs in results_pivot.columns[::5]]\n326 ylabels = [\"{:0.02f}\".format(fd) for fd in results_pivot.index]\n327 plt.xticks(range(0, 5*len(xlabels), 5), xlabels)\n328 plt.yticks(range(0, len(ylabels)), ylabels)\n329 plt.title('Module P_mp across shading conditions')\n330 plt.colorbar()\n331 plt.show()\n332 # use this figure as the thumbnail:\n333 # sphinx_gallery_thumbnail_number = 3\n334 \n335 # %%\n336 # The heatmap makes a few things evident:\n337 #\n338 # - When diffuse fraction is equal to 1, there is no beam irradiance to lose,\n339 #   so shading has no effect on production.\n340 # - When shaded fraction is equal to 0, no irradiance is blocked, so module\n341 #   output does not change with the diffuse fraction.\n342 # - Under sunny conditions (diffuse fraction < 0.5), module output is\n343 #   significantly reduced after just the first cell is shaded\n344 #   (1/12 = ~8% shaded fraction).\n345 \n[end of docs/examples/plot_partial_module_shading_simple.py]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 \n8 \n9 TEMPERATURE_MODEL_PARAMETERS = {\n10     'sapm': {\n11         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n12         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n13         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n14         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n15     },\n16     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n17                'insulated': {'u_c': 15.0, 'u_v': 0}}\n18 }\n19 \n20 \n21 def _temperature_model_params(model, parameter_set):\n22     try:\n23         params = TEMPERATURE_MODEL_PARAMETERS[model]\n24         return params[parameter_set]\n25     except KeyError:\n26         msg = ('{} is not a named set of parameters for the {} cell'\n27                ' temperature model.'\n28                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n29                ' for names'.format(parameter_set, model))\n30         raise KeyError(msg)\n31 \n32 \n33 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n34               irrad_ref=1000):\n35     r'''\n36     Calculate cell temperature per the Sandia Array Performance Model.\n37 \n38     See [1]_ for details on the Sandia Array Performance Model.\n39 \n40     Parameters\n41     ----------\n42     poa_global : numeric\n43         Total incident irradiance [W/m^2].\n44 \n45     temp_air : numeric\n46         Ambient dry bulb temperature [C].\n47 \n48     wind_speed : numeric\n49         Wind speed at a height of 10 meters [m/s].\n50 \n51     a : float\n52         Parameter :math:`a` in :eq:`sapm1`.\n53 \n54     b : float\n55         Parameter :math:`b` in :eq:`sapm1`.\n56 \n57     deltaT : float\n58         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n59 \n60     irrad_ref : float, default 1000\n61         Reference irradiance, parameter :math:`E_{0}` in\n62         :eq:`sapm2` [W/m^2].\n63 \n64     Returns\n65     -------\n66     numeric, values in degrees C.\n67 \n68     Notes\n69     -----\n70     The model for cell temperature :math:`T_{C}` is given by a pair of\n71     equations (Eq. 11 and 12 in [1]_).\n72 \n73     .. math::\n74        :label: sapm1\n75 \n76        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n77 \n78     .. math::\n79        :label: sapm2\n80 \n81        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n82 \n83     The module back surface temperature :math:`T_{m}` is implemented in\n84     :py:func:`~pvlib.temperature.sapm_module`.\n85 \n86     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n87     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n88     the module construction and its mounting. Parameter sets are provided in\n89     [1]_ for representative modules and mounting, and are coded for convenience\n90     in ``pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS``.\n91 \n92     +---------------+----------------+-------+---------+---------------------+\n93     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n94     +===============+================+=======+=========+=====================+\n95     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n96     +---------------+----------------+-------+---------+---------------------+\n97     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n98     +---------------+----------------+-------+---------+---------------------+\n99     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n100     +---------------+----------------+-------+---------+---------------------+\n101     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n102     +---------------+----------------+-------+---------+---------------------+\n103 \n104     References\n105     ----------\n106     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n107        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n108        NM.\n109 \n110     See also\n111     --------\n112     sapm_cell_from_module\n113     sapm_module\n114 \n115     Examples\n116     --------\n117     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n118     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n119     >>> sapm_cell(1000, 10, 0, **params)\n120     44.11703066106086\n121     '''\n122     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n123                                      a, b)\n124     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n125                                  irrad_ref)\n126 \n127 \n128 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n129     r'''\n130     Calculate module back surface temperature per the Sandia Array\n131     Performance Model.\n132 \n133     See [1]_ for details on the Sandia Array Performance Model.\n134 \n135     Parameters\n136     ----------\n137     poa_global : numeric\n138         Total incident irradiance [W/m^2].\n139 \n140     temp_air : numeric\n141         Ambient dry bulb temperature [C].\n142 \n143     wind_speed : numeric\n144         Wind speed at a height of 10 meters [m/s].\n145 \n146     a : float\n147         Parameter :math:`a` in :eq:`sapm1mod`.\n148 \n149     b : float\n150         Parameter :math:`b` in :eq:`sapm1mod`.\n151 \n152     Returns\n153     -------\n154     numeric, values in degrees C.\n155 \n156     Notes\n157     -----\n158     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n159 \n160     .. math::\n161        :label: sapm1mod\n162 \n163        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n164 \n165     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n166     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n167     temperature at the back of the module :math:`T_{m}` and cell temperature\n168     :math:`T_{C}`. Model parameters depend both on the module construction and\n169     its mounting. Parameter sets are provided in [1]_ for representative\n170     modules and mounting, and are coded for convenience in\n171     ``temperature.TEMPERATURE_MODEL_PARAMETERS``.\n172 \n173     +---------------+----------------+-------+---------+---------------------+\n174     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n175     +===============+================+=======+=========+=====================+\n176     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n177     +---------------+----------------+-------+---------+---------------------+\n178     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n179     +---------------+----------------+-------+---------+---------------------+\n180     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n181     +---------------+----------------+-------+---------+---------------------+\n182     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n183     +---------------+----------------+-------+---------+---------------------+\n184 \n185     References\n186     ----------\n187     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n188        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n189        NM.\n190 \n191     See also\n192     --------\n193     sapm_cell\n194     sapm_cell_from_module\n195     '''\n196     return poa_global * np.exp(a + b * wind_speed) + temp_air\n197 \n198 \n199 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n200                           irrad_ref=1000):\n201     r'''\n202     Calculate cell temperature from module temperature using the Sandia Array\n203     Performance Model.\n204 \n205     See [1]_ for details on the Sandia Array Performance Model.\n206 \n207     Parameters\n208     ----------\n209     module_temperature : numeric\n210         Temperature of back of module surface [C].\n211 \n212     poa_global : numeric\n213         Total incident irradiance [W/m^2].\n214 \n215     deltaT : float\n216         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n217 \n218     irrad_ref : float, default 1000\n219         Reference irradiance, parameter :math:`E_{0}` in\n220         :eq:`sapm2` [W/m^2].\n221 \n222     Returns\n223     -------\n224     numeric, values in degrees C.\n225 \n226     Notes\n227     -----\n228     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n229 \n230     .. math::\n231        :label: sapm2_cell_from_mod\n232 \n233        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n234 \n235     The module back surface temperature :math:`T_{m}` is implemented in\n236     :py:func:`~pvlib.temperature.sapm_module`.\n237 \n238     Model parameters depend both on the module construction and its mounting.\n239     Parameter sets are provided in [1]_ for representative modules and\n240     mounting, and are coded for convenience in\n241     ``pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS``.\n242 \n243     +---------------+----------------+-------+---------+---------------------+\n244     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n245     +===============+================+=======+=========+=====================+\n246     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n247     +---------------+----------------+-------+---------+---------------------+\n248     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n249     +---------------+----------------+-------+---------+---------------------+\n250     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n251     +---------------+----------------+-------+---------+---------------------+\n252     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n253     +---------------+----------------+-------+---------+---------------------+\n254 \n255     References\n256     ----------\n257     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n258        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n259        NM.\n260 \n261     See also\n262     --------\n263     sapm_cell\n264     sapm_module\n265     '''\n266     return module_temperature + (poa_global / irrad_ref) * deltaT\n267 \n268 \n269 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n270                 eta_m=0.1, alpha_absorption=0.9):\n271     r\"\"\"\n272     Calculate cell temperature using an empirical heat loss factor model\n273     as implemented in PVsyst.\n274 \n275     Parameters\n276     ----------\n277     poa_global : numeric\n278         Total incident irradiance [W/m^2].\n279 \n280     temp_air : numeric\n281         Ambient dry bulb temperature [C].\n282 \n283     wind_speed : numeric, default 1.0\n284         Wind speed in m/s measured at the same height for which the wind loss\n285         factor was determined.  The default value 1.0 m/2 is the wind\n286         speed at module height used to determine NOCT. [m/s]\n287 \n288     u_c : float, default 29.0\n289         Combined heat loss factor coefficient. The default value is\n290         representative of freestanding modules with the rear surfaces exposed\n291         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n292         :eq:`pvsyst`.\n293         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n294 \n295     u_v : float, default 0.0\n296         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n297         in :eq:`pvsyst`.\n298         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n299 \n300     eta_m : numeric, default 0.1\n301         Module external efficiency as a fraction, i.e., DC power / poa_global.\n302         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n303 \n304     alpha_absorption : numeric, default 0.9\n305         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n306 \n307     Returns\n308     -------\n309     numeric, values in degrees Celsius\n310 \n311     Notes\n312     -----\n313     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n314 \n315     .. math::\n316        :label: pvsyst\n317 \n318         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n319 \n320     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n321     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n322     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n323     the module construction and its mounting. Parameters are provided in\n324     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n325     , and are coded for convenience in\n326     ``temperature.TEMPERATURE_MODEL_PARAMETERS``. The heat loss factors\n327     provided represent the combined effect of convection, radiation and\n328     conduction, and their values are experimentally determined.\n329 \n330     +--------------+---------------+---------------+\n331     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n332     +==============+===============+===============+\n333     | freestanding | 29.0          | 0.0           |\n334     +--------------+---------------+---------------+\n335     | insulated    | 15.0          | 0.0           |\n336     +--------------+---------------+---------------+\n337 \n338     References\n339     ----------\n340     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n341        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n342 \n343     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n344        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n345 \n346     Examples\n347     --------\n348     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n349     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n350     >>> pvsyst_cell(1000, 10, **params)\n351     37.93103448275862\n352     \"\"\"\n353 \n354     total_loss_factor = u_c + u_v * wind_speed\n355     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n356     temp_difference = heat_input / total_loss_factor\n357     return temp_air + temp_difference\n358 \n359 \n360 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n361     r'''\n362     Calculate cell or module temperature using the Faiman model.  The Faiman\n363     model uses an empirical heat loss factor model [1]_ and is adopted in the\n364     IEC 61853 standards [2]_ and [3]_.\n365 \n366     Usage of this model in the IEC 61853 standard does not distinguish\n367     between cell and module temperature.\n368 \n369     Parameters\n370     ----------\n371     poa_global : numeric\n372         Total incident irradiance [W/m^2].\n373 \n374     temp_air : numeric\n375         Ambient dry bulb temperature [C].\n376 \n377     wind_speed : numeric, default 1.0\n378         Wind speed in m/s measured at the same height for which the wind loss\n379         factor was determined.  The default value 1.0 m/s is the wind\n380         speed at module height used to determine NOCT. [m/s]\n381 \n382     u0 : numeric, default 25.0\n383         Combined heat loss factor coefficient. The default value is one\n384         determined by Faiman for 7 silicon modules.\n385         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n386 \n387     u1 : numeric, default 6.84\n388         Combined heat loss factor influenced by wind. The default value is one\n389         determined by Faiman for 7 silicon modules.\n390         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n391 \n392     Returns\n393     -------\n394     numeric, values in degrees Celsius\n395 \n396     Notes\n397     -----\n398     All arguments may be scalars or vectors. If multiple arguments\n399     are vectors they must be the same length.\n400 \n401     References\n402     ----------\n403     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n404        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n405 \n406     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n407        rating - Part 2: Spectral responsivity, incidence angle and module\n408        operating temperature measurements\". IEC, Geneva, 2018.\n409 \n410     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n411        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n412 \n413     '''\n414     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n415 \n416     # The following lines may seem odd since u0 & u1 are probably scalar,\n417     # but it serves an indirect and easy way of allowing lists and\n418     # tuples for the other function arguments.\n419     u0 = np.asanyarray(u0)\n420     u1 = np.asanyarray(u1)\n421 \n422     total_loss_factor = u0 + u1 * wind_speed\n423     heat_input = poa_global\n424     temp_difference = heat_input / total_loss_factor\n425     return temp_air + temp_difference\n426 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "27872b83b0932cc419116f79e442963cced935bb", "problem_statement": "make read_crn accomodate bad files\nA couple of issues with our `read_crn` function. \r\n\r\nFirst, the character sequence '\\x00\\x00\\x00\\x00\\x00\\x00' occasionally shows up and trips up pandas. This can be fixed by adding `na_values=['\\x00\\x00\\x00\\x00\\x00\\x00']` to the reader.\r\n\r\nSecond, we try to set the `CRX_VN` column to dtype int, but it occasionally has floats that cannot be coerced. The [documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/subhourly01/README.txt) says it should be treated like a string.\r\n\r\nExample below shows both issues in `'CRNS0101-05-2020-FL_Titusville_7_E.txt'`\r\n\r\n```\r\n92821 20200706 1145 20200706 0645      3  -80.69   28.62    24.5     0.0    151 0    24.7 C 0    94 0 -99.000 -9999.0   990 0   1.23 0\r\n92821 20200706 1150 20200706 0650      3  -80.69   28.62    24.7     0.0    168 0    25.0 C 0    94 0 -99.000 -9999.0   990 0   1.28 0\r\n92821 20200706 1155 20200706 0655      3  -80.69   28.62    24.9     0.0    173 0    25.3 C 0    93 0 -99.000 -9999.0   990 0   1.48 0\r\n92821 20200706 1200 20200706 0700      3  -80.69   28.62    24.9     0.0    190 0    25.5 C 0    93 0 -99.000 -9999.0   990 0   1.57 0\r\n\\x00\\x00\\x00\\x00\\x00\\x00 repeated\r\n92821 20200706 1305 20200706 0805  2.623  -80.69   28.62    26.8     0.0    409 0    30.0 C 0    87 0 -99.000 -9999.0   988 0   1.44 0\r\n92821 20200706 1310 20200706 0810  2.623  -80.69   28.62    26.9     0.0    430 0    30.2 C 0    87 0 -99.000 -9999.0   989 0   1.64 0\r\n92821 20200706 1315 20200706 0815  2.623  -80.69   28.62    27.0     0.0    445 0    30.4 C 0    86 0 -99.000 -9999.0   989 0   1.94 0\r\n92821 20200706 1320 20200706 0820  2.623  -80.69   28.62    27.3     0.0    463 0    30.8 C 0    86 0 -99.000 -9999.0   988 0   1.50 0\r\n92821 20200706 1325 20200706 0825  2.623  -80.69   28.62    27.6     0.0    478 0    31.1 C 0    85 0 -99.000 -9999.0   988 0   1.54 0\r\n92821 20200706 1330 20200706 0830  2.623  -80.69   28.62    27.6     0.0    496 0    31.5 C 0    84 0 -99.000 -9999.0   988 0   1.48 0\r\n```\r\n\r\nfyi @lboeman \n", "hints_text": "", "created_at": "2020-08-21T16:27:41Z", "patch": "<patch>\ndiff --git a/pvlib/iotools/crn.py b/pvlib/iotools/crn.py\n--- a/pvlib/iotools/crn.py\n+++ b/pvlib/iotools/crn.py\n@@ -33,7 +33,7 @@\n \n # specify dtypes for potentially problematic values\n DTYPES = [\n-    'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', 'float64',\n+    'int64', 'int64', 'int64', 'int64', 'int64', 'str', 'float64', 'float64',\n     'float64', 'float64', 'float64', 'int64', 'float64', 'O', 'int64',\n     'float64', 'int64', 'float64', 'float64', 'int64', 'int64', 'float64',\n     'int64'\n@@ -67,6 +67,13 @@ def read_crn(filename):\n     e.g. `SOLAR_RADIATION` becomes `ghi`. See the\n     `pvlib.iotools.crn.VARIABLE_MAP` dict for the complete mapping.\n \n+    CRN files occasionally have a set of null characters on a line\n+    instead of valid data. This function drops those lines. Sometimes\n+    these null characters appear on a line of their own and sometimes\n+    they occur on the same line as valid data. In the latter case, the\n+    valid data will not be returned. Users may manually remove the null\n+    characters and reparse the file if they need that line.\n+\n     References\n     ----------\n     .. [1] U.S. Climate Reference Network\n@@ -78,9 +85,13 @@ def read_crn(filename):\n        Amer. Meteor. Soc., 94, 489-498. :doi:`10.1175/BAMS-D-12-00170.1`\n     \"\"\"\n \n-    # read in data\n+    # read in data. set fields with NUL characters to NaN\n     data = pd.read_fwf(filename, header=None, names=HEADERS.split(' '),\n-                       widths=WIDTHS)\n+                       widths=WIDTHS, na_values=['\\x00\\x00\\x00\\x00\\x00\\x00'])\n+    # at this point we only have NaNs from NUL characters, not -999 etc.\n+    # these bad rows need to be removed so that dtypes can be set.\n+    # NaNs require float dtype so we run into errors if we don't do this.\n+    data = data.dropna(axis=0)\n     # loop here because dtype kwarg not supported in read_fwf until 0.20\n     for (col, _dtype) in zip(data.columns, DTYPES):\n         data[col] = data[col].astype(_dtype)\n@@ -98,8 +109,11 @@ def read_crn(filename):\n     except TypeError:\n         pass\n \n-    # set nans\n+    # Now we can set nans. This could be done a per column basis to be\n+    # safer, since in principle a real -99 value could occur in a -9999\n+    # column. Very unlikely to see that in the real world.\n     for val in [-99, -999, -9999]:\n+        # consider replacing with .replace([-99, -999, -9999])\n         data = data.where(data != val, np.nan)\n \n     data = data.rename(columns=VARIABLE_MAP)\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/iotools/test_crn.py b/pvlib/tests/iotools/test_crn.py\n--- a/pvlib/tests/iotools/test_crn.py\n+++ b/pvlib/tests/iotools/test_crn.py\n@@ -8,18 +8,39 @@\n \n \n @pytest.fixture\n-def testfile():\n-    return DATA_DIR / 'CRNS0101-05-2019-AZ_Tucson_11_W.txt'\n-\n-\n-def test_read_crn(testfile):\n-    columns = [\n+def columns():\n+    return [\n         'WBANNO', 'UTC_DATE', 'UTC_TIME', 'LST_DATE', 'LST_TIME', 'CRX_VN',\n         'longitude', 'latitude', 'temp_air', 'PRECIPITATION', 'ghi',\n         'ghi_flag',\n         'SURFACE_TEMPERATURE', 'ST_TYPE', 'ST_FLAG', 'relative_humidity',\n         'relative_humidity_flag', 'SOIL_MOISTURE_5', 'SOIL_TEMPERATURE_5',\n         'WETNESS', 'WET_FLAG', 'wind_speed', 'wind_speed_flag']\n+\n+\n+@pytest.fixture\n+def dtypes():\n+    return [\n+        dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n+        dtype('int64'), dtype('O'), dtype('float64'), dtype('float64'),\n+        dtype('float64'), dtype('float64'), dtype('float64'),\n+        dtype('int64'), dtype('float64'), dtype('O'), dtype('int64'),\n+        dtype('float64'), dtype('int64'), dtype('float64'),\n+        dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'),\n+        dtype('int64')]\n+\n+\n+@pytest.fixture\n+def testfile():\n+    return DATA_DIR / 'CRNS0101-05-2019-AZ_Tucson_11_W.txt'\n+\n+\n+@pytest.fixture\n+def testfile_problems():\n+    return DATA_DIR / 'CRN_with_problems.txt'\n+\n+\n+def test_read_crn(testfile, columns, dtypes):\n     index = pd.DatetimeIndex(['2019-01-01 16:10:00',\n                               '2019-01-01 16:15:00',\n                               '2019-01-01 16:20:00',\n@@ -34,16 +55,26 @@ def test_read_crn(testfile):\n          0.0, 340.0, 0, 4.3, 'C', 0, 83.0, 0, nan, nan, 1183, 0, 0.53, 0],\n         [53131, 20190101, 1625, 20190101, 925, 3, -111.17, 32.24, 4.0,\n          0.0, 393.0, 0, 4.8, 'C', 0, 81.0, 0, nan, nan, 1223, 0, 0.64, 0]])\n-    dtypes = [\n-        dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n-        dtype('int64'), dtype('int64'), dtype('float64'), dtype('float64'),\n-        dtype('float64'), dtype('float64'), dtype('float64'),\n-        dtype('int64'), dtype('float64'), dtype('O'), dtype('int64'),\n-        dtype('float64'), dtype('int64'), dtype('float64'),\n-        dtype('float64'), dtype('int64'), dtype('int64'), dtype('float64'),\n-        dtype('int64')]\n     expected = pd.DataFrame(values, columns=columns, index=index)\n     for (col, _dtype) in zip(expected.columns, dtypes):\n         expected[col] = expected[col].astype(_dtype)\n     out = crn.read_crn(testfile)\n     assert_frame_equal(out, expected)\n+\n+\n+def test_read_crn_problems(testfile_problems, columns, dtypes):\n+    # GH1025\n+    index = pd.DatetimeIndex(['2020-07-06 12:00:00',\n+                              '2020-07-06 13:10:00'],\n+                             freq=None).tz_localize('UTC')\n+    values = np.array([\n+        [92821, 20200706, 1200, 20200706, 700, '3', -80.69, 28.62, 24.9,\n+         0.0, 190.0, 0, 25.5, 'C', 0, 93.0, 0, nan, nan, 990, 0, 1.57, 0],\n+        [92821, 20200706, 1310, 20200706, 810, '2.623', -80.69, 28.62,\n+         26.9, 0.0, 430.0, 0, 30.2, 'C', 0, 87.0, 0, nan, nan, 989, 0,\n+         1.64, 0]])\n+    expected = pd.DataFrame(values, columns=columns, index=index)\n+    for (col, _dtype) in zip(expected.columns, dtypes):\n+        expected[col] = expected[col].astype(_dtype)\n+    out = crn.read_crn(testfile_problems)\n+    assert_frame_equal(out, expected)\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/iotools/test_crn.py::test_read_crn\"]", "PASS_TO_PASS": "[]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-980_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\npvlib.soiling.hsu model implementation errors\n**Describe the bug**\r\nI ran an example run using the Matlab version of the HSU soiling function and found that the python version did not give anywhere near the same results.  The Matlab results matched the results in the original JPV paper.  As a result of this test, I found two errors in the python implementation, which are listed below:\r\n\r\n1.  depo_veloc = {'2_5': 0.004, '10': 0.0009} has the wrong default values.  They are reversed.\r\nThe proper dictionary should be: {'2_5': 0.0009, '10': 0.004}.  This is confirmed in the JPV paper and the Matlab version of the function.\r\n\r\n2. The horiz_mass_rate is in g/(m^2*hr) but should be in g/(m^2*s).  The line needs to be multiplied by 60x60 or 3600.\r\nThe proper line of code should be: \r\nhoriz_mass_rate = (pm2_5 * depo_veloc['2_5']+ np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'])*3600\r\n\r\nWhen I made these changes I was able to match the validation dataset from the JPV paper, as shown below.\r\n![image](https://user-images.githubusercontent.com/5392756/82380831-61c43d80-99e6-11ea-9ee3-2368fa71e580.png)\r\n\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of pvlib/iam.py]\n1 r\"\"\"\n2 The ``iam`` module contains functions that implement models for the incidence\n3 angle modifier (IAM). The IAM quantifies the fraction of direct irradiance on\n4 a module's front surface that is transmitted through the module materials to\n5 the cells. Stated differently, the quantity 1 - IAM is the fraction of direct\n6 irradiance that is reflected away or absorbed by the module's front materials.\n7 IAM is typically a function of the angle of incidence (AOI) of the direct\n8 irradiance to the module's surface.\n9 \"\"\"\n10 \n11 import numpy as np\n12 import pandas as pd\n13 import functools\n14 from pvlib.tools import cosd, sind, tand, asind\n15 \n16 # a dict of required parameter names for each IAM model\n17 # keys are the function names for the IAM models\n18 _IAM_MODEL_PARAMS = {\n19     'ashrae': set(['b']),\n20     'physical': set(['n', 'K', 'L']),\n21     'martin_ruiz': set(['a_r']),\n22     'sapm': set(['B0', 'B1', 'B2', 'B3', 'B4', 'B5']),\n23     'interp': set([])\n24 }\n25 \n26 \n27 def ashrae(aoi, b=0.05):\n28     r\"\"\"\n29     Determine the incidence angle modifier using the ASHRAE transmission\n30     model.\n31 \n32     The ASHRAE (American Society of Heating, Refrigeration, and Air\n33     Conditioning Engineers) transmission model is developed in\n34     [1]_, and in [2]_. The model has been used in software such as PVSyst [3]_.\n35 \n36     Parameters\n37     ----------\n38     aoi : numeric\n39         The angle of incidence (AOI) between the module normal vector and the\n40         sun-beam vector in degrees. Angles of nan will result in nan.\n41 \n42     b : float, default 0.05\n43         A parameter to adjust the incidence angle modifier as a function of\n44         angle of incidence. Typical values are on the order of 0.05 [3].\n45 \n46     Returns\n47     -------\n48     iam : numeric\n49         The incident angle modifier (IAM). Returns zero for all abs(aoi) >= 90\n50         and for all ``iam`` values that would be less than 0.\n51 \n52     Notes\n53     -----\n54     The incidence angle modifier is calculated as\n55 \n56     .. math::\n57 \n58         IAM = 1 - b (\\sec(aoi) - 1)\n59 \n60     As AOI approaches 90 degrees, the model yields negative values for IAM;\n61     negative IAM values are set to zero in this implementation.\n62 \n63     References\n64     ----------\n65     .. [1] Souka A.F., Safwat H.H., \"Determination of the optimum\n66        orientations for the double exposure flat-plate collector and its\n67        reflections\". Solar Energy vol .10, pp 170-174. 1966.\n68 \n69     .. [2] ASHRAE standard 93-77\n70 \n71     .. [3] PVsyst Contextual Help.\n72        https://files.pvsyst.com/help/index.html?iam_loss.htm retrieved on\n73        October 14, 2019\n74 \n75     See Also\n76     --------\n77     pvlib.iam.physical\n78     pvlib.iam.martin_ruiz\n79     pvlib.iam.interp\n80     \"\"\"\n81 \n82     iam = 1 - b * ((1 / np.cos(np.radians(aoi)) - 1))\n83     aoi_gte_90 = np.full_like(aoi, False, dtype='bool')\n84     np.greater_equal(np.abs(aoi), 90, where=~np.isnan(aoi), out=aoi_gte_90)\n85     iam = np.where(aoi_gte_90, 0, iam)\n86     iam = np.maximum(0, iam)\n87 \n88     if isinstance(aoi, pd.Series):\n89         iam = pd.Series(iam, index=aoi.index)\n90 \n91     return iam\n92 \n93 \n94 def physical(aoi, n=1.526, K=4., L=0.002):\n95     r\"\"\"\n96     Determine the incidence angle modifier using refractive index ``n``,\n97     extinction coefficient ``K``, and glazing thickness ``L``.\n98 \n99     ``iam.physical`` calculates the incidence angle modifier as described in\n100     [1]_, Section 3. The calculation is based on a physical model of absorbtion\n101     and transmission through a transparent cover.\n102 \n103     Parameters\n104     ----------\n105     aoi : numeric\n106         The angle of incidence between the module normal vector and the\n107         sun-beam vector in degrees. Angles of 0 are replaced with 1e-06\n108         to ensure non-nan results. Angles of nan will result in nan.\n109 \n110     n : numeric, default 1.526\n111         The effective index of refraction (unitless). Reference [1]_\n112         indicates that a value of 1.526 is acceptable for glass.\n113 \n114     K : numeric, default 4.0\n115         The glazing extinction coefficient in units of 1/meters.\n116         Reference [1] indicates that a value of 4 is reasonable for\n117         \"water white\" glass.\n118 \n119     L : numeric, default 0.002\n120         The glazing thickness in units of meters. Reference [1]_\n121         indicates that 0.002 meters (2 mm) is reasonable for most\n122         glass-covered PV panels.\n123 \n124     Returns\n125     -------\n126     iam : numeric\n127         The incident angle modifier\n128 \n129     Notes\n130     -----\n131     The pvlib python authors believe that Eqn. 14 in [1]_ is\n132     incorrect, which presents :math:`\\theta_{r} = \\arcsin(n \\sin(AOI))`.\n133     Here, :math:`\\theta_{r} = \\arcsin(1/n \\times \\sin(AOI))`\n134 \n135     References\n136     ----------\n137     .. [1] W. De Soto et al., \"Improvement and validation of a model for\n138        photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n139        2006.\n140 \n141     .. [2] Duffie, John A. & Beckman, William A.. (2006). Solar Engineering\n142        of Thermal Processes, third edition. [Books24x7 version] Available\n143        from http://common.books24x7.com/toc.aspx?bookid=17160.\n144 \n145     See Also\n146     --------\n147     pvlib.iam.martin_ruiz\n148     pvlib.iam.ashrae\n149     pvlib.iam.interp\n150     pvlib.iam.sapm\n151     \"\"\"\n152     zeroang = 1e-06\n153 \n154     # hold a new reference to the input aoi object since we're going to\n155     # overwrite the aoi reference below, but we'll need it for the\n156     # series check at the end of the function\n157     aoi_input = aoi\n158 \n159     aoi = np.where(aoi == 0, zeroang, aoi)\n160 \n161     # angle of reflection\n162     thetar_deg = asind(1.0 / n * (sind(aoi)))\n163 \n164     # reflectance and transmittance for normal incidence light\n165     rho_zero = ((1-n) / (1+n)) ** 2\n166     tau_zero = np.exp(-K*L)\n167 \n168     # reflectance for parallel and perpendicular polarized light\n169     rho_para = (tand(thetar_deg - aoi) / tand(thetar_deg + aoi)) ** 2\n170     rho_perp = (sind(thetar_deg - aoi) / sind(thetar_deg + aoi)) ** 2\n171 \n172     # transmittance for non-normal light\n173     tau = np.exp(-K * L / cosd(thetar_deg))\n174 \n175     # iam is ratio of non-normal to normal incidence transmitted light\n176     # after deducting the reflected portion of each\n177     iam = ((1 - (rho_para + rho_perp) / 2) / (1 - rho_zero) * tau / tau_zero)\n178 \n179     with np.errstate(invalid='ignore'):\n180         # angles near zero produce nan, but iam is defined as one\n181         small_angle = 1e-06\n182         iam = np.where(np.abs(aoi) < small_angle, 1.0, iam)\n183 \n184         # angles at 90 degrees can produce tiny negative values,\n185         # which should be zero. this is a result of calculation precision\n186         # rather than the physical model\n187         iam = np.where(iam < 0, 0, iam)\n188 \n189         # for light coming from behind the plane, none can enter the module\n190         iam = np.where(aoi > 90, 0, iam)\n191 \n192     if isinstance(aoi_input, pd.Series):\n193         iam = pd.Series(iam, index=aoi_input.index)\n194 \n195     return iam\n196 \n197 \n198 def martin_ruiz(aoi, a_r=0.16):\n199     r'''\n200     Determine the incidence angle modifier (IAM) using the Martin\n201     and Ruiz incident angle model.\n202 \n203     Parameters\n204     ----------\n205     aoi : numeric, degrees\n206         The angle of incidence between the module normal vector and the\n207         sun-beam vector in degrees.\n208 \n209     a_r : numeric\n210         The angular losses coefficient described in equation 3 of [1]_.\n211         This is an empirical dimensionless parameter. Values of ``a_r`` are\n212         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n213 \n214     Returns\n215     -------\n216     iam : numeric\n217         The incident angle modifier(s)\n218 \n219     Notes\n220     -----\n221     `martin_ruiz` calculates the incidence angle modifier (IAM) as described in\n222     [1]_. The information required is the incident angle (AOI) and the angular\n223     losses coefficient (a_r). Note that [1]_ has a corrigendum [2]_ which\n224     clarifies a mix-up of 'alpha's and 'a's in the former.\n225 \n226     The incident angle modifier is defined as\n227 \n228     .. math::\n229 \n230        IAM = \\frac{1 - \\exp(-\\cos(\\frac{aoi}{a_r}))}\n231        {1 - \\exp(\\frac{-1}{a_r}}\n232 \n233     which is presented as :math:`AL(\\alpha) = 1 - IAM` in equation 4 of [1]_,\n234     with :math:`\\alpha` representing the angle of incidence AOI. Thus IAM = 1\n235     at AOI = 0, and IAM = 0 at AOI = 90.  This equation is only valid for\n236     -90 <= aoi <= 90, therefore `iam` is constrained to 0.0 outside this\n237     interval.\n238 \n239     References\n240     ----------\n241     .. [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n242        losses under field conditions by means of an analytical model\", Solar\n243        Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n244 \n245     .. [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n246        modules angular losses under field conditions by means of an\n247        analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n248        pp. 154, 2013.\n249 \n250     See Also\n251     --------\n252     pvlib.iam.martin_ruiz_diffuse\n253     pvlib.iam.physical\n254     pvlib.iam.ashrae\n255     pvlib.iam.interp\n256     pvlib.iam.sapm\n257     '''\n258     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n259 \n260     aoi_input = aoi\n261 \n262     aoi = np.asanyarray(aoi)\n263     a_r = np.asanyarray(a_r)\n264 \n265     if np.any(np.less_equal(a_r, 0)):\n266         raise ValueError(\"The parameter 'a_r' cannot be zero or negative.\")\n267 \n268     with np.errstate(invalid='ignore'):\n269         iam = (1 - np.exp(-cosd(aoi) / a_r)) / (1 - np.exp(-1 / a_r))\n270         iam = np.where(np.abs(aoi) >= 90.0, 0.0, iam)\n271 \n272     if isinstance(aoi_input, pd.Series):\n273         iam = pd.Series(iam, index=aoi_input.index)\n274 \n275     return iam\n276 \n277 \n278 def martin_ruiz_diffuse(surface_tilt, a_r=0.16, c1=0.4244, c2=None):\n279     '''\n280     Determine the incidence angle modifiers (iam) for diffuse sky and\n281     ground-reflected irradiance using the Martin and Ruiz incident angle model.\n282 \n283     Parameters\n284     ----------\n285     surface_tilt: float or array-like, default 0\n286         Surface tilt angles in decimal degrees.\n287         The tilt angle is defined as degrees from horizontal\n288         (e.g. surface facing up = 0, surface facing horizon = 90)\n289         surface_tilt must be in the range [0, 180]\n290 \n291     a_r : numeric\n292         The angular losses coefficient described in equation 3 of [1]_.\n293         This is an empirical dimensionless parameter. Values of a_r are\n294         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n295         a_r must be greater than zero.\n296 \n297     c1 : float\n298         First fitting parameter for the expressions that approximate the\n299         integral of diffuse irradiance coming from different directions.\n300         c1 is given as the constant 4 / 3 / pi (0.4244) in [1]_.\n301 \n302     c2 : float\n303         Second fitting parameter for the expressions that approximate the\n304         integral of diffuse irradiance coming from different directions.\n305         If c2 is None, it will be calculated according to the linear\n306         relationship given in [3]_.\n307 \n308     Returns\n309     -------\n310     iam_sky : numeric\n311         The incident angle modifier for sky diffuse\n312 \n313     iam_ground : numeric\n314         The incident angle modifier for ground-reflected diffuse\n315 \n316     Notes\n317     -----\n318     Sky and ground modifiers are complementary: iam_sky for tilt = 30 is\n319     equal to iam_ground for tilt = 180 - 30.  For vertical surfaces,\n320     tilt = 90, the two factors are equal.\n321 \n322     References\n323     ----------\n324     .. [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n325        losses under field conditions by means of an analytical model\", Solar\n326        Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n327 \n328     .. [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n329        modules angular losses under field conditions by means of an\n330        analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n331        pp. 154, 2013.\n332 \n333     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n334        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n335 \n336     See Also\n337     --------\n338     pvlib.iam.martin_ruiz\n339     pvlib.iam.physical\n340     pvlib.iam.ashrae\n341     pvlib.iam.interp\n342     pvlib.iam.sapm\n343     '''\n344     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Oct. 2019\n345 \n346     if isinstance(surface_tilt, pd.Series):\n347         out_index = surface_tilt.index\n348     else:\n349         out_index = None\n350 \n351     surface_tilt = np.asanyarray(surface_tilt)\n352 \n353     # avoid undefined results for horizontal or upside-down surfaces\n354     zeroang = 1e-06\n355 \n356     surface_tilt = np.where(surface_tilt == 0, zeroang, surface_tilt)\n357     surface_tilt = np.where(surface_tilt == 180, 180 - zeroang, surface_tilt)\n358 \n359     if c2 is None:\n360         # This equation is from [3] Sect. 7.2\n361         c2 = 0.5 * a_r - 0.154\n362 \n363     beta = np.radians(surface_tilt)\n364 \n365     from numpy import pi, sin, cos, exp\n366 \n367     # avoid RuntimeWarnings for <, sin, and cos with nan\n368     with np.errstate(invalid='ignore'):\n369         # because sin(pi) isn't exactly zero\n370         sin_beta = np.where(surface_tilt < 90, sin(beta), sin(pi - beta))\n371 \n372         trig_term_sky = sin_beta + (pi - beta - sin_beta) / (1 + cos(beta))\n373         trig_term_gnd = sin_beta +      (beta - sin_beta) / (1 - cos(beta))  # noqa: E222 E261 E501\n374 \n375     iam_sky = 1 - exp(-(c1 + c2 * trig_term_sky) * trig_term_sky / a_r)\n376     iam_gnd = 1 - exp(-(c1 + c2 * trig_term_gnd) * trig_term_gnd / a_r)\n377 \n378     if out_index is not None:\n379         iam_sky = pd.Series(iam_sky, index=out_index, name='iam_sky')\n380         iam_gnd = pd.Series(iam_gnd, index=out_index, name='iam_ground')\n381 \n382     return iam_sky, iam_gnd\n383 \n384 \n385 def interp(aoi, theta_ref, iam_ref, method='linear', normalize=True):\n386     r'''\n387     Determine the incidence angle modifier (IAM) by interpolating a set of\n388     reference values, which are usually measured values.\n389 \n390     Parameters\n391     ----------\n392     aoi : numeric\n393         The angle of incidence between the module normal vector and the\n394         sun-beam vector [degrees].\n395 \n396     theta_ref : numeric\n397         Vector of angles at which the IAM is known [degrees].\n398 \n399     iam_ref : numeric\n400         IAM values for each angle in ``theta_ref`` [unitless].\n401 \n402     method : str, default 'linear'\n403         Specifies the interpolation method.\n404         Useful options are: 'linear', 'quadratic', 'cubic'.\n405         See scipy.interpolate.interp1d for more options.\n406 \n407     normalize : boolean, default True\n408         When true, the interpolated values are divided by the interpolated\n409         value at zero degrees.  This ensures that ``iam=1.0`` at normal\n410         incidence.\n411 \n412     Returns\n413     -------\n414     iam : numeric\n415         The incident angle modifier(s) [unitless]\n416 \n417     Notes\n418     -----\n419     ``theta_ref`` must have two or more points and may span any range of\n420     angles. Typically there will be a dozen or more points in the range 0-90\n421     degrees. Beyond the range of ``theta_ref``, IAM values are extrapolated,\n422     but constrained to be non-negative.\n423 \n424     The sign of ``aoi`` is ignored; only the magnitude is used.\n425 \n426     See Also\n427     --------\n428     pvlib.iam.physical\n429     pvlib.iam.ashrae\n430     pvlib.iam.martin_ruiz\n431     pvlib.iam.sapm\n432     '''\n433     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n434 \n435     from scipy.interpolate import interp1d\n436 \n437     # Scipy doesn't give the clearest feedback, so check number of points here.\n438     MIN_REF_VALS = {'linear': 2, 'quadratic': 3, 'cubic': 4, 1: 2, 2: 3, 3: 4}\n439 \n440     if len(theta_ref) < MIN_REF_VALS.get(method, 2):\n441         raise ValueError(\"Too few reference points defined \"\n442                          \"for interpolation method '%s'.\" % method)\n443 \n444     if np.any(np.less(iam_ref, 0)):\n445         raise ValueError(\"Negative value(s) found in 'iam_ref'. \"\n446                          \"This is not physically possible.\")\n447 \n448     interpolator = interp1d(theta_ref, iam_ref, kind=method,\n449                             fill_value='extrapolate')\n450     aoi_input = aoi\n451 \n452     aoi = np.asanyarray(aoi)\n453     aoi = np.abs(aoi)\n454     iam = interpolator(aoi)\n455     iam = np.clip(iam, 0, None)\n456 \n457     if normalize:\n458         iam /= interpolator(0)\n459 \n460     if isinstance(aoi_input, pd.Series):\n461         iam = pd.Series(iam, index=aoi_input.index)\n462 \n463     return iam\n464 \n465 \n466 def sapm(aoi, module, upper=None):\n467     r\"\"\"\n468     Determine the incidence angle modifier (IAM) using the SAPM model.\n469 \n470     Parameters\n471     ----------\n472     aoi : numeric\n473         Angle of incidence in degrees. Negative input angles will return\n474         zeros.\n475 \n476     module : dict-like\n477         A dict or Series with the SAPM IAM model parameters.\n478         See the :py:func:`sapm` notes section for more details.\n479 \n480     upper : None or float, default None\n481         Upper limit on the results.\n482 \n483     Returns\n484     -------\n485     iam : numeric\n486         The SAPM angle of incidence loss coefficient, termed F2 in [1]_.\n487 \n488     Notes\n489     -----\n490     The SAPM [1]_ traditionally does not define an upper limit on the AOI\n491     loss function and values slightly exceeding 1 may exist for moderate\n492     angles of incidence (15-40 degrees). However, users may consider\n493     imposing an upper limit of 1.\n494 \n495     References\n496     ----------\n497     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n498        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n499        NM.\n500 \n501     .. [2] B.H. King et al, \"Procedure to Determine Coefficients for the\n502        Sandia Array Performance Model (SAPM),\" SAND2016-5284, Sandia\n503        National Laboratories (2016).\n504 \n505     .. [3] B.H. King et al, \"Recent Advancements in Outdoor Measurement\n506        Techniques for Angle of Incidence Effects,\" 42nd IEEE PVSC (2015).\n507        DOI: 10.1109/PVSC.2015.7355849\n508 \n509     See Also\n510     --------\n511     pvlib.iam.physical\n512     pvlib.iam.ashrae\n513     pvlib.iam.martin_ruiz\n514     pvlib.iam.interp\n515     \"\"\"\n516 \n517     aoi_coeff = [module['B5'], module['B4'], module['B3'], module['B2'],\n518                  module['B1'], module['B0']]\n519 \n520     iam = np.polyval(aoi_coeff, aoi)\n521     iam = np.clip(iam, 0, upper)\n522     # nan tolerant masking\n523     aoi_lt_0 = np.full_like(aoi, False, dtype='bool')\n524     np.less(aoi, 0, where=~np.isnan(aoi), out=aoi_lt_0)\n525     iam = np.where(aoi_lt_0, 0, iam)\n526 \n527     if isinstance(aoi, pd.Series):\n528         iam = pd.Series(iam, aoi.index)\n529 \n530     return iam\n531 \n532 \n533 def marion_diffuse(model, surface_tilt, **kwargs):\n534     \"\"\"\n535     Determine diffuse irradiance incidence angle modifiers using Marion's\n536     method of integrating over solid angle.\n537 \n538     Parameters\n539     ----------\n540     model : str\n541         The IAM function to evaluate across solid angle. Must be one of\n542         `'ashrae', 'physical', 'martin_ruiz', 'sapm'`.\n543 \n544     surface_tilt : numeric\n545         Surface tilt angles in decimal degrees.\n546         The tilt angle is defined as degrees from horizontal\n547         (e.g. surface facing up = 0, surface facing horizon = 90).\n548 \n549     **kwargs\n550         Extra parameters passed to the IAM function.\n551 \n552     Returns\n553     -------\n554     iam : dict\n555         IAM values for each type of diffuse irradiance:\n556 \n557             * 'sky': radiation from the sky dome (zenith <= 90)\n558             * 'horizon': radiation from the region of the sky near the horizon\n559               (89.5 <= zenith <= 90)\n560             * 'ground': radiation reflected from the ground (zenith >= 90)\n561 \n562         See [1]_ for a detailed description of each class.\n563 \n564     See Also\n565     --------\n566     pvlib.iam.marion_integrate\n567 \n568     References\n569     ----------\n570     .. [1] B. Marion \"Numerical method for angle-of-incidence correction\n571        factors for diffuse radiation incident photovoltaic modules\",\n572        Solar Energy, Volume 147, Pages 344-348. 2017.\n573        DOI: 10.1016/j.solener.2017.03.027\n574 \n575     Examples\n576     --------\n577     >>> marion_diffuse('physical', surface_tilt=20)\n578     {'sky': 0.9539178294437575,\n579      'horizon': 0.7652650139134007,\n580      'ground': 0.6387140117795903}\n581 \n582     >>> marion_diffuse('ashrae', [20, 30], b=0.04)\n583     {'sky': array([0.96748999, 0.96938408]),\n584      'horizon': array([0.86478428, 0.91825792]),\n585      'ground': array([0.77004435, 0.8522436 ])}\n586     \"\"\"\n587 \n588     models = {\n589         'physical': physical,\n590         'ashrae': ashrae,\n591         'sapm': sapm,\n592         'martin_ruiz': martin_ruiz,\n593     }\n594 \n595     try:\n596         iam_model = models[model]\n597     except KeyError:\n598         raise ValueError('model must be one of: ' + str(list(models.keys())))\n599 \n600     iam_function = functools.partial(iam_model, **kwargs)\n601     iam = {}\n602     for region in ['sky', 'horizon', 'ground']:\n603         iam[region] = marion_integrate(iam_function, surface_tilt, region)\n604 \n605     return iam\n606 \n607 \n608 def marion_integrate(function, surface_tilt, region, num=None):\n609     \"\"\"\n610     Integrate an incidence angle modifier (IAM) function over solid angle\n611     to determine a diffuse irradiance correction factor using Marion's method.\n612 \n613     This lower-level function actually performs the IAM integration for the\n614     specified solid angle region.\n615 \n616     Parameters\n617     ----------\n618     function : callable(aoi)\n619         The IAM function to evaluate across solid angle. The function must\n620         be vectorized and take only one parameter, the angle of incidence in\n621         degrees.\n622 \n623     surface_tilt : numeric\n624         Surface tilt angles in decimal degrees.\n625         The tilt angle is defined as degrees from horizontal\n626         (e.g. surface facing up = 0, surface facing horizon = 90).\n627 \n628     region : {'sky', 'horizon', 'ground'}\n629         The region to integrate over. Must be one of:\n630 \n631             * 'sky': radiation from the sky dome (zenith <= 90)\n632             * 'horizon': radiation from the region of the sky near the horizon\n633               (89.5 <= zenith <= 90)\n634             * 'ground': radiation reflected from the ground (zenith >= 90)\n635 \n636         See [1]_ for a detailed description of each class.\n637 \n638     num : int, optional\n639         The number of increments in the zenith integration.\n640         If not specified, N will follow the values used in [1]_:\n641 \n642             * 'sky' or 'ground': num = 180\n643             * 'horizon': num = 1800\n644 \n645     Returns\n646     -------\n647     iam : numeric\n648         AOI diffuse correction factor for the specified region.\n649 \n650     See Also\n651     --------\n652     pvlib.iam.marion_diffuse\n653 \n654     References\n655     ----------\n656     .. [1] B. Marion \"Numerical method for angle-of-incidence correction\n657        factors for diffuse radiation incident photovoltaic modules\",\n658        Solar Energy, Volume 147, Pages 344-348. 2017.\n659        DOI: 10.1016/j.solener.2017.03.027\n660 \n661     Examples\n662     --------\n663     >>> marion_integrate(pvlib.iam.ashrae, 20, 'sky')\n664     0.9596085829811408\n665 \n666     >>> from functools import partial\n667     >>> f = partial(pvlib.iam.physical, n=1.3)\n668     >>> marion_integrate(f, [20, 30], 'sky')\n669     array([0.96225034, 0.9653219 ])\n670     \"\"\"\n671 \n672     if num is None:\n673         if region in ['sky', 'ground']:\n674             num = 180\n675         elif region == 'horizon':\n676             num = 1800\n677         else:\n678             raise ValueError('Invalid region: {}'.format(region))\n679 \n680     beta = np.radians(surface_tilt)\n681     if isinstance(beta, pd.Series):\n682         # convert Series to np array for broadcasting later\n683         beta = beta.values\n684     ai = np.pi/num  # angular increment\n685 \n686     phi_range = np.linspace(0, np.pi, num, endpoint=False)\n687     psi_range = np.linspace(0, 2*np.pi, 2*num, endpoint=False)\n688 \n689     # the pseudocode in [1] do these checks at the end, but it's\n690     # faster to do this criteria check up front instead of later.\n691     if region == 'sky':\n692         mask = phi_range + ai <= np.pi/2\n693     elif region == 'horizon':\n694         lo = 89.5 * np.pi/180\n695         hi = np.pi/2\n696         mask = (lo <= phi_range) & (phi_range + ai <= hi)\n697     elif region == 'ground':\n698         mask = (phi_range >= np.pi/2)\n699     else:\n700         raise ValueError('Invalid region: {}'.format(region))\n701     phi_range = phi_range[mask]\n702 \n703     # fast Cartesian product of phi and psi\n704     angles = np.array(np.meshgrid(phi_range, psi_range)).T.reshape(-1, 2)\n705     # index with single-element lists to maintain 2nd dimension so that\n706     # these angle arrays broadcast across the beta array\n707     phi_1 = angles[:, [0]]\n708     psi_1 = angles[:, [1]]\n709     phi_2 = phi_1 + ai\n710     # psi_2 = psi_1 + ai  # not needed\n711     phi_avg = phi_1 + 0.5*ai\n712     psi_avg = psi_1 + 0.5*ai\n713     term_1 = np.cos(beta) * np.cos(phi_avg)\n714     # The AOI formula includes a term based on the difference between\n715     # panel azimuth and the photon azimuth, but because we assume each class\n716     # of diffuse irradiance is isotropic and we are integrating over all\n717     # angles, it doesn't matter what panel azimuth we choose (i.e., the\n718     # system is rotationally invariant).  So we choose gamma to be zero so\n719     # that we can omit it from the cos(psi_avg) term.\n720     # Marion's paper mentions this in the Section 3 pseudocode:\n721     # \"set gamma to pi (or any value between 0 and 2pi)\"\n722     term_2 = np.sin(beta) * np.sin(phi_avg) * np.cos(psi_avg)\n723     cosaoi = term_1 + term_2\n724     aoi = np.arccos(cosaoi)\n725     # simplify Eq 8, (psi_2 - psi_1) is always ai\n726     dAs = ai * (np.cos(phi_1) - np.cos(phi_2))\n727     cosaoi_dAs = cosaoi * dAs\n728     # apply the final AOI check, zeroing out non-passing points\n729     mask = aoi < np.pi/2\n730     cosaoi_dAs = np.where(mask, cosaoi_dAs, 0)\n731     numerator = np.sum(function(np.degrees(aoi)) * cosaoi_dAs, axis=0)\n732     denominator = np.sum(cosaoi_dAs, axis=0)\n733 \n734     with np.errstate(invalid='ignore'):\n735         # in some cases, no points pass the criteria\n736         # (e.g. region='ground', surface_tilt=0), so we override the division\n737         # by zero to set Fd=0.  Also, preserve nans in beta.\n738         Fd = np.where((denominator != 0) | ~np.isfinite(beta),\n739                       numerator / denominator,\n740                       0)\n741 \n742     # preserve input type\n743     if np.isscalar(surface_tilt):\n744         Fd = Fd.item()\n745     elif isinstance(surface_tilt, pd.Series):\n746         Fd = pd.Series(Fd, surface_tilt.index)\n747 \n748     return Fd\n749 \n[end of pvlib/iam.py]\n[start of pvlib/soiling.py]\n1 # -*- coding: utf-8 -*-\n2 \"\"\"\n3 This module contains functions for soiling models\n4 \"\"\"\n5 \n6 import datetime\n7 import numpy as np\n8 import pandas as pd\n9 from pvlib.tools import cosd\n10 \n11 \n12 def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n13         depo_veloc=None, rain_accum_period=pd.Timedelta('1h')):\n14     \"\"\"\n15     Calculates soiling ratio given particulate and rain data using the model\n16     from Humboldt State University (HSU).\n17 \n18     The HSU soiling model [1]_ returns the soiling ratio, a value between zero\n19     and one which is equivalent to (1 - transmission loss). Therefore a soiling\n20     ratio of 1.0 is equivalent to zero transmission loss.\n21 \n22     Parameters\n23     ----------\n24 \n25     rainfall : Series\n26         Rain accumulated in each time period. [mm]\n27 \n28     cleaning_threshold : float\n29         Amount of rain in an accumulation period needed to clean the PV\n30         modules. [mm]\n31 \n32     tilt : float\n33         Tilt of the PV panels from horizontal. [degree]\n34 \n35     pm2_5 : numeric\n36         Concentration of airborne particulate matter (PM) with\n37         aerodynamic diameter less than 2.5 microns. [g/m^3]\n38 \n39     pm10 : numeric\n40         Concentration of airborne particulate matter (PM) with\n41         aerodynamicdiameter less than 10 microns. [g/m^3]\n42 \n43     depo_veloc : dict, default {'2_5': 0.0009, '10': 0.004}\n44         Deposition or settling velocity of particulates. [m/s]\n45 \n46     rain_accum_period : Timedelta, default 1 hour\n47         Period for accumulating rainfall to check against `cleaning_threshold`\n48         It is recommended that `rain_accum_period` be between 1 hour and\n49         24 hours.\n50 \n51     Returns\n52     -------\n53     soiling_ratio : Series\n54         Values between 0 and 1. Equal to 1 - transmission loss.\n55 \n56     References\n57     -----------\n58     .. [1] M. Coello and L. Boyle, \"Simple Model For Predicting Time Series\n59        Soiling of Photovoltaic Panels,\" in IEEE Journal of Photovoltaics.\n60        doi: 10.1109/JPHOTOV.2019.2919628\n61     .. [2] Atmospheric Chemistry and Physics: From Air Pollution to Climate\n62        Change. J. Seinfeld and S. Pandis. Wiley and Sons 2001.\n63 \n64     \"\"\"\n65     try:\n66         from scipy.special import erf\n67     except ImportError:\n68         raise ImportError(\"The pvlib.soiling.hsu function requires scipy.\")\n69 \n70     # never use mutable input arguments\n71     if depo_veloc is None:\n72         depo_veloc = {'2_5': 0.0009, '10': 0.004}\n73 \n74     # accumulate rainfall into periods for comparison with threshold\n75     accum_rain = rainfall.rolling(rain_accum_period, closed='right').sum()\n76     # cleaning is True for intervals with rainfall greater than threshold\n77     cleaning_times = accum_rain.index[accum_rain >= cleaning_threshold]\n78 \n79     horiz_mass_rate = pm2_5 * depo_veloc['2_5']\\\n80         + np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'] * 3600\n81     tilted_mass_rate = horiz_mass_rate * cosd(tilt)  # assuming no rain\n82 \n83     # tms -> tilt_mass_rate\n84     tms_cumsum = np.cumsum(tilted_mass_rate * np.ones(rainfall.shape))\n85 \n86     mass_no_cleaning = pd.Series(index=rainfall.index, data=tms_cumsum)\n87     # specify dtype so pandas doesn't assume object\n88     mass_removed = pd.Series(index=rainfall.index, dtype='float64')\n89     mass_removed[0] = 0.\n90     mass_removed[cleaning_times] = mass_no_cleaning[cleaning_times]\n91     accum_mass = mass_no_cleaning - mass_removed.ffill()\n92 \n93     soiling_ratio = 1 - 0.3437 * erf(0.17 * accum_mass**0.8473)\n94 \n95     return soiling_ratio\n96 \n97 \n98 def kimber(rainfall, cleaning_threshold=6, soiling_loss_rate=0.0015,\n99            grace_period=14, max_soiling=0.3, manual_wash_dates=None,\n100            initial_soiling=0, rain_accum_period=24):\n101     \"\"\"\n102     Calculates fraction of energy lost due to soiling given rainfall data and\n103     daily loss rate using the Kimber model.\n104 \n105     Kimber soiling model [1]_ assumes soiling builds up at a daily rate unless\n106     the daily rainfall is greater than a threshold. The model also assumes that\n107     if daily rainfall has exceeded the threshold within a grace period, then\n108     the ground is too damp to cause soiling build-up. The model also assumes\n109     there is a maximum soiling build-up. Scheduled manual washes and rain\n110     events are assumed to reset soiling to zero.\n111 \n112     Parameters\n113     ----------\n114     rainfall: pandas.Series\n115         Accumulated rainfall at the end of each time period. [mm]\n116     cleaning_threshold: float, default 6\n117         Amount of daily rainfall required to clean the panels. [mm]\n118     soiling_loss_rate: float, default 0.0015\n119         Fraction of energy lost due to one day of soiling. [unitless]\n120     grace_period : int, default 14\n121         Number of days after a rainfall event when it's assumed the ground is\n122         damp, and so it's assumed there is no soiling. [days]\n123     max_soiling : float, default 0.3\n124         Maximum fraction of energy lost due to soiling. Soiling will build up\n125         until this value. [unitless]\n126     manual_wash_dates : sequence or None, default None\n127         List or tuple of dates as Python ``datetime.date`` when the panels were\n128         washed manually. Note there is no grace period after a manual wash, so\n129         soiling begins to build up immediately.\n130     initial_soiling : float, default 0\n131         Initial fraction of energy lost due to soiling at time zero in the\n132         `rainfall` series input. [unitless]\n133     rain_accum_period : int, default 24\n134         Period for accumulating rainfall to check against `cleaning_threshold`.\n135         The Kimber model defines this period as one day. [hours]\n136 \n137     Returns\n138     -------\n139     pandas.Series\n140         fraction of energy lost due to soiling, has same intervals as input\n141 \n142     Notes\n143     -----\n144     The soiling loss rate depends on both the geographical region and the\n145     soiling environment type. Rates measured by Kimber [1]_ are summarized in\n146     the following table:\n147 \n148     ===================  =======  =========  ======================\n149     Region/Environment   Rural    Suburban   Urban/Highway/Airport\n150     ===================  =======  =========  ======================\n151     Central Valley       0.0011   0.0019     0.0020\n152     Northern CA          0.0011   0.0010     0.0016\n153     Southern CA          0        0.0016     0.0019\n154     Desert               0.0030   0.0030     0.0030\n155     ===================  =======  =========  ======================\n156 \n157     Rainfall thresholds and grace periods may also vary by region. Please\n158     consult [1]_ for more information.\n159 \n160     References\n161     ----------\n162     .. [1] \"The Effect of Soiling on Large Grid-Connected Photovoltaic Systems\n163        in California and the Southwest Region of the United States,\" Adrianne\n164        Kimber, et al., IEEE 4th World Conference on Photovoltaic Energy\n165        Conference, 2006, :doi:`10.1109/WCPEC.2006.279690`\n166     \"\"\"\n167     # convert rain_accum_period to timedelta\n168     rain_accum_period = datetime.timedelta(hours=rain_accum_period)\n169 \n170     # convert grace_period to timedelta\n171     grace_period = datetime.timedelta(days=grace_period)\n172 \n173     # get indices as numpy datetime64, calculate timestep as numpy timedelta64,\n174     # and convert timestep to fraction of days\n175     rain_index_vals = rainfall.index.values\n176     timestep_interval = (rain_index_vals[1] - rain_index_vals[0])\n177     day_fraction = timestep_interval / np.timedelta64(24, 'h')\n178 \n179     # accumulate rainfall\n180     accumulated_rainfall = rainfall.rolling(\n181         rain_accum_period, closed='right').sum()\n182 \n183     # soiling rate\n184     soiling = np.ones_like(rainfall.values) * soiling_loss_rate * day_fraction\n185     soiling[0] = initial_soiling\n186     soiling = np.cumsum(soiling)\n187     soiling = pd.Series(soiling, index=rainfall.index, name='soiling')\n188 \n189     # rainfall events that clean the panels\n190     rain_events = accumulated_rainfall > cleaning_threshold\n191 \n192     # grace periods windows during which ground is assumed damp, so no soiling\n193     grace_windows = rain_events.rolling(grace_period, closed='right').sum() > 0\n194 \n195     # clean panels by subtracting soiling for indices in grace period windows\n196     cleaning = pd.Series(float('NaN'), index=rainfall.index)\n197     cleaning.iloc[0] = 0.0\n198     cleaning[grace_windows] = soiling[grace_windows]\n199 \n200     # manual wash dates\n201     if manual_wash_dates is not None:\n202         rain_tz = rainfall.index.tz\n203         # convert manual wash dates to datetime index in the timezone of rain\n204         manual_wash_dates = pd.DatetimeIndex(manual_wash_dates, tz=rain_tz)\n205         cleaning[manual_wash_dates] = soiling[manual_wash_dates]\n206 \n207     # remove soiling by foward filling cleaning where NaN\n208     soiling -= cleaning.ffill()\n209 \n210     # check if soiling has reached the maximum\n211     return soiling.where(soiling < max_soiling, max_soiling)\n212 \n[end of pvlib/soiling.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "75369dcabacb6c6c38790cc23825f33f155ad1a9", "problem_statement": "pvlib.soiling.hsu model implementation errors\n**Describe the bug**\r\nI ran an example run using the Matlab version of the HSU soiling function and found that the python version did not give anywhere near the same results.  The Matlab results matched the results in the original JPV paper.  As a result of this test, I found two errors in the python implementation, which are listed below:\r\n\r\n1.  depo_veloc = {'2_5': 0.004, '10': 0.0009} has the wrong default values.  They are reversed.\r\nThe proper dictionary should be: {'2_5': 0.0009, '10': 0.004}.  This is confirmed in the JPV paper and the Matlab version of the function.\r\n\r\n2. The horiz_mass_rate is in g/(m^2*hr) but should be in g/(m^2*s).  The line needs to be multiplied by 60x60 or 3600.\r\nThe proper line of code should be: \r\nhoriz_mass_rate = (pm2_5 * depo_veloc['2_5']+ np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'])*3600\r\n\r\nWhen I made these changes I was able to match the validation dataset from the JPV paper, as shown below.\r\n![image](https://user-images.githubusercontent.com/5392756/82380831-61c43d80-99e6-11ea-9ee3-2368fa71e580.png)\r\n\r\n\n", "hints_text": "nice sleuthing Josh! Is a PR forthcoming? \ud83c\udf89 \nHi Mark,\r\n                Yes, a PR is in the works.  I need to improve the testing first.\r\n\r\n-Josh\r\n\r\nFrom: Mark Mikofski <notifications@github.com>\r\nReply-To: pvlib/pvlib-python <reply@reply.github.com>\r\nDate: Tuesday, May 19, 2020 at 3:51 PM\r\nTo: pvlib/pvlib-python <pvlib-python@noreply.github.com>\r\nCc: Joshua Stein <jsstein@sandia.gov>, Author <author@noreply.github.com>\r\nSubject: [EXTERNAL] Re: [pvlib/pvlib-python] pvlib.soiling.hsu model implementation errors (#970)\r\n\r\n\r\nnice sleuthing Josh! Is a PR forthcoming? \ud83c\udf89\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/pvlib/pvlib-python/issues/970#issuecomment-631102921>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABJES5C2CRTZFF7ROT2EPOTRSL5ORANCNFSM4NFL4K3Q>.\r\n\nNow I need to go back and figure out where I missed these errors in the review.", "created_at": "2020-06-12T17:45:46Z", "patch": "<patch>\ndiff --git a/pvlib/soiling.py b/pvlib/soiling.py\n--- a/pvlib/soiling.py\n+++ b/pvlib/soiling.py\n@@ -12,8 +12,8 @@\n def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n         depo_veloc=None, rain_accum_period=pd.Timedelta('1h')):\n     \"\"\"\n-    Calculates soiling ratio given particulate and rain data using the model\n-    from Humboldt State University (HSU).\n+    Calculates soiling ratio given particulate and rain data using the\n+    Fixed Velocity model from Humboldt State University (HSU).\n \n     The HSU soiling model [1]_ returns the soiling ratio, a value between zero\n     and one which is equivalent to (1 - transmission loss). Therefore a soiling\n@@ -76,8 +76,17 @@ def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n     # cleaning is True for intervals with rainfall greater than threshold\n     cleaning_times = accum_rain.index[accum_rain >= cleaning_threshold]\n \n-    horiz_mass_rate = pm2_5 * depo_veloc['2_5']\\\n-        + np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'] * 3600\n+    # determine the time intervals in seconds (dt_sec)\n+    dt = rainfall.index\n+    # subtract shifted values from original and convert to seconds\n+    dt_diff = (dt[1:] - dt[:-1]).total_seconds()\n+    # ensure same number of elements in the array, assuming that the interval\n+    # prior to the first value is equal in length to the first interval\n+    dt_sec = np.append(dt_diff[0], dt_diff).astype('float64')\n+\n+    horiz_mass_rate = (\n+        pm2_5 * depo_veloc['2_5'] + np.maximum(pm10 - pm2_5, 0.)\n+        * depo_veloc['10']) * dt_sec\n     tilted_mass_rate = horiz_mass_rate * cosd(tilt)  # assuming no rain\n \n     # tms -> tilt_mass_rate\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_soiling.py b/pvlib/tests/test_soiling.py\n--- a/pvlib/tests/test_soiling.py\n+++ b/pvlib/tests/test_soiling.py\n@@ -18,24 +18,24 @@ def expected_output():\n                        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n \n     expected_no_cleaning = pd.Series(\n-        data=[0.97230454, 0.95036146, 0.93039061, 0.91177978, 0.89427556,\n-              0.8777455 , 0.86211038, 0.84731759, 0.83332881, 0.82011354,\n-              0.80764549, 0.79590056, 0.78485556, 0.77448749, 0.76477312,\n-              0.75568883, 0.74721046, 0.73931338, 0.73197253, 0.72516253,\n-              0.7188578 , 0.71303268, 0.7076616 , 0.70271919],\n+        data=[0.96998483, 0.94623958, 0.92468139, 0.90465654, 0.88589707,\n+              0.86826366, 0.85167258, 0.83606715, 0.82140458, 0.80764919,\n+              0.79476875, 0.78273241, 0.77150951, 0.76106905, 0.75137932,\n+              0.74240789, 0.73412165, 0.72648695, 0.71946981, 0.7130361,\n+              0.70715176, 0.70178307, 0.69689677, 0.69246034],\n         index=dt)\n     return expected_no_cleaning\n \n @pytest.fixture\n def expected_output_1():\n     dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n-        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n+                       end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n     expected_output_1 = pd.Series(\n-        data=[0.9872406 , 0.97706269, 0.96769693, 0.95884032, 1.,\n-              0.9872406 , 0.97706269, 0.96769693, 1.        , 1.        ,\n-              0.9872406 , 0.97706269, 0.96769693, 0.95884032, 0.95036001,\n-              0.94218263, 0.93426236, 0.92656836, 0.91907873, 0.91177728,\n-              0.9046517 , 0.89769238, 0.89089165, 0.88424329],\n+        data=[0.98484972, 0.97277367, 0.96167471, 0.95119603, 1.,\n+              0.98484972, 0.97277367, 0.96167471, 1., 1.,\n+              0.98484972, 0.97277367, 0.96167471, 0.95119603, 0.94118234,\n+              0.93154854, 0.922242, 0.91322759, 0.90448058, 0.89598283,\n+              0.88772062, 0.87968325, 0.8718622, 0.86425049],\n         index=dt)\n     return expected_output_1\n \n@@ -44,15 +44,31 @@ def expected_output_2():\n     dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n                        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n     expected_output_2 = pd.Series(\n-        data=[0.97229869, 0.95035106, 0.93037619, 0.91176175, 1.,\n-              1.        , 1.        , 0.97229869, 1.        , 1.        ,\n-              1.        , 1.        , 0.97229869, 0.95035106, 0.93037619,\n-              0.91176175, 0.89425431, 1.        , 1.        , 1.        ,\n-              1.        , 0.97229869, 0.95035106, 0.93037619],\n+        data=[0.95036261, 0.91178179, 0.87774818, 0.84732079, 1.,\n+              1., 1., 0.95036261, 1., 1.,\n+              1., 1., 0.95036261, 0.91178179, 0.87774818,\n+              0.84732079, 0.8201171, 1., 1., 1.,\n+              1., 0.95036261, 0.91178179, 0.87774818],\n         index=dt)\n-\n     return expected_output_2\n \n+\n+@pytest.fixture\n+def expected_output_3():\n+    dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n+                       end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n+    timedelta = [0, 0, 0, 0, 0, 30, 0, 30, 0, 30, 0, -30,\n+                 -30, -30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n+    dt_new = dt + pd.to_timedelta(timedelta, 'm')\n+    expected_output_3 = pd.Series(\n+        data=[0.96576705, 0.9387675, 0.91437615, 0.89186852, 1.,\n+              1., 0.98093819, 0.9387675, 1., 1.,\n+              1., 1., 0.96576705, 0.9387675, 0.90291005,\n+              0.88122293, 0.86104089, 1., 1., 1.,\n+              0.96576705, 0.9387675, 0.91437615, 0.89186852],\n+        index=dt_new)\n+    return expected_output_3\n+\n @pytest.fixture\n def rainfall_input():\n \n@@ -105,12 +121,30 @@ def test_hsu_defaults(rainfall_input, expected_output_1):\n     Test Soiling HSU function with default deposition velocity and default rain\n     accumulation period.\n     \"\"\"\n-    result = hsu(\n-        rainfall=rainfall_input, cleaning_threshold=0.5, tilt=0.0,\n-        pm2_5=1.0e-2,pm10=2.0e-2)\n+    result = hsu(rainfall=rainfall_input, cleaning_threshold=0.5, tilt=0.0,\n+                 pm2_5=1.0e-2, pm10=2.0e-2)\n     assert np.allclose(result.values, expected_output_1)\n \n \n+@requires_scipy\n+def test_hsu_variable_time_intervals(rainfall_input, expected_output_3):\n+    \"\"\"\n+    Test Soiling HSU function with variable time intervals.\n+    \"\"\"\n+    depo_veloc = {'2_5': 1.0e-4, '10': 1.0e-4}\n+    rain = pd.DataFrame(data=rainfall_input)\n+    # define time deltas in minutes\n+    timedelta = [0, 0, 0, 0, 0, 30, 0, 30, 0, 30, 0, -30,\n+                 -30, -30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n+    rain['mins_added'] = pd.to_timedelta(timedelta, 'm')\n+    rain['new_time'] = rain.index + rain['mins_added']\n+    rain_var_times = rain.set_index('new_time').iloc[:, 0]\n+    result = hsu(\n+        rainfall=rain_var_times, cleaning_threshold=0.5, tilt=50.0,\n+        pm2_5=1, pm10=2, depo_veloc=depo_veloc,\n+        rain_accum_period=pd.Timedelta('2h'))\n+    assert np.allclose(result, expected_output_3)\n+\n @pytest.fixture\n def greensboro_rain():\n     # get TMY3 data with rain\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/test_soiling.py::test_hsu_no_cleaning\", \"pvlib/tests/test_soiling.py::test_hsu\", \"pvlib/tests/test_soiling.py::test_hsu_defaults\", \"pvlib/tests/test_soiling.py::test_hsu_variable_time_intervals\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_soiling.py::test_kimber_nowash\", \"pvlib/tests/test_soiling.py::test_kimber_manwash\", \"pvlib/tests/test_soiling.py::test_kimber_norain\", \"pvlib/tests/test_soiling.py::test_kimber_initial_soil\"]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-980_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\npvlib.soiling.hsu model implementation errors\n**Describe the bug**\r\nI ran an example run using the Matlab version of the HSU soiling function and found that the python version did not give anywhere near the same results.  The Matlab results matched the results in the original JPV paper.  As a result of this test, I found two errors in the python implementation, which are listed below:\r\n\r\n1.  depo_veloc = {'2_5': 0.004, '10': 0.0009} has the wrong default values.  They are reversed.\r\nThe proper dictionary should be: {'2_5': 0.0009, '10': 0.004}.  This is confirmed in the JPV paper and the Matlab version of the function.\r\n\r\n2. The horiz_mass_rate is in g/(m^2*hr) but should be in g/(m^2*s).  The line needs to be multiplied by 60x60 or 3600.\r\nThe proper line of code should be: \r\nhoriz_mass_rate = (pm2_5 * depo_veloc['2_5']+ np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'])*3600\r\n\r\nWhen I made these changes I was able to match the validation dataset from the JPV paper, as shown below.\r\n![image](https://user-images.githubusercontent.com/5392756/82380831-61c43d80-99e6-11ea-9ee3-2368fa71e580.png)\r\n\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of pvlib/iam.py]\n1 r\"\"\"\n2 The ``iam`` module contains functions that implement models for the incidence\n3 angle modifier (IAM). The IAM quantifies the fraction of direct irradiance on\n4 a module's front surface that is transmitted through the module materials to\n5 the cells. Stated differently, the quantity 1 - IAM is the fraction of direct\n6 irradiance that is reflected away or absorbed by the module's front materials.\n7 IAM is typically a function of the angle of incidence (AOI) of the direct\n8 irradiance to the module's surface.\n9 \"\"\"\n10 \n11 import numpy as np\n12 import pandas as pd\n13 import functools\n14 from pvlib.tools import cosd, sind, tand, asind\n15 \n16 # a dict of required parameter names for each IAM model\n17 # keys are the function names for the IAM models\n18 _IAM_MODEL_PARAMS = {\n19     'ashrae': set(['b']),\n20     'physical': set(['n', 'K', 'L']),\n21     'martin_ruiz': set(['a_r']),\n22     'sapm': set(['B0', 'B1', 'B2', 'B3', 'B4', 'B5']),\n23     'interp': set([])\n24 }\n25 \n26 \n27 def ashrae(aoi, b=0.05):\n28     r\"\"\"\n29     Determine the incidence angle modifier using the ASHRAE transmission\n30     model.\n31 \n32     The ASHRAE (American Society of Heating, Refrigeration, and Air\n33     Conditioning Engineers) transmission model is developed in\n34     [1]_, and in [2]_. The model has been used in software such as PVSyst [3]_.\n35 \n36     Parameters\n37     ----------\n38     aoi : numeric\n39         The angle of incidence (AOI) between the module normal vector and the\n40         sun-beam vector in degrees. Angles of nan will result in nan.\n41 \n42     b : float, default 0.05\n43         A parameter to adjust the incidence angle modifier as a function of\n44         angle of incidence. Typical values are on the order of 0.05 [3].\n45 \n46     Returns\n47     -------\n48     iam : numeric\n49         The incident angle modifier (IAM). Returns zero for all abs(aoi) >= 90\n50         and for all ``iam`` values that would be less than 0.\n51 \n52     Notes\n53     -----\n54     The incidence angle modifier is calculated as\n55 \n56     .. math::\n57 \n58         IAM = 1 - b (\\sec(aoi) - 1)\n59 \n60     As AOI approaches 90 degrees, the model yields negative values for IAM;\n61     negative IAM values are set to zero in this implementation.\n62 \n63     References\n64     ----------\n65     .. [1] Souka A.F., Safwat H.H., \"Determination of the optimum\n66        orientations for the double exposure flat-plate collector and its\n67        reflections\". Solar Energy vol .10, pp 170-174. 1966.\n68 \n69     .. [2] ASHRAE standard 93-77\n70 \n71     .. [3] PVsyst Contextual Help.\n72        https://files.pvsyst.com/help/index.html?iam_loss.htm retrieved on\n73        October 14, 2019\n74 \n75     See Also\n76     --------\n77     pvlib.iam.physical\n78     pvlib.iam.martin_ruiz\n79     pvlib.iam.interp\n80     \"\"\"\n81 \n82     iam = 1 - b * ((1 / np.cos(np.radians(aoi)) - 1))\n83     aoi_gte_90 = np.full_like(aoi, False, dtype='bool')\n84     np.greater_equal(np.abs(aoi), 90, where=~np.isnan(aoi), out=aoi_gte_90)\n85     iam = np.where(aoi_gte_90, 0, iam)\n86     iam = np.maximum(0, iam)\n87 \n88     if isinstance(aoi, pd.Series):\n89         iam = pd.Series(iam, index=aoi.index)\n90 \n91     return iam\n92 \n93 \n94 def physical(aoi, n=1.526, K=4., L=0.002):\n95     r\"\"\"\n96     Determine the incidence angle modifier using refractive index ``n``,\n97     extinction coefficient ``K``, and glazing thickness ``L``.\n98 \n99     ``iam.physical`` calculates the incidence angle modifier as described in\n100     [1]_, Section 3. The calculation is based on a physical model of absorbtion\n101     and transmission through a transparent cover.\n102 \n103     Parameters\n104     ----------\n105     aoi : numeric\n106         The angle of incidence between the module normal vector and the\n107         sun-beam vector in degrees. Angles of 0 are replaced with 1e-06\n108         to ensure non-nan results. Angles of nan will result in nan.\n109 \n110     n : numeric, default 1.526\n111         The effective index of refraction (unitless). Reference [1]_\n112         indicates that a value of 1.526 is acceptable for glass.\n113 \n114     K : numeric, default 4.0\n115         The glazing extinction coefficient in units of 1/meters.\n116         Reference [1] indicates that a value of 4 is reasonable for\n117         \"water white\" glass.\n118 \n119     L : numeric, default 0.002\n120         The glazing thickness in units of meters. Reference [1]_\n121         indicates that 0.002 meters (2 mm) is reasonable for most\n122         glass-covered PV panels.\n123 \n124     Returns\n125     -------\n126     iam : numeric\n127         The incident angle modifier\n128 \n129     Notes\n130     -----\n131     The pvlib python authors believe that Eqn. 14 in [1]_ is\n132     incorrect, which presents :math:`\\theta_{r} = \\arcsin(n \\sin(AOI))`.\n133     Here, :math:`\\theta_{r} = \\arcsin(1/n \\times \\sin(AOI))`\n134 \n135     References\n136     ----------\n137     .. [1] W. De Soto et al., \"Improvement and validation of a model for\n138        photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n139        2006.\n140 \n141     .. [2] Duffie, John A. & Beckman, William A.. (2006). Solar Engineering\n142        of Thermal Processes, third edition. [Books24x7 version] Available\n143        from http://common.books24x7.com/toc.aspx?bookid=17160.\n144 \n145     See Also\n146     --------\n147     pvlib.iam.martin_ruiz\n148     pvlib.iam.ashrae\n149     pvlib.iam.interp\n150     pvlib.iam.sapm\n151     \"\"\"\n152     zeroang = 1e-06\n153 \n154     # hold a new reference to the input aoi object since we're going to\n155     # overwrite the aoi reference below, but we'll need it for the\n156     # series check at the end of the function\n157     aoi_input = aoi\n158 \n159     aoi = np.where(aoi == 0, zeroang, aoi)\n160 \n161     # angle of reflection\n162     thetar_deg = asind(1.0 / n * (sind(aoi)))\n163 \n164     # reflectance and transmittance for normal incidence light\n165     rho_zero = ((1-n) / (1+n)) ** 2\n166     tau_zero = np.exp(-K*L)\n167 \n168     # reflectance for parallel and perpendicular polarized light\n169     rho_para = (tand(thetar_deg - aoi) / tand(thetar_deg + aoi)) ** 2\n170     rho_perp = (sind(thetar_deg - aoi) / sind(thetar_deg + aoi)) ** 2\n171 \n172     # transmittance for non-normal light\n173     tau = np.exp(-K * L / cosd(thetar_deg))\n174 \n175     # iam is ratio of non-normal to normal incidence transmitted light\n176     # after deducting the reflected portion of each\n177     iam = ((1 - (rho_para + rho_perp) / 2) / (1 - rho_zero) * tau / tau_zero)\n178 \n179     with np.errstate(invalid='ignore'):\n180         # angles near zero produce nan, but iam is defined as one\n181         small_angle = 1e-06\n182         iam = np.where(np.abs(aoi) < small_angle, 1.0, iam)\n183 \n184         # angles at 90 degrees can produce tiny negative values,\n185         # which should be zero. this is a result of calculation precision\n186         # rather than the physical model\n187         iam = np.where(iam < 0, 0, iam)\n188 \n189         # for light coming from behind the plane, none can enter the module\n190         iam = np.where(aoi > 90, 0, iam)\n191 \n192     if isinstance(aoi_input, pd.Series):\n193         iam = pd.Series(iam, index=aoi_input.index)\n194 \n195     return iam\n196 \n197 \n198 def martin_ruiz(aoi, a_r=0.16):\n199     r'''\n200     Determine the incidence angle modifier (IAM) using the Martin\n201     and Ruiz incident angle model.\n202 \n203     Parameters\n204     ----------\n205     aoi : numeric, degrees\n206         The angle of incidence between the module normal vector and the\n207         sun-beam vector in degrees.\n208 \n209     a_r : numeric\n210         The angular losses coefficient described in equation 3 of [1]_.\n211         This is an empirical dimensionless parameter. Values of ``a_r`` are\n212         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n213 \n214     Returns\n215     -------\n216     iam : numeric\n217         The incident angle modifier(s)\n218 \n219     Notes\n220     -----\n221     `martin_ruiz` calculates the incidence angle modifier (IAM) as described in\n222     [1]_. The information required is the incident angle (AOI) and the angular\n223     losses coefficient (a_r). Note that [1]_ has a corrigendum [2]_ which\n224     clarifies a mix-up of 'alpha's and 'a's in the former.\n225 \n226     The incident angle modifier is defined as\n227 \n228     .. math::\n229 \n230        IAM = \\frac{1 - \\exp(-\\cos(\\frac{aoi}{a_r}))}\n231        {1 - \\exp(\\frac{-1}{a_r}}\n232 \n233     which is presented as :math:`AL(\\alpha) = 1 - IAM` in equation 4 of [1]_,\n234     with :math:`\\alpha` representing the angle of incidence AOI. Thus IAM = 1\n235     at AOI = 0, and IAM = 0 at AOI = 90.  This equation is only valid for\n236     -90 <= aoi <= 90, therefore `iam` is constrained to 0.0 outside this\n237     interval.\n238 \n239     References\n240     ----------\n241     .. [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n242        losses under field conditions by means of an analytical model\", Solar\n243        Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n244 \n245     .. [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n246        modules angular losses under field conditions by means of an\n247        analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n248        pp. 154, 2013.\n249 \n250     See Also\n251     --------\n252     pvlib.iam.martin_ruiz_diffuse\n253     pvlib.iam.physical\n254     pvlib.iam.ashrae\n255     pvlib.iam.interp\n256     pvlib.iam.sapm\n257     '''\n258     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n259 \n260     aoi_input = aoi\n261 \n262     aoi = np.asanyarray(aoi)\n263     a_r = np.asanyarray(a_r)\n264 \n265     if np.any(np.less_equal(a_r, 0)):\n266         raise ValueError(\"The parameter 'a_r' cannot be zero or negative.\")\n267 \n268     with np.errstate(invalid='ignore'):\n269         iam = (1 - np.exp(-cosd(aoi) / a_r)) / (1 - np.exp(-1 / a_r))\n270         iam = np.where(np.abs(aoi) >= 90.0, 0.0, iam)\n271 \n272     if isinstance(aoi_input, pd.Series):\n273         iam = pd.Series(iam, index=aoi_input.index)\n274 \n275     return iam\n276 \n277 \n278 def martin_ruiz_diffuse(surface_tilt, a_r=0.16, c1=0.4244, c2=None):\n279     '''\n280     Determine the incidence angle modifiers (iam) for diffuse sky and\n281     ground-reflected irradiance using the Martin and Ruiz incident angle model.\n282 \n283     Parameters\n284     ----------\n285     surface_tilt: float or array-like, default 0\n286         Surface tilt angles in decimal degrees.\n287         The tilt angle is defined as degrees from horizontal\n288         (e.g. surface facing up = 0, surface facing horizon = 90)\n289         surface_tilt must be in the range [0, 180]\n290 \n291     a_r : numeric\n292         The angular losses coefficient described in equation 3 of [1]_.\n293         This is an empirical dimensionless parameter. Values of a_r are\n294         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n295         a_r must be greater than zero.\n296 \n297     c1 : float\n298         First fitting parameter for the expressions that approximate the\n299         integral of diffuse irradiance coming from different directions.\n300         c1 is given as the constant 4 / 3 / pi (0.4244) in [1]_.\n301 \n302     c2 : float\n303         Second fitting parameter for the expressions that approximate the\n304         integral of diffuse irradiance coming from different directions.\n305         If c2 is None, it will be calculated according to the linear\n306         relationship given in [3]_.\n307 \n308     Returns\n309     -------\n310     iam_sky : numeric\n311         The incident angle modifier for sky diffuse\n312 \n313     iam_ground : numeric\n314         The incident angle modifier for ground-reflected diffuse\n315 \n316     Notes\n317     -----\n318     Sky and ground modifiers are complementary: iam_sky for tilt = 30 is\n319     equal to iam_ground for tilt = 180 - 30.  For vertical surfaces,\n320     tilt = 90, the two factors are equal.\n321 \n322     References\n323     ----------\n324     .. [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n325        losses under field conditions by means of an analytical model\", Solar\n326        Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n327 \n328     .. [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n329        modules angular losses under field conditions by means of an\n330        analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n331        pp. 154, 2013.\n332 \n333     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n334        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n335 \n336     See Also\n337     --------\n338     pvlib.iam.martin_ruiz\n339     pvlib.iam.physical\n340     pvlib.iam.ashrae\n341     pvlib.iam.interp\n342     pvlib.iam.sapm\n343     '''\n344     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Oct. 2019\n345 \n346     if isinstance(surface_tilt, pd.Series):\n347         out_index = surface_tilt.index\n348     else:\n349         out_index = None\n350 \n351     surface_tilt = np.asanyarray(surface_tilt)\n352 \n353     # avoid undefined results for horizontal or upside-down surfaces\n354     zeroang = 1e-06\n355 \n356     surface_tilt = np.where(surface_tilt == 0, zeroang, surface_tilt)\n357     surface_tilt = np.where(surface_tilt == 180, 180 - zeroang, surface_tilt)\n358 \n359     if c2 is None:\n360         # This equation is from [3] Sect. 7.2\n361         c2 = 0.5 * a_r - 0.154\n362 \n363     beta = np.radians(surface_tilt)\n364 \n365     from numpy import pi, sin, cos, exp\n366 \n367     # avoid RuntimeWarnings for <, sin, and cos with nan\n368     with np.errstate(invalid='ignore'):\n369         # because sin(pi) isn't exactly zero\n370         sin_beta = np.where(surface_tilt < 90, sin(beta), sin(pi - beta))\n371 \n372         trig_term_sky = sin_beta + (pi - beta - sin_beta) / (1 + cos(beta))\n373         trig_term_gnd = sin_beta +      (beta - sin_beta) / (1 - cos(beta))  # noqa: E222 E261 E501\n374 \n375     iam_sky = 1 - exp(-(c1 + c2 * trig_term_sky) * trig_term_sky / a_r)\n376     iam_gnd = 1 - exp(-(c1 + c2 * trig_term_gnd) * trig_term_gnd / a_r)\n377 \n378     if out_index is not None:\n379         iam_sky = pd.Series(iam_sky, index=out_index, name='iam_sky')\n380         iam_gnd = pd.Series(iam_gnd, index=out_index, name='iam_ground')\n381 \n382     return iam_sky, iam_gnd\n383 \n384 \n385 def interp(aoi, theta_ref, iam_ref, method='linear', normalize=True):\n386     r'''\n387     Determine the incidence angle modifier (IAM) by interpolating a set of\n388     reference values, which are usually measured values.\n389 \n390     Parameters\n391     ----------\n392     aoi : numeric\n393         The angle of incidence between the module normal vector and the\n394         sun-beam vector [degrees].\n395 \n396     theta_ref : numeric\n397         Vector of angles at which the IAM is known [degrees].\n398 \n399     iam_ref : numeric\n400         IAM values for each angle in ``theta_ref`` [unitless].\n401 \n402     method : str, default 'linear'\n403         Specifies the interpolation method.\n404         Useful options are: 'linear', 'quadratic', 'cubic'.\n405         See scipy.interpolate.interp1d for more options.\n406 \n407     normalize : boolean, default True\n408         When true, the interpolated values are divided by the interpolated\n409         value at zero degrees.  This ensures that ``iam=1.0`` at normal\n410         incidence.\n411 \n412     Returns\n413     -------\n414     iam : numeric\n415         The incident angle modifier(s) [unitless]\n416 \n417     Notes\n418     -----\n419     ``theta_ref`` must have two or more points and may span any range of\n420     angles. Typically there will be a dozen or more points in the range 0-90\n421     degrees. Beyond the range of ``theta_ref``, IAM values are extrapolated,\n422     but constrained to be non-negative.\n423 \n424     The sign of ``aoi`` is ignored; only the magnitude is used.\n425 \n426     See Also\n427     --------\n428     pvlib.iam.physical\n429     pvlib.iam.ashrae\n430     pvlib.iam.martin_ruiz\n431     pvlib.iam.sapm\n432     '''\n433     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n434 \n435     from scipy.interpolate import interp1d\n436 \n437     # Scipy doesn't give the clearest feedback, so check number of points here.\n438     MIN_REF_VALS = {'linear': 2, 'quadratic': 3, 'cubic': 4, 1: 2, 2: 3, 3: 4}\n439 \n440     if len(theta_ref) < MIN_REF_VALS.get(method, 2):\n441         raise ValueError(\"Too few reference points defined \"\n442                          \"for interpolation method '%s'.\" % method)\n443 \n444     if np.any(np.less(iam_ref, 0)):\n445         raise ValueError(\"Negative value(s) found in 'iam_ref'. \"\n446                          \"This is not physically possible.\")\n447 \n448     interpolator = interp1d(theta_ref, iam_ref, kind=method,\n449                             fill_value='extrapolate')\n450     aoi_input = aoi\n451 \n452     aoi = np.asanyarray(aoi)\n453     aoi = np.abs(aoi)\n454     iam = interpolator(aoi)\n455     iam = np.clip(iam, 0, None)\n456 \n457     if normalize:\n458         iam /= interpolator(0)\n459 \n460     if isinstance(aoi_input, pd.Series):\n461         iam = pd.Series(iam, index=aoi_input.index)\n462 \n463     return iam\n464 \n465 \n466 def sapm(aoi, module, upper=None):\n467     r\"\"\"\n468     Determine the incidence angle modifier (IAM) using the SAPM model.\n469 \n470     Parameters\n471     ----------\n472     aoi : numeric\n473         Angle of incidence in degrees. Negative input angles will return\n474         zeros.\n475 \n476     module : dict-like\n477         A dict or Series with the SAPM IAM model parameters.\n478         See the :py:func:`sapm` notes section for more details.\n479 \n480     upper : None or float, default None\n481         Upper limit on the results.\n482 \n483     Returns\n484     -------\n485     iam : numeric\n486         The SAPM angle of incidence loss coefficient, termed F2 in [1]_.\n487 \n488     Notes\n489     -----\n490     The SAPM [1]_ traditionally does not define an upper limit on the AOI\n491     loss function and values slightly exceeding 1 may exist for moderate\n492     angles of incidence (15-40 degrees). However, users may consider\n493     imposing an upper limit of 1.\n494 \n495     References\n496     ----------\n497     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n498        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n499        NM.\n500 \n501     .. [2] B.H. King et al, \"Procedure to Determine Coefficients for the\n502        Sandia Array Performance Model (SAPM),\" SAND2016-5284, Sandia\n503        National Laboratories (2016).\n504 \n505     .. [3] B.H. King et al, \"Recent Advancements in Outdoor Measurement\n506        Techniques for Angle of Incidence Effects,\" 42nd IEEE PVSC (2015).\n507        DOI: 10.1109/PVSC.2015.7355849\n508 \n509     See Also\n510     --------\n511     pvlib.iam.physical\n512     pvlib.iam.ashrae\n513     pvlib.iam.martin_ruiz\n514     pvlib.iam.interp\n515     \"\"\"\n516 \n517     aoi_coeff = [module['B5'], module['B4'], module['B3'], module['B2'],\n518                  module['B1'], module['B0']]\n519 \n520     iam = np.polyval(aoi_coeff, aoi)\n521     iam = np.clip(iam, 0, upper)\n522     # nan tolerant masking\n523     aoi_lt_0 = np.full_like(aoi, False, dtype='bool')\n524     np.less(aoi, 0, where=~np.isnan(aoi), out=aoi_lt_0)\n525     iam = np.where(aoi_lt_0, 0, iam)\n526 \n527     if isinstance(aoi, pd.Series):\n528         iam = pd.Series(iam, aoi.index)\n529 \n530     return iam\n531 \n532 \n533 def marion_diffuse(model, surface_tilt, **kwargs):\n534     \"\"\"\n535     Determine diffuse irradiance incidence angle modifiers using Marion's\n536     method of integrating over solid angle.\n537 \n538     Parameters\n539     ----------\n540     model : str\n541         The IAM function to evaluate across solid angle. Must be one of\n542         `'ashrae', 'physical', 'martin_ruiz', 'sapm'`.\n543 \n544     surface_tilt : numeric\n545         Surface tilt angles in decimal degrees.\n546         The tilt angle is defined as degrees from horizontal\n547         (e.g. surface facing up = 0, surface facing horizon = 90).\n548 \n549     **kwargs\n550         Extra parameters passed to the IAM function.\n551 \n552     Returns\n553     -------\n554     iam : dict\n555         IAM values for each type of diffuse irradiance:\n556 \n557             * 'sky': radiation from the sky dome (zenith <= 90)\n558             * 'horizon': radiation from the region of the sky near the horizon\n559               (89.5 <= zenith <= 90)\n560             * 'ground': radiation reflected from the ground (zenith >= 90)\n561 \n562         See [1]_ for a detailed description of each class.\n563 \n564     See Also\n565     --------\n566     pvlib.iam.marion_integrate\n567 \n568     References\n569     ----------\n570     .. [1] B. Marion \"Numerical method for angle-of-incidence correction\n571        factors for diffuse radiation incident photovoltaic modules\",\n572        Solar Energy, Volume 147, Pages 344-348. 2017.\n573        DOI: 10.1016/j.solener.2017.03.027\n574 \n575     Examples\n576     --------\n577     >>> marion_diffuse('physical', surface_tilt=20)\n578     {'sky': 0.9539178294437575,\n579      'horizon': 0.7652650139134007,\n580      'ground': 0.6387140117795903}\n581 \n582     >>> marion_diffuse('ashrae', [20, 30], b=0.04)\n583     {'sky': array([0.96748999, 0.96938408]),\n584      'horizon': array([0.86478428, 0.91825792]),\n585      'ground': array([0.77004435, 0.8522436 ])}\n586     \"\"\"\n587 \n588     models = {\n589         'physical': physical,\n590         'ashrae': ashrae,\n591         'sapm': sapm,\n592         'martin_ruiz': martin_ruiz,\n593     }\n594 \n595     try:\n596         iam_model = models[model]\n597     except KeyError:\n598         raise ValueError('model must be one of: ' + str(list(models.keys())))\n599 \n600     iam_function = functools.partial(iam_model, **kwargs)\n601     iam = {}\n602     for region in ['sky', 'horizon', 'ground']:\n603         iam[region] = marion_integrate(iam_function, surface_tilt, region)\n604 \n605     return iam\n606 \n607 \n608 def marion_integrate(function, surface_tilt, region, num=None):\n609     \"\"\"\n610     Integrate an incidence angle modifier (IAM) function over solid angle\n611     to determine a diffuse irradiance correction factor using Marion's method.\n612 \n613     This lower-level function actually performs the IAM integration for the\n614     specified solid angle region.\n615 \n616     Parameters\n617     ----------\n618     function : callable(aoi)\n619         The IAM function to evaluate across solid angle. The function must\n620         be vectorized and take only one parameter, the angle of incidence in\n621         degrees.\n622 \n623     surface_tilt : numeric\n624         Surface tilt angles in decimal degrees.\n625         The tilt angle is defined as degrees from horizontal\n626         (e.g. surface facing up = 0, surface facing horizon = 90).\n627 \n628     region : {'sky', 'horizon', 'ground'}\n629         The region to integrate over. Must be one of:\n630 \n631             * 'sky': radiation from the sky dome (zenith <= 90)\n632             * 'horizon': radiation from the region of the sky near the horizon\n633               (89.5 <= zenith <= 90)\n634             * 'ground': radiation reflected from the ground (zenith >= 90)\n635 \n636         See [1]_ for a detailed description of each class.\n637 \n638     num : int, optional\n639         The number of increments in the zenith integration.\n640         If not specified, N will follow the values used in [1]_:\n641 \n642             * 'sky' or 'ground': num = 180\n643             * 'horizon': num = 1800\n644 \n645     Returns\n646     -------\n647     iam : numeric\n648         AOI diffuse correction factor for the specified region.\n649 \n650     See Also\n651     --------\n652     pvlib.iam.marion_diffuse\n653 \n654     References\n655     ----------\n656     .. [1] B. Marion \"Numerical method for angle-of-incidence correction\n657        factors for diffuse radiation incident photovoltaic modules\",\n658        Solar Energy, Volume 147, Pages 344-348. 2017.\n659        DOI: 10.1016/j.solener.2017.03.027\n660 \n661     Examples\n662     --------\n663     >>> marion_integrate(pvlib.iam.ashrae, 20, 'sky')\n664     0.9596085829811408\n665 \n666     >>> from functools import partial\n667     >>> f = partial(pvlib.iam.physical, n=1.3)\n668     >>> marion_integrate(f, [20, 30], 'sky')\n669     array([0.96225034, 0.9653219 ])\n670     \"\"\"\n671 \n672     if num is None:\n673         if region in ['sky', 'ground']:\n674             num = 180\n675         elif region == 'horizon':\n676             num = 1800\n677         else:\n678             raise ValueError('Invalid region: {}'.format(region))\n679 \n680     beta = np.radians(surface_tilt)\n681     if isinstance(beta, pd.Series):\n682         # convert Series to np array for broadcasting later\n683         beta = beta.values\n684     ai = np.pi/num  # angular increment\n685 \n686     phi_range = np.linspace(0, np.pi, num, endpoint=False)\n687     psi_range = np.linspace(0, 2*np.pi, 2*num, endpoint=False)\n688 \n689     # the pseudocode in [1] do these checks at the end, but it's\n690     # faster to do this criteria check up front instead of later.\n691     if region == 'sky':\n692         mask = phi_range + ai <= np.pi/2\n693     elif region == 'horizon':\n694         lo = 89.5 * np.pi/180\n695         hi = np.pi/2\n696         mask = (lo <= phi_range) & (phi_range + ai <= hi)\n697     elif region == 'ground':\n698         mask = (phi_range >= np.pi/2)\n699     else:\n700         raise ValueError('Invalid region: {}'.format(region))\n701     phi_range = phi_range[mask]\n702 \n703     # fast Cartesian product of phi and psi\n704     angles = np.array(np.meshgrid(phi_range, psi_range)).T.reshape(-1, 2)\n705     # index with single-element lists to maintain 2nd dimension so that\n706     # these angle arrays broadcast across the beta array\n707     phi_1 = angles[:, [0]]\n708     psi_1 = angles[:, [1]]\n709     phi_2 = phi_1 + ai\n710     # psi_2 = psi_1 + ai  # not needed\n711     phi_avg = phi_1 + 0.5*ai\n712     psi_avg = psi_1 + 0.5*ai\n713     term_1 = np.cos(beta) * np.cos(phi_avg)\n714     # The AOI formula includes a term based on the difference between\n715     # panel azimuth and the photon azimuth, but because we assume each class\n716     # of diffuse irradiance is isotropic and we are integrating over all\n717     # angles, it doesn't matter what panel azimuth we choose (i.e., the\n718     # system is rotationally invariant).  So we choose gamma to be zero so\n719     # that we can omit it from the cos(psi_avg) term.\n720     # Marion's paper mentions this in the Section 3 pseudocode:\n721     # \"set gamma to pi (or any value between 0 and 2pi)\"\n722     term_2 = np.sin(beta) * np.sin(phi_avg) * np.cos(psi_avg)\n723     cosaoi = term_1 + term_2\n724     aoi = np.arccos(cosaoi)\n725     # simplify Eq 8, (psi_2 - psi_1) is always ai\n726     dAs = ai * (np.cos(phi_1) - np.cos(phi_2))\n727     cosaoi_dAs = cosaoi * dAs\n728     # apply the final AOI check, zeroing out non-passing points\n729     mask = aoi < np.pi/2\n730     cosaoi_dAs = np.where(mask, cosaoi_dAs, 0)\n731     numerator = np.sum(function(np.degrees(aoi)) * cosaoi_dAs, axis=0)\n732     denominator = np.sum(cosaoi_dAs, axis=0)\n733 \n734     with np.errstate(invalid='ignore'):\n735         # in some cases, no points pass the criteria\n736         # (e.g. region='ground', surface_tilt=0), so we override the division\n737         # by zero to set Fd=0.  Also, preserve nans in beta.\n738         Fd = np.where((denominator != 0) | ~np.isfinite(beta),\n739                       numerator / denominator,\n740                       0)\n741 \n742     # preserve input type\n743     if np.isscalar(surface_tilt):\n744         Fd = Fd.item()\n745     elif isinstance(surface_tilt, pd.Series):\n746         Fd = pd.Series(Fd, surface_tilt.index)\n747 \n748     return Fd\n749 \n[end of pvlib/iam.py]\n[start of pvlib/soiling.py]\n1 # -*- coding: utf-8 -*-\n2 \"\"\"\n3 This module contains functions for soiling models\n4 \"\"\"\n5 \n6 import datetime\n7 import numpy as np\n8 import pandas as pd\n9 from pvlib.tools import cosd\n10 \n11 \n12 def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n13         depo_veloc=None, rain_accum_period=pd.Timedelta('1h')):\n14     \"\"\"\n15     Calculates soiling ratio given particulate and rain data using the model\n16     from Humboldt State University (HSU).\n17 \n18     The HSU soiling model [1]_ returns the soiling ratio, a value between zero\n19     and one which is equivalent to (1 - transmission loss). Therefore a soiling\n20     ratio of 1.0 is equivalent to zero transmission loss.\n21 \n22     Parameters\n23     ----------\n24 \n25     rainfall : Series\n26         Rain accumulated in each time period. [mm]\n27 \n28     cleaning_threshold : float\n29         Amount of rain in an accumulation period needed to clean the PV\n30         modules. [mm]\n31 \n32     tilt : float\n33         Tilt of the PV panels from horizontal. [degree]\n34 \n35     pm2_5 : numeric\n36         Concentration of airborne particulate matter (PM) with\n37         aerodynamic diameter less than 2.5 microns. [g/m^3]\n38 \n39     pm10 : numeric\n40         Concentration of airborne particulate matter (PM) with\n41         aerodynamicdiameter less than 10 microns. [g/m^3]\n42 \n43     depo_veloc : dict, default {'2_5': 0.0009, '10': 0.004}\n44         Deposition or settling velocity of particulates. [m/s]\n45 \n46     rain_accum_period : Timedelta, default 1 hour\n47         Period for accumulating rainfall to check against `cleaning_threshold`\n48         It is recommended that `rain_accum_period` be between 1 hour and\n49         24 hours.\n50 \n51     Returns\n52     -------\n53     soiling_ratio : Series\n54         Values between 0 and 1. Equal to 1 - transmission loss.\n55 \n56     References\n57     -----------\n58     .. [1] M. Coello and L. Boyle, \"Simple Model For Predicting Time Series\n59        Soiling of Photovoltaic Panels,\" in IEEE Journal of Photovoltaics.\n60        doi: 10.1109/JPHOTOV.2019.2919628\n61     .. [2] Atmospheric Chemistry and Physics: From Air Pollution to Climate\n62        Change. J. Seinfeld and S. Pandis. Wiley and Sons 2001.\n63 \n64     \"\"\"\n65     try:\n66         from scipy.special import erf\n67     except ImportError:\n68         raise ImportError(\"The pvlib.soiling.hsu function requires scipy.\")\n69 \n70     # never use mutable input arguments\n71     if depo_veloc is None:\n72         depo_veloc = {'2_5': 0.0009, '10': 0.004}\n73 \n74     # accumulate rainfall into periods for comparison with threshold\n75     accum_rain = rainfall.rolling(rain_accum_period, closed='right').sum()\n76     # cleaning is True for intervals with rainfall greater than threshold\n77     cleaning_times = accum_rain.index[accum_rain >= cleaning_threshold]\n78 \n79     horiz_mass_rate = pm2_5 * depo_veloc['2_5']\\\n80         + np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'] * 3600\n81     tilted_mass_rate = horiz_mass_rate * cosd(tilt)  # assuming no rain\n82 \n83     # tms -> tilt_mass_rate\n84     tms_cumsum = np.cumsum(tilted_mass_rate * np.ones(rainfall.shape))\n85 \n86     mass_no_cleaning = pd.Series(index=rainfall.index, data=tms_cumsum)\n87     # specify dtype so pandas doesn't assume object\n88     mass_removed = pd.Series(index=rainfall.index, dtype='float64')\n89     mass_removed[0] = 0.\n90     mass_removed[cleaning_times] = mass_no_cleaning[cleaning_times]\n91     accum_mass = mass_no_cleaning - mass_removed.ffill()\n92 \n93     soiling_ratio = 1 - 0.3437 * erf(0.17 * accum_mass**0.8473)\n94 \n95     return soiling_ratio\n96 \n97 \n98 def kimber(rainfall, cleaning_threshold=6, soiling_loss_rate=0.0015,\n99            grace_period=14, max_soiling=0.3, manual_wash_dates=None,\n100            initial_soiling=0, rain_accum_period=24):\n101     \"\"\"\n102     Calculates fraction of energy lost due to soiling given rainfall data and\n103     daily loss rate using the Kimber model.\n104 \n105     Kimber soiling model [1]_ assumes soiling builds up at a daily rate unless\n106     the daily rainfall is greater than a threshold. The model also assumes that\n107     if daily rainfall has exceeded the threshold within a grace period, then\n108     the ground is too damp to cause soiling build-up. The model also assumes\n109     there is a maximum soiling build-up. Scheduled manual washes and rain\n110     events are assumed to reset soiling to zero.\n111 \n112     Parameters\n113     ----------\n114     rainfall: pandas.Series\n115         Accumulated rainfall at the end of each time period. [mm]\n116     cleaning_threshold: float, default 6\n117         Amount of daily rainfall required to clean the panels. [mm]\n118     soiling_loss_rate: float, default 0.0015\n119         Fraction of energy lost due to one day of soiling. [unitless]\n120     grace_period : int, default 14\n121         Number of days after a rainfall event when it's assumed the ground is\n122         damp, and so it's assumed there is no soiling. [days]\n123     max_soiling : float, default 0.3\n124         Maximum fraction of energy lost due to soiling. Soiling will build up\n125         until this value. [unitless]\n126     manual_wash_dates : sequence or None, default None\n127         List or tuple of dates as Python ``datetime.date`` when the panels were\n128         washed manually. Note there is no grace period after a manual wash, so\n129         soiling begins to build up immediately.\n130     initial_soiling : float, default 0\n131         Initial fraction of energy lost due to soiling at time zero in the\n132         `rainfall` series input. [unitless]\n133     rain_accum_period : int, default 24\n134         Period for accumulating rainfall to check against `cleaning_threshold`.\n135         The Kimber model defines this period as one day. [hours]\n136 \n137     Returns\n138     -------\n139     pandas.Series\n140         fraction of energy lost due to soiling, has same intervals as input\n141 \n142     Notes\n143     -----\n144     The soiling loss rate depends on both the geographical region and the\n145     soiling environment type. Rates measured by Kimber [1]_ are summarized in\n146     the following table:\n147 \n148     ===================  =======  =========  ======================\n149     Region/Environment   Rural    Suburban   Urban/Highway/Airport\n150     ===================  =======  =========  ======================\n151     Central Valley       0.0011   0.0019     0.0020\n152     Northern CA          0.0011   0.0010     0.0016\n153     Southern CA          0        0.0016     0.0019\n154     Desert               0.0030   0.0030     0.0030\n155     ===================  =======  =========  ======================\n156 \n157     Rainfall thresholds and grace periods may also vary by region. Please\n158     consult [1]_ for more information.\n159 \n160     References\n161     ----------\n162     .. [1] \"The Effect of Soiling on Large Grid-Connected Photovoltaic Systems\n163        in California and the Southwest Region of the United States,\" Adrianne\n164        Kimber, et al., IEEE 4th World Conference on Photovoltaic Energy\n165        Conference, 2006, :doi:`10.1109/WCPEC.2006.279690`\n166     \"\"\"\n167     # convert rain_accum_period to timedelta\n168     rain_accum_period = datetime.timedelta(hours=rain_accum_period)\n169 \n170     # convert grace_period to timedelta\n171     grace_period = datetime.timedelta(days=grace_period)\n172 \n173     # get indices as numpy datetime64, calculate timestep as numpy timedelta64,\n174     # and convert timestep to fraction of days\n175     rain_index_vals = rainfall.index.values\n176     timestep_interval = (rain_index_vals[1] - rain_index_vals[0])\n177     day_fraction = timestep_interval / np.timedelta64(24, 'h')\n178 \n179     # accumulate rainfall\n180     accumulated_rainfall = rainfall.rolling(\n181         rain_accum_period, closed='right').sum()\n182 \n183     # soiling rate\n184     soiling = np.ones_like(rainfall.values) * soiling_loss_rate * day_fraction\n185     soiling[0] = initial_soiling\n186     soiling = np.cumsum(soiling)\n187     soiling = pd.Series(soiling, index=rainfall.index, name='soiling')\n188 \n189     # rainfall events that clean the panels\n190     rain_events = accumulated_rainfall > cleaning_threshold\n191 \n192     # grace periods windows during which ground is assumed damp, so no soiling\n193     grace_windows = rain_events.rolling(grace_period, closed='right').sum() > 0\n194 \n195     # clean panels by subtracting soiling for indices in grace period windows\n196     cleaning = pd.Series(float('NaN'), index=rainfall.index)\n197     cleaning.iloc[0] = 0.0\n198     cleaning[grace_windows] = soiling[grace_windows]\n199 \n200     # manual wash dates\n201     if manual_wash_dates is not None:\n202         rain_tz = rainfall.index.tz\n203         # convert manual wash dates to datetime index in the timezone of rain\n204         manual_wash_dates = pd.DatetimeIndex(manual_wash_dates, tz=rain_tz)\n205         cleaning[manual_wash_dates] = soiling[manual_wash_dates]\n206 \n207     # remove soiling by foward filling cleaning where NaN\n208     soiling -= cleaning.ffill()\n209 \n210     # check if soiling has reached the maximum\n211     return soiling.where(soiling < max_soiling, max_soiling)\n212 \n[end of pvlib/soiling.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "75369dcabacb6c6c38790cc23825f33f155ad1a9", "problem_statement": "pvlib.soiling.hsu model implementation errors\n**Describe the bug**\r\nI ran an example run using the Matlab version of the HSU soiling function and found that the python version did not give anywhere near the same results.  The Matlab results matched the results in the original JPV paper.  As a result of this test, I found two errors in the python implementation, which are listed below:\r\n\r\n1.  depo_veloc = {'2_5': 0.004, '10': 0.0009} has the wrong default values.  They are reversed.\r\nThe proper dictionary should be: {'2_5': 0.0009, '10': 0.004}.  This is confirmed in the JPV paper and the Matlab version of the function.\r\n\r\n2. The horiz_mass_rate is in g/(m^2*hr) but should be in g/(m^2*s).  The line needs to be multiplied by 60x60 or 3600.\r\nThe proper line of code should be: \r\nhoriz_mass_rate = (pm2_5 * depo_veloc['2_5']+ np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'])*3600\r\n\r\nWhen I made these changes I was able to match the validation dataset from the JPV paper, as shown below.\r\n![image](https://user-images.githubusercontent.com/5392756/82380831-61c43d80-99e6-11ea-9ee3-2368fa71e580.png)\r\n\r\n\n", "hints_text": "nice sleuthing Josh! Is a PR forthcoming? \ud83c\udf89 \nHi Mark,\r\n                Yes, a PR is in the works.  I need to improve the testing first.\r\n\r\n-Josh\r\n\r\nFrom: Mark Mikofski <notifications@github.com>\r\nReply-To: pvlib/pvlib-python <reply@reply.github.com>\r\nDate: Tuesday, May 19, 2020 at 3:51 PM\r\nTo: pvlib/pvlib-python <pvlib-python@noreply.github.com>\r\nCc: Joshua Stein <jsstein@sandia.gov>, Author <author@noreply.github.com>\r\nSubject: [EXTERNAL] Re: [pvlib/pvlib-python] pvlib.soiling.hsu model implementation errors (#970)\r\n\r\n\r\nnice sleuthing Josh! Is a PR forthcoming? \ud83c\udf89\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/pvlib/pvlib-python/issues/970#issuecomment-631102921>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABJES5C2CRTZFF7ROT2EPOTRSL5ORANCNFSM4NFL4K3Q>.\r\n\nNow I need to go back and figure out where I missed these errors in the review.", "created_at": "2020-06-12T17:45:46Z", "patch": "<patch>\ndiff --git a/pvlib/soiling.py b/pvlib/soiling.py\n--- a/pvlib/soiling.py\n+++ b/pvlib/soiling.py\n@@ -12,8 +12,8 @@\n def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n         depo_veloc=None, rain_accum_period=pd.Timedelta('1h')):\n     \"\"\"\n-    Calculates soiling ratio given particulate and rain data using the model\n-    from Humboldt State University (HSU).\n+    Calculates soiling ratio given particulate and rain data using the\n+    Fixed Velocity model from Humboldt State University (HSU).\n \n     The HSU soiling model [1]_ returns the soiling ratio, a value between zero\n     and one which is equivalent to (1 - transmission loss). Therefore a soiling\n@@ -76,8 +76,17 @@ def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n     # cleaning is True for intervals with rainfall greater than threshold\n     cleaning_times = accum_rain.index[accum_rain >= cleaning_threshold]\n \n-    horiz_mass_rate = pm2_5 * depo_veloc['2_5']\\\n-        + np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'] * 3600\n+    # determine the time intervals in seconds (dt_sec)\n+    dt = rainfall.index\n+    # subtract shifted values from original and convert to seconds\n+    dt_diff = (dt[1:] - dt[:-1]).total_seconds()\n+    # ensure same number of elements in the array, assuming that the interval\n+    # prior to the first value is equal in length to the first interval\n+    dt_sec = np.append(dt_diff[0], dt_diff).astype('float64')\n+\n+    horiz_mass_rate = (\n+        pm2_5 * depo_veloc['2_5'] + np.maximum(pm10 - pm2_5, 0.)\n+        * depo_veloc['10']) * dt_sec\n     tilted_mass_rate = horiz_mass_rate * cosd(tilt)  # assuming no rain\n \n     # tms -> tilt_mass_rate\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_soiling.py b/pvlib/tests/test_soiling.py\n--- a/pvlib/tests/test_soiling.py\n+++ b/pvlib/tests/test_soiling.py\n@@ -18,24 +18,24 @@ def expected_output():\n                        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n \n     expected_no_cleaning = pd.Series(\n-        data=[0.97230454, 0.95036146, 0.93039061, 0.91177978, 0.89427556,\n-              0.8777455 , 0.86211038, 0.84731759, 0.83332881, 0.82011354,\n-              0.80764549, 0.79590056, 0.78485556, 0.77448749, 0.76477312,\n-              0.75568883, 0.74721046, 0.73931338, 0.73197253, 0.72516253,\n-              0.7188578 , 0.71303268, 0.7076616 , 0.70271919],\n+        data=[0.96998483, 0.94623958, 0.92468139, 0.90465654, 0.88589707,\n+              0.86826366, 0.85167258, 0.83606715, 0.82140458, 0.80764919,\n+              0.79476875, 0.78273241, 0.77150951, 0.76106905, 0.75137932,\n+              0.74240789, 0.73412165, 0.72648695, 0.71946981, 0.7130361,\n+              0.70715176, 0.70178307, 0.69689677, 0.69246034],\n         index=dt)\n     return expected_no_cleaning\n \n @pytest.fixture\n def expected_output_1():\n     dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n-        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n+                       end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n     expected_output_1 = pd.Series(\n-        data=[0.9872406 , 0.97706269, 0.96769693, 0.95884032, 1.,\n-              0.9872406 , 0.97706269, 0.96769693, 1.        , 1.        ,\n-              0.9872406 , 0.97706269, 0.96769693, 0.95884032, 0.95036001,\n-              0.94218263, 0.93426236, 0.92656836, 0.91907873, 0.91177728,\n-              0.9046517 , 0.89769238, 0.89089165, 0.88424329],\n+        data=[0.98484972, 0.97277367, 0.96167471, 0.95119603, 1.,\n+              0.98484972, 0.97277367, 0.96167471, 1., 1.,\n+              0.98484972, 0.97277367, 0.96167471, 0.95119603, 0.94118234,\n+              0.93154854, 0.922242, 0.91322759, 0.90448058, 0.89598283,\n+              0.88772062, 0.87968325, 0.8718622, 0.86425049],\n         index=dt)\n     return expected_output_1\n \n@@ -44,15 +44,31 @@ def expected_output_2():\n     dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n                        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n     expected_output_2 = pd.Series(\n-        data=[0.97229869, 0.95035106, 0.93037619, 0.91176175, 1.,\n-              1.        , 1.        , 0.97229869, 1.        , 1.        ,\n-              1.        , 1.        , 0.97229869, 0.95035106, 0.93037619,\n-              0.91176175, 0.89425431, 1.        , 1.        , 1.        ,\n-              1.        , 0.97229869, 0.95035106, 0.93037619],\n+        data=[0.95036261, 0.91178179, 0.87774818, 0.84732079, 1.,\n+              1., 1., 0.95036261, 1., 1.,\n+              1., 1., 0.95036261, 0.91178179, 0.87774818,\n+              0.84732079, 0.8201171, 1., 1., 1.,\n+              1., 0.95036261, 0.91178179, 0.87774818],\n         index=dt)\n-\n     return expected_output_2\n \n+\n+@pytest.fixture\n+def expected_output_3():\n+    dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n+                       end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n+    timedelta = [0, 0, 0, 0, 0, 30, 0, 30, 0, 30, 0, -30,\n+                 -30, -30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n+    dt_new = dt + pd.to_timedelta(timedelta, 'm')\n+    expected_output_3 = pd.Series(\n+        data=[0.96576705, 0.9387675, 0.91437615, 0.89186852, 1.,\n+              1., 0.98093819, 0.9387675, 1., 1.,\n+              1., 1., 0.96576705, 0.9387675, 0.90291005,\n+              0.88122293, 0.86104089, 1., 1., 1.,\n+              0.96576705, 0.9387675, 0.91437615, 0.89186852],\n+        index=dt_new)\n+    return expected_output_3\n+\n @pytest.fixture\n def rainfall_input():\n \n@@ -105,12 +121,30 @@ def test_hsu_defaults(rainfall_input, expected_output_1):\n     Test Soiling HSU function with default deposition velocity and default rain\n     accumulation period.\n     \"\"\"\n-    result = hsu(\n-        rainfall=rainfall_input, cleaning_threshold=0.5, tilt=0.0,\n-        pm2_5=1.0e-2,pm10=2.0e-2)\n+    result = hsu(rainfall=rainfall_input, cleaning_threshold=0.5, tilt=0.0,\n+                 pm2_5=1.0e-2, pm10=2.0e-2)\n     assert np.allclose(result.values, expected_output_1)\n \n \n+@requires_scipy\n+def test_hsu_variable_time_intervals(rainfall_input, expected_output_3):\n+    \"\"\"\n+    Test Soiling HSU function with variable time intervals.\n+    \"\"\"\n+    depo_veloc = {'2_5': 1.0e-4, '10': 1.0e-4}\n+    rain = pd.DataFrame(data=rainfall_input)\n+    # define time deltas in minutes\n+    timedelta = [0, 0, 0, 0, 0, 30, 0, 30, 0, 30, 0, -30,\n+                 -30, -30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n+    rain['mins_added'] = pd.to_timedelta(timedelta, 'm')\n+    rain['new_time'] = rain.index + rain['mins_added']\n+    rain_var_times = rain.set_index('new_time').iloc[:, 0]\n+    result = hsu(\n+        rainfall=rain_var_times, cleaning_threshold=0.5, tilt=50.0,\n+        pm2_5=1, pm10=2, depo_veloc=depo_veloc,\n+        rain_accum_period=pd.Timedelta('2h'))\n+    assert np.allclose(result, expected_output_3)\n+\n @pytest.fixture\n def greensboro_rain():\n     # get TMY3 data with rain\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/test_soiling.py::test_hsu_no_cleaning\", \"pvlib/tests/test_soiling.py::test_hsu\", \"pvlib/tests/test_soiling.py::test_hsu_defaults\", \"pvlib/tests/test_soiling.py::test_hsu_variable_time_intervals\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_soiling.py::test_kimber_nowash\", \"pvlib/tests/test_soiling.py::test_kimber_manwash\", \"pvlib/tests/test_soiling.py::test_kimber_norain\", \"pvlib/tests/test_soiling.py::test_kimber_initial_soil\"]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-980_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\npvlib.soiling.hsu model implementation errors\n**Describe the bug**\r\nI ran an example run using the Matlab version of the HSU soiling function and found that the python version did not give anywhere near the same results.  The Matlab results matched the results in the original JPV paper.  As a result of this test, I found two errors in the python implementation, which are listed below:\r\n\r\n1.  depo_veloc = {'2_5': 0.004, '10': 0.0009} has the wrong default values.  They are reversed.\r\nThe proper dictionary should be: {'2_5': 0.0009, '10': 0.004}.  This is confirmed in the JPV paper and the Matlab version of the function.\r\n\r\n2. The horiz_mass_rate is in g/(m^2*hr) but should be in g/(m^2*s).  The line needs to be multiplied by 60x60 or 3600.\r\nThe proper line of code should be: \r\nhoriz_mass_rate = (pm2_5 * depo_veloc['2_5']+ np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'])*3600\r\n\r\nWhen I made these changes I was able to match the validation dataset from the JPV paper, as shown below.\r\n![image](https://user-images.githubusercontent.com/5392756/82380831-61c43d80-99e6-11ea-9ee3-2368fa71e580.png)\r\n\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of pvlib/iam.py]\n1 r\"\"\"\n2 The ``iam`` module contains functions that implement models for the incidence\n3 angle modifier (IAM). The IAM quantifies the fraction of direct irradiance on\n4 a module's front surface that is transmitted through the module materials to\n5 the cells. Stated differently, the quantity 1 - IAM is the fraction of direct\n6 irradiance that is reflected away or absorbed by the module's front materials.\n7 IAM is typically a function of the angle of incidence (AOI) of the direct\n8 irradiance to the module's surface.\n9 \"\"\"\n10 \n11 import numpy as np\n12 import pandas as pd\n13 import functools\n14 from pvlib.tools import cosd, sind, tand, asind\n15 \n16 # a dict of required parameter names for each IAM model\n17 # keys are the function names for the IAM models\n18 _IAM_MODEL_PARAMS = {\n19     'ashrae': set(['b']),\n20     'physical': set(['n', 'K', 'L']),\n21     'martin_ruiz': set(['a_r']),\n22     'sapm': set(['B0', 'B1', 'B2', 'B3', 'B4', 'B5']),\n23     'interp': set([])\n24 }\n25 \n26 \n27 def ashrae(aoi, b=0.05):\n28     r\"\"\"\n29     Determine the incidence angle modifier using the ASHRAE transmission\n30     model.\n31 \n32     The ASHRAE (American Society of Heating, Refrigeration, and Air\n33     Conditioning Engineers) transmission model is developed in\n34     [1]_, and in [2]_. The model has been used in software such as PVSyst [3]_.\n35 \n36     Parameters\n37     ----------\n38     aoi : numeric\n39         The angle of incidence (AOI) between the module normal vector and the\n40         sun-beam vector in degrees. Angles of nan will result in nan.\n41 \n42     b : float, default 0.05\n43         A parameter to adjust the incidence angle modifier as a function of\n44         angle of incidence. Typical values are on the order of 0.05 [3].\n45 \n46     Returns\n47     -------\n48     iam : numeric\n49         The incident angle modifier (IAM). Returns zero for all abs(aoi) >= 90\n50         and for all ``iam`` values that would be less than 0.\n51 \n52     Notes\n53     -----\n54     The incidence angle modifier is calculated as\n55 \n56     .. math::\n57 \n58         IAM = 1 - b (\\sec(aoi) - 1)\n59 \n60     As AOI approaches 90 degrees, the model yields negative values for IAM;\n61     negative IAM values are set to zero in this implementation.\n62 \n63     References\n64     ----------\n65     .. [1] Souka A.F., Safwat H.H., \"Determination of the optimum\n66        orientations for the double exposure flat-plate collector and its\n67        reflections\". Solar Energy vol .10, pp 170-174. 1966.\n68 \n69     .. [2] ASHRAE standard 93-77\n70 \n71     .. [3] PVsyst Contextual Help.\n72        https://files.pvsyst.com/help/index.html?iam_loss.htm retrieved on\n73        October 14, 2019\n74 \n75     See Also\n76     --------\n77     pvlib.iam.physical\n78     pvlib.iam.martin_ruiz\n79     pvlib.iam.interp\n80     \"\"\"\n81 \n82     iam = 1 - b * ((1 / np.cos(np.radians(aoi)) - 1))\n83     aoi_gte_90 = np.full_like(aoi, False, dtype='bool')\n84     np.greater_equal(np.abs(aoi), 90, where=~np.isnan(aoi), out=aoi_gte_90)\n85     iam = np.where(aoi_gte_90, 0, iam)\n86     iam = np.maximum(0, iam)\n87 \n88     if isinstance(aoi, pd.Series):\n89         iam = pd.Series(iam, index=aoi.index)\n90 \n91     return iam\n92 \n93 \n94 def physical(aoi, n=1.526, K=4., L=0.002):\n95     r\"\"\"\n96     Determine the incidence angle modifier using refractive index ``n``,\n97     extinction coefficient ``K``, and glazing thickness ``L``.\n98 \n99     ``iam.physical`` calculates the incidence angle modifier as described in\n100     [1]_, Section 3. The calculation is based on a physical model of absorbtion\n101     and transmission through a transparent cover.\n102 \n103     Parameters\n104     ----------\n105     aoi : numeric\n106         The angle of incidence between the module normal vector and the\n107         sun-beam vector in degrees. Angles of 0 are replaced with 1e-06\n108         to ensure non-nan results. Angles of nan will result in nan.\n109 \n110     n : numeric, default 1.526\n111         The effective index of refraction (unitless). Reference [1]_\n112         indicates that a value of 1.526 is acceptable for glass.\n113 \n114     K : numeric, default 4.0\n115         The glazing extinction coefficient in units of 1/meters.\n116         Reference [1] indicates that a value of 4 is reasonable for\n117         \"water white\" glass.\n118 \n119     L : numeric, default 0.002\n120         The glazing thickness in units of meters. Reference [1]_\n121         indicates that 0.002 meters (2 mm) is reasonable for most\n122         glass-covered PV panels.\n123 \n124     Returns\n125     -------\n126     iam : numeric\n127         The incident angle modifier\n128 \n129     Notes\n130     -----\n131     The pvlib python authors believe that Eqn. 14 in [1]_ is\n132     incorrect, which presents :math:`\\theta_{r} = \\arcsin(n \\sin(AOI))`.\n133     Here, :math:`\\theta_{r} = \\arcsin(1/n \\times \\sin(AOI))`\n134 \n135     References\n136     ----------\n137     .. [1] W. De Soto et al., \"Improvement and validation of a model for\n138        photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n139        2006.\n140 \n141     .. [2] Duffie, John A. & Beckman, William A.. (2006). Solar Engineering\n142        of Thermal Processes, third edition. [Books24x7 version] Available\n143        from http://common.books24x7.com/toc.aspx?bookid=17160.\n144 \n145     See Also\n146     --------\n147     pvlib.iam.martin_ruiz\n148     pvlib.iam.ashrae\n149     pvlib.iam.interp\n150     pvlib.iam.sapm\n151     \"\"\"\n152     zeroang = 1e-06\n153 \n154     # hold a new reference to the input aoi object since we're going to\n155     # overwrite the aoi reference below, but we'll need it for the\n156     # series check at the end of the function\n157     aoi_input = aoi\n158 \n159     aoi = np.where(aoi == 0, zeroang, aoi)\n160 \n161     # angle of reflection\n162     thetar_deg = asind(1.0 / n * (sind(aoi)))\n163 \n164     # reflectance and transmittance for normal incidence light\n165     rho_zero = ((1-n) / (1+n)) ** 2\n166     tau_zero = np.exp(-K*L)\n167 \n168     # reflectance for parallel and perpendicular polarized light\n169     rho_para = (tand(thetar_deg - aoi) / tand(thetar_deg + aoi)) ** 2\n170     rho_perp = (sind(thetar_deg - aoi) / sind(thetar_deg + aoi)) ** 2\n171 \n172     # transmittance for non-normal light\n173     tau = np.exp(-K * L / cosd(thetar_deg))\n174 \n175     # iam is ratio of non-normal to normal incidence transmitted light\n176     # after deducting the reflected portion of each\n177     iam = ((1 - (rho_para + rho_perp) / 2) / (1 - rho_zero) * tau / tau_zero)\n178 \n179     with np.errstate(invalid='ignore'):\n180         # angles near zero produce nan, but iam is defined as one\n181         small_angle = 1e-06\n182         iam = np.where(np.abs(aoi) < small_angle, 1.0, iam)\n183 \n184         # angles at 90 degrees can produce tiny negative values,\n185         # which should be zero. this is a result of calculation precision\n186         # rather than the physical model\n187         iam = np.where(iam < 0, 0, iam)\n188 \n189         # for light coming from behind the plane, none can enter the module\n190         iam = np.where(aoi > 90, 0, iam)\n191 \n192     if isinstance(aoi_input, pd.Series):\n193         iam = pd.Series(iam, index=aoi_input.index)\n194 \n195     return iam\n196 \n197 \n198 def martin_ruiz(aoi, a_r=0.16):\n199     r'''\n200     Determine the incidence angle modifier (IAM) using the Martin\n201     and Ruiz incident angle model.\n202 \n203     Parameters\n204     ----------\n205     aoi : numeric, degrees\n206         The angle of incidence between the module normal vector and the\n207         sun-beam vector in degrees.\n208 \n209     a_r : numeric\n210         The angular losses coefficient described in equation 3 of [1]_.\n211         This is an empirical dimensionless parameter. Values of ``a_r`` are\n212         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n213 \n214     Returns\n215     -------\n216     iam : numeric\n217         The incident angle modifier(s)\n218 \n219     Notes\n220     -----\n221     `martin_ruiz` calculates the incidence angle modifier (IAM) as described in\n222     [1]_. The information required is the incident angle (AOI) and the angular\n223     losses coefficient (a_r). Note that [1]_ has a corrigendum [2]_ which\n224     clarifies a mix-up of 'alpha's and 'a's in the former.\n225 \n226     The incident angle modifier is defined as\n227 \n228     .. math::\n229 \n230        IAM = \\frac{1 - \\exp(-\\cos(\\frac{aoi}{a_r}))}\n231        {1 - \\exp(\\frac{-1}{a_r}}\n232 \n233     which is presented as :math:`AL(\\alpha) = 1 - IAM` in equation 4 of [1]_,\n234     with :math:`\\alpha` representing the angle of incidence AOI. Thus IAM = 1\n235     at AOI = 0, and IAM = 0 at AOI = 90.  This equation is only valid for\n236     -90 <= aoi <= 90, therefore `iam` is constrained to 0.0 outside this\n237     interval.\n238 \n239     References\n240     ----------\n241     .. [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n242        losses under field conditions by means of an analytical model\", Solar\n243        Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n244 \n245     .. [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n246        modules angular losses under field conditions by means of an\n247        analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n248        pp. 154, 2013.\n249 \n250     See Also\n251     --------\n252     pvlib.iam.martin_ruiz_diffuse\n253     pvlib.iam.physical\n254     pvlib.iam.ashrae\n255     pvlib.iam.interp\n256     pvlib.iam.sapm\n257     '''\n258     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n259 \n260     aoi_input = aoi\n261 \n262     aoi = np.asanyarray(aoi)\n263     a_r = np.asanyarray(a_r)\n264 \n265     if np.any(np.less_equal(a_r, 0)):\n266         raise ValueError(\"The parameter 'a_r' cannot be zero or negative.\")\n267 \n268     with np.errstate(invalid='ignore'):\n269         iam = (1 - np.exp(-cosd(aoi) / a_r)) / (1 - np.exp(-1 / a_r))\n270         iam = np.where(np.abs(aoi) >= 90.0, 0.0, iam)\n271 \n272     if isinstance(aoi_input, pd.Series):\n273         iam = pd.Series(iam, index=aoi_input.index)\n274 \n275     return iam\n276 \n277 \n278 def martin_ruiz_diffuse(surface_tilt, a_r=0.16, c1=0.4244, c2=None):\n279     '''\n280     Determine the incidence angle modifiers (iam) for diffuse sky and\n281     ground-reflected irradiance using the Martin and Ruiz incident angle model.\n282 \n283     Parameters\n284     ----------\n285     surface_tilt: float or array-like, default 0\n286         Surface tilt angles in decimal degrees.\n287         The tilt angle is defined as degrees from horizontal\n288         (e.g. surface facing up = 0, surface facing horizon = 90)\n289         surface_tilt must be in the range [0, 180]\n290 \n291     a_r : numeric\n292         The angular losses coefficient described in equation 3 of [1]_.\n293         This is an empirical dimensionless parameter. Values of a_r are\n294         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n295         a_r must be greater than zero.\n296 \n297     c1 : float\n298         First fitting parameter for the expressions that approximate the\n299         integral of diffuse irradiance coming from different directions.\n300         c1 is given as the constant 4 / 3 / pi (0.4244) in [1]_.\n301 \n302     c2 : float\n303         Second fitting parameter for the expressions that approximate the\n304         integral of diffuse irradiance coming from different directions.\n305         If c2 is None, it will be calculated according to the linear\n306         relationship given in [3]_.\n307 \n308     Returns\n309     -------\n310     iam_sky : numeric\n311         The incident angle modifier for sky diffuse\n312 \n313     iam_ground : numeric\n314         The incident angle modifier for ground-reflected diffuse\n315 \n316     Notes\n317     -----\n318     Sky and ground modifiers are complementary: iam_sky for tilt = 30 is\n319     equal to iam_ground for tilt = 180 - 30.  For vertical surfaces,\n320     tilt = 90, the two factors are equal.\n321 \n322     References\n323     ----------\n324     .. [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n325        losses under field conditions by means of an analytical model\", Solar\n326        Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n327 \n328     .. [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n329        modules angular losses under field conditions by means of an\n330        analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n331        pp. 154, 2013.\n332 \n333     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n334        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n335 \n336     See Also\n337     --------\n338     pvlib.iam.martin_ruiz\n339     pvlib.iam.physical\n340     pvlib.iam.ashrae\n341     pvlib.iam.interp\n342     pvlib.iam.sapm\n343     '''\n344     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Oct. 2019\n345 \n346     if isinstance(surface_tilt, pd.Series):\n347         out_index = surface_tilt.index\n348     else:\n349         out_index = None\n350 \n351     surface_tilt = np.asanyarray(surface_tilt)\n352 \n353     # avoid undefined results for horizontal or upside-down surfaces\n354     zeroang = 1e-06\n355 \n356     surface_tilt = np.where(surface_tilt == 0, zeroang, surface_tilt)\n357     surface_tilt = np.where(surface_tilt == 180, 180 - zeroang, surface_tilt)\n358 \n359     if c2 is None:\n360         # This equation is from [3] Sect. 7.2\n361         c2 = 0.5 * a_r - 0.154\n362 \n363     beta = np.radians(surface_tilt)\n364 \n365     from numpy import pi, sin, cos, exp\n366 \n367     # avoid RuntimeWarnings for <, sin, and cos with nan\n368     with np.errstate(invalid='ignore'):\n369         # because sin(pi) isn't exactly zero\n370         sin_beta = np.where(surface_tilt < 90, sin(beta), sin(pi - beta))\n371 \n372         trig_term_sky = sin_beta + (pi - beta - sin_beta) / (1 + cos(beta))\n373         trig_term_gnd = sin_beta +      (beta - sin_beta) / (1 - cos(beta))  # noqa: E222 E261 E501\n374 \n375     iam_sky = 1 - exp(-(c1 + c2 * trig_term_sky) * trig_term_sky / a_r)\n376     iam_gnd = 1 - exp(-(c1 + c2 * trig_term_gnd) * trig_term_gnd / a_r)\n377 \n378     if out_index is not None:\n379         iam_sky = pd.Series(iam_sky, index=out_index, name='iam_sky')\n380         iam_gnd = pd.Series(iam_gnd, index=out_index, name='iam_ground')\n381 \n382     return iam_sky, iam_gnd\n383 \n384 \n385 def interp(aoi, theta_ref, iam_ref, method='linear', normalize=True):\n386     r'''\n387     Determine the incidence angle modifier (IAM) by interpolating a set of\n388     reference values, which are usually measured values.\n389 \n390     Parameters\n391     ----------\n392     aoi : numeric\n393         The angle of incidence between the module normal vector and the\n394         sun-beam vector [degrees].\n395 \n396     theta_ref : numeric\n397         Vector of angles at which the IAM is known [degrees].\n398 \n399     iam_ref : numeric\n400         IAM values for each angle in ``theta_ref`` [unitless].\n401 \n402     method : str, default 'linear'\n403         Specifies the interpolation method.\n404         Useful options are: 'linear', 'quadratic', 'cubic'.\n405         See scipy.interpolate.interp1d for more options.\n406 \n407     normalize : boolean, default True\n408         When true, the interpolated values are divided by the interpolated\n409         value at zero degrees.  This ensures that ``iam=1.0`` at normal\n410         incidence.\n411 \n412     Returns\n413     -------\n414     iam : numeric\n415         The incident angle modifier(s) [unitless]\n416 \n417     Notes\n418     -----\n419     ``theta_ref`` must have two or more points and may span any range of\n420     angles. Typically there will be a dozen or more points in the range 0-90\n421     degrees. Beyond the range of ``theta_ref``, IAM values are extrapolated,\n422     but constrained to be non-negative.\n423 \n424     The sign of ``aoi`` is ignored; only the magnitude is used.\n425 \n426     See Also\n427     --------\n428     pvlib.iam.physical\n429     pvlib.iam.ashrae\n430     pvlib.iam.martin_ruiz\n431     pvlib.iam.sapm\n432     '''\n433     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n434 \n435     from scipy.interpolate import interp1d\n436 \n437     # Scipy doesn't give the clearest feedback, so check number of points here.\n438     MIN_REF_VALS = {'linear': 2, 'quadratic': 3, 'cubic': 4, 1: 2, 2: 3, 3: 4}\n439 \n440     if len(theta_ref) < MIN_REF_VALS.get(method, 2):\n441         raise ValueError(\"Too few reference points defined \"\n442                          \"for interpolation method '%s'.\" % method)\n443 \n444     if np.any(np.less(iam_ref, 0)):\n445         raise ValueError(\"Negative value(s) found in 'iam_ref'. \"\n446                          \"This is not physically possible.\")\n447 \n448     interpolator = interp1d(theta_ref, iam_ref, kind=method,\n449                             fill_value='extrapolate')\n450     aoi_input = aoi\n451 \n452     aoi = np.asanyarray(aoi)\n453     aoi = np.abs(aoi)\n454     iam = interpolator(aoi)\n455     iam = np.clip(iam, 0, None)\n456 \n457     if normalize:\n458         iam /= interpolator(0)\n459 \n460     if isinstance(aoi_input, pd.Series):\n461         iam = pd.Series(iam, index=aoi_input.index)\n462 \n463     return iam\n464 \n465 \n466 def sapm(aoi, module, upper=None):\n467     r\"\"\"\n468     Determine the incidence angle modifier (IAM) using the SAPM model.\n469 \n470     Parameters\n471     ----------\n472     aoi : numeric\n473         Angle of incidence in degrees. Negative input angles will return\n474         zeros.\n475 \n476     module : dict-like\n477         A dict or Series with the SAPM IAM model parameters.\n478         See the :py:func:`sapm` notes section for more details.\n479 \n480     upper : None or float, default None\n481         Upper limit on the results.\n482 \n483     Returns\n484     -------\n485     iam : numeric\n486         The SAPM angle of incidence loss coefficient, termed F2 in [1]_.\n487 \n488     Notes\n489     -----\n490     The SAPM [1]_ traditionally does not define an upper limit on the AOI\n491     loss function and values slightly exceeding 1 may exist for moderate\n492     angles of incidence (15-40 degrees). However, users may consider\n493     imposing an upper limit of 1.\n494 \n495     References\n496     ----------\n497     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n498        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n499        NM.\n500 \n501     .. [2] B.H. King et al, \"Procedure to Determine Coefficients for the\n502        Sandia Array Performance Model (SAPM),\" SAND2016-5284, Sandia\n503        National Laboratories (2016).\n504 \n505     .. [3] B.H. King et al, \"Recent Advancements in Outdoor Measurement\n506        Techniques for Angle of Incidence Effects,\" 42nd IEEE PVSC (2015).\n507        DOI: 10.1109/PVSC.2015.7355849\n508 \n509     See Also\n510     --------\n511     pvlib.iam.physical\n512     pvlib.iam.ashrae\n513     pvlib.iam.martin_ruiz\n514     pvlib.iam.interp\n515     \"\"\"\n516 \n517     aoi_coeff = [module['B5'], module['B4'], module['B3'], module['B2'],\n518                  module['B1'], module['B0']]\n519 \n520     iam = np.polyval(aoi_coeff, aoi)\n521     iam = np.clip(iam, 0, upper)\n522     # nan tolerant masking\n523     aoi_lt_0 = np.full_like(aoi, False, dtype='bool')\n524     np.less(aoi, 0, where=~np.isnan(aoi), out=aoi_lt_0)\n525     iam = np.where(aoi_lt_0, 0, iam)\n526 \n527     if isinstance(aoi, pd.Series):\n528         iam = pd.Series(iam, aoi.index)\n529 \n530     return iam\n531 \n532 \n533 def marion_diffuse(model, surface_tilt, **kwargs):\n534     \"\"\"\n535     Determine diffuse irradiance incidence angle modifiers using Marion's\n536     method of integrating over solid angle.\n537 \n538     Parameters\n539     ----------\n540     model : str\n541         The IAM function to evaluate across solid angle. Must be one of\n542         `'ashrae', 'physical', 'martin_ruiz', 'sapm'`.\n543 \n544     surface_tilt : numeric\n545         Surface tilt angles in decimal degrees.\n546         The tilt angle is defined as degrees from horizontal\n547         (e.g. surface facing up = 0, surface facing horizon = 90).\n548 \n549     **kwargs\n550         Extra parameters passed to the IAM function.\n551 \n552     Returns\n553     -------\n554     iam : dict\n555         IAM values for each type of diffuse irradiance:\n556 \n557             * 'sky': radiation from the sky dome (zenith <= 90)\n558             * 'horizon': radiation from the region of the sky near the horizon\n559               (89.5 <= zenith <= 90)\n560             * 'ground': radiation reflected from the ground (zenith >= 90)\n561 \n562         See [1]_ for a detailed description of each class.\n563 \n564     See Also\n565     --------\n566     pvlib.iam.marion_integrate\n567 \n568     References\n569     ----------\n570     .. [1] B. Marion \"Numerical method for angle-of-incidence correction\n571        factors for diffuse radiation incident photovoltaic modules\",\n572        Solar Energy, Volume 147, Pages 344-348. 2017.\n573        DOI: 10.1016/j.solener.2017.03.027\n574 \n575     Examples\n576     --------\n577     >>> marion_diffuse('physical', surface_tilt=20)\n578     {'sky': 0.9539178294437575,\n579      'horizon': 0.7652650139134007,\n580      'ground': 0.6387140117795903}\n581 \n582     >>> marion_diffuse('ashrae', [20, 30], b=0.04)\n583     {'sky': array([0.96748999, 0.96938408]),\n584      'horizon': array([0.86478428, 0.91825792]),\n585      'ground': array([0.77004435, 0.8522436 ])}\n586     \"\"\"\n587 \n588     models = {\n589         'physical': physical,\n590         'ashrae': ashrae,\n591         'sapm': sapm,\n592         'martin_ruiz': martin_ruiz,\n593     }\n594 \n595     try:\n596         iam_model = models[model]\n597     except KeyError:\n598         raise ValueError('model must be one of: ' + str(list(models.keys())))\n599 \n600     iam_function = functools.partial(iam_model, **kwargs)\n601     iam = {}\n602     for region in ['sky', 'horizon', 'ground']:\n603         iam[region] = marion_integrate(iam_function, surface_tilt, region)\n604 \n605     return iam\n606 \n607 \n608 def marion_integrate(function, surface_tilt, region, num=None):\n609     \"\"\"\n610     Integrate an incidence angle modifier (IAM) function over solid angle\n611     to determine a diffuse irradiance correction factor using Marion's method.\n612 \n613     This lower-level function actually performs the IAM integration for the\n614     specified solid angle region.\n615 \n616     Parameters\n617     ----------\n618     function : callable(aoi)\n619         The IAM function to evaluate across solid angle. The function must\n620         be vectorized and take only one parameter, the angle of incidence in\n621         degrees.\n622 \n623     surface_tilt : numeric\n624         Surface tilt angles in decimal degrees.\n625         The tilt angle is defined as degrees from horizontal\n626         (e.g. surface facing up = 0, surface facing horizon = 90).\n627 \n628     region : {'sky', 'horizon', 'ground'}\n629         The region to integrate over. Must be one of:\n630 \n631             * 'sky': radiation from the sky dome (zenith <= 90)\n632             * 'horizon': radiation from the region of the sky near the horizon\n633               (89.5 <= zenith <= 90)\n634             * 'ground': radiation reflected from the ground (zenith >= 90)\n635 \n636         See [1]_ for a detailed description of each class.\n637 \n638     num : int, optional\n639         The number of increments in the zenith integration.\n640         If not specified, N will follow the values used in [1]_:\n641 \n642             * 'sky' or 'ground': num = 180\n643             * 'horizon': num = 1800\n644 \n645     Returns\n646     -------\n647     iam : numeric\n648         AOI diffuse correction factor for the specified region.\n649 \n650     See Also\n651     --------\n652     pvlib.iam.marion_diffuse\n653 \n654     References\n655     ----------\n656     .. [1] B. Marion \"Numerical method for angle-of-incidence correction\n657        factors for diffuse radiation incident photovoltaic modules\",\n658        Solar Energy, Volume 147, Pages 344-348. 2017.\n659        DOI: 10.1016/j.solener.2017.03.027\n660 \n661     Examples\n662     --------\n663     >>> marion_integrate(pvlib.iam.ashrae, 20, 'sky')\n664     0.9596085829811408\n665 \n666     >>> from functools import partial\n667     >>> f = partial(pvlib.iam.physical, n=1.3)\n668     >>> marion_integrate(f, [20, 30], 'sky')\n669     array([0.96225034, 0.9653219 ])\n670     \"\"\"\n671 \n672     if num is None:\n673         if region in ['sky', 'ground']:\n674             num = 180\n675         elif region == 'horizon':\n676             num = 1800\n677         else:\n678             raise ValueError('Invalid region: {}'.format(region))\n679 \n680     beta = np.radians(surface_tilt)\n681     if isinstance(beta, pd.Series):\n682         # convert Series to np array for broadcasting later\n683         beta = beta.values\n684     ai = np.pi/num  # angular increment\n685 \n686     phi_range = np.linspace(0, np.pi, num, endpoint=False)\n687     psi_range = np.linspace(0, 2*np.pi, 2*num, endpoint=False)\n688 \n689     # the pseudocode in [1] do these checks at the end, but it's\n690     # faster to do this criteria check up front instead of later.\n691     if region == 'sky':\n692         mask = phi_range + ai <= np.pi/2\n693     elif region == 'horizon':\n694         lo = 89.5 * np.pi/180\n695         hi = np.pi/2\n696         mask = (lo <= phi_range) & (phi_range + ai <= hi)\n697     elif region == 'ground':\n698         mask = (phi_range >= np.pi/2)\n699     else:\n700         raise ValueError('Invalid region: {}'.format(region))\n701     phi_range = phi_range[mask]\n702 \n703     # fast Cartesian product of phi and psi\n704     angles = np.array(np.meshgrid(phi_range, psi_range)).T.reshape(-1, 2)\n705     # index with single-element lists to maintain 2nd dimension so that\n706     # these angle arrays broadcast across the beta array\n707     phi_1 = angles[:, [0]]\n708     psi_1 = angles[:, [1]]\n709     phi_2 = phi_1 + ai\n710     # psi_2 = psi_1 + ai  # not needed\n711     phi_avg = phi_1 + 0.5*ai\n712     psi_avg = psi_1 + 0.5*ai\n713     term_1 = np.cos(beta) * np.cos(phi_avg)\n714     # The AOI formula includes a term based on the difference between\n715     # panel azimuth and the photon azimuth, but because we assume each class\n716     # of diffuse irradiance is isotropic and we are integrating over all\n717     # angles, it doesn't matter what panel azimuth we choose (i.e., the\n718     # system is rotationally invariant).  So we choose gamma to be zero so\n719     # that we can omit it from the cos(psi_avg) term.\n720     # Marion's paper mentions this in the Section 3 pseudocode:\n721     # \"set gamma to pi (or any value between 0 and 2pi)\"\n722     term_2 = np.sin(beta) * np.sin(phi_avg) * np.cos(psi_avg)\n723     cosaoi = term_1 + term_2\n724     aoi = np.arccos(cosaoi)\n725     # simplify Eq 8, (psi_2 - psi_1) is always ai\n726     dAs = ai * (np.cos(phi_1) - np.cos(phi_2))\n727     cosaoi_dAs = cosaoi * dAs\n728     # apply the final AOI check, zeroing out non-passing points\n729     mask = aoi < np.pi/2\n730     cosaoi_dAs = np.where(mask, cosaoi_dAs, 0)\n731     numerator = np.sum(function(np.degrees(aoi)) * cosaoi_dAs, axis=0)\n732     denominator = np.sum(cosaoi_dAs, axis=0)\n733 \n734     with np.errstate(invalid='ignore'):\n735         # in some cases, no points pass the criteria\n736         # (e.g. region='ground', surface_tilt=0), so we override the division\n737         # by zero to set Fd=0.  Also, preserve nans in beta.\n738         Fd = np.where((denominator != 0) | ~np.isfinite(beta),\n739                       numerator / denominator,\n740                       0)\n741 \n742     # preserve input type\n743     if np.isscalar(surface_tilt):\n744         Fd = Fd.item()\n745     elif isinstance(surface_tilt, pd.Series):\n746         Fd = pd.Series(Fd, surface_tilt.index)\n747 \n748     return Fd\n749 \n[end of pvlib/iam.py]\n[start of pvlib/soiling.py]\n1 # -*- coding: utf-8 -*-\n2 \"\"\"\n3 This module contains functions for soiling models\n4 \"\"\"\n5 \n6 import datetime\n7 import numpy as np\n8 import pandas as pd\n9 from pvlib.tools import cosd\n10 \n11 \n12 def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n13         depo_veloc=None, rain_accum_period=pd.Timedelta('1h')):\n14     \"\"\"\n15     Calculates soiling ratio given particulate and rain data using the model\n16     from Humboldt State University (HSU).\n17 \n18     The HSU soiling model [1]_ returns the soiling ratio, a value between zero\n19     and one which is equivalent to (1 - transmission loss). Therefore a soiling\n20     ratio of 1.0 is equivalent to zero transmission loss.\n21 \n22     Parameters\n23     ----------\n24 \n25     rainfall : Series\n26         Rain accumulated in each time period. [mm]\n27 \n28     cleaning_threshold : float\n29         Amount of rain in an accumulation period needed to clean the PV\n30         modules. [mm]\n31 \n32     tilt : float\n33         Tilt of the PV panels from horizontal. [degree]\n34 \n35     pm2_5 : numeric\n36         Concentration of airborne particulate matter (PM) with\n37         aerodynamic diameter less than 2.5 microns. [g/m^3]\n38 \n39     pm10 : numeric\n40         Concentration of airborne particulate matter (PM) with\n41         aerodynamicdiameter less than 10 microns. [g/m^3]\n42 \n43     depo_veloc : dict, default {'2_5': 0.0009, '10': 0.004}\n44         Deposition or settling velocity of particulates. [m/s]\n45 \n46     rain_accum_period : Timedelta, default 1 hour\n47         Period for accumulating rainfall to check against `cleaning_threshold`\n48         It is recommended that `rain_accum_period` be between 1 hour and\n49         24 hours.\n50 \n51     Returns\n52     -------\n53     soiling_ratio : Series\n54         Values between 0 and 1. Equal to 1 - transmission loss.\n55 \n56     References\n57     -----------\n58     .. [1] M. Coello and L. Boyle, \"Simple Model For Predicting Time Series\n59        Soiling of Photovoltaic Panels,\" in IEEE Journal of Photovoltaics.\n60        doi: 10.1109/JPHOTOV.2019.2919628\n61     .. [2] Atmospheric Chemistry and Physics: From Air Pollution to Climate\n62        Change. J. Seinfeld and S. Pandis. Wiley and Sons 2001.\n63 \n64     \"\"\"\n65     try:\n66         from scipy.special import erf\n67     except ImportError:\n68         raise ImportError(\"The pvlib.soiling.hsu function requires scipy.\")\n69 \n70     # never use mutable input arguments\n71     if depo_veloc is None:\n72         depo_veloc = {'2_5': 0.0009, '10': 0.004}\n73 \n74     # accumulate rainfall into periods for comparison with threshold\n75     accum_rain = rainfall.rolling(rain_accum_period, closed='right').sum()\n76     # cleaning is True for intervals with rainfall greater than threshold\n77     cleaning_times = accum_rain.index[accum_rain >= cleaning_threshold]\n78 \n79     horiz_mass_rate = pm2_5 * depo_veloc['2_5']\\\n80         + np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'] * 3600\n81     tilted_mass_rate = horiz_mass_rate * cosd(tilt)  # assuming no rain\n82 \n83     # tms -> tilt_mass_rate\n84     tms_cumsum = np.cumsum(tilted_mass_rate * np.ones(rainfall.shape))\n85 \n86     mass_no_cleaning = pd.Series(index=rainfall.index, data=tms_cumsum)\n87     # specify dtype so pandas doesn't assume object\n88     mass_removed = pd.Series(index=rainfall.index, dtype='float64')\n89     mass_removed[0] = 0.\n90     mass_removed[cleaning_times] = mass_no_cleaning[cleaning_times]\n91     accum_mass = mass_no_cleaning - mass_removed.ffill()\n92 \n93     soiling_ratio = 1 - 0.3437 * erf(0.17 * accum_mass**0.8473)\n94 \n95     return soiling_ratio\n96 \n97 \n98 def kimber(rainfall, cleaning_threshold=6, soiling_loss_rate=0.0015,\n99            grace_period=14, max_soiling=0.3, manual_wash_dates=None,\n100            initial_soiling=0, rain_accum_period=24):\n101     \"\"\"\n102     Calculates fraction of energy lost due to soiling given rainfall data and\n103     daily loss rate using the Kimber model.\n104 \n105     Kimber soiling model [1]_ assumes soiling builds up at a daily rate unless\n106     the daily rainfall is greater than a threshold. The model also assumes that\n107     if daily rainfall has exceeded the threshold within a grace period, then\n108     the ground is too damp to cause soiling build-up. The model also assumes\n109     there is a maximum soiling build-up. Scheduled manual washes and rain\n110     events are assumed to reset soiling to zero.\n111 \n112     Parameters\n113     ----------\n114     rainfall: pandas.Series\n115         Accumulated rainfall at the end of each time period. [mm]\n116     cleaning_threshold: float, default 6\n117         Amount of daily rainfall required to clean the panels. [mm]\n118     soiling_loss_rate: float, default 0.0015\n119         Fraction of energy lost due to one day of soiling. [unitless]\n120     grace_period : int, default 14\n121         Number of days after a rainfall event when it's assumed the ground is\n122         damp, and so it's assumed there is no soiling. [days]\n123     max_soiling : float, default 0.3\n124         Maximum fraction of energy lost due to soiling. Soiling will build up\n125         until this value. [unitless]\n126     manual_wash_dates : sequence or None, default None\n127         List or tuple of dates as Python ``datetime.date`` when the panels were\n128         washed manually. Note there is no grace period after a manual wash, so\n129         soiling begins to build up immediately.\n130     initial_soiling : float, default 0\n131         Initial fraction of energy lost due to soiling at time zero in the\n132         `rainfall` series input. [unitless]\n133     rain_accum_period : int, default 24\n134         Period for accumulating rainfall to check against `cleaning_threshold`.\n135         The Kimber model defines this period as one day. [hours]\n136 \n137     Returns\n138     -------\n139     pandas.Series\n140         fraction of energy lost due to soiling, has same intervals as input\n141 \n142     Notes\n143     -----\n144     The soiling loss rate depends on both the geographical region and the\n145     soiling environment type. Rates measured by Kimber [1]_ are summarized in\n146     the following table:\n147 \n148     ===================  =======  =========  ======================\n149     Region/Environment   Rural    Suburban   Urban/Highway/Airport\n150     ===================  =======  =========  ======================\n151     Central Valley       0.0011   0.0019     0.0020\n152     Northern CA          0.0011   0.0010     0.0016\n153     Southern CA          0        0.0016     0.0019\n154     Desert               0.0030   0.0030     0.0030\n155     ===================  =======  =========  ======================\n156 \n157     Rainfall thresholds and grace periods may also vary by region. Please\n158     consult [1]_ for more information.\n159 \n160     References\n161     ----------\n162     .. [1] \"The Effect of Soiling on Large Grid-Connected Photovoltaic Systems\n163        in California and the Southwest Region of the United States,\" Adrianne\n164        Kimber, et al., IEEE 4th World Conference on Photovoltaic Energy\n165        Conference, 2006, :doi:`10.1109/WCPEC.2006.279690`\n166     \"\"\"\n167     # convert rain_accum_period to timedelta\n168     rain_accum_period = datetime.timedelta(hours=rain_accum_period)\n169 \n170     # convert grace_period to timedelta\n171     grace_period = datetime.timedelta(days=grace_period)\n172 \n173     # get indices as numpy datetime64, calculate timestep as numpy timedelta64,\n174     # and convert timestep to fraction of days\n175     rain_index_vals = rainfall.index.values\n176     timestep_interval = (rain_index_vals[1] - rain_index_vals[0])\n177     day_fraction = timestep_interval / np.timedelta64(24, 'h')\n178 \n179     # accumulate rainfall\n180     accumulated_rainfall = rainfall.rolling(\n181         rain_accum_period, closed='right').sum()\n182 \n183     # soiling rate\n184     soiling = np.ones_like(rainfall.values) * soiling_loss_rate * day_fraction\n185     soiling[0] = initial_soiling\n186     soiling = np.cumsum(soiling)\n187     soiling = pd.Series(soiling, index=rainfall.index, name='soiling')\n188 \n189     # rainfall events that clean the panels\n190     rain_events = accumulated_rainfall > cleaning_threshold\n191 \n192     # grace periods windows during which ground is assumed damp, so no soiling\n193     grace_windows = rain_events.rolling(grace_period, closed='right').sum() > 0\n194 \n195     # clean panels by subtracting soiling for indices in grace period windows\n196     cleaning = pd.Series(float('NaN'), index=rainfall.index)\n197     cleaning.iloc[0] = 0.0\n198     cleaning[grace_windows] = soiling[grace_windows]\n199 \n200     # manual wash dates\n201     if manual_wash_dates is not None:\n202         rain_tz = rainfall.index.tz\n203         # convert manual wash dates to datetime index in the timezone of rain\n204         manual_wash_dates = pd.DatetimeIndex(manual_wash_dates, tz=rain_tz)\n205         cleaning[manual_wash_dates] = soiling[manual_wash_dates]\n206 \n207     # remove soiling by foward filling cleaning where NaN\n208     soiling -= cleaning.ffill()\n209 \n210     # check if soiling has reached the maximum\n211     return soiling.where(soiling < max_soiling, max_soiling)\n212 \n[end of pvlib/soiling.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "75369dcabacb6c6c38790cc23825f33f155ad1a9", "problem_statement": "pvlib.soiling.hsu model implementation errors\n**Describe the bug**\r\nI ran an example run using the Matlab version of the HSU soiling function and found that the python version did not give anywhere near the same results.  The Matlab results matched the results in the original JPV paper.  As a result of this test, I found two errors in the python implementation, which are listed below:\r\n\r\n1.  depo_veloc = {'2_5': 0.004, '10': 0.0009} has the wrong default values.  They are reversed.\r\nThe proper dictionary should be: {'2_5': 0.0009, '10': 0.004}.  This is confirmed in the JPV paper and the Matlab version of the function.\r\n\r\n2. The horiz_mass_rate is in g/(m^2*hr) but should be in g/(m^2*s).  The line needs to be multiplied by 60x60 or 3600.\r\nThe proper line of code should be: \r\nhoriz_mass_rate = (pm2_5 * depo_veloc['2_5']+ np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'])*3600\r\n\r\nWhen I made these changes I was able to match the validation dataset from the JPV paper, as shown below.\r\n![image](https://user-images.githubusercontent.com/5392756/82380831-61c43d80-99e6-11ea-9ee3-2368fa71e580.png)\r\n\r\n\n", "hints_text": "nice sleuthing Josh! Is a PR forthcoming? \ud83c\udf89 \nHi Mark,\r\n                Yes, a PR is in the works.  I need to improve the testing first.\r\n\r\n-Josh\r\n\r\nFrom: Mark Mikofski <notifications@github.com>\r\nReply-To: pvlib/pvlib-python <reply@reply.github.com>\r\nDate: Tuesday, May 19, 2020 at 3:51 PM\r\nTo: pvlib/pvlib-python <pvlib-python@noreply.github.com>\r\nCc: Joshua Stein <jsstein@sandia.gov>, Author <author@noreply.github.com>\r\nSubject: [EXTERNAL] Re: [pvlib/pvlib-python] pvlib.soiling.hsu model implementation errors (#970)\r\n\r\n\r\nnice sleuthing Josh! Is a PR forthcoming? \ud83c\udf89\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/pvlib/pvlib-python/issues/970#issuecomment-631102921>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABJES5C2CRTZFF7ROT2EPOTRSL5ORANCNFSM4NFL4K3Q>.\r\n\nNow I need to go back and figure out where I missed these errors in the review.", "created_at": "2020-06-12T17:45:46Z", "patch": "<patch>\ndiff --git a/pvlib/soiling.py b/pvlib/soiling.py\n--- a/pvlib/soiling.py\n+++ b/pvlib/soiling.py\n@@ -12,8 +12,8 @@\n def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n         depo_veloc=None, rain_accum_period=pd.Timedelta('1h')):\n     \"\"\"\n-    Calculates soiling ratio given particulate and rain data using the model\n-    from Humboldt State University (HSU).\n+    Calculates soiling ratio given particulate and rain data using the\n+    Fixed Velocity model from Humboldt State University (HSU).\n \n     The HSU soiling model [1]_ returns the soiling ratio, a value between zero\n     and one which is equivalent to (1 - transmission loss). Therefore a soiling\n@@ -76,8 +76,17 @@ def hsu(rainfall, cleaning_threshold, tilt, pm2_5, pm10,\n     # cleaning is True for intervals with rainfall greater than threshold\n     cleaning_times = accum_rain.index[accum_rain >= cleaning_threshold]\n \n-    horiz_mass_rate = pm2_5 * depo_veloc['2_5']\\\n-        + np.maximum(pm10 - pm2_5, 0.) * depo_veloc['10'] * 3600\n+    # determine the time intervals in seconds (dt_sec)\n+    dt = rainfall.index\n+    # subtract shifted values from original and convert to seconds\n+    dt_diff = (dt[1:] - dt[:-1]).total_seconds()\n+    # ensure same number of elements in the array, assuming that the interval\n+    # prior to the first value is equal in length to the first interval\n+    dt_sec = np.append(dt_diff[0], dt_diff).astype('float64')\n+\n+    horiz_mass_rate = (\n+        pm2_5 * depo_veloc['2_5'] + np.maximum(pm10 - pm2_5, 0.)\n+        * depo_veloc['10']) * dt_sec\n     tilted_mass_rate = horiz_mass_rate * cosd(tilt)  # assuming no rain\n \n     # tms -> tilt_mass_rate\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_soiling.py b/pvlib/tests/test_soiling.py\n--- a/pvlib/tests/test_soiling.py\n+++ b/pvlib/tests/test_soiling.py\n@@ -18,24 +18,24 @@ def expected_output():\n                        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n \n     expected_no_cleaning = pd.Series(\n-        data=[0.97230454, 0.95036146, 0.93039061, 0.91177978, 0.89427556,\n-              0.8777455 , 0.86211038, 0.84731759, 0.83332881, 0.82011354,\n-              0.80764549, 0.79590056, 0.78485556, 0.77448749, 0.76477312,\n-              0.75568883, 0.74721046, 0.73931338, 0.73197253, 0.72516253,\n-              0.7188578 , 0.71303268, 0.7076616 , 0.70271919],\n+        data=[0.96998483, 0.94623958, 0.92468139, 0.90465654, 0.88589707,\n+              0.86826366, 0.85167258, 0.83606715, 0.82140458, 0.80764919,\n+              0.79476875, 0.78273241, 0.77150951, 0.76106905, 0.75137932,\n+              0.74240789, 0.73412165, 0.72648695, 0.71946981, 0.7130361,\n+              0.70715176, 0.70178307, 0.69689677, 0.69246034],\n         index=dt)\n     return expected_no_cleaning\n \n @pytest.fixture\n def expected_output_1():\n     dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n-        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n+                       end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n     expected_output_1 = pd.Series(\n-        data=[0.9872406 , 0.97706269, 0.96769693, 0.95884032, 1.,\n-              0.9872406 , 0.97706269, 0.96769693, 1.        , 1.        ,\n-              0.9872406 , 0.97706269, 0.96769693, 0.95884032, 0.95036001,\n-              0.94218263, 0.93426236, 0.92656836, 0.91907873, 0.91177728,\n-              0.9046517 , 0.89769238, 0.89089165, 0.88424329],\n+        data=[0.98484972, 0.97277367, 0.96167471, 0.95119603, 1.,\n+              0.98484972, 0.97277367, 0.96167471, 1., 1.,\n+              0.98484972, 0.97277367, 0.96167471, 0.95119603, 0.94118234,\n+              0.93154854, 0.922242, 0.91322759, 0.90448058, 0.89598283,\n+              0.88772062, 0.87968325, 0.8718622, 0.86425049],\n         index=dt)\n     return expected_output_1\n \n@@ -44,15 +44,31 @@ def expected_output_2():\n     dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n                        end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n     expected_output_2 = pd.Series(\n-        data=[0.97229869, 0.95035106, 0.93037619, 0.91176175, 1.,\n-              1.        , 1.        , 0.97229869, 1.        , 1.        ,\n-              1.        , 1.        , 0.97229869, 0.95035106, 0.93037619,\n-              0.91176175, 0.89425431, 1.        , 1.        , 1.        ,\n-              1.        , 0.97229869, 0.95035106, 0.93037619],\n+        data=[0.95036261, 0.91178179, 0.87774818, 0.84732079, 1.,\n+              1., 1., 0.95036261, 1., 1.,\n+              1., 1., 0.95036261, 0.91178179, 0.87774818,\n+              0.84732079, 0.8201171, 1., 1., 1.,\n+              1., 0.95036261, 0.91178179, 0.87774818],\n         index=dt)\n-\n     return expected_output_2\n \n+\n+@pytest.fixture\n+def expected_output_3():\n+    dt = pd.date_range(start=pd.Timestamp(2019, 1, 1, 0, 0, 0),\n+                       end=pd.Timestamp(2019, 1, 1, 23, 59, 0), freq='1h')\n+    timedelta = [0, 0, 0, 0, 0, 30, 0, 30, 0, 30, 0, -30,\n+                 -30, -30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n+    dt_new = dt + pd.to_timedelta(timedelta, 'm')\n+    expected_output_3 = pd.Series(\n+        data=[0.96576705, 0.9387675, 0.91437615, 0.89186852, 1.,\n+              1., 0.98093819, 0.9387675, 1., 1.,\n+              1., 1., 0.96576705, 0.9387675, 0.90291005,\n+              0.88122293, 0.86104089, 1., 1., 1.,\n+              0.96576705, 0.9387675, 0.91437615, 0.89186852],\n+        index=dt_new)\n+    return expected_output_3\n+\n @pytest.fixture\n def rainfall_input():\n \n@@ -105,12 +121,30 @@ def test_hsu_defaults(rainfall_input, expected_output_1):\n     Test Soiling HSU function with default deposition velocity and default rain\n     accumulation period.\n     \"\"\"\n-    result = hsu(\n-        rainfall=rainfall_input, cleaning_threshold=0.5, tilt=0.0,\n-        pm2_5=1.0e-2,pm10=2.0e-2)\n+    result = hsu(rainfall=rainfall_input, cleaning_threshold=0.5, tilt=0.0,\n+                 pm2_5=1.0e-2, pm10=2.0e-2)\n     assert np.allclose(result.values, expected_output_1)\n \n \n+@requires_scipy\n+def test_hsu_variable_time_intervals(rainfall_input, expected_output_3):\n+    \"\"\"\n+    Test Soiling HSU function with variable time intervals.\n+    \"\"\"\n+    depo_veloc = {'2_5': 1.0e-4, '10': 1.0e-4}\n+    rain = pd.DataFrame(data=rainfall_input)\n+    # define time deltas in minutes\n+    timedelta = [0, 0, 0, 0, 0, 30, 0, 30, 0, 30, 0, -30,\n+                 -30, -30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n+    rain['mins_added'] = pd.to_timedelta(timedelta, 'm')\n+    rain['new_time'] = rain.index + rain['mins_added']\n+    rain_var_times = rain.set_index('new_time').iloc[:, 0]\n+    result = hsu(\n+        rainfall=rain_var_times, cleaning_threshold=0.5, tilt=50.0,\n+        pm2_5=1, pm10=2, depo_veloc=depo_veloc,\n+        rain_accum_period=pd.Timedelta('2h'))\n+    assert np.allclose(result, expected_output_3)\n+\n @pytest.fixture\n def greensboro_rain():\n     # get TMY3 data with rain\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/test_soiling.py::test_hsu_no_cleaning\", \"pvlib/tests/test_soiling.py::test_hsu\", \"pvlib/tests/test_soiling.py::test_hsu_defaults\", \"pvlib/tests/test_soiling.py::test_hsu_variable_time_intervals\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_soiling.py::test_kimber_nowash\", \"pvlib/tests/test_soiling.py::test_kimber_manwash\", \"pvlib/tests/test_soiling.py::test_kimber_norain\", \"pvlib/tests/test_soiling.py::test_kimber_initial_soil\"]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pydicom__pydicom-1256_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nfrom_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 import base64\n11 import json\n12 from typing import (\n13     Optional, Any, Optional, Tuple, Callable, Union, TYPE_CHECKING, Dict,\n14     TypeVar, Type, List, NamedTuple\n15 )\n16 import warnings\n17 \n18 from pydicom import config  # don't import datetime_conversion directly\n19 from pydicom.config import logger\n20 from pydicom import config\n21 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n22                               dictionary_keyword, dictionary_is_retired,\n23                               private_dictionary_description, dictionary_VR,\n24                               repeater_has_tag)\n25 from pydicom.jsonrep import JsonDataElementConverter\n26 from pydicom.multival import MultiValue\n27 from pydicom.tag import Tag, BaseTag\n28 from pydicom.uid import UID\n29 from pydicom import jsonrep\n30 import pydicom.valuerep  # don't import DS directly as can be changed by config\n31 from pydicom.valuerep import PersonName\n32 \n33 if config.have_numpy:\n34     import numpy\n35 \n36 if TYPE_CHECKING:\n37     from pydicom.dataset import Dataset\n38 \n39 \n40 BINARY_VR_VALUES = [\n41     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n42     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n43 ]\n44 \n45 \n46 def empty_value_for_VR(\n47     VR: str, raw: bool = False\n48 ) -> Union[bytes, List[str], str, None]:\n49     \"\"\"Return the value for an empty element for `VR`.\n50 \n51     .. versionadded:: 1.4\n52 \n53     The behavior of this property depends on the setting of\n54     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n55     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n56     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n57     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n58     empty string is used as empty value representation, for all other VRs\n59     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n60     is used in all cases.\n61     Note that this is used only if decoding the element - it is always\n62     possible to set the value to another empty value representation,\n63     which will be preserved during the element object lifetime.\n64 \n65     Parameters\n66     ----------\n67     VR : str\n68         The VR of the corresponding element.\n69 \n70     raw : bool\n71         If ``True``, returns the value for a :class:`RawDataElement`,\n72         otherwise for a :class:`DataElement`\n73 \n74     Returns\n75     -------\n76     str or bytes or None or list\n77         The value a data element with `VR` is assigned on decoding\n78         if it is empty.\n79     \"\"\"\n80     if VR == 'SQ':\n81         return b'' if raw else []\n82     if config.use_none_as_empty_text_VR_value:\n83         return None\n84     if VR in ('AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT',\n85               'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR', 'UT'):\n86         return b'' if raw else ''\n87     return None\n88 \n89 \n90 def _is_bytes(val: object) -> bool:\n91     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n92     return isinstance(val, bytes)\n93 \n94 \n95 # double '\\' because it is used as escape chr in Python\n96 _backslash_str = \"\\\\\"\n97 _backslash_byte = b\"\\\\\"\n98 \n99 \n100 _DataElement = TypeVar(\"_DataElement\", bound=\"DataElement\")\n101 _Dataset = TypeVar(\"_Dataset\", bound=\"Dataset\")\n102 \n103 \n104 class DataElement:\n105     \"\"\"Contain and manipulate a DICOM Element.\n106 \n107     Examples\n108     --------\n109 \n110     While its possible to create a new :class:`DataElement` directly and add\n111     it to a :class:`~pydicom.dataset.Dataset`:\n112 \n113     >>> from pydicom import Dataset\n114     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n115     >>> ds = Dataset()\n116     >>> ds.add(elem)\n117 \n118     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n119     to add a new :class:`DataElement`, as the VR and tag are determined\n120     automatically from the DICOM dictionary:\n121 \n122     >>> ds = Dataset()\n123     >>> ds.PatientName = 'CITIZEN^Joan'\n124 \n125     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n126     value for text VRs and `None` for non-text (binary) VRs:\n127 \n128     >>> ds = Dataset()\n129     >>> ds.PatientName = None\n130     >>> ds.PatientName\n131     ''\n132 \n133     >>> ds.BitsAllocated = None\n134     >>> ds.BitsAllocated\n135 \n136     >>> str(ds.BitsAllocated)\n137     'None'\n138 \n139     Attributes\n140     ----------\n141     descripWidth : int\n142         For string display, this is the maximum width of the description\n143         field (default ``35``).\n144     is_undefined_length : bool\n145         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n146         (ie undefined).\n147     maxBytesToDisplay : int\n148         For string display, elements with values containing data which is\n149         longer than this value will display ``\"array of # bytes\"``\n150         (default ``16``).\n151     showVR : bool\n152         For string display, include the element's VR just before it's value\n153         (default ``True``).\n154     tag : pydicom.tag.BaseTag\n155         The element's tag.\n156     VR : str\n157         The element's Value Representation.\n158     \"\"\"\n159 \n160     descripWidth = 35\n161     maxBytesToDisplay = 16\n162     showVR = True\n163     is_raw = False\n164 \n165     def __init__(\n166         self,\n167         tag: Union[int, str, Tuple[int, int]],\n168         VR: str,\n169         value: object,\n170         file_value_tell: Optional[int] = None,\n171         is_undefined_length: bool = False,\n172         already_converted: bool = False\n173     ) -> None:\n174         \"\"\"Create a new :class:`DataElement`.\n175 \n176         Parameters\n177         ----------\n178         tag : int or str or 2-tuple of int\n179             The DICOM (group, element) tag in any form accepted by\n180             :func:`~pydicom.tag.Tag` such as ``'PatientName'``,\n181             ``(0x10, 0x10)``, ``0x00100010``, etc.\n182         VR : str\n183             The 2 character DICOM value representation (see DICOM Standard,\n184             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n185         value\n186             The value of the data element. One of the following:\n187 \n188             * a single string value\n189             * a number\n190             * a :class:`list` or :class:`tuple` with all strings or all numbers\n191             * a multi-value string with backslash separator\n192         file_value_tell : int, optional\n193             The byte offset to the start of the encoded element value.\n194         is_undefined_length : bool\n195             Used internally to store whether the length field for this element\n196             was ``0xFFFFFFFF``, i.e. 'undefined length'. Default is ``False``.\n197         already_converted : bool\n198             Used to determine whether or not the element's value requires\n199             conversion to a value with VM > 1. Default is ``False``.\n200         \"\"\"\n201         if not isinstance(tag, BaseTag):\n202             tag = Tag(tag)\n203         self.tag = tag\n204 \n205         # a known tag shall only have the VR 'UN' if it has a length that\n206         # exceeds the size that can be encoded in 16 bit - all other cases\n207         # can be seen as an encoding error and can be corrected\n208         if (\n209             VR == 'UN'\n210             and not tag.is_private\n211             and config.replace_un_with_known_vr\n212             and (is_undefined_length or value is None or len(value) < 0xffff)\n213         ):\n214             try:\n215                 VR = dictionary_VR(tag)\n216             except KeyError:\n217                 pass\n218 \n219         self.VR = VR  # Note: you must set VR before setting value\n220         if already_converted:\n221             self._value = value\n222         else:\n223             self.value = value  # calls property setter which will convert\n224         self.file_tell = file_value_tell\n225         self.is_undefined_length = is_undefined_length\n226         self.private_creator: Optional[str] = None\n227         self.parent: Optional[\"Dataset\"] = None\n228 \n229     @classmethod\n230     def from_json(\n231         cls: Type[_DataElement],\n232         dataset_class: Type[_Dataset],\n233         tag: Union[BaseTag, int],\n234         vr: str,\n235         value: object,\n236         value_key: Union[str, None],\n237         bulk_data_uri_handler: Optional[\n238             Union[\n239                 Callable[[BaseTag, str, str], object],\n240                 Callable[[str], object]\n241             ]\n242         ] = None\n243     ) -> _DataElement:\n244         \"\"\"Return a :class:`DataElement` from JSON.\n245 \n246         .. versionadded:: 1.3\n247 \n248         Parameters\n249         ----------\n250         dataset_class : dataset.Dataset derived class\n251             Class used to create sequence items.\n252         tag : pydicom.tag.BaseTag or int\n253             The data element tag.\n254         vr : str\n255             The data element value representation.\n256         value : list\n257             The data element's value(s).\n258         value_key : str or None\n259             Key of the data element that contains the value\n260             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n261         bulk_data_uri_handler: callable or None\n262             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n263             or just the \"BulkDataURI\" of the JSON\n264             representation of a data element and returns the actual value of\n265             that data element (retrieved via DICOMweb WADO-RS)\n266 \n267         Returns\n268         -------\n269         DataElement\n270         \"\"\"\n271         # TODO: test wado-rs retrieve wrapper\n272         converter = JsonDataElementConverter(\n273             dataset_class, tag, vr, value, value_key, bulk_data_uri_handler\n274         )\n275         elem_value = converter.get_element_values()\n276         try:\n277             return cls(tag=tag, value=elem_value, VR=vr)\n278         except Exception as exc:\n279             raise ValueError(\n280                 f\"Data element '{tag}' could not be loaded from JSON: \"\n281                 f\"{elem_value}\"\n282             ) from exc\n283 \n284     def to_json_dict(\n285         self,\n286         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]],\n287         bulk_data_threshold: int\n288     ) -> Dict[str, object]:\n289         \"\"\"Return a dictionary representation of the :class:`DataElement`\n290         conforming to the DICOM JSON Model as described in the DICOM\n291         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n292 \n293         .. versionadded:: 1.4\n294 \n295         Parameters\n296         ----------\n297         bulk_data_element_handler: callable or None\n298             Callable that accepts a bulk data element and returns the\n299             \"BulkDataURI\" for retrieving the value of the data element\n300             via DICOMweb WADO-RS\n301         bulk_data_threshold: int\n302             Size of base64 encoded data element above which a value will be\n303             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n304             Ignored if no bulk data handler is given.\n305 \n306         Returns\n307         -------\n308         dict\n309             Mapping representing a JSON encoded data element\n310         \"\"\"\n311         json_element = {'vr': self.VR, }\n312         if self.VR in jsonrep.BINARY_VR_VALUES:\n313             if not self.is_empty:\n314                 binary_value = self.value\n315                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n316                 if (\n317                     bulk_data_element_handler is not None\n318                     and len(encoded_value) > bulk_data_threshold\n319                 ):\n320                     json_element['BulkDataURI'] = (\n321                         bulk_data_element_handler(self)\n322                     )\n323                 else:\n324                     logger.info(\n325                         f\"encode bulk data element '{self.name}' inline\"\n326                     )\n327                     json_element['InlineBinary'] = encoded_value\n328         elif self.VR == 'SQ':\n329             # recursive call to get sequence item JSON dicts\n330             value = [\n331                 ds.to_json(\n332                     bulk_data_element_handler=bulk_data_element_handler,\n333                     bulk_data_threshold=bulk_data_threshold,\n334                     dump_handler=lambda d: d\n335                 )\n336                 for ds in self.value\n337             ]\n338             json_element['Value'] = value\n339         elif self.VR == 'PN':\n340             if not self.is_empty:\n341                 elem_value = []\n342                 if self.VM > 1:\n343                     value = self.value\n344                 else:\n345                     value = [self.value]\n346                 for v in value:\n347                     comps = {'Alphabetic': v.components[0]}\n348                     if len(v.components) > 1:\n349                         comps['Ideographic'] = v.components[1]\n350                     if len(v.components) > 2:\n351                         comps['Phonetic'] = v.components[2]\n352                     elem_value.append(comps)\n353                 json_element['Value'] = elem_value\n354         elif self.VR == 'AT':\n355             if not self.is_empty:\n356                 value = self.value\n357                 if self.VM == 1:\n358                     value = [value]\n359                 json_element['Value'] = [format(v, '08X') for v in value]\n360         else:\n361             if not self.is_empty:\n362                 if self.VM > 1:\n363                     value = self.value\n364                 else:\n365                     value = [self.value]\n366                 json_element['Value'] = [v for v in value]\n367         if hasattr(json_element, 'Value'):\n368             json_element['Value'] = jsonrep.convert_to_python_number(\n369                 json_element['Value'], self.VR\n370             )\n371         return json_element\n372 \n373     def to_json(\n374         self,\n375         bulk_data_threshold: int = 1024,\n376         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]] = None,  # noqa\n377         dump_handler: Optional[Callable[[Dict[object, object]], str]] = None\n378     ) -> Dict[str, object]:\n379         \"\"\"Return a JSON representation of the :class:`DataElement`.\n380 \n381         .. versionadded:: 1.3\n382 \n383         Parameters\n384         ----------\n385         bulk_data_element_handler: callable, optional\n386             Callable that accepts a bulk data element and returns the\n387             \"BulkDataURI\" for retrieving the value of the data element\n388             via DICOMweb WADO-RS\n389         bulk_data_threshold: int, optional\n390             Size of base64 encoded data element above which a value will be\n391             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n392             Ignored if no bulk data handler is given.\n393         dump_handler : callable, optional\n394             Callable function that accepts a :class:`dict` and returns the\n395             serialized (dumped) JSON string (by default uses\n396             :func:`json.dumps`).\n397 \n398         Returns\n399         -------\n400         dict\n401             Mapping representing a JSON encoded data element\n402 \n403         See also\n404         --------\n405         Dataset.to_json\n406         \"\"\"\n407         if dump_handler is None:\n408             def json_dump(d):\n409                 return json.dumps(d, sort_keys=True)\n410 \n411             dump_handler = json_dump\n412 \n413         return dump_handler(\n414             self.to_json_dict(bulk_data_element_handler, bulk_data_threshold)\n415         )\n416 \n417     @property\n418     def value(self) -> object:\n419         \"\"\"Return the element's value.\"\"\"\n420         return self._value\n421 \n422     @value.setter\n423     def value(self, val: object) -> None:\n424         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n425         # Check if is a string with multiple values separated by '\\'\n426         # If so, turn them into a list of separate strings\n427         #  Last condition covers 'US or SS' etc\n428         if isinstance(val, (str, bytes)) and self.VR not in \\\n429                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n430                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n431                  'OW or OB', 'UN'] and 'US' not in self.VR:\n432             try:\n433                 if _backslash_str in val:\n434                     val = val.split(_backslash_str)\n435             except TypeError:\n436                 if _backslash_byte in val:\n437                     val = val.split(_backslash_byte)\n438         self._value = self._convert_value(val)\n439 \n440     @property\n441     def VM(self) -> int:\n442         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n443         if self.value is None:\n444             return 0\n445         if isinstance(self.value, (str, bytes, PersonName)):\n446             return 1 if self.value else 0\n447         try:\n448             iter(self.value)\n449         except TypeError:\n450             return 1\n451         return len(self.value)\n452 \n453     @property\n454     def is_empty(self) -> bool:\n455         \"\"\"Return ``True`` if the element has no value.\n456 \n457         .. versionadded:: 1.4\n458         \"\"\"\n459         return self.VM == 0\n460 \n461     @property\n462     def empty_value(self) -> Union[bytes, List[str], None, str]:\n463         \"\"\"Return the value for an empty element.\n464 \n465         .. versionadded:: 1.4\n466 \n467         See :func:`empty_value_for_VR` for more information.\n468 \n469         Returns\n470         -------\n471         str or None\n472             The value this data element is assigned on decoding if it is empty.\n473         \"\"\"\n474         return empty_value_for_VR(self.VR)\n475 \n476     def clear(self) -> None:\n477         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n478 \n479         .. versionadded:: 1.4\n480 \n481         See :func:`empty_value_for_VR`.\n482         \"\"\"\n483         self._value = self.empty_value\n484 \n485     def _convert_value(self, val: object) -> object:\n486         \"\"\"Convert `val` to an appropriate type and return the result.\n487 \n488         Uses the element's VR in order to determine the conversion method and\n489         resulting type.\n490         \"\"\"\n491         if self.VR == 'SQ':  # a sequence - leave it alone\n492             from pydicom.sequence import Sequence\n493             if isinstance(val, Sequence):\n494                 return val\n495             else:\n496                 return Sequence(val)\n497 \n498         # if the value is a list, convert each element\n499         try:\n500             val.append\n501         except AttributeError:  # not a list\n502             return self._convert(val)\n503         else:\n504             return MultiValue(self._convert, val)\n505 \n506     def _convert(self, val: object) -> object:\n507         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n508         # If the value is a byte string and has a VR that can only be encoded\n509         # using the default character repertoire, we convert it to a string\n510         # here to allow for byte string input in these cases\n511         if _is_bytes(val) and self.VR in (\n512                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n513             val = val.decode()\n514 \n515         if self.VR == 'IS':\n516             return pydicom.valuerep.IS(val)\n517         elif self.VR == 'DA' and config.datetime_conversion:\n518             return pydicom.valuerep.DA(val)\n519         elif self.VR == 'DS':\n520             return pydicom.valuerep.DS(val)\n521         elif self.VR == 'DT' and config.datetime_conversion:\n522             return pydicom.valuerep.DT(val)\n523         elif self.VR == 'TM' and config.datetime_conversion:\n524             return pydicom.valuerep.TM(val)\n525         elif self.VR == \"UI\":\n526             return UID(val) if val is not None else None\n527         elif self.VR == \"PN\":\n528             return PersonName(val)\n529         # Later may need this for PersonName as for UI,\n530         #    but needs more thought\n531         # elif self.VR == \"PN\":\n532         #    return PersonName(val)\n533         else:  # is either a string or a type 2 optionally blank string\n534             return val  # this means a \"numeric\" value could be empty string \"\"\n535         # except TypeError:\n536             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n537             # % (repr(val), self.VR, self.tag)\n538         # except ValueError:\n539             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n540             # % (repr(val), self.VR, self.tag)\n541 \n542     def __eq__(self, other: object) -> bool:\n543         \"\"\"Compare `self` and `other` for equality.\n544 \n545         Returns\n546         -------\n547         bool\n548             The result if `self` and `other` are the same class\n549         NotImplemented\n550             If `other` is not the same class as `self` then returning\n551             :class:`NotImplemented` delegates the result to\n552             ``superclass.__eq__(subclass)``.\n553         \"\"\"\n554         # Faster result if same object\n555         if other is self:\n556             return True\n557 \n558         if isinstance(other, self.__class__):\n559             if self.tag != other.tag or self.VR != other.VR:\n560                 return False\n561 \n562             # tag and VR match, now check the value\n563             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n564                 return (len(self.value) == len(other.value)\n565                         and numpy.allclose(self.value, other.value))\n566             else:\n567                 return self.value == other.value\n568 \n569         return NotImplemented\n570 \n571     def __ne__(self, other: object) -> bool:\n572         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n573         return not (self == other)\n574 \n575     def __str__(self) -> str:\n576         \"\"\"Return :class:`str` representation of the element.\"\"\"\n577         repVal = self.repval or ''\n578         if self.showVR:\n579             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n580                                     self.description()[:self.descripWidth],\n581                                     self.VR, repVal)\n582         else:\n583             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n584                                 self.description()[:self.descripWidth], repVal)\n585         return s\n586 \n587     @property\n588     def repval(self) -> str:\n589         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n590         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n591         if set(self.VR.split(\" or \")) & long_VRs:\n592             try:\n593                 length = len(self.value)\n594             except TypeError:\n595                 pass\n596             else:\n597                 if length > self.maxBytesToDisplay:\n598                     return \"Array of %d elements\" % length\n599         if self.VM > self.maxBytesToDisplay:\n600             repVal = \"Array of %d elements\" % self.VM\n601         elif isinstance(self.value, UID):\n602             repVal = self.value.name\n603         else:\n604             repVal = repr(self.value)  # will tolerate unicode too\n605         return repVal\n606 \n607     def __getitem__(self, key: int) -> object:\n608         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n609         try:\n610             return self.value[key]\n611         except TypeError:\n612             raise TypeError(\"DataElement value is unscriptable \"\n613                             \"(not a Sequence)\")\n614 \n615     @property\n616     def name(self) -> str:\n617         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n618 \n619         For officially registered DICOM Data Elements this will be the *Name*\n620         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n621         For private elements known to *pydicom*\n622         this will be the *Name* in the format ``'[name]'``. For unknown\n623         private elements this will be ``'Private Creator'``. For unknown\n624         elements this will return an empty string ``''``.\n625         \"\"\"\n626         return self.description()\n627 \n628     def description(self) -> str:\n629         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n630         if self.tag.is_private:\n631             name = \"Private tag data\"  # default\n632             if self.private_creator:\n633                 try:\n634                     # If have name from private dictionary, use it, but\n635                     #   but put in square brackets so is differentiated,\n636                     #   and clear that cannot access it by name\n637                     name = private_dictionary_description(\n638                         self.tag, self.private_creator)\n639                     name = \"[%s]\" % (name)\n640                 except KeyError:\n641                     pass\n642             elif self.tag.element >> 8 == 0:\n643                 name = \"Private Creator\"\n644         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n645             name = dictionary_description(self.tag)\n646 \n647         # implied Group Length dicom versions < 3\n648         elif self.tag.element == 0:\n649             name = \"Group Length\"\n650         else:\n651             name = \"\"\n652         return name\n653 \n654     @property\n655     def is_private(self) -> bool:\n656         \"\"\"Return ``True`` if the element's tag is private.\n657 \n658         .. versionadded:: 2.1\n659         \"\"\"\n660         return self.tag.is_private\n661 \n662     @property\n663     def is_retired(self) -> bool:\n664         \"\"\"Return the element's retired status as :class:`bool`.\n665 \n666         For officially registered DICOM Data Elements this will be ``True`` if\n667         the retired status as given in the DICOM Standard, Part 6,\n668         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n669         or unknown elements this will always be ``False``.\n670         \"\"\"\n671         if dictionary_has_tag(self.tag):\n672             return dictionary_is_retired(self.tag)\n673 \n674         return False\n675 \n676     @property\n677     def keyword(self) -> str:\n678         \"\"\"Return the element's keyword (if known) as :class:`str`.\n679 \n680         For officially registered DICOM Data Elements this will be the\n681         *Keyword* as given in\n682         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n683         unknown elements this will return an empty string ``''``.\n684         \"\"\"\n685         if dictionary_has_tag(self.tag):\n686             return dictionary_keyword(self.tag)\n687 \n688         return ''\n689 \n690     def __repr__(self) -> str:\n691         \"\"\"Return the representation of the element.\"\"\"\n692         if self.VR == \"SQ\":\n693             return repr(self.value)\n694 \n695         return str(self)\n696 \n697 \n698 class RawDataElement(NamedTuple):\n699     \"\"\"Container for the data from a raw (mostly) undecoded element.\"\"\"\n700     tag: BaseTag\n701     VR: Optional[str]\n702     length: int\n703     value: bytes\n704     value_tell: int\n705     is_implicit_VR: bool\n706     is_little_endian: bool\n707     is_raw: bool = True\n708 \n709 \n710 # The first and third values of the following elements are always US\n711 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n712 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n713 # (0028,3002) LUT Descriptor\n714 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n715 \n716 \n717 def DataElement_from_raw(\n718     raw_data_element: RawDataElement, encoding: Optional[List[str]] = None\n719 ) -> DataElement:\n720     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n721 \n722     Parameters\n723     ----------\n724     raw_data_element : RawDataElement\n725         The raw data to convert to a :class:`DataElement`.\n726     encoding : list of str, optional\n727         The character encoding of the raw data.\n728 \n729     Returns\n730     -------\n731     DataElement\n732 \n733     Raises\n734     ------\n735     KeyError\n736         If `raw_data_element` belongs to an unknown non-private tag and\n737         `config.enforce_valid_values` is set.\n738     \"\"\"\n739     # XXX buried here to avoid circular import\n740     # filereader->Dataset->convert_value->filereader\n741     # (for SQ parsing)\n742 \n743     from pydicom.values import convert_value\n744     raw = raw_data_element\n745 \n746     # If user has hooked into conversion of raw values, call his/her routine\n747     if config.data_element_callback:\n748         raw = config.data_element_callback(\n749             raw_data_element,\n750             encoding=encoding,\n751             **config.data_element_callback_kwargs\n752         )\n753 \n754     VR = raw.VR\n755     if VR is None:  # Can be if was implicit VR\n756         try:\n757             VR = dictionary_VR(raw.tag)\n758         except KeyError:\n759             # just read the bytes, no way to know what they mean\n760             if raw.tag.is_private:\n761                 # for VR for private tags see PS3.5, 6.2.2\n762                 if raw.tag.is_private_creator:\n763                     VR = 'LO'\n764                 else:\n765                     VR = 'UN'\n766 \n767             # group length tag implied in versions < 3.0\n768             elif raw.tag.element == 0:\n769                 VR = 'UL'\n770             else:\n771                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n772                 if config.enforce_valid_values:\n773                     msg += \" can't look up VR\"\n774                     raise KeyError(msg)\n775                 else:\n776                     VR = 'UN'\n777                     msg += \" - setting VR to 'UN'\"\n778                     warnings.warn(msg)\n779     elif (VR == 'UN' and not raw.tag.is_private and\n780           config.replace_un_with_known_vr):\n781         # handle rare case of incorrectly set 'UN' in explicit encoding\n782         # see also DataElement.__init__()\n783         if (\n784             raw.length == 0xffffffff\n785             or raw.value is None\n786             or len(raw.value) < 0xffff\n787         ):\n788             try:\n789                 VR = dictionary_VR(raw.tag)\n790             except KeyError:\n791                 pass\n792     try:\n793         value = convert_value(VR, raw, encoding)\n794     except NotImplementedError as e:\n795         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n796 \n797     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n798         # We only fix the first value as the third value is 8 or 16\n799         try:\n800             if value[0] < 0:\n801                 value[0] += 65536\n802         except TypeError:\n803             pass\n804 \n805     return DataElement(raw.tag, VR, value, raw.value_tell,\n806                        raw.length == 0xFFFFFFFF, already_converted=True)\n807 \n[end of pydicom/dataelem.py]\n[start of pydicom/env_info.py]\n1 # Copyright 2020 pydicom authors. See LICENSE file for details.\n2 \"\"\"\n3 Gather system information and version information for pydicom and auxiliary\n4 modules.\n5 \n6 The output is a GitHub-flavoured markdown table whose contents can help\n7 diagnose any perceived bugs in pydicom. This can be pasted directly into a new\n8 GitHub bug report.\n9 \n10 This file is intended to be run as an executable module.\n11 \"\"\"\n12 \n13 import platform\n14 import sys\n15 import importlib\n16 \n17 \n18 def main():\n19     version_rows = [(\"platform\", platform.platform()), (\"Python\", sys.version)]\n20 \n21     for module in (\"pydicom\", \"gdcm\", \"jpeg_ls\", \"numpy\", \"PIL\"):\n22         try:\n23             m = importlib.import_module(module)\n24         except ImportError:\n25             version = \"_module not found_\"\n26         else:\n27             version = extract_version(m) or \"**cannot determine version**\"\n28 \n29         version_rows.append((module, version))\n30 \n31     print_table(version_rows)\n32 \n33 \n34 def print_table(version_rows):\n35     row_format = \"{:12} | {}\"\n36     print(row_format.format(\"module\", \"version\"))\n37     print(row_format.format(\"------\", \"-------\"))\n38     for module, version in version_rows:\n39         # Some version strings have multiple lines and need to be squashed\n40         print(row_format.format(module, version.replace(\"\\n\", \" \")))\n41 \n42 \n43 def extract_version(module):\n44     if module.__name__ == \"gdcm\":\n45         return getattr(module, \"GDCM_VERSION\", None)\n46     return getattr(module, \"__version__\", None)\n47 \n48 \n49 if __name__ == \"__main__\":\n50     main()\n51 \n[end of pydicom/env_info.py]\n[start of pydicom/jsonrep.py]\n1 # Copyright 2008-2019 pydicom authors. See LICENSE file for details.\n2 \"\"\"Methods for converting Datasets and DataElements to/from json\"\"\"\n3 \n4 import base64\n5 from inspect import signature\n6 import inspect\n7 from typing import Callable, Optional, Union\n8 import warnings\n9 \n10 from pydicom.tag import BaseTag\n11 \n12 # Order of keys is significant!\n13 JSON_VALUE_KEYS = ('Value', 'BulkDataURI', 'InlineBinary',)\n14 \n15 BINARY_VR_VALUES = ['OW', 'OB', 'OD', 'OF', 'OL', 'UN',\n16                     'OB or OW', 'US or OW', 'US or SS or OW']\n17 VRs_TO_BE_FLOATS = ['DS', 'FL', 'FD', ]\n18 VRs_TO_BE_INTS = ['IS', 'SL', 'SS', 'UL', 'US', 'US or SS']\n19 \n20 \n21 def convert_to_python_number(value, vr):\n22     \"\"\"Makes sure that values are either ints or floats\n23     based on their value representation.\n24 \n25     .. versionadded:: 1.4\n26 \n27     Parameters\n28     ----------\n29     value: Union[Union[str, int, float], List[Union[str, int, float]]]\n30         value of data element\n31     vr: str\n32         value representation of data element\n33 \n34     Returns\n35     -------\n36     Union[Union[str, int, float], List[Union[str, int, float]]]\n37 \n38     \"\"\"\n39     if value is None:\n40         return None\n41     number_type = None\n42     if vr in VRs_TO_BE_INTS:\n43         number_type = int\n44     if vr in VRs_TO_BE_FLOATS:\n45         number_type = float\n46     if number_type is not None:\n47         if isinstance(value, (list, tuple,)):\n48             value = [number_type(e) for e in value]\n49         else:\n50             value = number_type(value)\n51     return value\n52 \n53 \n54 class JsonDataElementConverter:\n55     \"\"\"Handles conversion between JSON struct and :class:`DataElement`.\n56 \n57     .. versionadded:: 1.4\n58     \"\"\"\n59 \n60     def __init__(\n61         self,\n62         dataset_class,\n63         tag,\n64         vr,\n65         value,\n66         value_key,\n67         bulk_data_uri_handler: Optional[\n68             Union[\n69                 Callable[[BaseTag, str, str], object],\n70                 Callable[[str], object]\n71             ]\n72         ] = None\n73     ):\n74         \"\"\"Create a new converter instance.\n75 \n76         Parameters\n77         ----------\n78         dataset_class : dataset.Dataset derived class\n79             Class used to create sequence items.\n80         tag : BaseTag\n81             The data element tag or int.\n82         vr : str\n83             The data element value representation.\n84         value : list\n85             The data element's value(s).\n86         value_key : str or None\n87             Key of the data element that contains the value\n88             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n89         bulk_data_uri_handler: callable or None\n90             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n91             or just the \"BulkDataURI\" of the JSON\n92             representation of a data element and returns the actual value of\n93             that data element (retrieved via DICOMweb WADO-RS)\n94         \"\"\"\n95         self.dataset_class = dataset_class\n96         self.tag = tag\n97         self.vr = vr\n98         self.value = value\n99         self.value_key = value_key\n100         if (\n101             bulk_data_uri_handler and\n102             len(signature(bulk_data_uri_handler).parameters) == 1\n103         ):\n104             def wrapped_bulk_data_handler(tag, vr, value):\n105                 return bulk_data_uri_handler(value)\n106             self.bulk_data_element_handler = wrapped_bulk_data_handler\n107         else:\n108             self.bulk_data_element_handler = bulk_data_uri_handler\n109 \n110     def get_element_values(self):\n111         \"\"\"Return a the data element value or list of values.\n112 \n113         Returns\n114         -------\n115         str or bytes or int or float or dataset_class\n116         or PersonName or list of any of these types\n117             The value or value list of the newly created data element.\n118         \"\"\"\n119         from pydicom.dataelem import empty_value_for_VR\n120         if self.value_key == 'Value':\n121             if not isinstance(self.value, list):\n122                 fmt = '\"{}\" of data element \"{}\" must be a list.'\n123                 raise TypeError(fmt.format(self.value_key, self.tag))\n124             if not self.value:\n125                 return empty_value_for_VR(self.vr)\n126             element_value = [self.get_regular_element_value(v)\n127                              for v in self.value]\n128             if len(element_value) == 1 and self.vr != 'SQ':\n129                 element_value = element_value[0]\n130             return convert_to_python_number(element_value, self.vr)\n131 \n132         # The value for \"InlineBinary\" shall be encoded as a base64 encoded\n133         # string, as shown in PS3.18, Table F.3.1-1, but the example in\n134         # PS3.18, Annex F.4 shows the string enclosed in a list.\n135         # We support both variants, as the standard is ambiguous here,\n136         # and do the same for \"BulkDataURI\".\n137         value = self.value\n138         if isinstance(value, list):\n139             value = value[0]\n140 \n141         if self.value_key == 'InlineBinary':\n142             if not isinstance(value, (str, bytes)):\n143                 fmt = '\"{}\" of data element \"{}\" must be a bytes-like object.'\n144                 raise TypeError(fmt.format(self.value_key, self.tag))\n145             return base64.b64decode(value)\n146 \n147         if self.value_key == 'BulkDataURI':\n148             if not isinstance(value, str):\n149                 fmt = '\"{}\" of data element \"{}\" must be a string.'\n150                 raise TypeError(fmt.format(self.value_key, self.tag))\n151             if self.bulk_data_element_handler is None:\n152                 warnings.warn(\n153                     'no bulk data URI handler provided for retrieval '\n154                     'of value of data element \"{}\"'.format(self.tag)\n155                 )\n156                 return empty_value_for_VR(self.vr, raw=True)\n157             return self.bulk_data_element_handler(self.tag, self.vr, value)\n158         return empty_value_for_VR(self.vr)\n159 \n160     def get_regular_element_value(self, value):\n161         \"\"\"Return a the data element value created from a json \"Value\" entry.\n162 \n163         Parameters\n164         ----------\n165         value : str or int or float or dict\n166             The data element's value from the json entry.\n167 \n168         Returns\n169         -------\n170         dataset_class or PersonName\n171         or str or int or float\n172             A single value of the corresponding :class:`DataElement`.\n173         \"\"\"\n174         if self.vr == 'SQ':\n175             return self.get_sequence_item(value)\n176 \n177         if self.vr == 'PN':\n178             return self.get_pn_element_value(value)\n179 \n180         if self.vr == 'AT':\n181             try:\n182                 return int(value, 16)\n183             except ValueError:\n184                 warnings.warn('Invalid value \"{}\" for AT element - '\n185                               'ignoring it'.format(value))\n186             return\n187         return value\n188 \n189     def get_sequence_item(self, value):\n190         \"\"\"Return a sequence item for the JSON dict `value`.\n191 \n192         Parameters\n193         ----------\n194         value : dict or None\n195             The sequence item from the JSON entry.\n196 \n197         Returns\n198         -------\n199         dataset_class\n200             The decoded dataset item.\n201 \n202         Raises\n203         ------\n204         KeyError\n205             If the \"vr\" key is missing for a contained element\n206         \"\"\"\n207         ds = self.dataset_class()\n208         if value:\n209             for key, val in value.items():\n210                 if 'vr' not in val:\n211                     fmt = 'Data element \"{}\" must have key \"vr\".'\n212                     raise KeyError(fmt.format(self.tag))\n213                 vr = val['vr']\n214                 unique_value_keys = tuple(\n215                     set(val.keys()) & set(JSON_VALUE_KEYS)\n216                 )\n217                 from pydicom import DataElement\n218                 from pydicom.dataelem import empty_value_for_VR\n219                 if not unique_value_keys:\n220                     # data element with no value\n221                     elem = DataElement(\n222                         tag=int(key, 16),\n223                         value=empty_value_for_VR(vr),\n224                         VR=vr)\n225                 else:\n226                     value_key = unique_value_keys[0]\n227                     elem = DataElement.from_json(\n228                         self.dataset_class, key, vr,\n229                         val[value_key], value_key\n230                     )\n231                 ds.add(elem)\n232         return ds\n233 \n234     def get_pn_element_value(self, value):\n235         \"\"\"Return PersonName value from JSON value.\n236 \n237         Values with VR PN have a special JSON encoding, see the DICOM Standard,\n238         Part 18, :dcm:`Annex F.2.2<part18/sect_F.2.2.html>`.\n239 \n240         Parameters\n241         ----------\n242         value : dict\n243             The person name components in the JSON entry.\n244 \n245         Returns\n246         -------\n247         PersonName or str\n248             The decoded PersonName object or an empty string.\n249         \"\"\"\n250         if not isinstance(value, dict):\n251             # Some DICOMweb services get this wrong, so we\n252             # workaround the issue and warn the user\n253             # rather than raising an error.\n254             warnings.warn(\n255                 'value of data element \"{}\" with VR Person Name (PN) '\n256                 'is not formatted correctly'.format(self.tag)\n257             )\n258             return value\n259         else:\n260             if 'Phonetic' in value:\n261                 comps = ['', '', '']\n262             elif 'Ideographic' in value:\n263                 comps = ['', '']\n264             else:\n265                 comps = ['']\n266             if 'Alphabetic' in value:\n267                 comps[0] = value['Alphabetic']\n268             if 'Ideographic' in value:\n269                 comps[1] = value['Ideographic']\n270             if 'Phonetic' in value:\n271                 comps[2] = value['Phonetic']\n272             elem_value = '='.join(comps)\n273             return elem_value\n274 \n[end of pydicom/jsonrep.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "49a3da4a3d9c24d7e8427a25048a1c7d5c4f7724", "problem_statement": "from_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n", "hints_text": "", "created_at": "2020-11-04T21:13:33Z", "patch": "<patch>\ndiff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ def get_sequence_item(self, value):\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_json.py b/pydicom/tests/test_json.py\n--- a/pydicom/tests/test_json.py\n+++ b/pydicom/tests/test_json.py\n@@ -354,3 +354,25 @@ def bulk_data_reader(tag, vr, value):\n         ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n \n         assert b'xyzzy' == ds[0x00091002].value\n+\n+    def test_bulk_data_reader_is_called_within_SQ(self):\n+        def bulk_data_reader(_):\n+            return b'xyzzy'\n+\n+        json_data = {\n+            \"003a0200\": {\n+                \"vr\": \"SQ\", \n+                \"Value\": [\n+                    {\n+                        \"54001010\": {\n+                            \"vr\": \"OW\",\n+                            \"BulkDataURI\": \"https://a.dummy.url\"\n+                        }\n+                    }\n+                ]\n+            }\n+        }\n+\n+        ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n+\n+        assert b'xyzzy' == ds[0x003a0200].value[0][0x54001010].value\n", "version": "2.1", "FAIL_TO_PASS": "[\"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_within_SQ\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_json.py::TestPersonName::test_json_pn_from_file\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_from_json\", \"pydicom/tests/test_json.py::TestPersonName::test_empty_value\", \"pydicom/tests/test_json.py::TestPersonName::test_multi_value_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_dataelem_from_json\", \"pydicom/tests/test_json.py::TestAT::test_to_json\", \"pydicom/tests/test_json.py::TestAT::test_from_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_value_in_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_tag_in_json\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_json_from_dicom_file\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_roundtrip\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataset_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataelement_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_sort_order\", \"pydicom/tests/test_json.py::TestSequence::test_nested_sequences\", \"pydicom/tests/test_json.py::TestBinary::test_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_valid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_2\"]", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}
{"instance_id": "pydicom__pydicom-1256_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nfrom_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 import base64\n11 import json\n12 from typing import (\n13     Optional, Any, Optional, Tuple, Callable, Union, TYPE_CHECKING, Dict,\n14     TypeVar, Type, List, NamedTuple\n15 )\n16 import warnings\n17 \n18 from pydicom import config  # don't import datetime_conversion directly\n19 from pydicom.config import logger\n20 from pydicom import config\n21 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n22                               dictionary_keyword, dictionary_is_retired,\n23                               private_dictionary_description, dictionary_VR,\n24                               repeater_has_tag)\n25 from pydicom.jsonrep import JsonDataElementConverter\n26 from pydicom.multival import MultiValue\n27 from pydicom.tag import Tag, BaseTag\n28 from pydicom.uid import UID\n29 from pydicom import jsonrep\n30 import pydicom.valuerep  # don't import DS directly as can be changed by config\n31 from pydicom.valuerep import PersonName\n32 \n33 if config.have_numpy:\n34     import numpy\n35 \n36 if TYPE_CHECKING:\n37     from pydicom.dataset import Dataset\n38 \n39 \n40 BINARY_VR_VALUES = [\n41     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n42     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n43 ]\n44 \n45 \n46 def empty_value_for_VR(\n47     VR: str, raw: bool = False\n48 ) -> Union[bytes, List[str], str, None]:\n49     \"\"\"Return the value for an empty element for `VR`.\n50 \n51     .. versionadded:: 1.4\n52 \n53     The behavior of this property depends on the setting of\n54     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n55     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n56     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n57     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n58     empty string is used as empty value representation, for all other VRs\n59     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n60     is used in all cases.\n61     Note that this is used only if decoding the element - it is always\n62     possible to set the value to another empty value representation,\n63     which will be preserved during the element object lifetime.\n64 \n65     Parameters\n66     ----------\n67     VR : str\n68         The VR of the corresponding element.\n69 \n70     raw : bool\n71         If ``True``, returns the value for a :class:`RawDataElement`,\n72         otherwise for a :class:`DataElement`\n73 \n74     Returns\n75     -------\n76     str or bytes or None or list\n77         The value a data element with `VR` is assigned on decoding\n78         if it is empty.\n79     \"\"\"\n80     if VR == 'SQ':\n81         return b'' if raw else []\n82     if config.use_none_as_empty_text_VR_value:\n83         return None\n84     if VR in ('AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT',\n85               'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR', 'UT'):\n86         return b'' if raw else ''\n87     return None\n88 \n89 \n90 def _is_bytes(val: object) -> bool:\n91     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n92     return isinstance(val, bytes)\n93 \n94 \n95 # double '\\' because it is used as escape chr in Python\n96 _backslash_str = \"\\\\\"\n97 _backslash_byte = b\"\\\\\"\n98 \n99 \n100 _DataElement = TypeVar(\"_DataElement\", bound=\"DataElement\")\n101 _Dataset = TypeVar(\"_Dataset\", bound=\"Dataset\")\n102 \n103 \n104 class DataElement:\n105     \"\"\"Contain and manipulate a DICOM Element.\n106 \n107     Examples\n108     --------\n109 \n110     While its possible to create a new :class:`DataElement` directly and add\n111     it to a :class:`~pydicom.dataset.Dataset`:\n112 \n113     >>> from pydicom import Dataset\n114     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n115     >>> ds = Dataset()\n116     >>> ds.add(elem)\n117 \n118     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n119     to add a new :class:`DataElement`, as the VR and tag are determined\n120     automatically from the DICOM dictionary:\n121 \n122     >>> ds = Dataset()\n123     >>> ds.PatientName = 'CITIZEN^Joan'\n124 \n125     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n126     value for text VRs and `None` for non-text (binary) VRs:\n127 \n128     >>> ds = Dataset()\n129     >>> ds.PatientName = None\n130     >>> ds.PatientName\n131     ''\n132 \n133     >>> ds.BitsAllocated = None\n134     >>> ds.BitsAllocated\n135 \n136     >>> str(ds.BitsAllocated)\n137     'None'\n138 \n139     Attributes\n140     ----------\n141     descripWidth : int\n142         For string display, this is the maximum width of the description\n143         field (default ``35``).\n144     is_undefined_length : bool\n145         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n146         (ie undefined).\n147     maxBytesToDisplay : int\n148         For string display, elements with values containing data which is\n149         longer than this value will display ``\"array of # bytes\"``\n150         (default ``16``).\n151     showVR : bool\n152         For string display, include the element's VR just before it's value\n153         (default ``True``).\n154     tag : pydicom.tag.BaseTag\n155         The element's tag.\n156     VR : str\n157         The element's Value Representation.\n158     \"\"\"\n159 \n160     descripWidth = 35\n161     maxBytesToDisplay = 16\n162     showVR = True\n163     is_raw = False\n164 \n165     def __init__(\n166         self,\n167         tag: Union[int, str, Tuple[int, int]],\n168         VR: str,\n169         value: object,\n170         file_value_tell: Optional[int] = None,\n171         is_undefined_length: bool = False,\n172         already_converted: bool = False\n173     ) -> None:\n174         \"\"\"Create a new :class:`DataElement`.\n175 \n176         Parameters\n177         ----------\n178         tag : int or str or 2-tuple of int\n179             The DICOM (group, element) tag in any form accepted by\n180             :func:`~pydicom.tag.Tag` such as ``'PatientName'``,\n181             ``(0x10, 0x10)``, ``0x00100010``, etc.\n182         VR : str\n183             The 2 character DICOM value representation (see DICOM Standard,\n184             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n185         value\n186             The value of the data element. One of the following:\n187 \n188             * a single string value\n189             * a number\n190             * a :class:`list` or :class:`tuple` with all strings or all numbers\n191             * a multi-value string with backslash separator\n192         file_value_tell : int, optional\n193             The byte offset to the start of the encoded element value.\n194         is_undefined_length : bool\n195             Used internally to store whether the length field for this element\n196             was ``0xFFFFFFFF``, i.e. 'undefined length'. Default is ``False``.\n197         already_converted : bool\n198             Used to determine whether or not the element's value requires\n199             conversion to a value with VM > 1. Default is ``False``.\n200         \"\"\"\n201         if not isinstance(tag, BaseTag):\n202             tag = Tag(tag)\n203         self.tag = tag\n204 \n205         # a known tag shall only have the VR 'UN' if it has a length that\n206         # exceeds the size that can be encoded in 16 bit - all other cases\n207         # can be seen as an encoding error and can be corrected\n208         if (\n209             VR == 'UN'\n210             and not tag.is_private\n211             and config.replace_un_with_known_vr\n212             and (is_undefined_length or value is None or len(value) < 0xffff)\n213         ):\n214             try:\n215                 VR = dictionary_VR(tag)\n216             except KeyError:\n217                 pass\n218 \n219         self.VR = VR  # Note: you must set VR before setting value\n220         if already_converted:\n221             self._value = value\n222         else:\n223             self.value = value  # calls property setter which will convert\n224         self.file_tell = file_value_tell\n225         self.is_undefined_length = is_undefined_length\n226         self.private_creator: Optional[str] = None\n227         self.parent: Optional[\"Dataset\"] = None\n228 \n229     @classmethod\n230     def from_json(\n231         cls: Type[_DataElement],\n232         dataset_class: Type[_Dataset],\n233         tag: Union[BaseTag, int],\n234         vr: str,\n235         value: object,\n236         value_key: Union[str, None],\n237         bulk_data_uri_handler: Optional[\n238             Union[\n239                 Callable[[BaseTag, str, str], object],\n240                 Callable[[str], object]\n241             ]\n242         ] = None\n243     ) -> _DataElement:\n244         \"\"\"Return a :class:`DataElement` from JSON.\n245 \n246         .. versionadded:: 1.3\n247 \n248         Parameters\n249         ----------\n250         dataset_class : dataset.Dataset derived class\n251             Class used to create sequence items.\n252         tag : pydicom.tag.BaseTag or int\n253             The data element tag.\n254         vr : str\n255             The data element value representation.\n256         value : list\n257             The data element's value(s).\n258         value_key : str or None\n259             Key of the data element that contains the value\n260             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n261         bulk_data_uri_handler: callable or None\n262             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n263             or just the \"BulkDataURI\" of the JSON\n264             representation of a data element and returns the actual value of\n265             that data element (retrieved via DICOMweb WADO-RS)\n266 \n267         Returns\n268         -------\n269         DataElement\n270         \"\"\"\n271         # TODO: test wado-rs retrieve wrapper\n272         converter = JsonDataElementConverter(\n273             dataset_class, tag, vr, value, value_key, bulk_data_uri_handler\n274         )\n275         elem_value = converter.get_element_values()\n276         try:\n277             return cls(tag=tag, value=elem_value, VR=vr)\n278         except Exception as exc:\n279             raise ValueError(\n280                 f\"Data element '{tag}' could not be loaded from JSON: \"\n281                 f\"{elem_value}\"\n282             ) from exc\n283 \n284     def to_json_dict(\n285         self,\n286         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]],\n287         bulk_data_threshold: int\n288     ) -> Dict[str, object]:\n289         \"\"\"Return a dictionary representation of the :class:`DataElement`\n290         conforming to the DICOM JSON Model as described in the DICOM\n291         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n292 \n293         .. versionadded:: 1.4\n294 \n295         Parameters\n296         ----------\n297         bulk_data_element_handler: callable or None\n298             Callable that accepts a bulk data element and returns the\n299             \"BulkDataURI\" for retrieving the value of the data element\n300             via DICOMweb WADO-RS\n301         bulk_data_threshold: int\n302             Size of base64 encoded data element above which a value will be\n303             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n304             Ignored if no bulk data handler is given.\n305 \n306         Returns\n307         -------\n308         dict\n309             Mapping representing a JSON encoded data element\n310         \"\"\"\n311         json_element = {'vr': self.VR, }\n312         if self.VR in jsonrep.BINARY_VR_VALUES:\n313             if not self.is_empty:\n314                 binary_value = self.value\n315                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n316                 if (\n317                     bulk_data_element_handler is not None\n318                     and len(encoded_value) > bulk_data_threshold\n319                 ):\n320                     json_element['BulkDataURI'] = (\n321                         bulk_data_element_handler(self)\n322                     )\n323                 else:\n324                     logger.info(\n325                         f\"encode bulk data element '{self.name}' inline\"\n326                     )\n327                     json_element['InlineBinary'] = encoded_value\n328         elif self.VR == 'SQ':\n329             # recursive call to get sequence item JSON dicts\n330             value = [\n331                 ds.to_json(\n332                     bulk_data_element_handler=bulk_data_element_handler,\n333                     bulk_data_threshold=bulk_data_threshold,\n334                     dump_handler=lambda d: d\n335                 )\n336                 for ds in self.value\n337             ]\n338             json_element['Value'] = value\n339         elif self.VR == 'PN':\n340             if not self.is_empty:\n341                 elem_value = []\n342                 if self.VM > 1:\n343                     value = self.value\n344                 else:\n345                     value = [self.value]\n346                 for v in value:\n347                     comps = {'Alphabetic': v.components[0]}\n348                     if len(v.components) > 1:\n349                         comps['Ideographic'] = v.components[1]\n350                     if len(v.components) > 2:\n351                         comps['Phonetic'] = v.components[2]\n352                     elem_value.append(comps)\n353                 json_element['Value'] = elem_value\n354         elif self.VR == 'AT':\n355             if not self.is_empty:\n356                 value = self.value\n357                 if self.VM == 1:\n358                     value = [value]\n359                 json_element['Value'] = [format(v, '08X') for v in value]\n360         else:\n361             if not self.is_empty:\n362                 if self.VM > 1:\n363                     value = self.value\n364                 else:\n365                     value = [self.value]\n366                 json_element['Value'] = [v for v in value]\n367         if hasattr(json_element, 'Value'):\n368             json_element['Value'] = jsonrep.convert_to_python_number(\n369                 json_element['Value'], self.VR\n370             )\n371         return json_element\n372 \n373     def to_json(\n374         self,\n375         bulk_data_threshold: int = 1024,\n376         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]] = None,  # noqa\n377         dump_handler: Optional[Callable[[Dict[object, object]], str]] = None\n378     ) -> Dict[str, object]:\n379         \"\"\"Return a JSON representation of the :class:`DataElement`.\n380 \n381         .. versionadded:: 1.3\n382 \n383         Parameters\n384         ----------\n385         bulk_data_element_handler: callable, optional\n386             Callable that accepts a bulk data element and returns the\n387             \"BulkDataURI\" for retrieving the value of the data element\n388             via DICOMweb WADO-RS\n389         bulk_data_threshold: int, optional\n390             Size of base64 encoded data element above which a value will be\n391             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n392             Ignored if no bulk data handler is given.\n393         dump_handler : callable, optional\n394             Callable function that accepts a :class:`dict` and returns the\n395             serialized (dumped) JSON string (by default uses\n396             :func:`json.dumps`).\n397 \n398         Returns\n399         -------\n400         dict\n401             Mapping representing a JSON encoded data element\n402 \n403         See also\n404         --------\n405         Dataset.to_json\n406         \"\"\"\n407         if dump_handler is None:\n408             def json_dump(d):\n409                 return json.dumps(d, sort_keys=True)\n410 \n411             dump_handler = json_dump\n412 \n413         return dump_handler(\n414             self.to_json_dict(bulk_data_element_handler, bulk_data_threshold)\n415         )\n416 \n417     @property\n418     def value(self) -> object:\n419         \"\"\"Return the element's value.\"\"\"\n420         return self._value\n421 \n422     @value.setter\n423     def value(self, val: object) -> None:\n424         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n425         # Check if is a string with multiple values separated by '\\'\n426         # If so, turn them into a list of separate strings\n427         #  Last condition covers 'US or SS' etc\n428         if isinstance(val, (str, bytes)) and self.VR not in \\\n429                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n430                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n431                  'OW or OB', 'UN'] and 'US' not in self.VR:\n432             try:\n433                 if _backslash_str in val:\n434                     val = val.split(_backslash_str)\n435             except TypeError:\n436                 if _backslash_byte in val:\n437                     val = val.split(_backslash_byte)\n438         self._value = self._convert_value(val)\n439 \n440     @property\n441     def VM(self) -> int:\n442         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n443         if self.value is None:\n444             return 0\n445         if isinstance(self.value, (str, bytes, PersonName)):\n446             return 1 if self.value else 0\n447         try:\n448             iter(self.value)\n449         except TypeError:\n450             return 1\n451         return len(self.value)\n452 \n453     @property\n454     def is_empty(self) -> bool:\n455         \"\"\"Return ``True`` if the element has no value.\n456 \n457         .. versionadded:: 1.4\n458         \"\"\"\n459         return self.VM == 0\n460 \n461     @property\n462     def empty_value(self) -> Union[bytes, List[str], None, str]:\n463         \"\"\"Return the value for an empty element.\n464 \n465         .. versionadded:: 1.4\n466 \n467         See :func:`empty_value_for_VR` for more information.\n468 \n469         Returns\n470         -------\n471         str or None\n472             The value this data element is assigned on decoding if it is empty.\n473         \"\"\"\n474         return empty_value_for_VR(self.VR)\n475 \n476     def clear(self) -> None:\n477         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n478 \n479         .. versionadded:: 1.4\n480 \n481         See :func:`empty_value_for_VR`.\n482         \"\"\"\n483         self._value = self.empty_value\n484 \n485     def _convert_value(self, val: object) -> object:\n486         \"\"\"Convert `val` to an appropriate type and return the result.\n487 \n488         Uses the element's VR in order to determine the conversion method and\n489         resulting type.\n490         \"\"\"\n491         if self.VR == 'SQ':  # a sequence - leave it alone\n492             from pydicom.sequence import Sequence\n493             if isinstance(val, Sequence):\n494                 return val\n495             else:\n496                 return Sequence(val)\n497 \n498         # if the value is a list, convert each element\n499         try:\n500             val.append\n501         except AttributeError:  # not a list\n502             return self._convert(val)\n503         else:\n504             return MultiValue(self._convert, val)\n505 \n506     def _convert(self, val: object) -> object:\n507         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n508         # If the value is a byte string and has a VR that can only be encoded\n509         # using the default character repertoire, we convert it to a string\n510         # here to allow for byte string input in these cases\n511         if _is_bytes(val) and self.VR in (\n512                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n513             val = val.decode()\n514 \n515         if self.VR == 'IS':\n516             return pydicom.valuerep.IS(val)\n517         elif self.VR == 'DA' and config.datetime_conversion:\n518             return pydicom.valuerep.DA(val)\n519         elif self.VR == 'DS':\n520             return pydicom.valuerep.DS(val)\n521         elif self.VR == 'DT' and config.datetime_conversion:\n522             return pydicom.valuerep.DT(val)\n523         elif self.VR == 'TM' and config.datetime_conversion:\n524             return pydicom.valuerep.TM(val)\n525         elif self.VR == \"UI\":\n526             return UID(val) if val is not None else None\n527         elif self.VR == \"PN\":\n528             return PersonName(val)\n529         # Later may need this for PersonName as for UI,\n530         #    but needs more thought\n531         # elif self.VR == \"PN\":\n532         #    return PersonName(val)\n533         else:  # is either a string or a type 2 optionally blank string\n534             return val  # this means a \"numeric\" value could be empty string \"\"\n535         # except TypeError:\n536             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n537             # % (repr(val), self.VR, self.tag)\n538         # except ValueError:\n539             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n540             # % (repr(val), self.VR, self.tag)\n541 \n542     def __eq__(self, other: object) -> bool:\n543         \"\"\"Compare `self` and `other` for equality.\n544 \n545         Returns\n546         -------\n547         bool\n548             The result if `self` and `other` are the same class\n549         NotImplemented\n550             If `other` is not the same class as `self` then returning\n551             :class:`NotImplemented` delegates the result to\n552             ``superclass.__eq__(subclass)``.\n553         \"\"\"\n554         # Faster result if same object\n555         if other is self:\n556             return True\n557 \n558         if isinstance(other, self.__class__):\n559             if self.tag != other.tag or self.VR != other.VR:\n560                 return False\n561 \n562             # tag and VR match, now check the value\n563             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n564                 return (len(self.value) == len(other.value)\n565                         and numpy.allclose(self.value, other.value))\n566             else:\n567                 return self.value == other.value\n568 \n569         return NotImplemented\n570 \n571     def __ne__(self, other: object) -> bool:\n572         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n573         return not (self == other)\n574 \n575     def __str__(self) -> str:\n576         \"\"\"Return :class:`str` representation of the element.\"\"\"\n577         repVal = self.repval or ''\n578         if self.showVR:\n579             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n580                                     self.description()[:self.descripWidth],\n581                                     self.VR, repVal)\n582         else:\n583             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n584                                 self.description()[:self.descripWidth], repVal)\n585         return s\n586 \n587     @property\n588     def repval(self) -> str:\n589         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n590         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n591         if set(self.VR.split(\" or \")) & long_VRs:\n592             try:\n593                 length = len(self.value)\n594             except TypeError:\n595                 pass\n596             else:\n597                 if length > self.maxBytesToDisplay:\n598                     return \"Array of %d elements\" % length\n599         if self.VM > self.maxBytesToDisplay:\n600             repVal = \"Array of %d elements\" % self.VM\n601         elif isinstance(self.value, UID):\n602             repVal = self.value.name\n603         else:\n604             repVal = repr(self.value)  # will tolerate unicode too\n605         return repVal\n606 \n607     def __getitem__(self, key: int) -> object:\n608         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n609         try:\n610             return self.value[key]\n611         except TypeError:\n612             raise TypeError(\"DataElement value is unscriptable \"\n613                             \"(not a Sequence)\")\n614 \n615     @property\n616     def name(self) -> str:\n617         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n618 \n619         For officially registered DICOM Data Elements this will be the *Name*\n620         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n621         For private elements known to *pydicom*\n622         this will be the *Name* in the format ``'[name]'``. For unknown\n623         private elements this will be ``'Private Creator'``. For unknown\n624         elements this will return an empty string ``''``.\n625         \"\"\"\n626         return self.description()\n627 \n628     def description(self) -> str:\n629         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n630         if self.tag.is_private:\n631             name = \"Private tag data\"  # default\n632             if self.private_creator:\n633                 try:\n634                     # If have name from private dictionary, use it, but\n635                     #   but put in square brackets so is differentiated,\n636                     #   and clear that cannot access it by name\n637                     name = private_dictionary_description(\n638                         self.tag, self.private_creator)\n639                     name = \"[%s]\" % (name)\n640                 except KeyError:\n641                     pass\n642             elif self.tag.element >> 8 == 0:\n643                 name = \"Private Creator\"\n644         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n645             name = dictionary_description(self.tag)\n646 \n647         # implied Group Length dicom versions < 3\n648         elif self.tag.element == 0:\n649             name = \"Group Length\"\n650         else:\n651             name = \"\"\n652         return name\n653 \n654     @property\n655     def is_private(self) -> bool:\n656         \"\"\"Return ``True`` if the element's tag is private.\n657 \n658         .. versionadded:: 2.1\n659         \"\"\"\n660         return self.tag.is_private\n661 \n662     @property\n663     def is_retired(self) -> bool:\n664         \"\"\"Return the element's retired status as :class:`bool`.\n665 \n666         For officially registered DICOM Data Elements this will be ``True`` if\n667         the retired status as given in the DICOM Standard, Part 6,\n668         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n669         or unknown elements this will always be ``False``.\n670         \"\"\"\n671         if dictionary_has_tag(self.tag):\n672             return dictionary_is_retired(self.tag)\n673 \n674         return False\n675 \n676     @property\n677     def keyword(self) -> str:\n678         \"\"\"Return the element's keyword (if known) as :class:`str`.\n679 \n680         For officially registered DICOM Data Elements this will be the\n681         *Keyword* as given in\n682         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n683         unknown elements this will return an empty string ``''``.\n684         \"\"\"\n685         if dictionary_has_tag(self.tag):\n686             return dictionary_keyword(self.tag)\n687 \n688         return ''\n689 \n690     def __repr__(self) -> str:\n691         \"\"\"Return the representation of the element.\"\"\"\n692         if self.VR == \"SQ\":\n693             return repr(self.value)\n694 \n695         return str(self)\n696 \n697 \n698 class RawDataElement(NamedTuple):\n699     \"\"\"Container for the data from a raw (mostly) undecoded element.\"\"\"\n700     tag: BaseTag\n701     VR: Optional[str]\n702     length: int\n703     value: bytes\n704     value_tell: int\n705     is_implicit_VR: bool\n706     is_little_endian: bool\n707     is_raw: bool = True\n708 \n709 \n710 # The first and third values of the following elements are always US\n711 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n712 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n713 # (0028,3002) LUT Descriptor\n714 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n715 \n716 \n717 def DataElement_from_raw(\n718     raw_data_element: RawDataElement, encoding: Optional[List[str]] = None\n719 ) -> DataElement:\n720     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n721 \n722     Parameters\n723     ----------\n724     raw_data_element : RawDataElement\n725         The raw data to convert to a :class:`DataElement`.\n726     encoding : list of str, optional\n727         The character encoding of the raw data.\n728 \n729     Returns\n730     -------\n731     DataElement\n732 \n733     Raises\n734     ------\n735     KeyError\n736         If `raw_data_element` belongs to an unknown non-private tag and\n737         `config.enforce_valid_values` is set.\n738     \"\"\"\n739     # XXX buried here to avoid circular import\n740     # filereader->Dataset->convert_value->filereader\n741     # (for SQ parsing)\n742 \n743     from pydicom.values import convert_value\n744     raw = raw_data_element\n745 \n746     # If user has hooked into conversion of raw values, call his/her routine\n747     if config.data_element_callback:\n748         raw = config.data_element_callback(\n749             raw_data_element,\n750             encoding=encoding,\n751             **config.data_element_callback_kwargs\n752         )\n753 \n754     VR = raw.VR\n755     if VR is None:  # Can be if was implicit VR\n756         try:\n757             VR = dictionary_VR(raw.tag)\n758         except KeyError:\n759             # just read the bytes, no way to know what they mean\n760             if raw.tag.is_private:\n761                 # for VR for private tags see PS3.5, 6.2.2\n762                 if raw.tag.is_private_creator:\n763                     VR = 'LO'\n764                 else:\n765                     VR = 'UN'\n766 \n767             # group length tag implied in versions < 3.0\n768             elif raw.tag.element == 0:\n769                 VR = 'UL'\n770             else:\n771                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n772                 if config.enforce_valid_values:\n773                     msg += \" can't look up VR\"\n774                     raise KeyError(msg)\n775                 else:\n776                     VR = 'UN'\n777                     msg += \" - setting VR to 'UN'\"\n778                     warnings.warn(msg)\n779     elif (VR == 'UN' and not raw.tag.is_private and\n780           config.replace_un_with_known_vr):\n781         # handle rare case of incorrectly set 'UN' in explicit encoding\n782         # see also DataElement.__init__()\n783         if (\n784             raw.length == 0xffffffff\n785             or raw.value is None\n786             or len(raw.value) < 0xffff\n787         ):\n788             try:\n789                 VR = dictionary_VR(raw.tag)\n790             except KeyError:\n791                 pass\n792     try:\n793         value = convert_value(VR, raw, encoding)\n794     except NotImplementedError as e:\n795         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n796 \n797     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n798         # We only fix the first value as the third value is 8 or 16\n799         try:\n800             if value[0] < 0:\n801                 value[0] += 65536\n802         except TypeError:\n803             pass\n804 \n805     return DataElement(raw.tag, VR, value, raw.value_tell,\n806                        raw.length == 0xFFFFFFFF, already_converted=True)\n807 \n[end of pydicom/dataelem.py]\n[start of pydicom/env_info.py]\n1 # Copyright 2020 pydicom authors. See LICENSE file for details.\n2 \"\"\"\n3 Gather system information and version information for pydicom and auxiliary\n4 modules.\n5 \n6 The output is a GitHub-flavoured markdown table whose contents can help\n7 diagnose any perceived bugs in pydicom. This can be pasted directly into a new\n8 GitHub bug report.\n9 \n10 This file is intended to be run as an executable module.\n11 \"\"\"\n12 \n13 import platform\n14 import sys\n15 import importlib\n16 \n17 \n18 def main():\n19     version_rows = [(\"platform\", platform.platform()), (\"Python\", sys.version)]\n20 \n21     for module in (\"pydicom\", \"gdcm\", \"jpeg_ls\", \"numpy\", \"PIL\"):\n22         try:\n23             m = importlib.import_module(module)\n24         except ImportError:\n25             version = \"_module not found_\"\n26         else:\n27             version = extract_version(m) or \"**cannot determine version**\"\n28 \n29         version_rows.append((module, version))\n30 \n31     print_table(version_rows)\n32 \n33 \n34 def print_table(version_rows):\n35     row_format = \"{:12} | {}\"\n36     print(row_format.format(\"module\", \"version\"))\n37     print(row_format.format(\"------\", \"-------\"))\n38     for module, version in version_rows:\n39         # Some version strings have multiple lines and need to be squashed\n40         print(row_format.format(module, version.replace(\"\\n\", \" \")))\n41 \n42 \n43 def extract_version(module):\n44     if module.__name__ == \"gdcm\":\n45         return getattr(module, \"GDCM_VERSION\", None)\n46     return getattr(module, \"__version__\", None)\n47 \n48 \n49 if __name__ == \"__main__\":\n50     main()\n51 \n[end of pydicom/env_info.py]\n[start of pydicom/jsonrep.py]\n1 # Copyright 2008-2019 pydicom authors. See LICENSE file for details.\n2 \"\"\"Methods for converting Datasets and DataElements to/from json\"\"\"\n3 \n4 import base64\n5 from inspect import signature\n6 import inspect\n7 from typing import Callable, Optional, Union\n8 import warnings\n9 \n10 from pydicom.tag import BaseTag\n11 \n12 # Order of keys is significant!\n13 JSON_VALUE_KEYS = ('Value', 'BulkDataURI', 'InlineBinary',)\n14 \n15 BINARY_VR_VALUES = ['OW', 'OB', 'OD', 'OF', 'OL', 'UN',\n16                     'OB or OW', 'US or OW', 'US or SS or OW']\n17 VRs_TO_BE_FLOATS = ['DS', 'FL', 'FD', ]\n18 VRs_TO_BE_INTS = ['IS', 'SL', 'SS', 'UL', 'US', 'US or SS']\n19 \n20 \n21 def convert_to_python_number(value, vr):\n22     \"\"\"Makes sure that values are either ints or floats\n23     based on their value representation.\n24 \n25     .. versionadded:: 1.4\n26 \n27     Parameters\n28     ----------\n29     value: Union[Union[str, int, float], List[Union[str, int, float]]]\n30         value of data element\n31     vr: str\n32         value representation of data element\n33 \n34     Returns\n35     -------\n36     Union[Union[str, int, float], List[Union[str, int, float]]]\n37 \n38     \"\"\"\n39     if value is None:\n40         return None\n41     number_type = None\n42     if vr in VRs_TO_BE_INTS:\n43         number_type = int\n44     if vr in VRs_TO_BE_FLOATS:\n45         number_type = float\n46     if number_type is not None:\n47         if isinstance(value, (list, tuple,)):\n48             value = [number_type(e) for e in value]\n49         else:\n50             value = number_type(value)\n51     return value\n52 \n53 \n54 class JsonDataElementConverter:\n55     \"\"\"Handles conversion between JSON struct and :class:`DataElement`.\n56 \n57     .. versionadded:: 1.4\n58     \"\"\"\n59 \n60     def __init__(\n61         self,\n62         dataset_class,\n63         tag,\n64         vr,\n65         value,\n66         value_key,\n67         bulk_data_uri_handler: Optional[\n68             Union[\n69                 Callable[[BaseTag, str, str], object],\n70                 Callable[[str], object]\n71             ]\n72         ] = None\n73     ):\n74         \"\"\"Create a new converter instance.\n75 \n76         Parameters\n77         ----------\n78         dataset_class : dataset.Dataset derived class\n79             Class used to create sequence items.\n80         tag : BaseTag\n81             The data element tag or int.\n82         vr : str\n83             The data element value representation.\n84         value : list\n85             The data element's value(s).\n86         value_key : str or None\n87             Key of the data element that contains the value\n88             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n89         bulk_data_uri_handler: callable or None\n90             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n91             or just the \"BulkDataURI\" of the JSON\n92             representation of a data element and returns the actual value of\n93             that data element (retrieved via DICOMweb WADO-RS)\n94         \"\"\"\n95         self.dataset_class = dataset_class\n96         self.tag = tag\n97         self.vr = vr\n98         self.value = value\n99         self.value_key = value_key\n100         if (\n101             bulk_data_uri_handler and\n102             len(signature(bulk_data_uri_handler).parameters) == 1\n103         ):\n104             def wrapped_bulk_data_handler(tag, vr, value):\n105                 return bulk_data_uri_handler(value)\n106             self.bulk_data_element_handler = wrapped_bulk_data_handler\n107         else:\n108             self.bulk_data_element_handler = bulk_data_uri_handler\n109 \n110     def get_element_values(self):\n111         \"\"\"Return a the data element value or list of values.\n112 \n113         Returns\n114         -------\n115         str or bytes or int or float or dataset_class\n116         or PersonName or list of any of these types\n117             The value or value list of the newly created data element.\n118         \"\"\"\n119         from pydicom.dataelem import empty_value_for_VR\n120         if self.value_key == 'Value':\n121             if not isinstance(self.value, list):\n122                 fmt = '\"{}\" of data element \"{}\" must be a list.'\n123                 raise TypeError(fmt.format(self.value_key, self.tag))\n124             if not self.value:\n125                 return empty_value_for_VR(self.vr)\n126             element_value = [self.get_regular_element_value(v)\n127                              for v in self.value]\n128             if len(element_value) == 1 and self.vr != 'SQ':\n129                 element_value = element_value[0]\n130             return convert_to_python_number(element_value, self.vr)\n131 \n132         # The value for \"InlineBinary\" shall be encoded as a base64 encoded\n133         # string, as shown in PS3.18, Table F.3.1-1, but the example in\n134         # PS3.18, Annex F.4 shows the string enclosed in a list.\n135         # We support both variants, as the standard is ambiguous here,\n136         # and do the same for \"BulkDataURI\".\n137         value = self.value\n138         if isinstance(value, list):\n139             value = value[0]\n140 \n141         if self.value_key == 'InlineBinary':\n142             if not isinstance(value, (str, bytes)):\n143                 fmt = '\"{}\" of data element \"{}\" must be a bytes-like object.'\n144                 raise TypeError(fmt.format(self.value_key, self.tag))\n145             return base64.b64decode(value)\n146 \n147         if self.value_key == 'BulkDataURI':\n148             if not isinstance(value, str):\n149                 fmt = '\"{}\" of data element \"{}\" must be a string.'\n150                 raise TypeError(fmt.format(self.value_key, self.tag))\n151             if self.bulk_data_element_handler is None:\n152                 warnings.warn(\n153                     'no bulk data URI handler provided for retrieval '\n154                     'of value of data element \"{}\"'.format(self.tag)\n155                 )\n156                 return empty_value_for_VR(self.vr, raw=True)\n157             return self.bulk_data_element_handler(self.tag, self.vr, value)\n158         return empty_value_for_VR(self.vr)\n159 \n160     def get_regular_element_value(self, value):\n161         \"\"\"Return a the data element value created from a json \"Value\" entry.\n162 \n163         Parameters\n164         ----------\n165         value : str or int or float or dict\n166             The data element's value from the json entry.\n167 \n168         Returns\n169         -------\n170         dataset_class or PersonName\n171         or str or int or float\n172             A single value of the corresponding :class:`DataElement`.\n173         \"\"\"\n174         if self.vr == 'SQ':\n175             return self.get_sequence_item(value)\n176 \n177         if self.vr == 'PN':\n178             return self.get_pn_element_value(value)\n179 \n180         if self.vr == 'AT':\n181             try:\n182                 return int(value, 16)\n183             except ValueError:\n184                 warnings.warn('Invalid value \"{}\" for AT element - '\n185                               'ignoring it'.format(value))\n186             return\n187         return value\n188 \n189     def get_sequence_item(self, value):\n190         \"\"\"Return a sequence item for the JSON dict `value`.\n191 \n192         Parameters\n193         ----------\n194         value : dict or None\n195             The sequence item from the JSON entry.\n196 \n197         Returns\n198         -------\n199         dataset_class\n200             The decoded dataset item.\n201 \n202         Raises\n203         ------\n204         KeyError\n205             If the \"vr\" key is missing for a contained element\n206         \"\"\"\n207         ds = self.dataset_class()\n208         if value:\n209             for key, val in value.items():\n210                 if 'vr' not in val:\n211                     fmt = 'Data element \"{}\" must have key \"vr\".'\n212                     raise KeyError(fmt.format(self.tag))\n213                 vr = val['vr']\n214                 unique_value_keys = tuple(\n215                     set(val.keys()) & set(JSON_VALUE_KEYS)\n216                 )\n217                 from pydicom import DataElement\n218                 from pydicom.dataelem import empty_value_for_VR\n219                 if not unique_value_keys:\n220                     # data element with no value\n221                     elem = DataElement(\n222                         tag=int(key, 16),\n223                         value=empty_value_for_VR(vr),\n224                         VR=vr)\n225                 else:\n226                     value_key = unique_value_keys[0]\n227                     elem = DataElement.from_json(\n228                         self.dataset_class, key, vr,\n229                         val[value_key], value_key\n230                     )\n231                 ds.add(elem)\n232         return ds\n233 \n234     def get_pn_element_value(self, value):\n235         \"\"\"Return PersonName value from JSON value.\n236 \n237         Values with VR PN have a special JSON encoding, see the DICOM Standard,\n238         Part 18, :dcm:`Annex F.2.2<part18/sect_F.2.2.html>`.\n239 \n240         Parameters\n241         ----------\n242         value : dict\n243             The person name components in the JSON entry.\n244 \n245         Returns\n246         -------\n247         PersonName or str\n248             The decoded PersonName object or an empty string.\n249         \"\"\"\n250         if not isinstance(value, dict):\n251             # Some DICOMweb services get this wrong, so we\n252             # workaround the issue and warn the user\n253             # rather than raising an error.\n254             warnings.warn(\n255                 'value of data element \"{}\" with VR Person Name (PN) '\n256                 'is not formatted correctly'.format(self.tag)\n257             )\n258             return value\n259         else:\n260             if 'Phonetic' in value:\n261                 comps = ['', '', '']\n262             elif 'Ideographic' in value:\n263                 comps = ['', '']\n264             else:\n265                 comps = ['']\n266             if 'Alphabetic' in value:\n267                 comps[0] = value['Alphabetic']\n268             if 'Ideographic' in value:\n269                 comps[1] = value['Ideographic']\n270             if 'Phonetic' in value:\n271                 comps[2] = value['Phonetic']\n272             elem_value = '='.join(comps)\n273             return elem_value\n274 \n[end of pydicom/jsonrep.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "49a3da4a3d9c24d7e8427a25048a1c7d5c4f7724", "problem_statement": "from_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n", "hints_text": "", "created_at": "2020-11-04T21:13:33Z", "patch": "<patch>\ndiff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ def get_sequence_item(self, value):\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_json.py b/pydicom/tests/test_json.py\n--- a/pydicom/tests/test_json.py\n+++ b/pydicom/tests/test_json.py\n@@ -354,3 +354,25 @@ def bulk_data_reader(tag, vr, value):\n         ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n \n         assert b'xyzzy' == ds[0x00091002].value\n+\n+    def test_bulk_data_reader_is_called_within_SQ(self):\n+        def bulk_data_reader(_):\n+            return b'xyzzy'\n+\n+        json_data = {\n+            \"003a0200\": {\n+                \"vr\": \"SQ\", \n+                \"Value\": [\n+                    {\n+                        \"54001010\": {\n+                            \"vr\": \"OW\",\n+                            \"BulkDataURI\": \"https://a.dummy.url\"\n+                        }\n+                    }\n+                ]\n+            }\n+        }\n+\n+        ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n+\n+        assert b'xyzzy' == ds[0x003a0200].value[0][0x54001010].value\n", "version": "2.1", "FAIL_TO_PASS": "[\"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_within_SQ\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_json.py::TestPersonName::test_json_pn_from_file\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_from_json\", \"pydicom/tests/test_json.py::TestPersonName::test_empty_value\", \"pydicom/tests/test_json.py::TestPersonName::test_multi_value_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_dataelem_from_json\", \"pydicom/tests/test_json.py::TestAT::test_to_json\", \"pydicom/tests/test_json.py::TestAT::test_from_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_value_in_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_tag_in_json\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_json_from_dicom_file\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_roundtrip\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataset_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataelement_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_sort_order\", \"pydicom/tests/test_json.py::TestSequence::test_nested_sequences\", \"pydicom/tests/test_json.py::TestBinary::test_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_valid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_2\"]", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}
{"instance_id": "pydicom__pydicom-1256_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nfrom_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 import base64\n11 import json\n12 from typing import (\n13     Optional, Any, Optional, Tuple, Callable, Union, TYPE_CHECKING, Dict,\n14     TypeVar, Type, List, NamedTuple\n15 )\n16 import warnings\n17 \n18 from pydicom import config  # don't import datetime_conversion directly\n19 from pydicom.config import logger\n20 from pydicom import config\n21 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n22                               dictionary_keyword, dictionary_is_retired,\n23                               private_dictionary_description, dictionary_VR,\n24                               repeater_has_tag)\n25 from pydicom.jsonrep import JsonDataElementConverter\n26 from pydicom.multival import MultiValue\n27 from pydicom.tag import Tag, BaseTag\n28 from pydicom.uid import UID\n29 from pydicom import jsonrep\n30 import pydicom.valuerep  # don't import DS directly as can be changed by config\n31 from pydicom.valuerep import PersonName\n32 \n33 if config.have_numpy:\n34     import numpy\n35 \n36 if TYPE_CHECKING:\n37     from pydicom.dataset import Dataset\n38 \n39 \n40 BINARY_VR_VALUES = [\n41     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n42     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n43 ]\n44 \n45 \n46 def empty_value_for_VR(\n47     VR: str, raw: bool = False\n48 ) -> Union[bytes, List[str], str, None]:\n49     \"\"\"Return the value for an empty element for `VR`.\n50 \n51     .. versionadded:: 1.4\n52 \n53     The behavior of this property depends on the setting of\n54     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n55     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n56     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n57     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n58     empty string is used as empty value representation, for all other VRs\n59     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n60     is used in all cases.\n61     Note that this is used only if decoding the element - it is always\n62     possible to set the value to another empty value representation,\n63     which will be preserved during the element object lifetime.\n64 \n65     Parameters\n66     ----------\n67     VR : str\n68         The VR of the corresponding element.\n69 \n70     raw : bool\n71         If ``True``, returns the value for a :class:`RawDataElement`,\n72         otherwise for a :class:`DataElement`\n73 \n74     Returns\n75     -------\n76     str or bytes or None or list\n77         The value a data element with `VR` is assigned on decoding\n78         if it is empty.\n79     \"\"\"\n80     if VR == 'SQ':\n81         return b'' if raw else []\n82     if config.use_none_as_empty_text_VR_value:\n83         return None\n84     if VR in ('AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT',\n85               'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR', 'UT'):\n86         return b'' if raw else ''\n87     return None\n88 \n89 \n90 def _is_bytes(val: object) -> bool:\n91     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n92     return isinstance(val, bytes)\n93 \n94 \n95 # double '\\' because it is used as escape chr in Python\n96 _backslash_str = \"\\\\\"\n97 _backslash_byte = b\"\\\\\"\n98 \n99 \n100 _DataElement = TypeVar(\"_DataElement\", bound=\"DataElement\")\n101 _Dataset = TypeVar(\"_Dataset\", bound=\"Dataset\")\n102 \n103 \n104 class DataElement:\n105     \"\"\"Contain and manipulate a DICOM Element.\n106 \n107     Examples\n108     --------\n109 \n110     While its possible to create a new :class:`DataElement` directly and add\n111     it to a :class:`~pydicom.dataset.Dataset`:\n112 \n113     >>> from pydicom import Dataset\n114     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n115     >>> ds = Dataset()\n116     >>> ds.add(elem)\n117 \n118     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n119     to add a new :class:`DataElement`, as the VR and tag are determined\n120     automatically from the DICOM dictionary:\n121 \n122     >>> ds = Dataset()\n123     >>> ds.PatientName = 'CITIZEN^Joan'\n124 \n125     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n126     value for text VRs and `None` for non-text (binary) VRs:\n127 \n128     >>> ds = Dataset()\n129     >>> ds.PatientName = None\n130     >>> ds.PatientName\n131     ''\n132 \n133     >>> ds.BitsAllocated = None\n134     >>> ds.BitsAllocated\n135 \n136     >>> str(ds.BitsAllocated)\n137     'None'\n138 \n139     Attributes\n140     ----------\n141     descripWidth : int\n142         For string display, this is the maximum width of the description\n143         field (default ``35``).\n144     is_undefined_length : bool\n145         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n146         (ie undefined).\n147     maxBytesToDisplay : int\n148         For string display, elements with values containing data which is\n149         longer than this value will display ``\"array of # bytes\"``\n150         (default ``16``).\n151     showVR : bool\n152         For string display, include the element's VR just before it's value\n153         (default ``True``).\n154     tag : pydicom.tag.BaseTag\n155         The element's tag.\n156     VR : str\n157         The element's Value Representation.\n158     \"\"\"\n159 \n160     descripWidth = 35\n161     maxBytesToDisplay = 16\n162     showVR = True\n163     is_raw = False\n164 \n165     def __init__(\n166         self,\n167         tag: Union[int, str, Tuple[int, int]],\n168         VR: str,\n169         value: object,\n170         file_value_tell: Optional[int] = None,\n171         is_undefined_length: bool = False,\n172         already_converted: bool = False\n173     ) -> None:\n174         \"\"\"Create a new :class:`DataElement`.\n175 \n176         Parameters\n177         ----------\n178         tag : int or str or 2-tuple of int\n179             The DICOM (group, element) tag in any form accepted by\n180             :func:`~pydicom.tag.Tag` such as ``'PatientName'``,\n181             ``(0x10, 0x10)``, ``0x00100010``, etc.\n182         VR : str\n183             The 2 character DICOM value representation (see DICOM Standard,\n184             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n185         value\n186             The value of the data element. One of the following:\n187 \n188             * a single string value\n189             * a number\n190             * a :class:`list` or :class:`tuple` with all strings or all numbers\n191             * a multi-value string with backslash separator\n192         file_value_tell : int, optional\n193             The byte offset to the start of the encoded element value.\n194         is_undefined_length : bool\n195             Used internally to store whether the length field for this element\n196             was ``0xFFFFFFFF``, i.e. 'undefined length'. Default is ``False``.\n197         already_converted : bool\n198             Used to determine whether or not the element's value requires\n199             conversion to a value with VM > 1. Default is ``False``.\n200         \"\"\"\n201         if not isinstance(tag, BaseTag):\n202             tag = Tag(tag)\n203         self.tag = tag\n204 \n205         # a known tag shall only have the VR 'UN' if it has a length that\n206         # exceeds the size that can be encoded in 16 bit - all other cases\n207         # can be seen as an encoding error and can be corrected\n208         if (\n209             VR == 'UN'\n210             and not tag.is_private\n211             and config.replace_un_with_known_vr\n212             and (is_undefined_length or value is None or len(value) < 0xffff)\n213         ):\n214             try:\n215                 VR = dictionary_VR(tag)\n216             except KeyError:\n217                 pass\n218 \n219         self.VR = VR  # Note: you must set VR before setting value\n220         if already_converted:\n221             self._value = value\n222         else:\n223             self.value = value  # calls property setter which will convert\n224         self.file_tell = file_value_tell\n225         self.is_undefined_length = is_undefined_length\n226         self.private_creator: Optional[str] = None\n227         self.parent: Optional[\"Dataset\"] = None\n228 \n229     @classmethod\n230     def from_json(\n231         cls: Type[_DataElement],\n232         dataset_class: Type[_Dataset],\n233         tag: Union[BaseTag, int],\n234         vr: str,\n235         value: object,\n236         value_key: Union[str, None],\n237         bulk_data_uri_handler: Optional[\n238             Union[\n239                 Callable[[BaseTag, str, str], object],\n240                 Callable[[str], object]\n241             ]\n242         ] = None\n243     ) -> _DataElement:\n244         \"\"\"Return a :class:`DataElement` from JSON.\n245 \n246         .. versionadded:: 1.3\n247 \n248         Parameters\n249         ----------\n250         dataset_class : dataset.Dataset derived class\n251             Class used to create sequence items.\n252         tag : pydicom.tag.BaseTag or int\n253             The data element tag.\n254         vr : str\n255             The data element value representation.\n256         value : list\n257             The data element's value(s).\n258         value_key : str or None\n259             Key of the data element that contains the value\n260             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n261         bulk_data_uri_handler: callable or None\n262             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n263             or just the \"BulkDataURI\" of the JSON\n264             representation of a data element and returns the actual value of\n265             that data element (retrieved via DICOMweb WADO-RS)\n266 \n267         Returns\n268         -------\n269         DataElement\n270         \"\"\"\n271         # TODO: test wado-rs retrieve wrapper\n272         converter = JsonDataElementConverter(\n273             dataset_class, tag, vr, value, value_key, bulk_data_uri_handler\n274         )\n275         elem_value = converter.get_element_values()\n276         try:\n277             return cls(tag=tag, value=elem_value, VR=vr)\n278         except Exception as exc:\n279             raise ValueError(\n280                 f\"Data element '{tag}' could not be loaded from JSON: \"\n281                 f\"{elem_value}\"\n282             ) from exc\n283 \n284     def to_json_dict(\n285         self,\n286         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]],\n287         bulk_data_threshold: int\n288     ) -> Dict[str, object]:\n289         \"\"\"Return a dictionary representation of the :class:`DataElement`\n290         conforming to the DICOM JSON Model as described in the DICOM\n291         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n292 \n293         .. versionadded:: 1.4\n294 \n295         Parameters\n296         ----------\n297         bulk_data_element_handler: callable or None\n298             Callable that accepts a bulk data element and returns the\n299             \"BulkDataURI\" for retrieving the value of the data element\n300             via DICOMweb WADO-RS\n301         bulk_data_threshold: int\n302             Size of base64 encoded data element above which a value will be\n303             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n304             Ignored if no bulk data handler is given.\n305 \n306         Returns\n307         -------\n308         dict\n309             Mapping representing a JSON encoded data element\n310         \"\"\"\n311         json_element = {'vr': self.VR, }\n312         if self.VR in jsonrep.BINARY_VR_VALUES:\n313             if not self.is_empty:\n314                 binary_value = self.value\n315                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n316                 if (\n317                     bulk_data_element_handler is not None\n318                     and len(encoded_value) > bulk_data_threshold\n319                 ):\n320                     json_element['BulkDataURI'] = (\n321                         bulk_data_element_handler(self)\n322                     )\n323                 else:\n324                     logger.info(\n325                         f\"encode bulk data element '{self.name}' inline\"\n326                     )\n327                     json_element['InlineBinary'] = encoded_value\n328         elif self.VR == 'SQ':\n329             # recursive call to get sequence item JSON dicts\n330             value = [\n331                 ds.to_json(\n332                     bulk_data_element_handler=bulk_data_element_handler,\n333                     bulk_data_threshold=bulk_data_threshold,\n334                     dump_handler=lambda d: d\n335                 )\n336                 for ds in self.value\n337             ]\n338             json_element['Value'] = value\n339         elif self.VR == 'PN':\n340             if not self.is_empty:\n341                 elem_value = []\n342                 if self.VM > 1:\n343                     value = self.value\n344                 else:\n345                     value = [self.value]\n346                 for v in value:\n347                     comps = {'Alphabetic': v.components[0]}\n348                     if len(v.components) > 1:\n349                         comps['Ideographic'] = v.components[1]\n350                     if len(v.components) > 2:\n351                         comps['Phonetic'] = v.components[2]\n352                     elem_value.append(comps)\n353                 json_element['Value'] = elem_value\n354         elif self.VR == 'AT':\n355             if not self.is_empty:\n356                 value = self.value\n357                 if self.VM == 1:\n358                     value = [value]\n359                 json_element['Value'] = [format(v, '08X') for v in value]\n360         else:\n361             if not self.is_empty:\n362                 if self.VM > 1:\n363                     value = self.value\n364                 else:\n365                     value = [self.value]\n366                 json_element['Value'] = [v for v in value]\n367         if hasattr(json_element, 'Value'):\n368             json_element['Value'] = jsonrep.convert_to_python_number(\n369                 json_element['Value'], self.VR\n370             )\n371         return json_element\n372 \n373     def to_json(\n374         self,\n375         bulk_data_threshold: int = 1024,\n376         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]] = None,  # noqa\n377         dump_handler: Optional[Callable[[Dict[object, object]], str]] = None\n378     ) -> Dict[str, object]:\n379         \"\"\"Return a JSON representation of the :class:`DataElement`.\n380 \n381         .. versionadded:: 1.3\n382 \n383         Parameters\n384         ----------\n385         bulk_data_element_handler: callable, optional\n386             Callable that accepts a bulk data element and returns the\n387             \"BulkDataURI\" for retrieving the value of the data element\n388             via DICOMweb WADO-RS\n389         bulk_data_threshold: int, optional\n390             Size of base64 encoded data element above which a value will be\n391             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n392             Ignored if no bulk data handler is given.\n393         dump_handler : callable, optional\n394             Callable function that accepts a :class:`dict` and returns the\n395             serialized (dumped) JSON string (by default uses\n396             :func:`json.dumps`).\n397 \n398         Returns\n399         -------\n400         dict\n401             Mapping representing a JSON encoded data element\n402 \n403         See also\n404         --------\n405         Dataset.to_json\n406         \"\"\"\n407         if dump_handler is None:\n408             def json_dump(d):\n409                 return json.dumps(d, sort_keys=True)\n410 \n411             dump_handler = json_dump\n412 \n413         return dump_handler(\n414             self.to_json_dict(bulk_data_element_handler, bulk_data_threshold)\n415         )\n416 \n417     @property\n418     def value(self) -> object:\n419         \"\"\"Return the element's value.\"\"\"\n420         return self._value\n421 \n422     @value.setter\n423     def value(self, val: object) -> None:\n424         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n425         # Check if is a string with multiple values separated by '\\'\n426         # If so, turn them into a list of separate strings\n427         #  Last condition covers 'US or SS' etc\n428         if isinstance(val, (str, bytes)) and self.VR not in \\\n429                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n430                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n431                  'OW or OB', 'UN'] and 'US' not in self.VR:\n432             try:\n433                 if _backslash_str in val:\n434                     val = val.split(_backslash_str)\n435             except TypeError:\n436                 if _backslash_byte in val:\n437                     val = val.split(_backslash_byte)\n438         self._value = self._convert_value(val)\n439 \n440     @property\n441     def VM(self) -> int:\n442         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n443         if self.value is None:\n444             return 0\n445         if isinstance(self.value, (str, bytes, PersonName)):\n446             return 1 if self.value else 0\n447         try:\n448             iter(self.value)\n449         except TypeError:\n450             return 1\n451         return len(self.value)\n452 \n453     @property\n454     def is_empty(self) -> bool:\n455         \"\"\"Return ``True`` if the element has no value.\n456 \n457         .. versionadded:: 1.4\n458         \"\"\"\n459         return self.VM == 0\n460 \n461     @property\n462     def empty_value(self) -> Union[bytes, List[str], None, str]:\n463         \"\"\"Return the value for an empty element.\n464 \n465         .. versionadded:: 1.4\n466 \n467         See :func:`empty_value_for_VR` for more information.\n468 \n469         Returns\n470         -------\n471         str or None\n472             The value this data element is assigned on decoding if it is empty.\n473         \"\"\"\n474         return empty_value_for_VR(self.VR)\n475 \n476     def clear(self) -> None:\n477         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n478 \n479         .. versionadded:: 1.4\n480 \n481         See :func:`empty_value_for_VR`.\n482         \"\"\"\n483         self._value = self.empty_value\n484 \n485     def _convert_value(self, val: object) -> object:\n486         \"\"\"Convert `val` to an appropriate type and return the result.\n487 \n488         Uses the element's VR in order to determine the conversion method and\n489         resulting type.\n490         \"\"\"\n491         if self.VR == 'SQ':  # a sequence - leave it alone\n492             from pydicom.sequence import Sequence\n493             if isinstance(val, Sequence):\n494                 return val\n495             else:\n496                 return Sequence(val)\n497 \n498         # if the value is a list, convert each element\n499         try:\n500             val.append\n501         except AttributeError:  # not a list\n502             return self._convert(val)\n503         else:\n504             return MultiValue(self._convert, val)\n505 \n506     def _convert(self, val: object) -> object:\n507         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n508         # If the value is a byte string and has a VR that can only be encoded\n509         # using the default character repertoire, we convert it to a string\n510         # here to allow for byte string input in these cases\n511         if _is_bytes(val) and self.VR in (\n512                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n513             val = val.decode()\n514 \n515         if self.VR == 'IS':\n516             return pydicom.valuerep.IS(val)\n517         elif self.VR == 'DA' and config.datetime_conversion:\n518             return pydicom.valuerep.DA(val)\n519         elif self.VR == 'DS':\n520             return pydicom.valuerep.DS(val)\n521         elif self.VR == 'DT' and config.datetime_conversion:\n522             return pydicom.valuerep.DT(val)\n523         elif self.VR == 'TM' and config.datetime_conversion:\n524             return pydicom.valuerep.TM(val)\n525         elif self.VR == \"UI\":\n526             return UID(val) if val is not None else None\n527         elif self.VR == \"PN\":\n528             return PersonName(val)\n529         # Later may need this for PersonName as for UI,\n530         #    but needs more thought\n531         # elif self.VR == \"PN\":\n532         #    return PersonName(val)\n533         else:  # is either a string or a type 2 optionally blank string\n534             return val  # this means a \"numeric\" value could be empty string \"\"\n535         # except TypeError:\n536             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n537             # % (repr(val), self.VR, self.tag)\n538         # except ValueError:\n539             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n540             # % (repr(val), self.VR, self.tag)\n541 \n542     def __eq__(self, other: object) -> bool:\n543         \"\"\"Compare `self` and `other` for equality.\n544 \n545         Returns\n546         -------\n547         bool\n548             The result if `self` and `other` are the same class\n549         NotImplemented\n550             If `other` is not the same class as `self` then returning\n551             :class:`NotImplemented` delegates the result to\n552             ``superclass.__eq__(subclass)``.\n553         \"\"\"\n554         # Faster result if same object\n555         if other is self:\n556             return True\n557 \n558         if isinstance(other, self.__class__):\n559             if self.tag != other.tag or self.VR != other.VR:\n560                 return False\n561 \n562             # tag and VR match, now check the value\n563             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n564                 return (len(self.value) == len(other.value)\n565                         and numpy.allclose(self.value, other.value))\n566             else:\n567                 return self.value == other.value\n568 \n569         return NotImplemented\n570 \n571     def __ne__(self, other: object) -> bool:\n572         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n573         return not (self == other)\n574 \n575     def __str__(self) -> str:\n576         \"\"\"Return :class:`str` representation of the element.\"\"\"\n577         repVal = self.repval or ''\n578         if self.showVR:\n579             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n580                                     self.description()[:self.descripWidth],\n581                                     self.VR, repVal)\n582         else:\n583             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n584                                 self.description()[:self.descripWidth], repVal)\n585         return s\n586 \n587     @property\n588     def repval(self) -> str:\n589         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n590         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n591         if set(self.VR.split(\" or \")) & long_VRs:\n592             try:\n593                 length = len(self.value)\n594             except TypeError:\n595                 pass\n596             else:\n597                 if length > self.maxBytesToDisplay:\n598                     return \"Array of %d elements\" % length\n599         if self.VM > self.maxBytesToDisplay:\n600             repVal = \"Array of %d elements\" % self.VM\n601         elif isinstance(self.value, UID):\n602             repVal = self.value.name\n603         else:\n604             repVal = repr(self.value)  # will tolerate unicode too\n605         return repVal\n606 \n607     def __getitem__(self, key: int) -> object:\n608         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n609         try:\n610             return self.value[key]\n611         except TypeError:\n612             raise TypeError(\"DataElement value is unscriptable \"\n613                             \"(not a Sequence)\")\n614 \n615     @property\n616     def name(self) -> str:\n617         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n618 \n619         For officially registered DICOM Data Elements this will be the *Name*\n620         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n621         For private elements known to *pydicom*\n622         this will be the *Name* in the format ``'[name]'``. For unknown\n623         private elements this will be ``'Private Creator'``. For unknown\n624         elements this will return an empty string ``''``.\n625         \"\"\"\n626         return self.description()\n627 \n628     def description(self) -> str:\n629         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n630         if self.tag.is_private:\n631             name = \"Private tag data\"  # default\n632             if self.private_creator:\n633                 try:\n634                     # If have name from private dictionary, use it, but\n635                     #   but put in square brackets so is differentiated,\n636                     #   and clear that cannot access it by name\n637                     name = private_dictionary_description(\n638                         self.tag, self.private_creator)\n639                     name = \"[%s]\" % (name)\n640                 except KeyError:\n641                     pass\n642             elif self.tag.element >> 8 == 0:\n643                 name = \"Private Creator\"\n644         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n645             name = dictionary_description(self.tag)\n646 \n647         # implied Group Length dicom versions < 3\n648         elif self.tag.element == 0:\n649             name = \"Group Length\"\n650         else:\n651             name = \"\"\n652         return name\n653 \n654     @property\n655     def is_private(self) -> bool:\n656         \"\"\"Return ``True`` if the element's tag is private.\n657 \n658         .. versionadded:: 2.1\n659         \"\"\"\n660         return self.tag.is_private\n661 \n662     @property\n663     def is_retired(self) -> bool:\n664         \"\"\"Return the element's retired status as :class:`bool`.\n665 \n666         For officially registered DICOM Data Elements this will be ``True`` if\n667         the retired status as given in the DICOM Standard, Part 6,\n668         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n669         or unknown elements this will always be ``False``.\n670         \"\"\"\n671         if dictionary_has_tag(self.tag):\n672             return dictionary_is_retired(self.tag)\n673 \n674         return False\n675 \n676     @property\n677     def keyword(self) -> str:\n678         \"\"\"Return the element's keyword (if known) as :class:`str`.\n679 \n680         For officially registered DICOM Data Elements this will be the\n681         *Keyword* as given in\n682         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n683         unknown elements this will return an empty string ``''``.\n684         \"\"\"\n685         if dictionary_has_tag(self.tag):\n686             return dictionary_keyword(self.tag)\n687 \n688         return ''\n689 \n690     def __repr__(self) -> str:\n691         \"\"\"Return the representation of the element.\"\"\"\n692         if self.VR == \"SQ\":\n693             return repr(self.value)\n694 \n695         return str(self)\n696 \n697 \n698 class RawDataElement(NamedTuple):\n699     \"\"\"Container for the data from a raw (mostly) undecoded element.\"\"\"\n700     tag: BaseTag\n701     VR: Optional[str]\n702     length: int\n703     value: bytes\n704     value_tell: int\n705     is_implicit_VR: bool\n706     is_little_endian: bool\n707     is_raw: bool = True\n708 \n709 \n710 # The first and third values of the following elements are always US\n711 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n712 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n713 # (0028,3002) LUT Descriptor\n714 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n715 \n716 \n717 def DataElement_from_raw(\n718     raw_data_element: RawDataElement, encoding: Optional[List[str]] = None\n719 ) -> DataElement:\n720     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n721 \n722     Parameters\n723     ----------\n724     raw_data_element : RawDataElement\n725         The raw data to convert to a :class:`DataElement`.\n726     encoding : list of str, optional\n727         The character encoding of the raw data.\n728 \n729     Returns\n730     -------\n731     DataElement\n732 \n733     Raises\n734     ------\n735     KeyError\n736         If `raw_data_element` belongs to an unknown non-private tag and\n737         `config.enforce_valid_values` is set.\n738     \"\"\"\n739     # XXX buried here to avoid circular import\n740     # filereader->Dataset->convert_value->filereader\n741     # (for SQ parsing)\n742 \n743     from pydicom.values import convert_value\n744     raw = raw_data_element\n745 \n746     # If user has hooked into conversion of raw values, call his/her routine\n747     if config.data_element_callback:\n748         raw = config.data_element_callback(\n749             raw_data_element,\n750             encoding=encoding,\n751             **config.data_element_callback_kwargs\n752         )\n753 \n754     VR = raw.VR\n755     if VR is None:  # Can be if was implicit VR\n756         try:\n757             VR = dictionary_VR(raw.tag)\n758         except KeyError:\n759             # just read the bytes, no way to know what they mean\n760             if raw.tag.is_private:\n761                 # for VR for private tags see PS3.5, 6.2.2\n762                 if raw.tag.is_private_creator:\n763                     VR = 'LO'\n764                 else:\n765                     VR = 'UN'\n766 \n767             # group length tag implied in versions < 3.0\n768             elif raw.tag.element == 0:\n769                 VR = 'UL'\n770             else:\n771                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n772                 if config.enforce_valid_values:\n773                     msg += \" can't look up VR\"\n774                     raise KeyError(msg)\n775                 else:\n776                     VR = 'UN'\n777                     msg += \" - setting VR to 'UN'\"\n778                     warnings.warn(msg)\n779     elif (VR == 'UN' and not raw.tag.is_private and\n780           config.replace_un_with_known_vr):\n781         # handle rare case of incorrectly set 'UN' in explicit encoding\n782         # see also DataElement.__init__()\n783         if (\n784             raw.length == 0xffffffff\n785             or raw.value is None\n786             or len(raw.value) < 0xffff\n787         ):\n788             try:\n789                 VR = dictionary_VR(raw.tag)\n790             except KeyError:\n791                 pass\n792     try:\n793         value = convert_value(VR, raw, encoding)\n794     except NotImplementedError as e:\n795         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n796 \n797     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n798         # We only fix the first value as the third value is 8 or 16\n799         try:\n800             if value[0] < 0:\n801                 value[0] += 65536\n802         except TypeError:\n803             pass\n804 \n805     return DataElement(raw.tag, VR, value, raw.value_tell,\n806                        raw.length == 0xFFFFFFFF, already_converted=True)\n807 \n[end of pydicom/dataelem.py]\n[start of pydicom/env_info.py]\n1 # Copyright 2020 pydicom authors. See LICENSE file for details.\n2 \"\"\"\n3 Gather system information and version information for pydicom and auxiliary\n4 modules.\n5 \n6 The output is a GitHub-flavoured markdown table whose contents can help\n7 diagnose any perceived bugs in pydicom. This can be pasted directly into a new\n8 GitHub bug report.\n9 \n10 This file is intended to be run as an executable module.\n11 \"\"\"\n12 \n13 import platform\n14 import sys\n15 import importlib\n16 \n17 \n18 def main():\n19     version_rows = [(\"platform\", platform.platform()), (\"Python\", sys.version)]\n20 \n21     for module in (\"pydicom\", \"gdcm\", \"jpeg_ls\", \"numpy\", \"PIL\"):\n22         try:\n23             m = importlib.import_module(module)\n24         except ImportError:\n25             version = \"_module not found_\"\n26         else:\n27             version = extract_version(m) or \"**cannot determine version**\"\n28 \n29         version_rows.append((module, version))\n30 \n31     print_table(version_rows)\n32 \n33 \n34 def print_table(version_rows):\n35     row_format = \"{:12} | {}\"\n36     print(row_format.format(\"module\", \"version\"))\n37     print(row_format.format(\"------\", \"-------\"))\n38     for module, version in version_rows:\n39         # Some version strings have multiple lines and need to be squashed\n40         print(row_format.format(module, version.replace(\"\\n\", \" \")))\n41 \n42 \n43 def extract_version(module):\n44     if module.__name__ == \"gdcm\":\n45         return getattr(module, \"GDCM_VERSION\", None)\n46     return getattr(module, \"__version__\", None)\n47 \n48 \n49 if __name__ == \"__main__\":\n50     main()\n51 \n[end of pydicom/env_info.py]\n[start of pydicom/jsonrep.py]\n1 # Copyright 2008-2019 pydicom authors. See LICENSE file for details.\n2 \"\"\"Methods for converting Datasets and DataElements to/from json\"\"\"\n3 \n4 import base64\n5 from inspect import signature\n6 import inspect\n7 from typing import Callable, Optional, Union\n8 import warnings\n9 \n10 from pydicom.tag import BaseTag\n11 \n12 # Order of keys is significant!\n13 JSON_VALUE_KEYS = ('Value', 'BulkDataURI', 'InlineBinary',)\n14 \n15 BINARY_VR_VALUES = ['OW', 'OB', 'OD', 'OF', 'OL', 'UN',\n16                     'OB or OW', 'US or OW', 'US or SS or OW']\n17 VRs_TO_BE_FLOATS = ['DS', 'FL', 'FD', ]\n18 VRs_TO_BE_INTS = ['IS', 'SL', 'SS', 'UL', 'US', 'US or SS']\n19 \n20 \n21 def convert_to_python_number(value, vr):\n22     \"\"\"Makes sure that values are either ints or floats\n23     based on their value representation.\n24 \n25     .. versionadded:: 1.4\n26 \n27     Parameters\n28     ----------\n29     value: Union[Union[str, int, float], List[Union[str, int, float]]]\n30         value of data element\n31     vr: str\n32         value representation of data element\n33 \n34     Returns\n35     -------\n36     Union[Union[str, int, float], List[Union[str, int, float]]]\n37 \n38     \"\"\"\n39     if value is None:\n40         return None\n41     number_type = None\n42     if vr in VRs_TO_BE_INTS:\n43         number_type = int\n44     if vr in VRs_TO_BE_FLOATS:\n45         number_type = float\n46     if number_type is not None:\n47         if isinstance(value, (list, tuple,)):\n48             value = [number_type(e) for e in value]\n49         else:\n50             value = number_type(value)\n51     return value\n52 \n53 \n54 class JsonDataElementConverter:\n55     \"\"\"Handles conversion between JSON struct and :class:`DataElement`.\n56 \n57     .. versionadded:: 1.4\n58     \"\"\"\n59 \n60     def __init__(\n61         self,\n62         dataset_class,\n63         tag,\n64         vr,\n65         value,\n66         value_key,\n67         bulk_data_uri_handler: Optional[\n68             Union[\n69                 Callable[[BaseTag, str, str], object],\n70                 Callable[[str], object]\n71             ]\n72         ] = None\n73     ):\n74         \"\"\"Create a new converter instance.\n75 \n76         Parameters\n77         ----------\n78         dataset_class : dataset.Dataset derived class\n79             Class used to create sequence items.\n80         tag : BaseTag\n81             The data element tag or int.\n82         vr : str\n83             The data element value representation.\n84         value : list\n85             The data element's value(s).\n86         value_key : str or None\n87             Key of the data element that contains the value\n88             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n89         bulk_data_uri_handler: callable or None\n90             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n91             or just the \"BulkDataURI\" of the JSON\n92             representation of a data element and returns the actual value of\n93             that data element (retrieved via DICOMweb WADO-RS)\n94         \"\"\"\n95         self.dataset_class = dataset_class\n96         self.tag = tag\n97         self.vr = vr\n98         self.value = value\n99         self.value_key = value_key\n100         if (\n101             bulk_data_uri_handler and\n102             len(signature(bulk_data_uri_handler).parameters) == 1\n103         ):\n104             def wrapped_bulk_data_handler(tag, vr, value):\n105                 return bulk_data_uri_handler(value)\n106             self.bulk_data_element_handler = wrapped_bulk_data_handler\n107         else:\n108             self.bulk_data_element_handler = bulk_data_uri_handler\n109 \n110     def get_element_values(self):\n111         \"\"\"Return a the data element value or list of values.\n112 \n113         Returns\n114         -------\n115         str or bytes or int or float or dataset_class\n116         or PersonName or list of any of these types\n117             The value or value list of the newly created data element.\n118         \"\"\"\n119         from pydicom.dataelem import empty_value_for_VR\n120         if self.value_key == 'Value':\n121             if not isinstance(self.value, list):\n122                 fmt = '\"{}\" of data element \"{}\" must be a list.'\n123                 raise TypeError(fmt.format(self.value_key, self.tag))\n124             if not self.value:\n125                 return empty_value_for_VR(self.vr)\n126             element_value = [self.get_regular_element_value(v)\n127                              for v in self.value]\n128             if len(element_value) == 1 and self.vr != 'SQ':\n129                 element_value = element_value[0]\n130             return convert_to_python_number(element_value, self.vr)\n131 \n132         # The value for \"InlineBinary\" shall be encoded as a base64 encoded\n133         # string, as shown in PS3.18, Table F.3.1-1, but the example in\n134         # PS3.18, Annex F.4 shows the string enclosed in a list.\n135         # We support both variants, as the standard is ambiguous here,\n136         # and do the same for \"BulkDataURI\".\n137         value = self.value\n138         if isinstance(value, list):\n139             value = value[0]\n140 \n141         if self.value_key == 'InlineBinary':\n142             if not isinstance(value, (str, bytes)):\n143                 fmt = '\"{}\" of data element \"{}\" must be a bytes-like object.'\n144                 raise TypeError(fmt.format(self.value_key, self.tag))\n145             return base64.b64decode(value)\n146 \n147         if self.value_key == 'BulkDataURI':\n148             if not isinstance(value, str):\n149                 fmt = '\"{}\" of data element \"{}\" must be a string.'\n150                 raise TypeError(fmt.format(self.value_key, self.tag))\n151             if self.bulk_data_element_handler is None:\n152                 warnings.warn(\n153                     'no bulk data URI handler provided for retrieval '\n154                     'of value of data element \"{}\"'.format(self.tag)\n155                 )\n156                 return empty_value_for_VR(self.vr, raw=True)\n157             return self.bulk_data_element_handler(self.tag, self.vr, value)\n158         return empty_value_for_VR(self.vr)\n159 \n160     def get_regular_element_value(self, value):\n161         \"\"\"Return a the data element value created from a json \"Value\" entry.\n162 \n163         Parameters\n164         ----------\n165         value : str or int or float or dict\n166             The data element's value from the json entry.\n167 \n168         Returns\n169         -------\n170         dataset_class or PersonName\n171         or str or int or float\n172             A single value of the corresponding :class:`DataElement`.\n173         \"\"\"\n174         if self.vr == 'SQ':\n175             return self.get_sequence_item(value)\n176 \n177         if self.vr == 'PN':\n178             return self.get_pn_element_value(value)\n179 \n180         if self.vr == 'AT':\n181             try:\n182                 return int(value, 16)\n183             except ValueError:\n184                 warnings.warn('Invalid value \"{}\" for AT element - '\n185                               'ignoring it'.format(value))\n186             return\n187         return value\n188 \n189     def get_sequence_item(self, value):\n190         \"\"\"Return a sequence item for the JSON dict `value`.\n191 \n192         Parameters\n193         ----------\n194         value : dict or None\n195             The sequence item from the JSON entry.\n196 \n197         Returns\n198         -------\n199         dataset_class\n200             The decoded dataset item.\n201 \n202         Raises\n203         ------\n204         KeyError\n205             If the \"vr\" key is missing for a contained element\n206         \"\"\"\n207         ds = self.dataset_class()\n208         if value:\n209             for key, val in value.items():\n210                 if 'vr' not in val:\n211                     fmt = 'Data element \"{}\" must have key \"vr\".'\n212                     raise KeyError(fmt.format(self.tag))\n213                 vr = val['vr']\n214                 unique_value_keys = tuple(\n215                     set(val.keys()) & set(JSON_VALUE_KEYS)\n216                 )\n217                 from pydicom import DataElement\n218                 from pydicom.dataelem import empty_value_for_VR\n219                 if not unique_value_keys:\n220                     # data element with no value\n221                     elem = DataElement(\n222                         tag=int(key, 16),\n223                         value=empty_value_for_VR(vr),\n224                         VR=vr)\n225                 else:\n226                     value_key = unique_value_keys[0]\n227                     elem = DataElement.from_json(\n228                         self.dataset_class, key, vr,\n229                         val[value_key], value_key\n230                     )\n231                 ds.add(elem)\n232         return ds\n233 \n234     def get_pn_element_value(self, value):\n235         \"\"\"Return PersonName value from JSON value.\n236 \n237         Values with VR PN have a special JSON encoding, see the DICOM Standard,\n238         Part 18, :dcm:`Annex F.2.2<part18/sect_F.2.2.html>`.\n239 \n240         Parameters\n241         ----------\n242         value : dict\n243             The person name components in the JSON entry.\n244 \n245         Returns\n246         -------\n247         PersonName or str\n248             The decoded PersonName object or an empty string.\n249         \"\"\"\n250         if not isinstance(value, dict):\n251             # Some DICOMweb services get this wrong, so we\n252             # workaround the issue and warn the user\n253             # rather than raising an error.\n254             warnings.warn(\n255                 'value of data element \"{}\" with VR Person Name (PN) '\n256                 'is not formatted correctly'.format(self.tag)\n257             )\n258             return value\n259         else:\n260             if 'Phonetic' in value:\n261                 comps = ['', '', '']\n262             elif 'Ideographic' in value:\n263                 comps = ['', '']\n264             else:\n265                 comps = ['']\n266             if 'Alphabetic' in value:\n267                 comps[0] = value['Alphabetic']\n268             if 'Ideographic' in value:\n269                 comps[1] = value['Ideographic']\n270             if 'Phonetic' in value:\n271                 comps[2] = value['Phonetic']\n272             elem_value = '='.join(comps)\n273             return elem_value\n274 \n[end of pydicom/jsonrep.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "49a3da4a3d9c24d7e8427a25048a1c7d5c4f7724", "problem_statement": "from_json does not correctly convert BulkDataURI's in SQ data elements\n**Describe the bug**\r\nWhen a DICOM object contains large data elements in SQ elements and is converted to JSON, those elements are correctly turned into BulkDataURI's. However, when the JSON is converted back to DICOM using from_json, the BulkDataURI's in SQ data elements are not converted back and warnings are thrown.\r\n\r\n**Expected behavior**\r\nThe BulkDataURI's in SQ data elements get converted back correctly.\r\n\r\n**Steps To Reproduce**\r\nTake the `waveform_ecg.dcm` in the test data, convert it to JSON, and then convert the JSON to DICOM\r\n\r\n**Your environment**\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.7-x86_64-i386-64bit\r\nPython       | 3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18)  [Clang 6.0 (clang-600.0.57)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | _module not found_\r\nPIL          | _module not found_\r\n\r\nThe problem is in `jsonrep.py` at line 227. I plan on submitting a pull-request today for this.\n", "hints_text": "", "created_at": "2020-11-04T21:13:33Z", "patch": "<patch>\ndiff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ def get_sequence_item(self, value):\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_json.py b/pydicom/tests/test_json.py\n--- a/pydicom/tests/test_json.py\n+++ b/pydicom/tests/test_json.py\n@@ -354,3 +354,25 @@ def bulk_data_reader(tag, vr, value):\n         ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n \n         assert b'xyzzy' == ds[0x00091002].value\n+\n+    def test_bulk_data_reader_is_called_within_SQ(self):\n+        def bulk_data_reader(_):\n+            return b'xyzzy'\n+\n+        json_data = {\n+            \"003a0200\": {\n+                \"vr\": \"SQ\", \n+                \"Value\": [\n+                    {\n+                        \"54001010\": {\n+                            \"vr\": \"OW\",\n+                            \"BulkDataURI\": \"https://a.dummy.url\"\n+                        }\n+                    }\n+                ]\n+            }\n+        }\n+\n+        ds = Dataset().from_json(json.dumps(json_data), bulk_data_reader)\n+\n+        assert b'xyzzy' == ds[0x003a0200].value[0][0x54001010].value\n", "version": "2.1", "FAIL_TO_PASS": "[\"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_within_SQ\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_json.py::TestPersonName::test_json_pn_from_file\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_pn_components_from_json\", \"pydicom/tests/test_json.py::TestPersonName::test_empty_value\", \"pydicom/tests/test_json.py::TestPersonName::test_multi_value_to_json\", \"pydicom/tests/test_json.py::TestPersonName::test_dataelem_from_json\", \"pydicom/tests/test_json.py::TestAT::test_to_json\", \"pydicom/tests/test_json.py::TestAT::test_from_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_value_in_json\", \"pydicom/tests/test_json.py::TestAT::test_invalid_tag_in_json\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_json_from_dicom_file\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_roundtrip\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataset_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_dataelement_dumphandler\", \"pydicom/tests/test_json.py::TestDataSetToJson::test_sort_order\", \"pydicom/tests/test_json.py::TestSequence::test_nested_sequences\", \"pydicom/tests/test_json.py::TestBinary::test_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_inline_binary\", \"pydicom/tests/test_json.py::TestBinary::test_valid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_invalid_bulkdata_uri\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called\", \"pydicom/tests/test_json.py::TestBinary::test_bulk_data_reader_is_called_2\"]", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}
{"instance_id": "pydicom__pydicom-1375_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nPickling/unpickling timezone in DT does not work\n**Describe the bug**\r\n\r\nThe following tests fail because the timezone is not set in the unpickled `DT`:\r\n```py\r\n    def test_pickling_with_timezone():\r\n        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n\r\n    def test_pickling_dt_from_datetime_with_timezone():\r\n        tz_info = timezone(timedelta(seconds=-23400), '-0630')\r\n        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\r\n        dt = pydicom.valuerep.DT(dt_object)\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n```\r\n\r\nThis is a spin-off of PR #1365, see [this comment](https://github.com/pydicom/pydicom/pull/1365#issuecomment-829544827).\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of examples/input_output/plot_write_dicom.py]\n1 \"\"\"\n2 ================\n3 Write DICOM data\n4 ================\n5 \n6 This example shows how to write a DICOM file from scratch using pydicom. This\n7 example does not produce a DICOM standards compliant file as written, you will\n8 have to change UIDs to valid values and add all required DICOM data elements.\n9 \n10 \"\"\"\n11 \n12 # authors : Guillaume Lemaitre <g.lemaitre58@gmail.com>\n13 # license : MIT\n14 \n15 import os\n16 import tempfile\n17 import datetime\n18 \n19 import pydicom\n20 from pydicom.dataset import Dataset, FileDataset, FileMetaDataset\n21 \n22 # Create some temporary filenames\n23 suffix = '.dcm'\n24 filename_little_endian = tempfile.NamedTemporaryFile(suffix=suffix).name\n25 filename_big_endian = tempfile.NamedTemporaryFile(suffix=suffix).name\n26 \n27 print(\"Setting file meta information...\")\n28 # Populate required values for file meta information\n29 file_meta = FileMetaDataset()\n30 file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.2'\n31 file_meta.MediaStorageSOPInstanceUID = \"1.2.3\"\n32 file_meta.ImplementationClassUID = \"1.2.3.4\"\n33 \n34 print(\"Setting dataset values...\")\n35 # Create the FileDataset instance (initially no data elements, but file_meta\n36 # supplied)\n37 ds = FileDataset(filename_little_endian, {},\n38                  file_meta=file_meta, preamble=b\"\\0\" * 128)\n39 \n40 # Add the data elements -- not trying to set all required here. Check DICOM\n41 # standard\n42 ds.PatientName = \"Test^Firstname\"\n43 ds.PatientID = \"123456\"\n44 \n45 # Set the transfer syntax\n46 ds.is_little_endian = True\n47 ds.is_implicit_VR = True\n48 \n49 # Set creation date/time\n50 dt = datetime.datetime.now()\n51 ds.ContentDate = dt.strftime('%Y%m%d')\n52 timeStr = dt.strftime('%H%M%S.%f')  # long format with micro seconds\n53 ds.ContentTime = timeStr\n54 \n55 print(\"Writing test file\", filename_little_endian)\n56 ds.save_as(filename_little_endian)\n57 print(\"File saved.\")\n58 \n59 # Write as a different transfer syntax XXX shouldn't need this but pydicom\n60 # 0.9.5 bug not recognizing transfer syntax\n61 ds.file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRBigEndian\n62 ds.is_little_endian = False\n63 ds.is_implicit_VR = False\n64 \n65 print(\"Writing test file as Big Endian Explicit VR\", filename_big_endian)\n66 ds.save_as(filename_big_endian)\n67 \n68 # reopen the data just for checking\n69 for filename in (filename_little_endian, filename_big_endian):\n70     print('Load file {} ...'.format(filename))\n71     ds = pydicom.dcmread(filename)\n72     print(ds)\n73 \n74     # remove the created file\n75     print('Remove file {} ...'.format(filename))\n76     os.remove(filename)\n77 \n[end of examples/input_output/plot_write_dicom.py]\n[start of pydicom/benchmarks/bench_handler_rle_decode.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Decoding benchmarks for the rle_handler module.\"\"\"\n3 \n4 from pydicom import dcmread\n5 from pydicom.data import get_testdata_file\n6 from pydicom.encaps import decode_data_sequence\n7 from pydicom.pixel_data_handlers.rle_handler import (\n8     get_pixeldata,\n9     _rle_decode_frame,\n10 )\n11 \n12 \n13 # 8/8-bit, 1 sample/pixel, 1 frame\n14 OB_RLE_1F = get_testdata_file(\"OBXXXX1A_rle.dcm\")\n15 # 8/8-bit, 1 sample/pixel, 2 frame\n16 OB_RLE_2F = get_testdata_file(\"OBXXXX1A_rle_2frame.dcm\")\n17 # 8/8-bit, 3 sample/pixel, 1 frame\n18 SC_RLE_1F = get_testdata_file(\"SC_rgb_rle.dcm\")\n19 # 8/8-bit, 3 sample/pixel, 2 frame\n20 SC_RLE_2F = get_testdata_file(\"SC_rgb_rle_2frame.dcm\")\n21 # 16/16-bit, 1 sample/pixel, 1 frame\n22 MR_RLE_1F = get_testdata_file(\"MR_small_RLE.dcm\")\n23 # 16/16-bit, 3 sample/pixel, 1 frame\n24 SC_RLE_16_1F = get_testdata_file(\"SC_rgb_rle_16bit.dcm\")\n25 # 16/16-bit, 3 sample/pixel, 2 frame\n26 SC_RLE_16_2F = get_testdata_file(\"SC_rgb_rle_16bit_2frame.dcm\")\n27 # 16/12-bit, 1 sample/pixel, 10 frame\n28 EMRI_RLE_10F = get_testdata_file(\"emri_small_RLE.dcm\")\n29 # 32/32-bit, 1 sample/pixel, 1 frame\n30 RTDOSE_RLE_1F = get_testdata_file(\"rtdose_rle_1frame.dcm\")\n31 # 32/32-bit, 3 sample/pixel, 1 frame\n32 SC_RLE_32_1F = get_testdata_file(\"SC_rgb_rle_32bit.dcm\")\n33 # 32/32-bit, 3 sample/pixel, 2 frame\n34 SC_RLE_32_2F = get_testdata_file(\"SC_rgb_rle_32bit_2frame.dcm\")\n35 # 32/32-bit, 1 sample/pixel, 15 frame\n36 RTDOSE_RLE_15F = get_testdata_file(\"rtdose_rle.dcm\")\n37 \n38 \n39 class TimeRLEDecodeFrame:\n40     \"\"\"Time tests for rle_handler._rle_decode_frame.\"\"\"\n41     def setup(self):\n42         # MONOCHROME2, 64x64, 1 sample/pixel, 16 bits allocated, 12 bits stored\n43         self.ds = dcmread(EMRI_RLE_10F)\n44         self.frames = decode_data_sequence(self.ds.PixelData)\n45         assert len(self.frames) == 10\n46 \n47         self.no_runs = 100\n48 \n49     def time_decode_16bit_1sample_1frame(self):\n50         \"\"\"Time decoding the pixel data from a single RLE frame.\"\"\"\n51         for ii in range(self.no_runs):\n52             _rle_decode_frame(self.frames[0],\n53                               self.ds.Rows,\n54                               self.ds.Columns,\n55                               self.ds.SamplesPerPixel,\n56                               self.ds.BitsAllocated)\n57 \n58     def time_decode_16bit_1sample_10frame(self):\n59         \"\"\"Time decoding the pixel data from 10 RLE frames.\"\"\"\n60         for ii in range(self.no_runs):\n61             for frame in self.frames:\n62                 _rle_decode_frame(frame,\n63                                   self.ds.Rows,\n64                                   self.ds.Columns,\n65                                   self.ds.SamplesPerPixel,\n66                                   self.ds.BitsAllocated)\n67 \n68 \n69 class TimeGetPixelData:\n70     \"\"\"Time tests for rle_handler.get_pixeldata.\"\"\"\n71     def setup(self):\n72         \"\"\"Setup the test\"\"\"\n73         self.ds_8_1_1 = dcmread(OB_RLE_1F)\n74         self.ds_8_3_1 = dcmread(SC_RLE_1F)\n75         self.ds_16_1_1 = dcmread(MR_RLE_1F)\n76         self.ds_16_3_1 = dcmread(SC_RLE_16_1F)\n77         self.ds_32_1_1 = dcmread(RTDOSE_RLE_1F)\n78         self.ds_32_3_1 = dcmread(SC_RLE_32_1F)\n79 \n80         self.no_runs = 100\n81 \n82     def time_08bit_1sample(self):\n83         \"\"\"Time retrieval of 8-bit, 1 sample/pixel RLE data.\"\"\"\n84         for ii in range(self.no_runs):\n85             get_pixeldata(self.ds_8_1_1)\n86 \n87     def time_08bit_3sample(self):\n88         \"\"\"Time retrieval of 8-bit, 3 sample/pixel RLE data.\"\"\"\n89         for ii in range(self.no_runs):\n90             get_pixeldata(self.ds_8_3_1)\n91 \n92     def time_16bit_1sample(self):\n93         \"\"\"Time retrieval of 16-bit, 1 sample/pixel RLE data.\"\"\"\n94         for ii in range(self.no_runs):\n95             get_pixeldata(self.ds_16_1_1)\n96 \n97     def time_16bit_3sample(self):\n98         \"\"\"Time retrieval of 16-bit, 3 sample/pixel RLE data.\"\"\"\n99         for ii in range(self.no_runs):\n100             get_pixeldata(self.ds_16_3_1)\n101 \n102     def time_32bit_1sample(self):\n103         \"\"\"Time retrieval of 32-bit, 1 sample/pixel RLE data.\"\"\"\n104         for ii in range(self.no_runs):\n105             get_pixeldata(self.ds_32_1_1)\n106 \n107     def time_32bit_3sample(self):\n108         \"\"\"Time retrieval of 32-bit, 3 sample/pixel RLE data.\"\"\"\n109         for ii in range(self.no_runs):\n110             get_pixeldata(self.ds_32_3_1)\n111 \n[end of pydicom/benchmarks/bench_handler_rle_decode.py]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 import base64\n11 import json\n12 from typing import (\n13     Optional, Any, Optional, Tuple, Callable, Union, TYPE_CHECKING, Dict,\n14     TypeVar, Type, List, NamedTuple\n15 )\n16 import warnings\n17 \n18 from pydicom import config  # don't import datetime_conversion directly\n19 from pydicom.config import logger\n20 from pydicom import config\n21 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n22                               dictionary_keyword, dictionary_is_retired,\n23                               private_dictionary_description, dictionary_VR,\n24                               repeater_has_tag, private_dictionary_VR)\n25 from pydicom.errors import BytesLengthException\n26 from pydicom.jsonrep import JsonDataElementConverter\n27 from pydicom.multival import MultiValue\n28 from pydicom.tag import Tag, BaseTag\n29 from pydicom.uid import UID\n30 from pydicom import jsonrep\n31 import pydicom.valuerep  # don't import DS directly as can be changed by config\n32 from pydicom.valuerep import PersonName\n33 \n34 if config.have_numpy:\n35     import numpy\n36 \n37 if TYPE_CHECKING:\n38     from pydicom.dataset import Dataset\n39 \n40 \n41 BINARY_VR_VALUES = [\n42     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n43     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n44 ]\n45 \n46 \n47 def empty_value_for_VR(\n48     VR: str, raw: bool = False\n49 ) -> Union[bytes, List[str], str, None]:\n50     \"\"\"Return the value for an empty element for `VR`.\n51 \n52     .. versionadded:: 1.4\n53 \n54     The behavior of this property depends on the setting of\n55     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n56     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n57     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n58     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n59     empty string is used as empty value representation, for all other VRs\n60     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n61     is used in all cases.\n62     Note that this is used only if decoding the element - it is always\n63     possible to set the value to another empty value representation,\n64     which will be preserved during the element object lifetime.\n65 \n66     Parameters\n67     ----------\n68     VR : str\n69         The VR of the corresponding element.\n70     raw : bool, optional\n71         If ``True``, returns the value for a :class:`RawDataElement`,\n72         otherwise for a :class:`DataElement`\n73 \n74     Returns\n75     -------\n76     str or bytes or None or list\n77         The value a data element with `VR` is assigned on decoding\n78         if it is empty.\n79     \"\"\"\n80     if VR == 'SQ':\n81         return b'' if raw else []\n82 \n83     if config.use_none_as_empty_text_VR_value:\n84         return None\n85 \n86     if VR == 'PN':\n87         return b'' if raw else PersonName('')\n88 \n89     if VR in (\n90         'AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT', 'SH', 'ST', 'TM',\n91         'UC', 'UI', 'UR', 'UT'\n92     ):\n93         return b'' if raw else ''\n94 \n95     return None\n96 \n97 \n98 def _is_bytes(val: object) -> bool:\n99     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n100     return isinstance(val, bytes)\n101 \n102 \n103 # double '\\' because it is used as escape chr in Python\n104 _backslash_str = \"\\\\\"\n105 _backslash_byte = b\"\\\\\"\n106 \n107 \n108 _DataElement = TypeVar(\"_DataElement\", bound=\"DataElement\")\n109 _Dataset = TypeVar(\"_Dataset\", bound=\"Dataset\")\n110 \n111 \n112 class DataElement:\n113     \"\"\"Contain and manipulate a DICOM Element.\n114 \n115     Examples\n116     --------\n117 \n118     While its possible to create a new :class:`DataElement` directly and add\n119     it to a :class:`~pydicom.dataset.Dataset`:\n120 \n121     >>> from pydicom import Dataset\n122     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n123     >>> ds = Dataset()\n124     >>> ds.add(elem)\n125 \n126     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n127     to add a new :class:`DataElement`, as the VR and tag are determined\n128     automatically from the DICOM dictionary:\n129 \n130     >>> ds = Dataset()\n131     >>> ds.PatientName = 'CITIZEN^Joan'\n132 \n133     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n134     value for text VRs and `None` for non-text (binary) VRs:\n135 \n136     >>> ds = Dataset()\n137     >>> ds.PatientName = None\n138     >>> ds.PatientName\n139     ''\n140 \n141     >>> ds.BitsAllocated = None\n142     >>> ds.BitsAllocated\n143 \n144     >>> str(ds.BitsAllocated)\n145     'None'\n146 \n147     Attributes\n148     ----------\n149     descripWidth : int\n150         For string display, this is the maximum width of the description\n151         field (default ``35``).\n152     is_undefined_length : bool\n153         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n154         (ie undefined).\n155     maxBytesToDisplay : int\n156         For string display, elements with values containing data which is\n157         longer than this value will display ``\"array of # bytes\"``\n158         (default ``16``).\n159     showVR : bool\n160         For string display, include the element's VR just before it's value\n161         (default ``True``).\n162     tag : pydicom.tag.BaseTag\n163         The element's tag.\n164     VR : str\n165         The element's Value Representation.\n166     \"\"\"\n167 \n168     descripWidth = 35\n169     maxBytesToDisplay = 16\n170     showVR = True\n171     is_raw = False\n172 \n173     def __init__(\n174         self,\n175         tag: Union[int, str, Tuple[int, int]],\n176         VR: str,\n177         value: object,\n178         file_value_tell: Optional[int] = None,\n179         is_undefined_length: bool = False,\n180         already_converted: bool = False\n181     ) -> None:\n182         \"\"\"Create a new :class:`DataElement`.\n183 \n184         Parameters\n185         ----------\n186         tag : int or str or 2-tuple of int\n187             The DICOM (group, element) tag in any form accepted by\n188             :func:`~pydicom.tag.Tag` such as ``'PatientName'``,\n189             ``(0x10, 0x10)``, ``0x00100010``, etc.\n190         VR : str\n191             The 2 character DICOM value representation (see DICOM Standard,\n192             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n193         value\n194             The value of the data element. One of the following:\n195 \n196             * a single string value\n197             * a number\n198             * a :class:`list` or :class:`tuple` with all strings or all numbers\n199             * a multi-value string with backslash separator\n200         file_value_tell : int, optional\n201             The byte offset to the start of the encoded element value.\n202         is_undefined_length : bool\n203             Used internally to store whether the length field for this element\n204             was ``0xFFFFFFFF``, i.e. 'undefined length'. Default is ``False``.\n205         already_converted : bool\n206             Used to determine whether or not the element's value requires\n207             conversion to a value with VM > 1. Default is ``False``.\n208         \"\"\"\n209         if not isinstance(tag, BaseTag):\n210             tag = Tag(tag)\n211         self.tag = tag\n212 \n213         # a known tag shall only have the VR 'UN' if it has a length that\n214         # exceeds the size that can be encoded in 16 bit - all other cases\n215         # can be seen as an encoding error and can be corrected\n216         if (\n217             VR == 'UN'\n218             and not tag.is_private\n219             and config.replace_un_with_known_vr\n220             and (is_undefined_length or value is None or len(value) < 0xffff)\n221         ):\n222             try:\n223                 VR = dictionary_VR(tag)\n224             except KeyError:\n225                 pass\n226 \n227         self.VR = VR  # Note: you must set VR before setting value\n228         if already_converted:\n229             self._value = value\n230         else:\n231             self.value = value  # calls property setter which will convert\n232         self.file_tell = file_value_tell\n233         self.is_undefined_length = is_undefined_length\n234         self.private_creator: Optional[str] = None\n235         self.parent: Optional[\"Dataset\"] = None\n236 \n237     @classmethod\n238     def from_json(\n239         cls: Type[_DataElement],\n240         dataset_class: Type[_Dataset],\n241         tag: Union[BaseTag, int],\n242         vr: str,\n243         value: object,\n244         value_key: Union[str, None],\n245         bulk_data_uri_handler: Optional[\n246             Union[\n247                 Callable[[BaseTag, str, str], object],\n248                 Callable[[str], object]\n249             ]\n250         ] = None\n251     ) -> _DataElement:\n252         \"\"\"Return a :class:`DataElement` from JSON.\n253 \n254         .. versionadded:: 1.3\n255 \n256         Parameters\n257         ----------\n258         dataset_class : dataset.Dataset derived class\n259             Class used to create sequence items.\n260         tag : pydicom.tag.BaseTag or int\n261             The data element tag.\n262         vr : str\n263             The data element value representation.\n264         value : list\n265             The data element's value(s).\n266         value_key : str or None\n267             Key of the data element that contains the value\n268             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n269         bulk_data_uri_handler: callable or None\n270             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n271             or just the \"BulkDataURI\" of the JSON\n272             representation of a data element and returns the actual value of\n273             that data element (retrieved via DICOMweb WADO-RS)\n274 \n275         Returns\n276         -------\n277         DataElement\n278         \"\"\"\n279         # TODO: test wado-rs retrieve wrapper\n280         converter = JsonDataElementConverter(\n281             dataset_class, tag, vr, value, value_key, bulk_data_uri_handler\n282         )\n283         elem_value = converter.get_element_values()\n284         try:\n285             return cls(tag=tag, value=elem_value, VR=vr)\n286         except Exception as exc:\n287             raise ValueError(\n288                 f\"Data element '{tag}' could not be loaded from JSON: \"\n289                 f\"{elem_value}\"\n290             ) from exc\n291 \n292     def to_json_dict(\n293         self,\n294         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]],\n295         bulk_data_threshold: int\n296     ) -> Dict[str, object]:\n297         \"\"\"Return a dictionary representation of the :class:`DataElement`\n298         conforming to the DICOM JSON Model as described in the DICOM\n299         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n300 \n301         .. versionadded:: 1.4\n302 \n303         Parameters\n304         ----------\n305         bulk_data_element_handler: callable or None\n306             Callable that accepts a bulk data element and returns the\n307             \"BulkDataURI\" for retrieving the value of the data element\n308             via DICOMweb WADO-RS\n309         bulk_data_threshold: int\n310             Size of base64 encoded data element above which a value will be\n311             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n312             Ignored if no bulk data handler is given.\n313 \n314         Returns\n315         -------\n316         dict\n317             Mapping representing a JSON encoded data element\n318         \"\"\"\n319         json_element = {'vr': self.VR, }\n320         if self.VR in jsonrep.BINARY_VR_VALUES:\n321             if not self.is_empty:\n322                 binary_value = self.value\n323                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n324                 if (\n325                     bulk_data_element_handler is not None\n326                     and len(encoded_value) > bulk_data_threshold\n327                 ):\n328                     json_element['BulkDataURI'] = (\n329                         bulk_data_element_handler(self)\n330                     )\n331                 else:\n332                     logger.info(\n333                         f\"encode bulk data element '{self.name}' inline\"\n334                     )\n335                     json_element['InlineBinary'] = encoded_value\n336         elif self.VR == 'SQ':\n337             # recursive call to get sequence item JSON dicts\n338             value = [\n339                 ds.to_json(\n340                     bulk_data_element_handler=bulk_data_element_handler,\n341                     bulk_data_threshold=bulk_data_threshold,\n342                     dump_handler=lambda d: d\n343                 )\n344                 for ds in self.value\n345             ]\n346             json_element['Value'] = value\n347         elif self.VR == 'PN':\n348             if not self.is_empty:\n349                 elem_value = []\n350                 if self.VM > 1:\n351                     value = self.value\n352                 else:\n353                     value = [self.value]\n354                 for v in value:\n355                     comps = {'Alphabetic': v.components[0]}\n356                     if len(v.components) > 1:\n357                         comps['Ideographic'] = v.components[1]\n358                     if len(v.components) > 2:\n359                         comps['Phonetic'] = v.components[2]\n360                     elem_value.append(comps)\n361                 json_element['Value'] = elem_value\n362         elif self.VR == 'AT':\n363             if not self.is_empty:\n364                 value = self.value\n365                 if self.VM == 1:\n366                     value = [value]\n367                 json_element['Value'] = [format(v, '08X') for v in value]\n368         else:\n369             if not self.is_empty:\n370                 if self.VM > 1:\n371                     value = self.value\n372                 else:\n373                     value = [self.value]\n374                 json_element['Value'] = [v for v in value]\n375         if 'Value' in json_element:\n376             json_element['Value'] = jsonrep.convert_to_python_number(\n377                 json_element['Value'], self.VR\n378             )\n379         return json_element\n380 \n381     def to_json(\n382         self,\n383         bulk_data_threshold: int = 1024,\n384         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]] = None,  # noqa\n385         dump_handler: Optional[Callable[[Dict[object, object]], str]] = None\n386     ) -> Dict[str, object]:\n387         \"\"\"Return a JSON representation of the :class:`DataElement`.\n388 \n389         .. versionadded:: 1.3\n390 \n391         Parameters\n392         ----------\n393         bulk_data_element_handler: callable, optional\n394             Callable that accepts a bulk data element and returns the\n395             \"BulkDataURI\" for retrieving the value of the data element\n396             via DICOMweb WADO-RS\n397         bulk_data_threshold: int, optional\n398             Size of base64 encoded data element above which a value will be\n399             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n400             Ignored if no bulk data handler is given.\n401         dump_handler : callable, optional\n402             Callable function that accepts a :class:`dict` and returns the\n403             serialized (dumped) JSON string (by default uses\n404             :func:`json.dumps`).\n405 \n406         Returns\n407         -------\n408         dict\n409             Mapping representing a JSON encoded data element\n410 \n411         See also\n412         --------\n413         Dataset.to_json\n414         \"\"\"\n415         if dump_handler is None:\n416             def json_dump(d):\n417                 return json.dumps(d, sort_keys=True)\n418 \n419             dump_handler = json_dump\n420 \n421         return dump_handler(\n422             self.to_json_dict(bulk_data_element_handler, bulk_data_threshold)\n423         )\n424 \n425     @property\n426     def value(self) -> object:\n427         \"\"\"Return the element's value.\"\"\"\n428         return self._value\n429 \n430     @value.setter\n431     def value(self, val: object) -> None:\n432         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n433         # Check if is a string with multiple values separated by '\\'\n434         # If so, turn them into a list of separate strings\n435         #  Last condition covers 'US or SS' etc\n436         if isinstance(val, (str, bytes)) and self.VR not in \\\n437                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n438                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n439                  'OW or OB', 'UN'] and 'US' not in self.VR:\n440             try:\n441                 if _backslash_str in val:\n442                     val = val.split(_backslash_str)\n443             except TypeError:\n444                 if _backslash_byte in val:\n445                     val = val.split(_backslash_byte)\n446         self._value = self._convert_value(val)\n447 \n448     @property\n449     def VM(self) -> int:\n450         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n451         if self.value is None:\n452             return 0\n453         if isinstance(self.value, (str, bytes, PersonName)):\n454             return 1 if self.value else 0\n455         try:\n456             iter(self.value)\n457         except TypeError:\n458             return 1\n459         return len(self.value)\n460 \n461     @property\n462     def is_empty(self) -> bool:\n463         \"\"\"Return ``True`` if the element has no value.\n464 \n465         .. versionadded:: 1.4\n466         \"\"\"\n467         return self.VM == 0\n468 \n469     @property\n470     def empty_value(self) -> Union[bytes, List[str], None, str]:\n471         \"\"\"Return the value for an empty element.\n472 \n473         .. versionadded:: 1.4\n474 \n475         See :func:`empty_value_for_VR` for more information.\n476 \n477         Returns\n478         -------\n479         str or None\n480             The value this data element is assigned on decoding if it is empty.\n481         \"\"\"\n482         return empty_value_for_VR(self.VR)\n483 \n484     def clear(self) -> None:\n485         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n486 \n487         .. versionadded:: 1.4\n488 \n489         See :func:`empty_value_for_VR`.\n490         \"\"\"\n491         self._value = self.empty_value\n492 \n493     def _convert_value(self, val: object) -> object:\n494         \"\"\"Convert `val` to an appropriate type and return the result.\n495 \n496         Uses the element's VR in order to determine the conversion method and\n497         resulting type.\n498         \"\"\"\n499         if self.VR == 'SQ':  # a sequence - leave it alone\n500             from pydicom.sequence import Sequence\n501             if isinstance(val, Sequence):\n502                 return val\n503             else:\n504                 return Sequence(val)\n505 \n506         # if the value is a list, convert each element\n507         try:\n508             val.append\n509         except AttributeError:  # not a list\n510             return self._convert(val)\n511         else:\n512             return MultiValue(self._convert, val)\n513 \n514     def _convert(self, val: object) -> object:\n515         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n516         # If the value is a byte string and has a VR that can only be encoded\n517         # using the default character repertoire, we convert it to a string\n518         # here to allow for byte string input in these cases\n519         if _is_bytes(val) and self.VR in (\n520                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n521             val = val.decode()\n522 \n523         if self.VR == 'IS':\n524             return pydicom.valuerep.IS(val)\n525         elif self.VR == 'DA' and config.datetime_conversion:\n526             return pydicom.valuerep.DA(val)\n527         elif self.VR == 'DS':\n528             return pydicom.valuerep.DS(val)\n529         elif self.VR == 'DT' and config.datetime_conversion:\n530             return pydicom.valuerep.DT(val)\n531         elif self.VR == 'TM' and config.datetime_conversion:\n532             return pydicom.valuerep.TM(val)\n533         elif self.VR == \"UI\":\n534             return UID(val) if val is not None else None\n535         elif self.VR == \"PN\":\n536             return PersonName(val)\n537         elif self.VR == \"AT\" and (val == 0 or val):\n538             return val if isinstance(val, BaseTag) else Tag(val)\n539         # Later may need this for PersonName as for UI,\n540         #    but needs more thought\n541         # elif self.VR == \"PN\":\n542         #    return PersonName(val)\n543         else:  # is either a string or a type 2 optionally blank string\n544             return val  # this means a \"numeric\" value could be empty string \"\"\n545         # except TypeError:\n546             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n547             # % (repr(val), self.VR, self.tag)\n548         # except ValueError:\n549             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n550             # % (repr(val), self.VR, self.tag)\n551 \n552     def __eq__(self, other: object) -> bool:\n553         \"\"\"Compare `self` and `other` for equality.\n554 \n555         Returns\n556         -------\n557         bool\n558             The result if `self` and `other` are the same class\n559         NotImplemented\n560             If `other` is not the same class as `self` then returning\n561             :class:`NotImplemented` delegates the result to\n562             ``superclass.__eq__(subclass)``.\n563         \"\"\"\n564         # Faster result if same object\n565         if other is self:\n566             return True\n567 \n568         if isinstance(other, self.__class__):\n569             if self.tag != other.tag or self.VR != other.VR:\n570                 return False\n571 \n572             # tag and VR match, now check the value\n573             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n574                 return (len(self.value) == len(other.value)\n575                         and numpy.allclose(self.value, other.value))\n576             else:\n577                 return self.value == other.value\n578 \n579         return NotImplemented\n580 \n581     def __ne__(self, other: object) -> bool:\n582         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n583         return not (self == other)\n584 \n585     def __str__(self) -> str:\n586         \"\"\"Return :class:`str` representation of the element.\"\"\"\n587         repVal = self.repval or ''\n588         if self.showVR:\n589             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n590                                     self.description()[:self.descripWidth],\n591                                     self.VR, repVal)\n592         else:\n593             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n594                                 self.description()[:self.descripWidth], repVal)\n595         return s\n596 \n597     @property\n598     def repval(self) -> str:\n599         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n600         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n601         if set(self.VR.split(\" or \")) & long_VRs:\n602             try:\n603                 length = len(self.value)\n604             except TypeError:\n605                 pass\n606             else:\n607                 if length > self.maxBytesToDisplay:\n608                     return \"Array of %d elements\" % length\n609         if self.VM > self.maxBytesToDisplay:\n610             repVal = \"Array of %d elements\" % self.VM\n611         elif isinstance(self.value, UID):\n612             repVal = self.value.name\n613         else:\n614             repVal = repr(self.value)  # will tolerate unicode too\n615         return repVal\n616 \n617     def __getitem__(self, key: int) -> object:\n618         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n619         try:\n620             return self.value[key]\n621         except TypeError:\n622             raise TypeError(\"DataElement value is unscriptable \"\n623                             \"(not a Sequence)\")\n624 \n625     @property\n626     def name(self) -> str:\n627         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n628 \n629         For officially registered DICOM Data Elements this will be the *Name*\n630         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n631         For private elements known to *pydicom*\n632         this will be the *Name* in the format ``'[name]'``. For unknown\n633         private elements this will be ``'Private Creator'``. For unknown\n634         elements this will return an empty string ``''``.\n635         \"\"\"\n636         return self.description()\n637 \n638     def description(self) -> str:\n639         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n640         if self.tag.is_private:\n641             name = \"Private tag data\"  # default\n642             if self.private_creator:\n643                 try:\n644                     # If have name from private dictionary, use it, but\n645                     #   but put in square brackets so is differentiated,\n646                     #   and clear that cannot access it by name\n647                     name = private_dictionary_description(\n648                         self.tag, self.private_creator)\n649                     name = \"[%s]\" % (name)\n650                 except KeyError:\n651                     pass\n652             elif self.tag.element >> 8 == 0:\n653                 name = \"Private Creator\"\n654         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n655             name = dictionary_description(self.tag)\n656 \n657         # implied Group Length dicom versions < 3\n658         elif self.tag.element == 0:\n659             name = \"Group Length\"\n660         else:\n661             name = \"\"\n662         return name\n663 \n664     @property\n665     def is_private(self) -> bool:\n666         \"\"\"Return ``True`` if the element's tag is private.\n667 \n668         .. versionadded:: 2.1\n669         \"\"\"\n670         return self.tag.is_private\n671 \n672     @property\n673     def is_retired(self) -> bool:\n674         \"\"\"Return the element's retired status as :class:`bool`.\n675 \n676         For officially registered DICOM Data Elements this will be ``True`` if\n677         the retired status as given in the DICOM Standard, Part 6,\n678         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n679         or unknown elements this will always be ``False``.\n680         \"\"\"\n681         if dictionary_has_tag(self.tag):\n682             return dictionary_is_retired(self.tag)\n683 \n684         return False\n685 \n686     @property\n687     def keyword(self) -> str:\n688         \"\"\"Return the element's keyword (if known) as :class:`str`.\n689 \n690         For officially registered DICOM Data Elements this will be the\n691         *Keyword* as given in\n692         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n693         unknown elements this will return an empty string ``''``.\n694         \"\"\"\n695         if dictionary_has_tag(self.tag):\n696             return dictionary_keyword(self.tag)\n697 \n698         return ''\n699 \n700     def __repr__(self) -> str:\n701         \"\"\"Return the representation of the element.\"\"\"\n702         if self.VR == \"SQ\":\n703             return repr(self.value)\n704 \n705         return str(self)\n706 \n707 \n708 class RawDataElement(NamedTuple):\n709     \"\"\"Container for the data from a raw (mostly) undecoded element.\"\"\"\n710     tag: BaseTag\n711     VR: Optional[str]\n712     length: int\n713     value: bytes\n714     value_tell: int\n715     is_implicit_VR: bool\n716     is_little_endian: bool\n717     is_raw: bool = True\n718 \n719 \n720 # The first and third values of the following elements are always US\n721 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n722 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n723 # (0028,3002) LUT Descriptor\n724 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n725 \n726 \n727 def _private_vr_for_tag(ds: Optional[\"Dataset\"], tag: BaseTag) -> str:\n728     \"\"\"Return the VR for a known private tag, otherwise \"UN\".\n729 \n730     Parameters\n731     ----------\n732     ds : Dataset, optional\n733         The dataset needed for the private creator lookup.\n734         If not given, \"UN\" is returned.\n735     tag : BaseTag\n736         The private tag to lookup. The caller has to ensure that the\n737         tag is private.\n738 \n739     Returns\n740     -------\n741     str\n742         \"LO\" if the tag is a private creator, the VR of the private tag if\n743         found in the private dictionary, or \"UN\".\n744     \"\"\"\n745     if tag.is_private_creator:\n746         return \"LO\"\n747     # invalid private tags are handled as UN\n748     if ds is not None and (tag.element & 0xff00):\n749         private_creator_tag = tag.group << 16 | (tag.element >> 8)\n750         private_creator = ds.get(private_creator_tag, \"\")\n751         if private_creator:\n752             try:\n753                 return private_dictionary_VR(tag, private_creator.value)\n754             except KeyError:\n755                 pass\n756     return \"UN\"\n757 \n758 \n759 def DataElement_from_raw(\n760     raw_data_element: RawDataElement,\n761         encoding: Optional[List[str]] = None,\n762         dataset: Optional[\"Dataset\"] = None\n763 ) -> DataElement:\n764     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n765 \n766     Parameters\n767     ----------\n768     raw_data_element : RawDataElement\n769         The raw data to convert to a :class:`DataElement`.\n770     encoding : list of str, optional\n771         The character encoding of the raw data.\n772     dataset : Dataset, optional\n773         If given, used to resolve the VR for known private tags.\n774 \n775     Returns\n776     -------\n777     DataElement\n778 \n779     Raises\n780     ------\n781     KeyError\n782         If `raw_data_element` belongs to an unknown non-private tag and\n783         `config.enforce_valid_values` is set.\n784     \"\"\"\n785     # XXX buried here to avoid circular import\n786     # filereader->Dataset->convert_value->filereader\n787     # (for SQ parsing)\n788 \n789     from pydicom.values import convert_value\n790     raw = raw_data_element\n791 \n792     # If user has hooked into conversion of raw values, call his/her routine\n793     if config.data_element_callback:\n794         raw = config.data_element_callback(\n795             raw_data_element,\n796             encoding=encoding,\n797             **config.data_element_callback_kwargs\n798         )\n799 \n800     VR = raw.VR\n801     if VR is None:  # Can be if was implicit VR\n802         try:\n803             VR = dictionary_VR(raw.tag)\n804         except KeyError:\n805             # just read the bytes, no way to know what they mean\n806             if raw.tag.is_private:\n807                 # for VR for private tags see PS3.5, 6.2.2\n808                 VR = _private_vr_for_tag(dataset, raw.tag)\n809 \n810             # group length tag implied in versions < 3.0\n811             elif raw.tag.element == 0:\n812                 VR = 'UL'\n813             else:\n814                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n815                 if config.enforce_valid_values:\n816                     msg += \" can't look up VR\"\n817                     raise KeyError(msg)\n818                 else:\n819                     VR = 'UN'\n820                     msg += \" - setting VR to 'UN'\"\n821                     warnings.warn(msg)\n822     elif VR == 'UN' and config.replace_un_with_known_vr:\n823         # handle rare case of incorrectly set 'UN' in explicit encoding\n824         # see also DataElement.__init__()\n825         if raw.tag.is_private:\n826             VR = _private_vr_for_tag(dataset, raw.tag)\n827         elif raw.value is None or len(raw.value) < 0xffff:\n828             try:\n829                 VR = dictionary_VR(raw.tag)\n830             except KeyError:\n831                 pass\n832     try:\n833         value = convert_value(VR, raw, encoding)\n834     except NotImplementedError as e:\n835         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n836     except BytesLengthException as e:\n837         message = (f\"{e} This occurred while trying to parse \"\n838                    f\"{raw.tag} according to VR '{VR}'.\")\n839         if config.convert_wrong_length_to_UN:\n840             warnings.warn(f\"{message} Setting VR to 'UN'.\")\n841             VR = \"UN\"\n842             value = raw.value\n843         else:\n844             raise BytesLengthException(\n845                 f\"{message} To replace this error with a warning set \"\n846                 \"pydicom.config.convert_wrong_length_to_UN = True.\"\n847             )\n848 \n849     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n850         # We only fix the first value as the third value is 8 or 16\n851         try:\n852             if value[0] < 0:\n853                 value[0] += 65536\n854         except TypeError:\n855             pass\n856 \n857     return DataElement(raw.tag, VR, value, raw.value_tell,\n858                        raw.length == 0xFFFFFFFF, already_converted=True)\n859 \n[end of pydicom/dataelem.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "c14bf96040e4cc930db890638b9f190d4ede0a21", "problem_statement": "Pickling/unpickling timezone in DT does not work\n**Describe the bug**\r\n\r\nThe following tests fail because the timezone is not set in the unpickled `DT`:\r\n```py\r\n    def test_pickling_with_timezone():\r\n        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n\r\n    def test_pickling_dt_from_datetime_with_timezone():\r\n        tz_info = timezone(timedelta(seconds=-23400), '-0630')\r\n        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\r\n        dt = pydicom.valuerep.DT(dt_object)\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n```\r\n\r\nThis is a spin-off of PR #1365, see [this comment](https://github.com/pydicom/pydicom/pull/1365#issuecomment-829544827).\n", "hints_text": "", "created_at": "2021-05-03T18:27:35Z", "patch": "<patch>\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -2,23 +2,19 @@\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n \n import datetime\n-from decimal import Decimal\n-from math import floor, isfinite, log10\n-import platform\n import re\n import sys\n+import warnings\n+from decimal import Decimal\n+from math import floor, isfinite, log10\n+from typing import Sequence as SequenceType\n from typing import (\n-    TypeVar, Type, Tuple, Optional, List, Dict, Union, Any, Generator, AnyStr,\n-    Callable, Iterator, overload\n+    TypeVar, Type, Tuple, Optional, List, Dict, Union, Any, Generator, Callable\n )\n-from typing import Sequence as SequenceType\n-import warnings\n \n # don't import datetime_conversion directly\n from pydicom import config\n from pydicom.multival import MultiValue\n-from pydicom.uid import UID\n-\n \n # Types\n _T = TypeVar('_T')\n@@ -84,23 +80,23 @@ class DA(_DateTimeBase, datetime.date):\n \n     Note that the :class:`datetime.date` base class is immutable.\n     \"\"\"\n-    def __new__(\n-        cls: Type[_DA], val: Union[None, str, _DA, datetime.date]\n-    ) -> Optional[_DA]:\n+    def __new__(cls: Type[_DA], *args, **kwargs) -> Optional[_DA]:\n         \"\"\"Create an instance of DA object.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the DA definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.date`, or the first argument is\n+        a string conformant to the DA definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.date` object, or an object of type\n+        :class:`~pydicom.valuerep.DA`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None  # empty date\n@@ -123,14 +119,15 @@ def __new__(\n             return super().__new__(cls, val.year, val.month, val.day)\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'DA' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _DA, datetime.date]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n         \"\"\"Create a new **DA** element value.\"\"\"\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, DA) and hasattr(val, 'original_string'):\n@@ -171,23 +168,23 @@ def _utc_offset(value: str) -> datetime.timezone:\n             name=value\n         )\n \n-    def __new__(\n-        cls: Type[_DT], val: Union[None, str, _DT, datetime.datetime]\n-    ) -> Optional[_DT]:\n+    def __new__(cls: Type[_DT], *args, **kwargs) -> Optional[_DT]:\n         \"\"\"Create an instance of DT object.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the DT definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.datetime`, or the first argument is\n+        a string conformant to the DT definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.datetime` object, or an object of type\n+        :class:`~pydicom.valuerep.DT`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None\n@@ -233,13 +230,15 @@ def __new__(\n             )\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'DT' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _DT, datetime.datetime]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n+        \"\"\"Create a new **DT** element value.\"\"\"\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, DT) and hasattr(val, 'original_string'):\n@@ -274,23 +273,23 @@ class TM(_DateTimeBase, datetime.time):\n         r\"(?(7)(\\.(?P<ms>([0-9]{1,6})?))?))$\"\n     )\n \n-    def __new__(\n-        cls: Type[_TM], val: Union[None, str, _TM, datetime.time]\n-    ) -> Optional[_TM]:\n+    def __new__(cls: Type[_TM], *args, **kwargs) -> Optional[_TM]:\n         \"\"\"Create an instance of TM object from a string.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the TM definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.time`, or the first argument is\n+        a string conformant to the TM definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.time` object, or an object of type\n+        :class:`~pydicom.valuerep.TM`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None  # empty time\n@@ -325,13 +324,15 @@ def __new__(\n             )\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'TM' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _TM, datetime.time]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n+        super().__init__()\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, TM) and hasattr(val, 'original_string'):\n@@ -344,16 +345,6 @@ def __init__(self, val: Union[str, _TM, datetime.time]) -> None:\n             if val.microsecond > 0:\n                 self.original_string += f\".{val.microsecond:06}\"\n \n-    if platform.python_implementation() == \"PyPy\":\n-        # Workaround for CPython/PyPy bug in time.__reduce_ex__()\n-        #   caused by returning (time, ...) rather than (self.__class__, ...)\n-        def __reduce_ex__(self, protocol: int) -> Union[str, Tuple[Any, ...]]:\n-            return (\n-                self.__class__,\n-                super()._getstate(protocol),\n-                self.__getstate__()\n-            )\n-\n \n # Regex to match strings that represent valid DICOM decimal strings (DS)\n _DS_REGEX = re.compile(r'\\s*[\\+\\-]?\\d+(\\.\\d+)?([eE][\\+\\-]?\\d+)?\\s*$')\n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -5,10 +5,7 @@\n import copy\n from datetime import datetime, date, time, timedelta, timezone\n from decimal import Decimal\n-try:\n-    import cPickle as pickle\n-except ImportError:\n-    import pickle\n+import pickle\n import math\n import sys\n from typing import Union\n@@ -17,7 +14,6 @@\n from pydicom.values import convert_value\n \n import pydicom\n-import platform\n from pydicom import config\n from pydicom import valuerep\n from pydicom.data import get_testdata_file\n@@ -56,68 +52,70 @@ class TestTM:\n     \"\"\"Unit tests for pickling TM\"\"\"\n     def test_pickling(self):\n         # Check that a pickled TM is read back properly\n-        x = pydicom.valuerep.TM(\"212223\")\n-        assert time(21, 22, 23) == x\n-        x.original_string = \"hello\"\n-        assert \"hello\" == x.original_string\n-        assert time(21, 22, 23) == x\n-        data1_string = pickle.dumps(x)\n-        x2 = pickle.loads(data1_string)\n-        assert x == x2\n-        assert x.original_string == x2.original_string\n-        assert str(x) == str(x2)\n-\n-    def test_str(self):\n-        \"\"\"Test str(TM).\"\"\"\n-        assert \"212223.1234\" == str(pydicom.valuerep.TM(\"212223.1234\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(\"212223\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(\"212223\"))\n-        assert \"2122\" == str(pydicom.valuerep.TM(\"2122\"))\n-        assert \"21\" == str(pydicom.valuerep.TM(\"21\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(time(21, 22, 23)))\n-        assert \"212223.000024\" == str(\n-            pydicom.valuerep.TM(time(21, 22, 23, 24)))\n-        assert \"010203\" == str(pydicom.valuerep.TM(time(1, 2, 3)))\n+        tm = pydicom.valuerep.TM(\"212223\")\n+        assert tm == time(21, 22, 23)\n+        assert tm.original_string == \"212223\"\n+        assert tm == time(21, 22, 23)\n+        loaded_tm = pickle.loads(pickle.dumps(tm))\n+        assert loaded_tm == tm\n+        assert loaded_tm.original_string == tm.original_string\n+        assert str(loaded_tm) == str(tm)\n+\n+    def test_pickling_tm_from_time(self):\n+        tm = pydicom.valuerep.TM(time(21, 22, 23))\n+        assert tm.original_string == \"212223\"\n+        time_string = pickle.dumps(tm)\n+        loaded_tm = pickle.loads(time_string)\n+        assert loaded_tm == tm\n+        assert loaded_tm.original_string == tm.original_string\n+        assert str(loaded_tm) == str(tm)\n+\n+    def test_str_and_repr(self):\n+        assert str(pydicom.valuerep.TM(\"212223.1234\")) == \"212223.1234\"\n+        assert repr(pydicom.valuerep.TM(\"212223.1234\")) == '\"212223.1234\"'\n+        assert str(pydicom.valuerep.TM(\"212223\")) == \"212223\"\n+        assert repr(pydicom.valuerep.TM(\"212223\")) == '\"212223\"'\n+        assert str(pydicom.valuerep.TM(\"2122\")) == \"2122\"\n+        assert repr(pydicom.valuerep.TM(\"2122\")) == '\"2122\"'\n+        assert str(pydicom.valuerep.TM(\"21\")) == \"21\"\n+        assert str(pydicom.valuerep.TM(time(21, 22, 23))) == \"212223\"\n+        assert str(pydicom.valuerep.TM(\n+            time(21, 22, 23, 24))) == \"212223.000024\"\n+        assert str(pydicom.valuerep.TM(time(1, 2, 3))) == \"010203\"\n+        assert repr(pydicom.valuerep.TM(time(1, 2, 3))) == '\"010203\"'\n \n     def test_new_empty_str(self):\n         \"\"\"Test converting an empty string.\"\"\"\n-        x = pydicom.valuerep.TM('')\n-        assert x is None\n+        assert pydicom.valuerep.TM('') is None\n \n     def test_new_str_conversion(self):\n         \"\"\"Test converting strings to times.\"\"\"\n-        x = pydicom.valuerep.TM('00')\n-        assert \"00\" == str(x)\n-        assert time(0, 0, 0) == x\n-        x = pydicom.valuerep.TM('23')\n-        assert \"23\" == str(x)\n-        assert time(23, 0, 0) == x\n+        tm = pydicom.valuerep.TM('00')\n+        assert tm == time(0, 0, 0)\n+        tm = pydicom.valuerep.TM('23')\n+        assert tm == time(23, 0, 0)\n         msg = r\"Unable to convert non-conformant value '24' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM('24')\n \n-        x = pydicom.valuerep.TM('0000')\n-        assert \"0000\" == str(x)\n-        assert time(0, 0, 0) == x\n-        x = pydicom.valuerep.TM('2359')\n-        assert \"2359\" == str(x)\n-        assert time(23, 59, 0) == x\n+        tm = pydicom.valuerep.TM('0000')\n+        assert tm == time(0, 0, 0)\n+        tm = pydicom.valuerep.TM('2359')\n+        assert tm == time(23, 59, 0)\n         msg = r\"Unable to convert non-conformant value '2360' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM('2360')\n \n-        x = pydicom.valuerep.TM('000000')\n-        assert \"000000\" == str(x)\n-        assert time(0, 0, 0) == x\n+        tm = pydicom.valuerep.TM('000000')\n+        assert tm == time(0, 0, 0)\n         # Valid DICOM TM seconds range is 0..60, but time is 0..59\n         msg = (\n             r\"'datetime.time' doesn't allow a value of '60' for the \"\n             r\"seconds component, changing to '59'\"\n         )\n         with pytest.warns(UserWarning, match=msg):\n-            x = pydicom.valuerep.TM('235960')\n-        assert \"235960\" == str(x)\n-        assert time(23, 59, 59) == x\n+            tm = pydicom.valuerep.TM('235960')\n+        assert tm == time(23, 59, 59)\n \n         msg = r\"Unable to convert non-conformant value '235' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n@@ -126,45 +124,101 @@ def test_new_str_conversion(self):\n     def test_new_obj_conversion(self):\n         \"\"\"Test other conversion attempts.\"\"\"\n         assert pydicom.valuerep.TM(None) is None\n-        x = pydicom.valuerep.TM(\"010203.123456\")\n-        assert time(1, 2, 3, 123456) == pydicom.valuerep.TM(x)\n-        assert x == pydicom.valuerep.TM(x)\n-        x = pydicom.valuerep.TM(time(1, 2, 3))\n-        assert isinstance(x, pydicom.valuerep.TM)\n-        assert time(1, 2, 3) == x\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        assert pydicom.valuerep.TM(tm) == time(1, 2, 3, 123456)\n+        assert tm == pydicom.valuerep.TM(tm)\n+        tm = pydicom.valuerep.TM(time(1, 2, 3))\n+        assert isinstance(tm, pydicom.valuerep.TM)\n+        assert tm == time(1, 2, 3)\n \n         msg = r\"Unable to convert '123456' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM(123456)\n \n+    def test_comparison(self):\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        tm_object = time(1, 2, 3, 123456)\n+        assert tm == tm\n+        assert tm != 1\n+        assert tm == tm_object\n+        assert tm_object == tm\n+        assert hash(tm) == hash(tm_object)\n+        assert tm == pydicom.valuerep.TM(tm_object)\n+        assert tm < time(1, 2, 3, 123457)\n+        assert tm != time(1, 2, 3, 123457)\n+        assert tm < pydicom.valuerep.TM(time(1, 2, 3, 123457))\n+        assert tm <= time(1, 2, 3, 123457)\n+        assert tm <= tm_object\n+        assert tm > time(1, 2, 3)\n+        assert tm > pydicom.valuerep.TM(time(1, 2, 3))\n+        assert tm >= time(1, 2, 3)\n+        assert time(1, 2, 3, 123457) > tm\n+        assert tm_object >= tm\n+        assert time(1, 2, 3) < tm\n+        with pytest.raises(TypeError):\n+            tm > 5\n+\n+    def test_time_behavior(self):\n+        \"\"\"Test that TM behaves like time.\"\"\"\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        assert tm.hour == 1\n+        assert tm.second == 3\n+        assert tm.microsecond == 123456\n+        assert tm.replace(hour=23) == time(23, 2, 3, 123456)\n+        assert \"minute\" in dir(tm)\n+        assert \"original_string\" in dir(tm)\n+\n \n class TestDT:\n     \"\"\"Unit tests for pickling DT\"\"\"\n     def test_pickling(self):\n         # Check that a pickled DT is read back properly\n-        x = pydicom.valuerep.DT(\"19111213212123\")\n-        assert datetime(1911, 12, 13, 21, 21, 23) == x\n-        x.original_string = \"hello\"\n-        data1_string = pickle.dumps(x)\n-        x2 = pickle.loads(data1_string)\n-        assert x == x2\n-        assert x.original_string == x2.original_string\n-        assert str(x) == str(x2)\n+        dt = pydicom.valuerep.DT(\"19111213212123\")\n+        assert dt == datetime(1911, 12, 13, 21, 21, 23)\n+        data1_string = pickle.dumps(dt)\n+        loaded_dt = pickle.loads(data1_string)\n+        assert loaded_dt == dt\n+        assert dt.original_string == loaded_dt.original_string\n+        assert str(loaded_dt) == str(dt)\n+\n+    def test_pickling_with_timezone(self):\n+        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert loaded_dt == dt\n+        assert loaded_dt.original_string == dt.original_string\n+        assert str(loaded_dt) == str(dt)\n+\n+    def test_pickling_dt_from_datetime(self):\n+        dt = pydicom.valuerep.DT(datetime(2222, 11, 23, 1, 2, 3, 4))\n+        assert dt.original_string == \"22221123010203.000004\"\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert loaded_dt == dt\n+        assert loaded_dt.original_string == dt.original_string\n+        assert str(dt) == str(loaded_dt)\n+\n+    def test_pickling_dt_from_datetime_with_timezone(self):\n+        tz_info = timezone(timedelta(seconds=-23400), '-0630')\n+        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n+        dt = pydicom.valuerep.DT(dt_object)\n+        assert dt.original_string == \"20221231235959.000042-0630\"\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert dt == loaded_dt\n+        assert dt.original_string == loaded_dt.original_string\n+        assert str(dt) == str(loaded_dt)\n \n     def test_new_empty_str(self):\n         \"\"\"Test converting an empty string.\"\"\"\n-        x = pydicom.valuerep.DT('')\n-        assert x is None\n+        assert pydicom.valuerep.DT('') is None\n \n     def test_new_obj_conversion(self):\n         \"\"\"Test other conversion attempts.\"\"\"\n         assert pydicom.valuerep.DT(None) is None\n-        x = pydicom.valuerep.DT(\"10010203\")\n-        assert datetime(1001, 2, 3) == pydicom.valuerep.DT(x)\n-        assert x == pydicom.valuerep.DT(x)\n-        x = pydicom.valuerep.DT(datetime(1001, 2, 3))\n-        assert isinstance(x, pydicom.valuerep.DT)\n-        assert datetime(1001, 2, 3) == x\n+        dt = pydicom.valuerep.DT(\"10010203\")\n+        assert pydicom.valuerep.DT(dt) == datetime(1001, 2, 3)\n+        assert dt == pydicom.valuerep.DT(dt)\n+        dt = pydicom.valuerep.DT(datetime(1001, 2, 3))\n+        assert isinstance(dt, pydicom.valuerep.DT)\n+        assert dt == datetime(1001, 2, 3)\n \n         msg = r\"Unable to convert '123456' to 'DT' object\"\n         with pytest.raises(ValueError, match=msg):\n@@ -178,9 +232,9 @@ def test_new_str_conversion(self):\n             r\"seconds component, changing to '59'\"\n         )\n         with pytest.warns(UserWarning, match=msg):\n-            x = pydicom.valuerep.DT('20010101235960')\n-        assert \"20010101235960\" == str(x)\n-        assert datetime(2001, 1, 1, 23, 59, 59) == x\n+            dt = pydicom.valuerep.DT('20010101235960')\n+        assert str(dt) == \"20010101235960\"\n+        assert dt == datetime(2001, 1, 1, 23, 59, 59)\n \n         msg = (\n             r\"Unable to convert non-conformant value 'a2000,00,00' to 'DT' \"\n@@ -189,17 +243,61 @@ def test_new_str_conversion(self):\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.DT(\"a2000,00,00\")\n \n-    def test_str(self):\n+    def test_str_and_repr(self):\n         dt = datetime(1911, 12, 13, 21, 21, 23)\n-        assert \"19111213212123\" == str(pydicom.valuerep.DT(dt))\n-        assert \"19111213212123\" == str(pydicom.valuerep.DT(\"19111213212123\"))\n-        assert \"1001.02.03\" == str(pydicom.valuerep.DA(\"1001.02.03\"))\n+        assert str(pydicom.valuerep.DT(dt)) == \"19111213212123\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"19111213212123\"'\n+        assert str(pydicom.valuerep.DT(\"19111213212123\")) == \"19111213212123\"\n+        assert str(pydicom.valuerep.DA(\"1001.02.03\")) == \"1001.02.03\"\n+        assert repr(pydicom.valuerep.DA(\"1001.02.03\")) == '\"1001.02.03\"'\n         tz_info = timezone(timedelta(seconds=21600), '+0600')\n         dt = datetime(2022, 1, 2, 8, 9, 7, 123456, tzinfo=tz_info)\n-        assert \"20220102080907.123456+0600\" == str(pydicom.valuerep.DT(dt))\n+        assert str(pydicom.valuerep.DT(dt)) == \"20220102080907.123456+0600\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"20220102080907.123456+0600\"'\n         tz_info = timezone(timedelta(seconds=-23400), '-0630')\n         dt = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n-        assert \"20221231235959.000042-0630\" == str(pydicom.valuerep.DT(dt))\n+        assert str(pydicom.valuerep.DT(dt)) == \"20221231235959.000042-0630\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"20221231235959.000042-0630\"'\n+\n+    def test_comparison(self):\n+        dt = pydicom.valuerep.DT(\"19111213212123\")\n+        dt_object = datetime(1911, 12, 13, 21, 21, 23)\n+        assert dt == dt\n+        assert dt != 1\n+        assert dt == dt_object\n+        assert dt_object == dt\n+        assert hash(dt) == hash(dt_object)\n+        assert dt == pydicom.valuerep.DT(dt_object)\n+        assert dt < datetime(1911, 12, 13, 21, 21, 23, 123)\n+        assert dt != datetime(1911, 12, 13, 21, 21, 24)\n+        assert dt < pydicom.valuerep.DT(datetime(1911, 12, 13, 21, 21, 24))\n+        assert dt <= datetime(1911, 12, 13, 21, 21, 23)\n+        assert dt <= dt_object\n+        assert dt > datetime(1911, 12, 13, 21, 21, 22)\n+        assert dt > pydicom.valuerep.DT(datetime(1911, 12, 13, 21, 21, 22))\n+        assert dt >= datetime(1911, 12, 13, 21, 21, 23)\n+        assert datetime(1911, 12, 13, 21, 21, 24) > dt\n+        assert dt_object >= dt\n+        assert datetime(1911, 12, 13, 21, 21, 22) < dt\n+        with pytest.raises(TypeError):\n+            dt > 5\n+\n+    def test_datetime_behavior(self):\n+        \"\"\"Test that DT behaves like datetime.\"\"\"\n+        tz_info = timezone(timedelta(seconds=-23400), '-0630')\n+        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n+        dt = pydicom.valuerep.DT(dt_object)\n+        assert dt == dt_object\n+        assert dt_object == dt\n+        assert dt.year == 2022\n+        assert dt.month == 12\n+        assert dt.hour == 23\n+        assert dt.second == 59\n+        assert dt.microsecond == 42\n+        assert dt.tzinfo == tz_info\n+        assert dt.today().date() == dt_object.today().date()\n+        assert \"hour\" in dir(dt)\n+        assert \"original_string\" in dir(dt)\n \n \n class TestDA:\n@@ -229,10 +327,48 @@ def test_new_obj_conversion(self):\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.DA(123456)\n \n-    def test_str(self):\n-        assert \"10010203\" == str(pydicom.valuerep.DA(date(1001, 2, 3)))\n-        assert \"10010203\" == str(pydicom.valuerep.DA(\"10010203\"))\n-        assert \"1001.02.03\" == str(pydicom.valuerep.DA(\"1001.02.03\"))\n+    def test_str_and_repr(self):\n+        assert str(pydicom.valuerep.DA(date(1001, 2, 3))) == \"10010203\"\n+        assert repr(pydicom.valuerep.DA(date(1001, 2, 3))) == '\"10010203\"'\n+        assert str(pydicom.valuerep.DA(\"10010203\")) == \"10010203\"\n+        assert repr(pydicom.valuerep.DA(\"10010203\")) == '\"10010203\"'\n+        assert str(pydicom.valuerep.DA(\"1001.02.03\")) == \"1001.02.03\"\n+        assert repr(pydicom.valuerep.DA(\"1001.02.03\")) == '\"1001.02.03\"'\n+\n+    def test_comparison(self):\n+        da = pydicom.valuerep.DA(\"19111213\")\n+        da_object = date(1911, 12, 13)\n+        assert da == da\n+        assert da != 1\n+        assert da == da_object\n+        assert hash(da) == hash(da_object)\n+        assert da_object == da\n+        assert da == pydicom.valuerep.DA(da_object)\n+        assert da < date(1911, 12, 14)\n+        assert da != date(1901, 12, 13)\n+        assert da < pydicom.valuerep.DA(date(1912, 12, 13))\n+        assert da <= date(1911, 12, 13)\n+        assert da <= da_object\n+        assert da > date(1911, 12, 12)\n+        assert da > pydicom.valuerep.DA(date(1911, 12, 12))\n+        assert da >= date(1911, 12, 13)\n+        assert date(1911, 12, 14) > da\n+        assert da_object >= da\n+        assert date(1911, 12, 12) < da\n+        with pytest.raises(TypeError):\n+            da > 5\n+\n+    def test_date_behavior(self):\n+        da = pydicom.valuerep.DA(\"10010203\")\n+        da_object = date(1001, 2, 3)\n+        assert da == da_object\n+        assert da_object == da\n+        assert da.year == 1001\n+        assert da.month == 2\n+        assert da.day == 3\n+        assert da.today() == da_object.today()\n+        assert \"day\" in dir(da)\n+        assert \"original_string\" in dir(da)\n \n \n class TestIsValidDS:\n@@ -338,8 +474,8 @@ def test_invalid(self, val: float):\n     def test_wrong_type(self):\n         \"\"\"Test calling with a string raises an error\"\"\"\n         with pytest.raises(\n-            TypeError,\n-            match=\"'val' must be of type float or decimal.Decimal\"\n+                TypeError,\n+                match=\"'val' must be of type float or decimal.Decimal\"\n         ):\n             pydicom.valuerep.format_number_as_ds('1.0')\n \n@@ -470,9 +606,9 @@ def test_DSfloat_auto_format(self):\n         ]\n     )\n     def test_enforce_valid_values_value(\n-        self,\n-        val: Union[float, str],\n-        enforce_valid_true_fixture\n+            self,\n+            val: Union[float, str],\n+            enforce_valid_true_fixture\n     ):\n         \"\"\"Test that errors are raised when value is invalid.\"\"\"\n         with pytest.raises(ValueError):\n@@ -568,9 +704,9 @@ def test_auto_format_invalid_string(self, enforce_valid_both_fixture):\n         ]\n     )\n     def test_enforce_valid_values_value(\n-        self,\n-        val: Union[Decimal, str],\n-        enforce_valid_true_fixture\n+            self,\n+            val: Union[Decimal, str],\n+            enforce_valid_true_fixture\n     ):\n         \"\"\"Test that errors are raised when value is invalid.\"\"\"\n         with pytest.raises(ValueError):\n", "version": "2.1", "FAIL_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestDT::test_pickling_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_datetime_behavior\", \"pydicom/tests/test_valuerep.py::TestDA::test_date_behavior\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestTM::test_pickling_tm_from_time\", \"pydicom/tests/test_valuerep.py::TestTM::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_comparison\", \"pydicom/tests/test_valuerep.py::TestTM::test_time_behavior\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDT::test_comparison\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDA::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDA::test_comparison\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[-1234.456e78]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E-5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E+5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[+1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[42\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[nan]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[3.141592653589793]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1,000]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[127.0.0.1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1.e]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.0-1.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.0-0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.0--0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.123-0.123]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.321--0.321]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1e-05-1e-05]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[3.141592653589793-3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-3.141592653589793--3.1415926535898]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[5.385940192876374e-07-5.3859401929e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-5.385940192876374e-07--5.385940193e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[12342534378.125532-12342534378.1255]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[64070869985876.78-64070869985876.8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.7976931348623157e+308-1.797693135e+308]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_wrong_type\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_length\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat_auto_format\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-nan]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan2]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf1]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val4]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val5]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val6]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val7]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal_auto_format\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_veterinary\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator_from_bytes\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\", \"pydicom/tests/test_valuerep.py::test_person_name_unicode_warns\"]", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}
{"instance_id": "pydicom__pydicom-1375_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nPickling/unpickling timezone in DT does not work\n**Describe the bug**\r\n\r\nThe following tests fail because the timezone is not set in the unpickled `DT`:\r\n```py\r\n    def test_pickling_with_timezone():\r\n        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n\r\n    def test_pickling_dt_from_datetime_with_timezone():\r\n        tz_info = timezone(timedelta(seconds=-23400), '-0630')\r\n        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\r\n        dt = pydicom.valuerep.DT(dt_object)\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n```\r\n\r\nThis is a spin-off of PR #1365, see [this comment](https://github.com/pydicom/pydicom/pull/1365#issuecomment-829544827).\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of examples/input_output/plot_write_dicom.py]\n1 \"\"\"\n2 ================\n3 Write DICOM data\n4 ================\n5 \n6 This example shows how to write a DICOM file from scratch using pydicom. This\n7 example does not produce a DICOM standards compliant file as written, you will\n8 have to change UIDs to valid values and add all required DICOM data elements.\n9 \n10 \"\"\"\n11 \n12 # authors : Guillaume Lemaitre <g.lemaitre58@gmail.com>\n13 # license : MIT\n14 \n15 import os\n16 import tempfile\n17 import datetime\n18 \n19 import pydicom\n20 from pydicom.dataset import Dataset, FileDataset, FileMetaDataset\n21 \n22 # Create some temporary filenames\n23 suffix = '.dcm'\n24 filename_little_endian = tempfile.NamedTemporaryFile(suffix=suffix).name\n25 filename_big_endian = tempfile.NamedTemporaryFile(suffix=suffix).name\n26 \n27 print(\"Setting file meta information...\")\n28 # Populate required values for file meta information\n29 file_meta = FileMetaDataset()\n30 file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.2'\n31 file_meta.MediaStorageSOPInstanceUID = \"1.2.3\"\n32 file_meta.ImplementationClassUID = \"1.2.3.4\"\n33 \n34 print(\"Setting dataset values...\")\n35 # Create the FileDataset instance (initially no data elements, but file_meta\n36 # supplied)\n37 ds = FileDataset(filename_little_endian, {},\n38                  file_meta=file_meta, preamble=b\"\\0\" * 128)\n39 \n40 # Add the data elements -- not trying to set all required here. Check DICOM\n41 # standard\n42 ds.PatientName = \"Test^Firstname\"\n43 ds.PatientID = \"123456\"\n44 \n45 # Set the transfer syntax\n46 ds.is_little_endian = True\n47 ds.is_implicit_VR = True\n48 \n49 # Set creation date/time\n50 dt = datetime.datetime.now()\n51 ds.ContentDate = dt.strftime('%Y%m%d')\n52 timeStr = dt.strftime('%H%M%S.%f')  # long format with micro seconds\n53 ds.ContentTime = timeStr\n54 \n55 print(\"Writing test file\", filename_little_endian)\n56 ds.save_as(filename_little_endian)\n57 print(\"File saved.\")\n58 \n59 # Write as a different transfer syntax XXX shouldn't need this but pydicom\n60 # 0.9.5 bug not recognizing transfer syntax\n61 ds.file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRBigEndian\n62 ds.is_little_endian = False\n63 ds.is_implicit_VR = False\n64 \n65 print(\"Writing test file as Big Endian Explicit VR\", filename_big_endian)\n66 ds.save_as(filename_big_endian)\n67 \n68 # reopen the data just for checking\n69 for filename in (filename_little_endian, filename_big_endian):\n70     print('Load file {} ...'.format(filename))\n71     ds = pydicom.dcmread(filename)\n72     print(ds)\n73 \n74     # remove the created file\n75     print('Remove file {} ...'.format(filename))\n76     os.remove(filename)\n77 \n[end of examples/input_output/plot_write_dicom.py]\n[start of pydicom/benchmarks/bench_handler_rle_decode.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Decoding benchmarks for the rle_handler module.\"\"\"\n3 \n4 from pydicom import dcmread\n5 from pydicom.data import get_testdata_file\n6 from pydicom.encaps import decode_data_sequence\n7 from pydicom.pixel_data_handlers.rle_handler import (\n8     get_pixeldata,\n9     _rle_decode_frame,\n10 )\n11 \n12 \n13 # 8/8-bit, 1 sample/pixel, 1 frame\n14 OB_RLE_1F = get_testdata_file(\"OBXXXX1A_rle.dcm\")\n15 # 8/8-bit, 1 sample/pixel, 2 frame\n16 OB_RLE_2F = get_testdata_file(\"OBXXXX1A_rle_2frame.dcm\")\n17 # 8/8-bit, 3 sample/pixel, 1 frame\n18 SC_RLE_1F = get_testdata_file(\"SC_rgb_rle.dcm\")\n19 # 8/8-bit, 3 sample/pixel, 2 frame\n20 SC_RLE_2F = get_testdata_file(\"SC_rgb_rle_2frame.dcm\")\n21 # 16/16-bit, 1 sample/pixel, 1 frame\n22 MR_RLE_1F = get_testdata_file(\"MR_small_RLE.dcm\")\n23 # 16/16-bit, 3 sample/pixel, 1 frame\n24 SC_RLE_16_1F = get_testdata_file(\"SC_rgb_rle_16bit.dcm\")\n25 # 16/16-bit, 3 sample/pixel, 2 frame\n26 SC_RLE_16_2F = get_testdata_file(\"SC_rgb_rle_16bit_2frame.dcm\")\n27 # 16/12-bit, 1 sample/pixel, 10 frame\n28 EMRI_RLE_10F = get_testdata_file(\"emri_small_RLE.dcm\")\n29 # 32/32-bit, 1 sample/pixel, 1 frame\n30 RTDOSE_RLE_1F = get_testdata_file(\"rtdose_rle_1frame.dcm\")\n31 # 32/32-bit, 3 sample/pixel, 1 frame\n32 SC_RLE_32_1F = get_testdata_file(\"SC_rgb_rle_32bit.dcm\")\n33 # 32/32-bit, 3 sample/pixel, 2 frame\n34 SC_RLE_32_2F = get_testdata_file(\"SC_rgb_rle_32bit_2frame.dcm\")\n35 # 32/32-bit, 1 sample/pixel, 15 frame\n36 RTDOSE_RLE_15F = get_testdata_file(\"rtdose_rle.dcm\")\n37 \n38 \n39 class TimeRLEDecodeFrame:\n40     \"\"\"Time tests for rle_handler._rle_decode_frame.\"\"\"\n41     def setup(self):\n42         # MONOCHROME2, 64x64, 1 sample/pixel, 16 bits allocated, 12 bits stored\n43         self.ds = dcmread(EMRI_RLE_10F)\n44         self.frames = decode_data_sequence(self.ds.PixelData)\n45         assert len(self.frames) == 10\n46 \n47         self.no_runs = 100\n48 \n49     def time_decode_16bit_1sample_1frame(self):\n50         \"\"\"Time decoding the pixel data from a single RLE frame.\"\"\"\n51         for ii in range(self.no_runs):\n52             _rle_decode_frame(self.frames[0],\n53                               self.ds.Rows,\n54                               self.ds.Columns,\n55                               self.ds.SamplesPerPixel,\n56                               self.ds.BitsAllocated)\n57 \n58     def time_decode_16bit_1sample_10frame(self):\n59         \"\"\"Time decoding the pixel data from 10 RLE frames.\"\"\"\n60         for ii in range(self.no_runs):\n61             for frame in self.frames:\n62                 _rle_decode_frame(frame,\n63                                   self.ds.Rows,\n64                                   self.ds.Columns,\n65                                   self.ds.SamplesPerPixel,\n66                                   self.ds.BitsAllocated)\n67 \n68 \n69 class TimeGetPixelData:\n70     \"\"\"Time tests for rle_handler.get_pixeldata.\"\"\"\n71     def setup(self):\n72         \"\"\"Setup the test\"\"\"\n73         self.ds_8_1_1 = dcmread(OB_RLE_1F)\n74         self.ds_8_3_1 = dcmread(SC_RLE_1F)\n75         self.ds_16_1_1 = dcmread(MR_RLE_1F)\n76         self.ds_16_3_1 = dcmread(SC_RLE_16_1F)\n77         self.ds_32_1_1 = dcmread(RTDOSE_RLE_1F)\n78         self.ds_32_3_1 = dcmread(SC_RLE_32_1F)\n79 \n80         self.no_runs = 100\n81 \n82     def time_08bit_1sample(self):\n83         \"\"\"Time retrieval of 8-bit, 1 sample/pixel RLE data.\"\"\"\n84         for ii in range(self.no_runs):\n85             get_pixeldata(self.ds_8_1_1)\n86 \n87     def time_08bit_3sample(self):\n88         \"\"\"Time retrieval of 8-bit, 3 sample/pixel RLE data.\"\"\"\n89         for ii in range(self.no_runs):\n90             get_pixeldata(self.ds_8_3_1)\n91 \n92     def time_16bit_1sample(self):\n93         \"\"\"Time retrieval of 16-bit, 1 sample/pixel RLE data.\"\"\"\n94         for ii in range(self.no_runs):\n95             get_pixeldata(self.ds_16_1_1)\n96 \n97     def time_16bit_3sample(self):\n98         \"\"\"Time retrieval of 16-bit, 3 sample/pixel RLE data.\"\"\"\n99         for ii in range(self.no_runs):\n100             get_pixeldata(self.ds_16_3_1)\n101 \n102     def time_32bit_1sample(self):\n103         \"\"\"Time retrieval of 32-bit, 1 sample/pixel RLE data.\"\"\"\n104         for ii in range(self.no_runs):\n105             get_pixeldata(self.ds_32_1_1)\n106 \n107     def time_32bit_3sample(self):\n108         \"\"\"Time retrieval of 32-bit, 3 sample/pixel RLE data.\"\"\"\n109         for ii in range(self.no_runs):\n110             get_pixeldata(self.ds_32_3_1)\n111 \n[end of pydicom/benchmarks/bench_handler_rle_decode.py]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 import base64\n11 import json\n12 from typing import (\n13     Optional, Any, Optional, Tuple, Callable, Union, TYPE_CHECKING, Dict,\n14     TypeVar, Type, List, NamedTuple\n15 )\n16 import warnings\n17 \n18 from pydicom import config  # don't import datetime_conversion directly\n19 from pydicom.config import logger\n20 from pydicom import config\n21 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n22                               dictionary_keyword, dictionary_is_retired,\n23                               private_dictionary_description, dictionary_VR,\n24                               repeater_has_tag, private_dictionary_VR)\n25 from pydicom.errors import BytesLengthException\n26 from pydicom.jsonrep import JsonDataElementConverter\n27 from pydicom.multival import MultiValue\n28 from pydicom.tag import Tag, BaseTag\n29 from pydicom.uid import UID\n30 from pydicom import jsonrep\n31 import pydicom.valuerep  # don't import DS directly as can be changed by config\n32 from pydicom.valuerep import PersonName\n33 \n34 if config.have_numpy:\n35     import numpy\n36 \n37 if TYPE_CHECKING:\n38     from pydicom.dataset import Dataset\n39 \n40 \n41 BINARY_VR_VALUES = [\n42     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n43     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n44 ]\n45 \n46 \n47 def empty_value_for_VR(\n48     VR: str, raw: bool = False\n49 ) -> Union[bytes, List[str], str, None]:\n50     \"\"\"Return the value for an empty element for `VR`.\n51 \n52     .. versionadded:: 1.4\n53 \n54     The behavior of this property depends on the setting of\n55     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n56     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n57     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n58     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n59     empty string is used as empty value representation, for all other VRs\n60     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n61     is used in all cases.\n62     Note that this is used only if decoding the element - it is always\n63     possible to set the value to another empty value representation,\n64     which will be preserved during the element object lifetime.\n65 \n66     Parameters\n67     ----------\n68     VR : str\n69         The VR of the corresponding element.\n70     raw : bool, optional\n71         If ``True``, returns the value for a :class:`RawDataElement`,\n72         otherwise for a :class:`DataElement`\n73 \n74     Returns\n75     -------\n76     str or bytes or None or list\n77         The value a data element with `VR` is assigned on decoding\n78         if it is empty.\n79     \"\"\"\n80     if VR == 'SQ':\n81         return b'' if raw else []\n82 \n83     if config.use_none_as_empty_text_VR_value:\n84         return None\n85 \n86     if VR == 'PN':\n87         return b'' if raw else PersonName('')\n88 \n89     if VR in (\n90         'AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT', 'SH', 'ST', 'TM',\n91         'UC', 'UI', 'UR', 'UT'\n92     ):\n93         return b'' if raw else ''\n94 \n95     return None\n96 \n97 \n98 def _is_bytes(val: object) -> bool:\n99     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n100     return isinstance(val, bytes)\n101 \n102 \n103 # double '\\' because it is used as escape chr in Python\n104 _backslash_str = \"\\\\\"\n105 _backslash_byte = b\"\\\\\"\n106 \n107 \n108 _DataElement = TypeVar(\"_DataElement\", bound=\"DataElement\")\n109 _Dataset = TypeVar(\"_Dataset\", bound=\"Dataset\")\n110 \n111 \n112 class DataElement:\n113     \"\"\"Contain and manipulate a DICOM Element.\n114 \n115     Examples\n116     --------\n117 \n118     While its possible to create a new :class:`DataElement` directly and add\n119     it to a :class:`~pydicom.dataset.Dataset`:\n120 \n121     >>> from pydicom import Dataset\n122     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n123     >>> ds = Dataset()\n124     >>> ds.add(elem)\n125 \n126     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n127     to add a new :class:`DataElement`, as the VR and tag are determined\n128     automatically from the DICOM dictionary:\n129 \n130     >>> ds = Dataset()\n131     >>> ds.PatientName = 'CITIZEN^Joan'\n132 \n133     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n134     value for text VRs and `None` for non-text (binary) VRs:\n135 \n136     >>> ds = Dataset()\n137     >>> ds.PatientName = None\n138     >>> ds.PatientName\n139     ''\n140 \n141     >>> ds.BitsAllocated = None\n142     >>> ds.BitsAllocated\n143 \n144     >>> str(ds.BitsAllocated)\n145     'None'\n146 \n147     Attributes\n148     ----------\n149     descripWidth : int\n150         For string display, this is the maximum width of the description\n151         field (default ``35``).\n152     is_undefined_length : bool\n153         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n154         (ie undefined).\n155     maxBytesToDisplay : int\n156         For string display, elements with values containing data which is\n157         longer than this value will display ``\"array of # bytes\"``\n158         (default ``16``).\n159     showVR : bool\n160         For string display, include the element's VR just before it's value\n161         (default ``True``).\n162     tag : pydicom.tag.BaseTag\n163         The element's tag.\n164     VR : str\n165         The element's Value Representation.\n166     \"\"\"\n167 \n168     descripWidth = 35\n169     maxBytesToDisplay = 16\n170     showVR = True\n171     is_raw = False\n172 \n173     def __init__(\n174         self,\n175         tag: Union[int, str, Tuple[int, int]],\n176         VR: str,\n177         value: object,\n178         file_value_tell: Optional[int] = None,\n179         is_undefined_length: bool = False,\n180         already_converted: bool = False\n181     ) -> None:\n182         \"\"\"Create a new :class:`DataElement`.\n183 \n184         Parameters\n185         ----------\n186         tag : int or str or 2-tuple of int\n187             The DICOM (group, element) tag in any form accepted by\n188             :func:`~pydicom.tag.Tag` such as ``'PatientName'``,\n189             ``(0x10, 0x10)``, ``0x00100010``, etc.\n190         VR : str\n191             The 2 character DICOM value representation (see DICOM Standard,\n192             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n193         value\n194             The value of the data element. One of the following:\n195 \n196             * a single string value\n197             * a number\n198             * a :class:`list` or :class:`tuple` with all strings or all numbers\n199             * a multi-value string with backslash separator\n200         file_value_tell : int, optional\n201             The byte offset to the start of the encoded element value.\n202         is_undefined_length : bool\n203             Used internally to store whether the length field for this element\n204             was ``0xFFFFFFFF``, i.e. 'undefined length'. Default is ``False``.\n205         already_converted : bool\n206             Used to determine whether or not the element's value requires\n207             conversion to a value with VM > 1. Default is ``False``.\n208         \"\"\"\n209         if not isinstance(tag, BaseTag):\n210             tag = Tag(tag)\n211         self.tag = tag\n212 \n213         # a known tag shall only have the VR 'UN' if it has a length that\n214         # exceeds the size that can be encoded in 16 bit - all other cases\n215         # can be seen as an encoding error and can be corrected\n216         if (\n217             VR == 'UN'\n218             and not tag.is_private\n219             and config.replace_un_with_known_vr\n220             and (is_undefined_length or value is None or len(value) < 0xffff)\n221         ):\n222             try:\n223                 VR = dictionary_VR(tag)\n224             except KeyError:\n225                 pass\n226 \n227         self.VR = VR  # Note: you must set VR before setting value\n228         if already_converted:\n229             self._value = value\n230         else:\n231             self.value = value  # calls property setter which will convert\n232         self.file_tell = file_value_tell\n233         self.is_undefined_length = is_undefined_length\n234         self.private_creator: Optional[str] = None\n235         self.parent: Optional[\"Dataset\"] = None\n236 \n237     @classmethod\n238     def from_json(\n239         cls: Type[_DataElement],\n240         dataset_class: Type[_Dataset],\n241         tag: Union[BaseTag, int],\n242         vr: str,\n243         value: object,\n244         value_key: Union[str, None],\n245         bulk_data_uri_handler: Optional[\n246             Union[\n247                 Callable[[BaseTag, str, str], object],\n248                 Callable[[str], object]\n249             ]\n250         ] = None\n251     ) -> _DataElement:\n252         \"\"\"Return a :class:`DataElement` from JSON.\n253 \n254         .. versionadded:: 1.3\n255 \n256         Parameters\n257         ----------\n258         dataset_class : dataset.Dataset derived class\n259             Class used to create sequence items.\n260         tag : pydicom.tag.BaseTag or int\n261             The data element tag.\n262         vr : str\n263             The data element value representation.\n264         value : list\n265             The data element's value(s).\n266         value_key : str or None\n267             Key of the data element that contains the value\n268             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n269         bulk_data_uri_handler: callable or None\n270             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n271             or just the \"BulkDataURI\" of the JSON\n272             representation of a data element and returns the actual value of\n273             that data element (retrieved via DICOMweb WADO-RS)\n274 \n275         Returns\n276         -------\n277         DataElement\n278         \"\"\"\n279         # TODO: test wado-rs retrieve wrapper\n280         converter = JsonDataElementConverter(\n281             dataset_class, tag, vr, value, value_key, bulk_data_uri_handler\n282         )\n283         elem_value = converter.get_element_values()\n284         try:\n285             return cls(tag=tag, value=elem_value, VR=vr)\n286         except Exception as exc:\n287             raise ValueError(\n288                 f\"Data element '{tag}' could not be loaded from JSON: \"\n289                 f\"{elem_value}\"\n290             ) from exc\n291 \n292     def to_json_dict(\n293         self,\n294         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]],\n295         bulk_data_threshold: int\n296     ) -> Dict[str, object]:\n297         \"\"\"Return a dictionary representation of the :class:`DataElement`\n298         conforming to the DICOM JSON Model as described in the DICOM\n299         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n300 \n301         .. versionadded:: 1.4\n302 \n303         Parameters\n304         ----------\n305         bulk_data_element_handler: callable or None\n306             Callable that accepts a bulk data element and returns the\n307             \"BulkDataURI\" for retrieving the value of the data element\n308             via DICOMweb WADO-RS\n309         bulk_data_threshold: int\n310             Size of base64 encoded data element above which a value will be\n311             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n312             Ignored if no bulk data handler is given.\n313 \n314         Returns\n315         -------\n316         dict\n317             Mapping representing a JSON encoded data element\n318         \"\"\"\n319         json_element = {'vr': self.VR, }\n320         if self.VR in jsonrep.BINARY_VR_VALUES:\n321             if not self.is_empty:\n322                 binary_value = self.value\n323                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n324                 if (\n325                     bulk_data_element_handler is not None\n326                     and len(encoded_value) > bulk_data_threshold\n327                 ):\n328                     json_element['BulkDataURI'] = (\n329                         bulk_data_element_handler(self)\n330                     )\n331                 else:\n332                     logger.info(\n333                         f\"encode bulk data element '{self.name}' inline\"\n334                     )\n335                     json_element['InlineBinary'] = encoded_value\n336         elif self.VR == 'SQ':\n337             # recursive call to get sequence item JSON dicts\n338             value = [\n339                 ds.to_json(\n340                     bulk_data_element_handler=bulk_data_element_handler,\n341                     bulk_data_threshold=bulk_data_threshold,\n342                     dump_handler=lambda d: d\n343                 )\n344                 for ds in self.value\n345             ]\n346             json_element['Value'] = value\n347         elif self.VR == 'PN':\n348             if not self.is_empty:\n349                 elem_value = []\n350                 if self.VM > 1:\n351                     value = self.value\n352                 else:\n353                     value = [self.value]\n354                 for v in value:\n355                     comps = {'Alphabetic': v.components[0]}\n356                     if len(v.components) > 1:\n357                         comps['Ideographic'] = v.components[1]\n358                     if len(v.components) > 2:\n359                         comps['Phonetic'] = v.components[2]\n360                     elem_value.append(comps)\n361                 json_element['Value'] = elem_value\n362         elif self.VR == 'AT':\n363             if not self.is_empty:\n364                 value = self.value\n365                 if self.VM == 1:\n366                     value = [value]\n367                 json_element['Value'] = [format(v, '08X') for v in value]\n368         else:\n369             if not self.is_empty:\n370                 if self.VM > 1:\n371                     value = self.value\n372                 else:\n373                     value = [self.value]\n374                 json_element['Value'] = [v for v in value]\n375         if 'Value' in json_element:\n376             json_element['Value'] = jsonrep.convert_to_python_number(\n377                 json_element['Value'], self.VR\n378             )\n379         return json_element\n380 \n381     def to_json(\n382         self,\n383         bulk_data_threshold: int = 1024,\n384         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]] = None,  # noqa\n385         dump_handler: Optional[Callable[[Dict[object, object]], str]] = None\n386     ) -> Dict[str, object]:\n387         \"\"\"Return a JSON representation of the :class:`DataElement`.\n388 \n389         .. versionadded:: 1.3\n390 \n391         Parameters\n392         ----------\n393         bulk_data_element_handler: callable, optional\n394             Callable that accepts a bulk data element and returns the\n395             \"BulkDataURI\" for retrieving the value of the data element\n396             via DICOMweb WADO-RS\n397         bulk_data_threshold: int, optional\n398             Size of base64 encoded data element above which a value will be\n399             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n400             Ignored if no bulk data handler is given.\n401         dump_handler : callable, optional\n402             Callable function that accepts a :class:`dict` and returns the\n403             serialized (dumped) JSON string (by default uses\n404             :func:`json.dumps`).\n405 \n406         Returns\n407         -------\n408         dict\n409             Mapping representing a JSON encoded data element\n410 \n411         See also\n412         --------\n413         Dataset.to_json\n414         \"\"\"\n415         if dump_handler is None:\n416             def json_dump(d):\n417                 return json.dumps(d, sort_keys=True)\n418 \n419             dump_handler = json_dump\n420 \n421         return dump_handler(\n422             self.to_json_dict(bulk_data_element_handler, bulk_data_threshold)\n423         )\n424 \n425     @property\n426     def value(self) -> object:\n427         \"\"\"Return the element's value.\"\"\"\n428         return self._value\n429 \n430     @value.setter\n431     def value(self, val: object) -> None:\n432         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n433         # Check if is a string with multiple values separated by '\\'\n434         # If so, turn them into a list of separate strings\n435         #  Last condition covers 'US or SS' etc\n436         if isinstance(val, (str, bytes)) and self.VR not in \\\n437                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n438                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n439                  'OW or OB', 'UN'] and 'US' not in self.VR:\n440             try:\n441                 if _backslash_str in val:\n442                     val = val.split(_backslash_str)\n443             except TypeError:\n444                 if _backslash_byte in val:\n445                     val = val.split(_backslash_byte)\n446         self._value = self._convert_value(val)\n447 \n448     @property\n449     def VM(self) -> int:\n450         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n451         if self.value is None:\n452             return 0\n453         if isinstance(self.value, (str, bytes, PersonName)):\n454             return 1 if self.value else 0\n455         try:\n456             iter(self.value)\n457         except TypeError:\n458             return 1\n459         return len(self.value)\n460 \n461     @property\n462     def is_empty(self) -> bool:\n463         \"\"\"Return ``True`` if the element has no value.\n464 \n465         .. versionadded:: 1.4\n466         \"\"\"\n467         return self.VM == 0\n468 \n469     @property\n470     def empty_value(self) -> Union[bytes, List[str], None, str]:\n471         \"\"\"Return the value for an empty element.\n472 \n473         .. versionadded:: 1.4\n474 \n475         See :func:`empty_value_for_VR` for more information.\n476 \n477         Returns\n478         -------\n479         str or None\n480             The value this data element is assigned on decoding if it is empty.\n481         \"\"\"\n482         return empty_value_for_VR(self.VR)\n483 \n484     def clear(self) -> None:\n485         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n486 \n487         .. versionadded:: 1.4\n488 \n489         See :func:`empty_value_for_VR`.\n490         \"\"\"\n491         self._value = self.empty_value\n492 \n493     def _convert_value(self, val: object) -> object:\n494         \"\"\"Convert `val` to an appropriate type and return the result.\n495 \n496         Uses the element's VR in order to determine the conversion method and\n497         resulting type.\n498         \"\"\"\n499         if self.VR == 'SQ':  # a sequence - leave it alone\n500             from pydicom.sequence import Sequence\n501             if isinstance(val, Sequence):\n502                 return val\n503             else:\n504                 return Sequence(val)\n505 \n506         # if the value is a list, convert each element\n507         try:\n508             val.append\n509         except AttributeError:  # not a list\n510             return self._convert(val)\n511         else:\n512             return MultiValue(self._convert, val)\n513 \n514     def _convert(self, val: object) -> object:\n515         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n516         # If the value is a byte string and has a VR that can only be encoded\n517         # using the default character repertoire, we convert it to a string\n518         # here to allow for byte string input in these cases\n519         if _is_bytes(val) and self.VR in (\n520                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n521             val = val.decode()\n522 \n523         if self.VR == 'IS':\n524             return pydicom.valuerep.IS(val)\n525         elif self.VR == 'DA' and config.datetime_conversion:\n526             return pydicom.valuerep.DA(val)\n527         elif self.VR == 'DS':\n528             return pydicom.valuerep.DS(val)\n529         elif self.VR == 'DT' and config.datetime_conversion:\n530             return pydicom.valuerep.DT(val)\n531         elif self.VR == 'TM' and config.datetime_conversion:\n532             return pydicom.valuerep.TM(val)\n533         elif self.VR == \"UI\":\n534             return UID(val) if val is not None else None\n535         elif self.VR == \"PN\":\n536             return PersonName(val)\n537         elif self.VR == \"AT\" and (val == 0 or val):\n538             return val if isinstance(val, BaseTag) else Tag(val)\n539         # Later may need this for PersonName as for UI,\n540         #    but needs more thought\n541         # elif self.VR == \"PN\":\n542         #    return PersonName(val)\n543         else:  # is either a string or a type 2 optionally blank string\n544             return val  # this means a \"numeric\" value could be empty string \"\"\n545         # except TypeError:\n546             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n547             # % (repr(val), self.VR, self.tag)\n548         # except ValueError:\n549             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n550             # % (repr(val), self.VR, self.tag)\n551 \n552     def __eq__(self, other: object) -> bool:\n553         \"\"\"Compare `self` and `other` for equality.\n554 \n555         Returns\n556         -------\n557         bool\n558             The result if `self` and `other` are the same class\n559         NotImplemented\n560             If `other` is not the same class as `self` then returning\n561             :class:`NotImplemented` delegates the result to\n562             ``superclass.__eq__(subclass)``.\n563         \"\"\"\n564         # Faster result if same object\n565         if other is self:\n566             return True\n567 \n568         if isinstance(other, self.__class__):\n569             if self.tag != other.tag or self.VR != other.VR:\n570                 return False\n571 \n572             # tag and VR match, now check the value\n573             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n574                 return (len(self.value) == len(other.value)\n575                         and numpy.allclose(self.value, other.value))\n576             else:\n577                 return self.value == other.value\n578 \n579         return NotImplemented\n580 \n581     def __ne__(self, other: object) -> bool:\n582         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n583         return not (self == other)\n584 \n585     def __str__(self) -> str:\n586         \"\"\"Return :class:`str` representation of the element.\"\"\"\n587         repVal = self.repval or ''\n588         if self.showVR:\n589             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n590                                     self.description()[:self.descripWidth],\n591                                     self.VR, repVal)\n592         else:\n593             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n594                                 self.description()[:self.descripWidth], repVal)\n595         return s\n596 \n597     @property\n598     def repval(self) -> str:\n599         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n600         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n601         if set(self.VR.split(\" or \")) & long_VRs:\n602             try:\n603                 length = len(self.value)\n604             except TypeError:\n605                 pass\n606             else:\n607                 if length > self.maxBytesToDisplay:\n608                     return \"Array of %d elements\" % length\n609         if self.VM > self.maxBytesToDisplay:\n610             repVal = \"Array of %d elements\" % self.VM\n611         elif isinstance(self.value, UID):\n612             repVal = self.value.name\n613         else:\n614             repVal = repr(self.value)  # will tolerate unicode too\n615         return repVal\n616 \n617     def __getitem__(self, key: int) -> object:\n618         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n619         try:\n620             return self.value[key]\n621         except TypeError:\n622             raise TypeError(\"DataElement value is unscriptable \"\n623                             \"(not a Sequence)\")\n624 \n625     @property\n626     def name(self) -> str:\n627         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n628 \n629         For officially registered DICOM Data Elements this will be the *Name*\n630         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n631         For private elements known to *pydicom*\n632         this will be the *Name* in the format ``'[name]'``. For unknown\n633         private elements this will be ``'Private Creator'``. For unknown\n634         elements this will return an empty string ``''``.\n635         \"\"\"\n636         return self.description()\n637 \n638     def description(self) -> str:\n639         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n640         if self.tag.is_private:\n641             name = \"Private tag data\"  # default\n642             if self.private_creator:\n643                 try:\n644                     # If have name from private dictionary, use it, but\n645                     #   but put in square brackets so is differentiated,\n646                     #   and clear that cannot access it by name\n647                     name = private_dictionary_description(\n648                         self.tag, self.private_creator)\n649                     name = \"[%s]\" % (name)\n650                 except KeyError:\n651                     pass\n652             elif self.tag.element >> 8 == 0:\n653                 name = \"Private Creator\"\n654         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n655             name = dictionary_description(self.tag)\n656 \n657         # implied Group Length dicom versions < 3\n658         elif self.tag.element == 0:\n659             name = \"Group Length\"\n660         else:\n661             name = \"\"\n662         return name\n663 \n664     @property\n665     def is_private(self) -> bool:\n666         \"\"\"Return ``True`` if the element's tag is private.\n667 \n668         .. versionadded:: 2.1\n669         \"\"\"\n670         return self.tag.is_private\n671 \n672     @property\n673     def is_retired(self) -> bool:\n674         \"\"\"Return the element's retired status as :class:`bool`.\n675 \n676         For officially registered DICOM Data Elements this will be ``True`` if\n677         the retired status as given in the DICOM Standard, Part 6,\n678         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n679         or unknown elements this will always be ``False``.\n680         \"\"\"\n681         if dictionary_has_tag(self.tag):\n682             return dictionary_is_retired(self.tag)\n683 \n684         return False\n685 \n686     @property\n687     def keyword(self) -> str:\n688         \"\"\"Return the element's keyword (if known) as :class:`str`.\n689 \n690         For officially registered DICOM Data Elements this will be the\n691         *Keyword* as given in\n692         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n693         unknown elements this will return an empty string ``''``.\n694         \"\"\"\n695         if dictionary_has_tag(self.tag):\n696             return dictionary_keyword(self.tag)\n697 \n698         return ''\n699 \n700     def __repr__(self) -> str:\n701         \"\"\"Return the representation of the element.\"\"\"\n702         if self.VR == \"SQ\":\n703             return repr(self.value)\n704 \n705         return str(self)\n706 \n707 \n708 class RawDataElement(NamedTuple):\n709     \"\"\"Container for the data from a raw (mostly) undecoded element.\"\"\"\n710     tag: BaseTag\n711     VR: Optional[str]\n712     length: int\n713     value: bytes\n714     value_tell: int\n715     is_implicit_VR: bool\n716     is_little_endian: bool\n717     is_raw: bool = True\n718 \n719 \n720 # The first and third values of the following elements are always US\n721 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n722 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n723 # (0028,3002) LUT Descriptor\n724 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n725 \n726 \n727 def _private_vr_for_tag(ds: Optional[\"Dataset\"], tag: BaseTag) -> str:\n728     \"\"\"Return the VR for a known private tag, otherwise \"UN\".\n729 \n730     Parameters\n731     ----------\n732     ds : Dataset, optional\n733         The dataset needed for the private creator lookup.\n734         If not given, \"UN\" is returned.\n735     tag : BaseTag\n736         The private tag to lookup. The caller has to ensure that the\n737         tag is private.\n738 \n739     Returns\n740     -------\n741     str\n742         \"LO\" if the tag is a private creator, the VR of the private tag if\n743         found in the private dictionary, or \"UN\".\n744     \"\"\"\n745     if tag.is_private_creator:\n746         return \"LO\"\n747     # invalid private tags are handled as UN\n748     if ds is not None and (tag.element & 0xff00):\n749         private_creator_tag = tag.group << 16 | (tag.element >> 8)\n750         private_creator = ds.get(private_creator_tag, \"\")\n751         if private_creator:\n752             try:\n753                 return private_dictionary_VR(tag, private_creator.value)\n754             except KeyError:\n755                 pass\n756     return \"UN\"\n757 \n758 \n759 def DataElement_from_raw(\n760     raw_data_element: RawDataElement,\n761         encoding: Optional[List[str]] = None,\n762         dataset: Optional[\"Dataset\"] = None\n763 ) -> DataElement:\n764     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n765 \n766     Parameters\n767     ----------\n768     raw_data_element : RawDataElement\n769         The raw data to convert to a :class:`DataElement`.\n770     encoding : list of str, optional\n771         The character encoding of the raw data.\n772     dataset : Dataset, optional\n773         If given, used to resolve the VR for known private tags.\n774 \n775     Returns\n776     -------\n777     DataElement\n778 \n779     Raises\n780     ------\n781     KeyError\n782         If `raw_data_element` belongs to an unknown non-private tag and\n783         `config.enforce_valid_values` is set.\n784     \"\"\"\n785     # XXX buried here to avoid circular import\n786     # filereader->Dataset->convert_value->filereader\n787     # (for SQ parsing)\n788 \n789     from pydicom.values import convert_value\n790     raw = raw_data_element\n791 \n792     # If user has hooked into conversion of raw values, call his/her routine\n793     if config.data_element_callback:\n794         raw = config.data_element_callback(\n795             raw_data_element,\n796             encoding=encoding,\n797             **config.data_element_callback_kwargs\n798         )\n799 \n800     VR = raw.VR\n801     if VR is None:  # Can be if was implicit VR\n802         try:\n803             VR = dictionary_VR(raw.tag)\n804         except KeyError:\n805             # just read the bytes, no way to know what they mean\n806             if raw.tag.is_private:\n807                 # for VR for private tags see PS3.5, 6.2.2\n808                 VR = _private_vr_for_tag(dataset, raw.tag)\n809 \n810             # group length tag implied in versions < 3.0\n811             elif raw.tag.element == 0:\n812                 VR = 'UL'\n813             else:\n814                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n815                 if config.enforce_valid_values:\n816                     msg += \" can't look up VR\"\n817                     raise KeyError(msg)\n818                 else:\n819                     VR = 'UN'\n820                     msg += \" - setting VR to 'UN'\"\n821                     warnings.warn(msg)\n822     elif VR == 'UN' and config.replace_un_with_known_vr:\n823         # handle rare case of incorrectly set 'UN' in explicit encoding\n824         # see also DataElement.__init__()\n825         if raw.tag.is_private:\n826             VR = _private_vr_for_tag(dataset, raw.tag)\n827         elif raw.value is None or len(raw.value) < 0xffff:\n828             try:\n829                 VR = dictionary_VR(raw.tag)\n830             except KeyError:\n831                 pass\n832     try:\n833         value = convert_value(VR, raw, encoding)\n834     except NotImplementedError as e:\n835         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n836     except BytesLengthException as e:\n837         message = (f\"{e} This occurred while trying to parse \"\n838                    f\"{raw.tag} according to VR '{VR}'.\")\n839         if config.convert_wrong_length_to_UN:\n840             warnings.warn(f\"{message} Setting VR to 'UN'.\")\n841             VR = \"UN\"\n842             value = raw.value\n843         else:\n844             raise BytesLengthException(\n845                 f\"{message} To replace this error with a warning set \"\n846                 \"pydicom.config.convert_wrong_length_to_UN = True.\"\n847             )\n848 \n849     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n850         # We only fix the first value as the third value is 8 or 16\n851         try:\n852             if value[0] < 0:\n853                 value[0] += 65536\n854         except TypeError:\n855             pass\n856 \n857     return DataElement(raw.tag, VR, value, raw.value_tell,\n858                        raw.length == 0xFFFFFFFF, already_converted=True)\n859 \n[end of pydicom/dataelem.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "c14bf96040e4cc930db890638b9f190d4ede0a21", "problem_statement": "Pickling/unpickling timezone in DT does not work\n**Describe the bug**\r\n\r\nThe following tests fail because the timezone is not set in the unpickled `DT`:\r\n```py\r\n    def test_pickling_with_timezone():\r\n        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n\r\n    def test_pickling_dt_from_datetime_with_timezone():\r\n        tz_info = timezone(timedelta(seconds=-23400), '-0630')\r\n        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\r\n        dt = pydicom.valuerep.DT(dt_object)\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n```\r\n\r\nThis is a spin-off of PR #1365, see [this comment](https://github.com/pydicom/pydicom/pull/1365#issuecomment-829544827).\n", "hints_text": "", "created_at": "2021-05-03T18:27:35Z", "patch": "<patch>\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -2,23 +2,19 @@\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n \n import datetime\n-from decimal import Decimal\n-from math import floor, isfinite, log10\n-import platform\n import re\n import sys\n+import warnings\n+from decimal import Decimal\n+from math import floor, isfinite, log10\n+from typing import Sequence as SequenceType\n from typing import (\n-    TypeVar, Type, Tuple, Optional, List, Dict, Union, Any, Generator, AnyStr,\n-    Callable, Iterator, overload\n+    TypeVar, Type, Tuple, Optional, List, Dict, Union, Any, Generator, Callable\n )\n-from typing import Sequence as SequenceType\n-import warnings\n \n # don't import datetime_conversion directly\n from pydicom import config\n from pydicom.multival import MultiValue\n-from pydicom.uid import UID\n-\n \n # Types\n _T = TypeVar('_T')\n@@ -84,23 +80,23 @@ class DA(_DateTimeBase, datetime.date):\n \n     Note that the :class:`datetime.date` base class is immutable.\n     \"\"\"\n-    def __new__(\n-        cls: Type[_DA], val: Union[None, str, _DA, datetime.date]\n-    ) -> Optional[_DA]:\n+    def __new__(cls: Type[_DA], *args, **kwargs) -> Optional[_DA]:\n         \"\"\"Create an instance of DA object.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the DA definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.date`, or the first argument is\n+        a string conformant to the DA definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.date` object, or an object of type\n+        :class:`~pydicom.valuerep.DA`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None  # empty date\n@@ -123,14 +119,15 @@ def __new__(\n             return super().__new__(cls, val.year, val.month, val.day)\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'DA' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _DA, datetime.date]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n         \"\"\"Create a new **DA** element value.\"\"\"\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, DA) and hasattr(val, 'original_string'):\n@@ -171,23 +168,23 @@ def _utc_offset(value: str) -> datetime.timezone:\n             name=value\n         )\n \n-    def __new__(\n-        cls: Type[_DT], val: Union[None, str, _DT, datetime.datetime]\n-    ) -> Optional[_DT]:\n+    def __new__(cls: Type[_DT], *args, **kwargs) -> Optional[_DT]:\n         \"\"\"Create an instance of DT object.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the DT definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.datetime`, or the first argument is\n+        a string conformant to the DT definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.datetime` object, or an object of type\n+        :class:`~pydicom.valuerep.DT`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None\n@@ -233,13 +230,15 @@ def __new__(\n             )\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'DT' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _DT, datetime.datetime]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n+        \"\"\"Create a new **DT** element value.\"\"\"\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, DT) and hasattr(val, 'original_string'):\n@@ -274,23 +273,23 @@ class TM(_DateTimeBase, datetime.time):\n         r\"(?(7)(\\.(?P<ms>([0-9]{1,6})?))?))$\"\n     )\n \n-    def __new__(\n-        cls: Type[_TM], val: Union[None, str, _TM, datetime.time]\n-    ) -> Optional[_TM]:\n+    def __new__(cls: Type[_TM], *args, **kwargs) -> Optional[_TM]:\n         \"\"\"Create an instance of TM object from a string.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the TM definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.time`, or the first argument is\n+        a string conformant to the TM definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.time` object, or an object of type\n+        :class:`~pydicom.valuerep.TM`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None  # empty time\n@@ -325,13 +324,15 @@ def __new__(\n             )\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'TM' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _TM, datetime.time]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n+        super().__init__()\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, TM) and hasattr(val, 'original_string'):\n@@ -344,16 +345,6 @@ def __init__(self, val: Union[str, _TM, datetime.time]) -> None:\n             if val.microsecond > 0:\n                 self.original_string += f\".{val.microsecond:06}\"\n \n-    if platform.python_implementation() == \"PyPy\":\n-        # Workaround for CPython/PyPy bug in time.__reduce_ex__()\n-        #   caused by returning (time, ...) rather than (self.__class__, ...)\n-        def __reduce_ex__(self, protocol: int) -> Union[str, Tuple[Any, ...]]:\n-            return (\n-                self.__class__,\n-                super()._getstate(protocol),\n-                self.__getstate__()\n-            )\n-\n \n # Regex to match strings that represent valid DICOM decimal strings (DS)\n _DS_REGEX = re.compile(r'\\s*[\\+\\-]?\\d+(\\.\\d+)?([eE][\\+\\-]?\\d+)?\\s*$')\n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -5,10 +5,7 @@\n import copy\n from datetime import datetime, date, time, timedelta, timezone\n from decimal import Decimal\n-try:\n-    import cPickle as pickle\n-except ImportError:\n-    import pickle\n+import pickle\n import math\n import sys\n from typing import Union\n@@ -17,7 +14,6 @@\n from pydicom.values import convert_value\n \n import pydicom\n-import platform\n from pydicom import config\n from pydicom import valuerep\n from pydicom.data import get_testdata_file\n@@ -56,68 +52,70 @@ class TestTM:\n     \"\"\"Unit tests for pickling TM\"\"\"\n     def test_pickling(self):\n         # Check that a pickled TM is read back properly\n-        x = pydicom.valuerep.TM(\"212223\")\n-        assert time(21, 22, 23) == x\n-        x.original_string = \"hello\"\n-        assert \"hello\" == x.original_string\n-        assert time(21, 22, 23) == x\n-        data1_string = pickle.dumps(x)\n-        x2 = pickle.loads(data1_string)\n-        assert x == x2\n-        assert x.original_string == x2.original_string\n-        assert str(x) == str(x2)\n-\n-    def test_str(self):\n-        \"\"\"Test str(TM).\"\"\"\n-        assert \"212223.1234\" == str(pydicom.valuerep.TM(\"212223.1234\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(\"212223\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(\"212223\"))\n-        assert \"2122\" == str(pydicom.valuerep.TM(\"2122\"))\n-        assert \"21\" == str(pydicom.valuerep.TM(\"21\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(time(21, 22, 23)))\n-        assert \"212223.000024\" == str(\n-            pydicom.valuerep.TM(time(21, 22, 23, 24)))\n-        assert \"010203\" == str(pydicom.valuerep.TM(time(1, 2, 3)))\n+        tm = pydicom.valuerep.TM(\"212223\")\n+        assert tm == time(21, 22, 23)\n+        assert tm.original_string == \"212223\"\n+        assert tm == time(21, 22, 23)\n+        loaded_tm = pickle.loads(pickle.dumps(tm))\n+        assert loaded_tm == tm\n+        assert loaded_tm.original_string == tm.original_string\n+        assert str(loaded_tm) == str(tm)\n+\n+    def test_pickling_tm_from_time(self):\n+        tm = pydicom.valuerep.TM(time(21, 22, 23))\n+        assert tm.original_string == \"212223\"\n+        time_string = pickle.dumps(tm)\n+        loaded_tm = pickle.loads(time_string)\n+        assert loaded_tm == tm\n+        assert loaded_tm.original_string == tm.original_string\n+        assert str(loaded_tm) == str(tm)\n+\n+    def test_str_and_repr(self):\n+        assert str(pydicom.valuerep.TM(\"212223.1234\")) == \"212223.1234\"\n+        assert repr(pydicom.valuerep.TM(\"212223.1234\")) == '\"212223.1234\"'\n+        assert str(pydicom.valuerep.TM(\"212223\")) == \"212223\"\n+        assert repr(pydicom.valuerep.TM(\"212223\")) == '\"212223\"'\n+        assert str(pydicom.valuerep.TM(\"2122\")) == \"2122\"\n+        assert repr(pydicom.valuerep.TM(\"2122\")) == '\"2122\"'\n+        assert str(pydicom.valuerep.TM(\"21\")) == \"21\"\n+        assert str(pydicom.valuerep.TM(time(21, 22, 23))) == \"212223\"\n+        assert str(pydicom.valuerep.TM(\n+            time(21, 22, 23, 24))) == \"212223.000024\"\n+        assert str(pydicom.valuerep.TM(time(1, 2, 3))) == \"010203\"\n+        assert repr(pydicom.valuerep.TM(time(1, 2, 3))) == '\"010203\"'\n \n     def test_new_empty_str(self):\n         \"\"\"Test converting an empty string.\"\"\"\n-        x = pydicom.valuerep.TM('')\n-        assert x is None\n+        assert pydicom.valuerep.TM('') is None\n \n     def test_new_str_conversion(self):\n         \"\"\"Test converting strings to times.\"\"\"\n-        x = pydicom.valuerep.TM('00')\n-        assert \"00\" == str(x)\n-        assert time(0, 0, 0) == x\n-        x = pydicom.valuerep.TM('23')\n-        assert \"23\" == str(x)\n-        assert time(23, 0, 0) == x\n+        tm = pydicom.valuerep.TM('00')\n+        assert tm == time(0, 0, 0)\n+        tm = pydicom.valuerep.TM('23')\n+        assert tm == time(23, 0, 0)\n         msg = r\"Unable to convert non-conformant value '24' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM('24')\n \n-        x = pydicom.valuerep.TM('0000')\n-        assert \"0000\" == str(x)\n-        assert time(0, 0, 0) == x\n-        x = pydicom.valuerep.TM('2359')\n-        assert \"2359\" == str(x)\n-        assert time(23, 59, 0) == x\n+        tm = pydicom.valuerep.TM('0000')\n+        assert tm == time(0, 0, 0)\n+        tm = pydicom.valuerep.TM('2359')\n+        assert tm == time(23, 59, 0)\n         msg = r\"Unable to convert non-conformant value '2360' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM('2360')\n \n-        x = pydicom.valuerep.TM('000000')\n-        assert \"000000\" == str(x)\n-        assert time(0, 0, 0) == x\n+        tm = pydicom.valuerep.TM('000000')\n+        assert tm == time(0, 0, 0)\n         # Valid DICOM TM seconds range is 0..60, but time is 0..59\n         msg = (\n             r\"'datetime.time' doesn't allow a value of '60' for the \"\n             r\"seconds component, changing to '59'\"\n         )\n         with pytest.warns(UserWarning, match=msg):\n-            x = pydicom.valuerep.TM('235960')\n-        assert \"235960\" == str(x)\n-        assert time(23, 59, 59) == x\n+            tm = pydicom.valuerep.TM('235960')\n+        assert tm == time(23, 59, 59)\n \n         msg = r\"Unable to convert non-conformant value '235' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n@@ -126,45 +124,101 @@ def test_new_str_conversion(self):\n     def test_new_obj_conversion(self):\n         \"\"\"Test other conversion attempts.\"\"\"\n         assert pydicom.valuerep.TM(None) is None\n-        x = pydicom.valuerep.TM(\"010203.123456\")\n-        assert time(1, 2, 3, 123456) == pydicom.valuerep.TM(x)\n-        assert x == pydicom.valuerep.TM(x)\n-        x = pydicom.valuerep.TM(time(1, 2, 3))\n-        assert isinstance(x, pydicom.valuerep.TM)\n-        assert time(1, 2, 3) == x\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        assert pydicom.valuerep.TM(tm) == time(1, 2, 3, 123456)\n+        assert tm == pydicom.valuerep.TM(tm)\n+        tm = pydicom.valuerep.TM(time(1, 2, 3))\n+        assert isinstance(tm, pydicom.valuerep.TM)\n+        assert tm == time(1, 2, 3)\n \n         msg = r\"Unable to convert '123456' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM(123456)\n \n+    def test_comparison(self):\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        tm_object = time(1, 2, 3, 123456)\n+        assert tm == tm\n+        assert tm != 1\n+        assert tm == tm_object\n+        assert tm_object == tm\n+        assert hash(tm) == hash(tm_object)\n+        assert tm == pydicom.valuerep.TM(tm_object)\n+        assert tm < time(1, 2, 3, 123457)\n+        assert tm != time(1, 2, 3, 123457)\n+        assert tm < pydicom.valuerep.TM(time(1, 2, 3, 123457))\n+        assert tm <= time(1, 2, 3, 123457)\n+        assert tm <= tm_object\n+        assert tm > time(1, 2, 3)\n+        assert tm > pydicom.valuerep.TM(time(1, 2, 3))\n+        assert tm >= time(1, 2, 3)\n+        assert time(1, 2, 3, 123457) > tm\n+        assert tm_object >= tm\n+        assert time(1, 2, 3) < tm\n+        with pytest.raises(TypeError):\n+            tm > 5\n+\n+    def test_time_behavior(self):\n+        \"\"\"Test that TM behaves like time.\"\"\"\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        assert tm.hour == 1\n+        assert tm.second == 3\n+        assert tm.microsecond == 123456\n+        assert tm.replace(hour=23) == time(23, 2, 3, 123456)\n+        assert \"minute\" in dir(tm)\n+        assert \"original_string\" in dir(tm)\n+\n \n class TestDT:\n     \"\"\"Unit tests for pickling DT\"\"\"\n     def test_pickling(self):\n         # Check that a pickled DT is read back properly\n-        x = pydicom.valuerep.DT(\"19111213212123\")\n-        assert datetime(1911, 12, 13, 21, 21, 23) == x\n-        x.original_string = \"hello\"\n-        data1_string = pickle.dumps(x)\n-        x2 = pickle.loads(data1_string)\n-        assert x == x2\n-        assert x.original_string == x2.original_string\n-        assert str(x) == str(x2)\n+        dt = pydicom.valuerep.DT(\"19111213212123\")\n+        assert dt == datetime(1911, 12, 13, 21, 21, 23)\n+        data1_string = pickle.dumps(dt)\n+        loaded_dt = pickle.loads(data1_string)\n+        assert loaded_dt == dt\n+        assert dt.original_string == loaded_dt.original_string\n+        assert str(loaded_dt) == str(dt)\n+\n+    def test_pickling_with_timezone(self):\n+        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert loaded_dt == dt\n+        assert loaded_dt.original_string == dt.original_string\n+        assert str(loaded_dt) == str(dt)\n+\n+    def test_pickling_dt_from_datetime(self):\n+        dt = pydicom.valuerep.DT(datetime(2222, 11, 23, 1, 2, 3, 4))\n+        assert dt.original_string == \"22221123010203.000004\"\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert loaded_dt == dt\n+        assert loaded_dt.original_string == dt.original_string\n+        assert str(dt) == str(loaded_dt)\n+\n+    def test_pickling_dt_from_datetime_with_timezone(self):\n+        tz_info = timezone(timedelta(seconds=-23400), '-0630')\n+        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n+        dt = pydicom.valuerep.DT(dt_object)\n+        assert dt.original_string == \"20221231235959.000042-0630\"\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert dt == loaded_dt\n+        assert dt.original_string == loaded_dt.original_string\n+        assert str(dt) == str(loaded_dt)\n \n     def test_new_empty_str(self):\n         \"\"\"Test converting an empty string.\"\"\"\n-        x = pydicom.valuerep.DT('')\n-        assert x is None\n+        assert pydicom.valuerep.DT('') is None\n \n     def test_new_obj_conversion(self):\n         \"\"\"Test other conversion attempts.\"\"\"\n         assert pydicom.valuerep.DT(None) is None\n-        x = pydicom.valuerep.DT(\"10010203\")\n-        assert datetime(1001, 2, 3) == pydicom.valuerep.DT(x)\n-        assert x == pydicom.valuerep.DT(x)\n-        x = pydicom.valuerep.DT(datetime(1001, 2, 3))\n-        assert isinstance(x, pydicom.valuerep.DT)\n-        assert datetime(1001, 2, 3) == x\n+        dt = pydicom.valuerep.DT(\"10010203\")\n+        assert pydicom.valuerep.DT(dt) == datetime(1001, 2, 3)\n+        assert dt == pydicom.valuerep.DT(dt)\n+        dt = pydicom.valuerep.DT(datetime(1001, 2, 3))\n+        assert isinstance(dt, pydicom.valuerep.DT)\n+        assert dt == datetime(1001, 2, 3)\n \n         msg = r\"Unable to convert '123456' to 'DT' object\"\n         with pytest.raises(ValueError, match=msg):\n@@ -178,9 +232,9 @@ def test_new_str_conversion(self):\n             r\"seconds component, changing to '59'\"\n         )\n         with pytest.warns(UserWarning, match=msg):\n-            x = pydicom.valuerep.DT('20010101235960')\n-        assert \"20010101235960\" == str(x)\n-        assert datetime(2001, 1, 1, 23, 59, 59) == x\n+            dt = pydicom.valuerep.DT('20010101235960')\n+        assert str(dt) == \"20010101235960\"\n+        assert dt == datetime(2001, 1, 1, 23, 59, 59)\n \n         msg = (\n             r\"Unable to convert non-conformant value 'a2000,00,00' to 'DT' \"\n@@ -189,17 +243,61 @@ def test_new_str_conversion(self):\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.DT(\"a2000,00,00\")\n \n-    def test_str(self):\n+    def test_str_and_repr(self):\n         dt = datetime(1911, 12, 13, 21, 21, 23)\n-        assert \"19111213212123\" == str(pydicom.valuerep.DT(dt))\n-        assert \"19111213212123\" == str(pydicom.valuerep.DT(\"19111213212123\"))\n-        assert \"1001.02.03\" == str(pydicom.valuerep.DA(\"1001.02.03\"))\n+        assert str(pydicom.valuerep.DT(dt)) == \"19111213212123\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"19111213212123\"'\n+        assert str(pydicom.valuerep.DT(\"19111213212123\")) == \"19111213212123\"\n+        assert str(pydicom.valuerep.DA(\"1001.02.03\")) == \"1001.02.03\"\n+        assert repr(pydicom.valuerep.DA(\"1001.02.03\")) == '\"1001.02.03\"'\n         tz_info = timezone(timedelta(seconds=21600), '+0600')\n         dt = datetime(2022, 1, 2, 8, 9, 7, 123456, tzinfo=tz_info)\n-        assert \"20220102080907.123456+0600\" == str(pydicom.valuerep.DT(dt))\n+        assert str(pydicom.valuerep.DT(dt)) == \"20220102080907.123456+0600\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"20220102080907.123456+0600\"'\n         tz_info = timezone(timedelta(seconds=-23400), '-0630')\n         dt = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n-        assert \"20221231235959.000042-0630\" == str(pydicom.valuerep.DT(dt))\n+        assert str(pydicom.valuerep.DT(dt)) == \"20221231235959.000042-0630\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"20221231235959.000042-0630\"'\n+\n+    def test_comparison(self):\n+        dt = pydicom.valuerep.DT(\"19111213212123\")\n+        dt_object = datetime(1911, 12, 13, 21, 21, 23)\n+        assert dt == dt\n+        assert dt != 1\n+        assert dt == dt_object\n+        assert dt_object == dt\n+        assert hash(dt) == hash(dt_object)\n+        assert dt == pydicom.valuerep.DT(dt_object)\n+        assert dt < datetime(1911, 12, 13, 21, 21, 23, 123)\n+        assert dt != datetime(1911, 12, 13, 21, 21, 24)\n+        assert dt < pydicom.valuerep.DT(datetime(1911, 12, 13, 21, 21, 24))\n+        assert dt <= datetime(1911, 12, 13, 21, 21, 23)\n+        assert dt <= dt_object\n+        assert dt > datetime(1911, 12, 13, 21, 21, 22)\n+        assert dt > pydicom.valuerep.DT(datetime(1911, 12, 13, 21, 21, 22))\n+        assert dt >= datetime(1911, 12, 13, 21, 21, 23)\n+        assert datetime(1911, 12, 13, 21, 21, 24) > dt\n+        assert dt_object >= dt\n+        assert datetime(1911, 12, 13, 21, 21, 22) < dt\n+        with pytest.raises(TypeError):\n+            dt > 5\n+\n+    def test_datetime_behavior(self):\n+        \"\"\"Test that DT behaves like datetime.\"\"\"\n+        tz_info = timezone(timedelta(seconds=-23400), '-0630')\n+        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n+        dt = pydicom.valuerep.DT(dt_object)\n+        assert dt == dt_object\n+        assert dt_object == dt\n+        assert dt.year == 2022\n+        assert dt.month == 12\n+        assert dt.hour == 23\n+        assert dt.second == 59\n+        assert dt.microsecond == 42\n+        assert dt.tzinfo == tz_info\n+        assert dt.today().date() == dt_object.today().date()\n+        assert \"hour\" in dir(dt)\n+        assert \"original_string\" in dir(dt)\n \n \n class TestDA:\n@@ -229,10 +327,48 @@ def test_new_obj_conversion(self):\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.DA(123456)\n \n-    def test_str(self):\n-        assert \"10010203\" == str(pydicom.valuerep.DA(date(1001, 2, 3)))\n-        assert \"10010203\" == str(pydicom.valuerep.DA(\"10010203\"))\n-        assert \"1001.02.03\" == str(pydicom.valuerep.DA(\"1001.02.03\"))\n+    def test_str_and_repr(self):\n+        assert str(pydicom.valuerep.DA(date(1001, 2, 3))) == \"10010203\"\n+        assert repr(pydicom.valuerep.DA(date(1001, 2, 3))) == '\"10010203\"'\n+        assert str(pydicom.valuerep.DA(\"10010203\")) == \"10010203\"\n+        assert repr(pydicom.valuerep.DA(\"10010203\")) == '\"10010203\"'\n+        assert str(pydicom.valuerep.DA(\"1001.02.03\")) == \"1001.02.03\"\n+        assert repr(pydicom.valuerep.DA(\"1001.02.03\")) == '\"1001.02.03\"'\n+\n+    def test_comparison(self):\n+        da = pydicom.valuerep.DA(\"19111213\")\n+        da_object = date(1911, 12, 13)\n+        assert da == da\n+        assert da != 1\n+        assert da == da_object\n+        assert hash(da) == hash(da_object)\n+        assert da_object == da\n+        assert da == pydicom.valuerep.DA(da_object)\n+        assert da < date(1911, 12, 14)\n+        assert da != date(1901, 12, 13)\n+        assert da < pydicom.valuerep.DA(date(1912, 12, 13))\n+        assert da <= date(1911, 12, 13)\n+        assert da <= da_object\n+        assert da > date(1911, 12, 12)\n+        assert da > pydicom.valuerep.DA(date(1911, 12, 12))\n+        assert da >= date(1911, 12, 13)\n+        assert date(1911, 12, 14) > da\n+        assert da_object >= da\n+        assert date(1911, 12, 12) < da\n+        with pytest.raises(TypeError):\n+            da > 5\n+\n+    def test_date_behavior(self):\n+        da = pydicom.valuerep.DA(\"10010203\")\n+        da_object = date(1001, 2, 3)\n+        assert da == da_object\n+        assert da_object == da\n+        assert da.year == 1001\n+        assert da.month == 2\n+        assert da.day == 3\n+        assert da.today() == da_object.today()\n+        assert \"day\" in dir(da)\n+        assert \"original_string\" in dir(da)\n \n \n class TestIsValidDS:\n@@ -338,8 +474,8 @@ def test_invalid(self, val: float):\n     def test_wrong_type(self):\n         \"\"\"Test calling with a string raises an error\"\"\"\n         with pytest.raises(\n-            TypeError,\n-            match=\"'val' must be of type float or decimal.Decimal\"\n+                TypeError,\n+                match=\"'val' must be of type float or decimal.Decimal\"\n         ):\n             pydicom.valuerep.format_number_as_ds('1.0')\n \n@@ -470,9 +606,9 @@ def test_DSfloat_auto_format(self):\n         ]\n     )\n     def test_enforce_valid_values_value(\n-        self,\n-        val: Union[float, str],\n-        enforce_valid_true_fixture\n+            self,\n+            val: Union[float, str],\n+            enforce_valid_true_fixture\n     ):\n         \"\"\"Test that errors are raised when value is invalid.\"\"\"\n         with pytest.raises(ValueError):\n@@ -568,9 +704,9 @@ def test_auto_format_invalid_string(self, enforce_valid_both_fixture):\n         ]\n     )\n     def test_enforce_valid_values_value(\n-        self,\n-        val: Union[Decimal, str],\n-        enforce_valid_true_fixture\n+            self,\n+            val: Union[Decimal, str],\n+            enforce_valid_true_fixture\n     ):\n         \"\"\"Test that errors are raised when value is invalid.\"\"\"\n         with pytest.raises(ValueError):\n", "version": "2.1", "FAIL_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestDT::test_pickling_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_datetime_behavior\", \"pydicom/tests/test_valuerep.py::TestDA::test_date_behavior\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestTM::test_pickling_tm_from_time\", \"pydicom/tests/test_valuerep.py::TestTM::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_comparison\", \"pydicom/tests/test_valuerep.py::TestTM::test_time_behavior\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDT::test_comparison\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDA::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDA::test_comparison\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[-1234.456e78]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E-5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E+5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[+1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[42\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[nan]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[3.141592653589793]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1,000]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[127.0.0.1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1.e]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.0-1.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.0-0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.0--0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.123-0.123]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.321--0.321]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1e-05-1e-05]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[3.141592653589793-3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-3.141592653589793--3.1415926535898]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[5.385940192876374e-07-5.3859401929e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-5.385940192876374e-07--5.385940193e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[12342534378.125532-12342534378.1255]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[64070869985876.78-64070869985876.8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.7976931348623157e+308-1.797693135e+308]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_wrong_type\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_length\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat_auto_format\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-nan]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan2]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf1]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val4]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val5]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val6]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val7]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal_auto_format\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_veterinary\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator_from_bytes\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\", \"pydicom/tests/test_valuerep.py::test_person_name_unicode_warns\"]", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}
{"instance_id": "pydicom__pydicom-1375_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nPickling/unpickling timezone in DT does not work\n**Describe the bug**\r\n\r\nThe following tests fail because the timezone is not set in the unpickled `DT`:\r\n```py\r\n    def test_pickling_with_timezone():\r\n        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n\r\n    def test_pickling_dt_from_datetime_with_timezone():\r\n        tz_info = timezone(timedelta(seconds=-23400), '-0630')\r\n        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\r\n        dt = pydicom.valuerep.DT(dt_object)\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n```\r\n\r\nThis is a spin-off of PR #1365, see [this comment](https://github.com/pydicom/pydicom/pull/1365#issuecomment-829544827).\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of examples/input_output/plot_write_dicom.py]\n1 \"\"\"\n2 ================\n3 Write DICOM data\n4 ================\n5 \n6 This example shows how to write a DICOM file from scratch using pydicom. This\n7 example does not produce a DICOM standards compliant file as written, you will\n8 have to change UIDs to valid values and add all required DICOM data elements.\n9 \n10 \"\"\"\n11 \n12 # authors : Guillaume Lemaitre <g.lemaitre58@gmail.com>\n13 # license : MIT\n14 \n15 import os\n16 import tempfile\n17 import datetime\n18 \n19 import pydicom\n20 from pydicom.dataset import Dataset, FileDataset, FileMetaDataset\n21 \n22 # Create some temporary filenames\n23 suffix = '.dcm'\n24 filename_little_endian = tempfile.NamedTemporaryFile(suffix=suffix).name\n25 filename_big_endian = tempfile.NamedTemporaryFile(suffix=suffix).name\n26 \n27 print(\"Setting file meta information...\")\n28 # Populate required values for file meta information\n29 file_meta = FileMetaDataset()\n30 file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.2'\n31 file_meta.MediaStorageSOPInstanceUID = \"1.2.3\"\n32 file_meta.ImplementationClassUID = \"1.2.3.4\"\n33 \n34 print(\"Setting dataset values...\")\n35 # Create the FileDataset instance (initially no data elements, but file_meta\n36 # supplied)\n37 ds = FileDataset(filename_little_endian, {},\n38                  file_meta=file_meta, preamble=b\"\\0\" * 128)\n39 \n40 # Add the data elements -- not trying to set all required here. Check DICOM\n41 # standard\n42 ds.PatientName = \"Test^Firstname\"\n43 ds.PatientID = \"123456\"\n44 \n45 # Set the transfer syntax\n46 ds.is_little_endian = True\n47 ds.is_implicit_VR = True\n48 \n49 # Set creation date/time\n50 dt = datetime.datetime.now()\n51 ds.ContentDate = dt.strftime('%Y%m%d')\n52 timeStr = dt.strftime('%H%M%S.%f')  # long format with micro seconds\n53 ds.ContentTime = timeStr\n54 \n55 print(\"Writing test file\", filename_little_endian)\n56 ds.save_as(filename_little_endian)\n57 print(\"File saved.\")\n58 \n59 # Write as a different transfer syntax XXX shouldn't need this but pydicom\n60 # 0.9.5 bug not recognizing transfer syntax\n61 ds.file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRBigEndian\n62 ds.is_little_endian = False\n63 ds.is_implicit_VR = False\n64 \n65 print(\"Writing test file as Big Endian Explicit VR\", filename_big_endian)\n66 ds.save_as(filename_big_endian)\n67 \n68 # reopen the data just for checking\n69 for filename in (filename_little_endian, filename_big_endian):\n70     print('Load file {} ...'.format(filename))\n71     ds = pydicom.dcmread(filename)\n72     print(ds)\n73 \n74     # remove the created file\n75     print('Remove file {} ...'.format(filename))\n76     os.remove(filename)\n77 \n[end of examples/input_output/plot_write_dicom.py]\n[start of pydicom/benchmarks/bench_handler_rle_decode.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Decoding benchmarks for the rle_handler module.\"\"\"\n3 \n4 from pydicom import dcmread\n5 from pydicom.data import get_testdata_file\n6 from pydicom.encaps import decode_data_sequence\n7 from pydicom.pixel_data_handlers.rle_handler import (\n8     get_pixeldata,\n9     _rle_decode_frame,\n10 )\n11 \n12 \n13 # 8/8-bit, 1 sample/pixel, 1 frame\n14 OB_RLE_1F = get_testdata_file(\"OBXXXX1A_rle.dcm\")\n15 # 8/8-bit, 1 sample/pixel, 2 frame\n16 OB_RLE_2F = get_testdata_file(\"OBXXXX1A_rle_2frame.dcm\")\n17 # 8/8-bit, 3 sample/pixel, 1 frame\n18 SC_RLE_1F = get_testdata_file(\"SC_rgb_rle.dcm\")\n19 # 8/8-bit, 3 sample/pixel, 2 frame\n20 SC_RLE_2F = get_testdata_file(\"SC_rgb_rle_2frame.dcm\")\n21 # 16/16-bit, 1 sample/pixel, 1 frame\n22 MR_RLE_1F = get_testdata_file(\"MR_small_RLE.dcm\")\n23 # 16/16-bit, 3 sample/pixel, 1 frame\n24 SC_RLE_16_1F = get_testdata_file(\"SC_rgb_rle_16bit.dcm\")\n25 # 16/16-bit, 3 sample/pixel, 2 frame\n26 SC_RLE_16_2F = get_testdata_file(\"SC_rgb_rle_16bit_2frame.dcm\")\n27 # 16/12-bit, 1 sample/pixel, 10 frame\n28 EMRI_RLE_10F = get_testdata_file(\"emri_small_RLE.dcm\")\n29 # 32/32-bit, 1 sample/pixel, 1 frame\n30 RTDOSE_RLE_1F = get_testdata_file(\"rtdose_rle_1frame.dcm\")\n31 # 32/32-bit, 3 sample/pixel, 1 frame\n32 SC_RLE_32_1F = get_testdata_file(\"SC_rgb_rle_32bit.dcm\")\n33 # 32/32-bit, 3 sample/pixel, 2 frame\n34 SC_RLE_32_2F = get_testdata_file(\"SC_rgb_rle_32bit_2frame.dcm\")\n35 # 32/32-bit, 1 sample/pixel, 15 frame\n36 RTDOSE_RLE_15F = get_testdata_file(\"rtdose_rle.dcm\")\n37 \n38 \n39 class TimeRLEDecodeFrame:\n40     \"\"\"Time tests for rle_handler._rle_decode_frame.\"\"\"\n41     def setup(self):\n42         # MONOCHROME2, 64x64, 1 sample/pixel, 16 bits allocated, 12 bits stored\n43         self.ds = dcmread(EMRI_RLE_10F)\n44         self.frames = decode_data_sequence(self.ds.PixelData)\n45         assert len(self.frames) == 10\n46 \n47         self.no_runs = 100\n48 \n49     def time_decode_16bit_1sample_1frame(self):\n50         \"\"\"Time decoding the pixel data from a single RLE frame.\"\"\"\n51         for ii in range(self.no_runs):\n52             _rle_decode_frame(self.frames[0],\n53                               self.ds.Rows,\n54                               self.ds.Columns,\n55                               self.ds.SamplesPerPixel,\n56                               self.ds.BitsAllocated)\n57 \n58     def time_decode_16bit_1sample_10frame(self):\n59         \"\"\"Time decoding the pixel data from 10 RLE frames.\"\"\"\n60         for ii in range(self.no_runs):\n61             for frame in self.frames:\n62                 _rle_decode_frame(frame,\n63                                   self.ds.Rows,\n64                                   self.ds.Columns,\n65                                   self.ds.SamplesPerPixel,\n66                                   self.ds.BitsAllocated)\n67 \n68 \n69 class TimeGetPixelData:\n70     \"\"\"Time tests for rle_handler.get_pixeldata.\"\"\"\n71     def setup(self):\n72         \"\"\"Setup the test\"\"\"\n73         self.ds_8_1_1 = dcmread(OB_RLE_1F)\n74         self.ds_8_3_1 = dcmread(SC_RLE_1F)\n75         self.ds_16_1_1 = dcmread(MR_RLE_1F)\n76         self.ds_16_3_1 = dcmread(SC_RLE_16_1F)\n77         self.ds_32_1_1 = dcmread(RTDOSE_RLE_1F)\n78         self.ds_32_3_1 = dcmread(SC_RLE_32_1F)\n79 \n80         self.no_runs = 100\n81 \n82     def time_08bit_1sample(self):\n83         \"\"\"Time retrieval of 8-bit, 1 sample/pixel RLE data.\"\"\"\n84         for ii in range(self.no_runs):\n85             get_pixeldata(self.ds_8_1_1)\n86 \n87     def time_08bit_3sample(self):\n88         \"\"\"Time retrieval of 8-bit, 3 sample/pixel RLE data.\"\"\"\n89         for ii in range(self.no_runs):\n90             get_pixeldata(self.ds_8_3_1)\n91 \n92     def time_16bit_1sample(self):\n93         \"\"\"Time retrieval of 16-bit, 1 sample/pixel RLE data.\"\"\"\n94         for ii in range(self.no_runs):\n95             get_pixeldata(self.ds_16_1_1)\n96 \n97     def time_16bit_3sample(self):\n98         \"\"\"Time retrieval of 16-bit, 3 sample/pixel RLE data.\"\"\"\n99         for ii in range(self.no_runs):\n100             get_pixeldata(self.ds_16_3_1)\n101 \n102     def time_32bit_1sample(self):\n103         \"\"\"Time retrieval of 32-bit, 1 sample/pixel RLE data.\"\"\"\n104         for ii in range(self.no_runs):\n105             get_pixeldata(self.ds_32_1_1)\n106 \n107     def time_32bit_3sample(self):\n108         \"\"\"Time retrieval of 32-bit, 3 sample/pixel RLE data.\"\"\"\n109         for ii in range(self.no_runs):\n110             get_pixeldata(self.ds_32_3_1)\n111 \n[end of pydicom/benchmarks/bench_handler_rle_decode.py]\n[start of pydicom/dataelem.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Define the DataElement class.\n3 \n4 A DataElement has a tag,\n5               a value representation (VR),\n6               a value multiplicity (VM)\n7               and a value.\n8 \"\"\"\n9 \n10 import base64\n11 import json\n12 from typing import (\n13     Optional, Any, Optional, Tuple, Callable, Union, TYPE_CHECKING, Dict,\n14     TypeVar, Type, List, NamedTuple\n15 )\n16 import warnings\n17 \n18 from pydicom import config  # don't import datetime_conversion directly\n19 from pydicom.config import logger\n20 from pydicom import config\n21 from pydicom.datadict import (dictionary_has_tag, dictionary_description,\n22                               dictionary_keyword, dictionary_is_retired,\n23                               private_dictionary_description, dictionary_VR,\n24                               repeater_has_tag, private_dictionary_VR)\n25 from pydicom.errors import BytesLengthException\n26 from pydicom.jsonrep import JsonDataElementConverter\n27 from pydicom.multival import MultiValue\n28 from pydicom.tag import Tag, BaseTag\n29 from pydicom.uid import UID\n30 from pydicom import jsonrep\n31 import pydicom.valuerep  # don't import DS directly as can be changed by config\n32 from pydicom.valuerep import PersonName\n33 \n34 if config.have_numpy:\n35     import numpy\n36 \n37 if TYPE_CHECKING:\n38     from pydicom.dataset import Dataset\n39 \n40 \n41 BINARY_VR_VALUES = [\n42     'US', 'SS', 'UL', 'SL', 'OW', 'OB', 'OL', 'UN',\n43     'OB or OW', 'US or OW', 'US or SS or OW', 'FL', 'FD', 'OF', 'OD'\n44 ]\n45 \n46 \n47 def empty_value_for_VR(\n48     VR: str, raw: bool = False\n49 ) -> Union[bytes, List[str], str, None]:\n50     \"\"\"Return the value for an empty element for `VR`.\n51 \n52     .. versionadded:: 1.4\n53 \n54     The behavior of this property depends on the setting of\n55     :attr:`config.use_none_as_empty_value`. If that is set to ``True``,\n56     an empty value is represented by ``None`` (except for VR 'SQ'), otherwise\n57     it depends on `VR`. For text VRs (this includes 'AE', 'AS', 'CS', 'DA',\n58     'DT', 'LO', 'LT', 'PN', 'SH', 'ST', 'TM', 'UC', 'UI', 'UR' and 'UT') an\n59     empty string is used as empty value representation, for all other VRs\n60     except 'SQ', ``None``. For empty sequence values (VR 'SQ') an empty list\n61     is used in all cases.\n62     Note that this is used only if decoding the element - it is always\n63     possible to set the value to another empty value representation,\n64     which will be preserved during the element object lifetime.\n65 \n66     Parameters\n67     ----------\n68     VR : str\n69         The VR of the corresponding element.\n70     raw : bool, optional\n71         If ``True``, returns the value for a :class:`RawDataElement`,\n72         otherwise for a :class:`DataElement`\n73 \n74     Returns\n75     -------\n76     str or bytes or None or list\n77         The value a data element with `VR` is assigned on decoding\n78         if it is empty.\n79     \"\"\"\n80     if VR == 'SQ':\n81         return b'' if raw else []\n82 \n83     if config.use_none_as_empty_text_VR_value:\n84         return None\n85 \n86     if VR == 'PN':\n87         return b'' if raw else PersonName('')\n88 \n89     if VR in (\n90         'AE', 'AS', 'CS', 'DA', 'DT', 'LO', 'LT', 'SH', 'ST', 'TM',\n91         'UC', 'UI', 'UR', 'UT'\n92     ):\n93         return b'' if raw else ''\n94 \n95     return None\n96 \n97 \n98 def _is_bytes(val: object) -> bool:\n99     \"\"\"Return True only if `val` is of type `bytes`.\"\"\"\n100     return isinstance(val, bytes)\n101 \n102 \n103 # double '\\' because it is used as escape chr in Python\n104 _backslash_str = \"\\\\\"\n105 _backslash_byte = b\"\\\\\"\n106 \n107 \n108 _DataElement = TypeVar(\"_DataElement\", bound=\"DataElement\")\n109 _Dataset = TypeVar(\"_Dataset\", bound=\"Dataset\")\n110 \n111 \n112 class DataElement:\n113     \"\"\"Contain and manipulate a DICOM Element.\n114 \n115     Examples\n116     --------\n117 \n118     While its possible to create a new :class:`DataElement` directly and add\n119     it to a :class:`~pydicom.dataset.Dataset`:\n120 \n121     >>> from pydicom import Dataset\n122     >>> elem = DataElement(0x00100010, 'PN', 'CITIZEN^Joan')\n123     >>> ds = Dataset()\n124     >>> ds.add(elem)\n125 \n126     Its far more convenient to use a :class:`~pydicom.dataset.Dataset`\n127     to add a new :class:`DataElement`, as the VR and tag are determined\n128     automatically from the DICOM dictionary:\n129 \n130     >>> ds = Dataset()\n131     >>> ds.PatientName = 'CITIZEN^Joan'\n132 \n133     Empty DataElement objects (e.g. with VM = 0) show an empty string as\n134     value for text VRs and `None` for non-text (binary) VRs:\n135 \n136     >>> ds = Dataset()\n137     >>> ds.PatientName = None\n138     >>> ds.PatientName\n139     ''\n140 \n141     >>> ds.BitsAllocated = None\n142     >>> ds.BitsAllocated\n143 \n144     >>> str(ds.BitsAllocated)\n145     'None'\n146 \n147     Attributes\n148     ----------\n149     descripWidth : int\n150         For string display, this is the maximum width of the description\n151         field (default ``35``).\n152     is_undefined_length : bool\n153         Indicates whether the length field for the element was ``0xFFFFFFFFL``\n154         (ie undefined).\n155     maxBytesToDisplay : int\n156         For string display, elements with values containing data which is\n157         longer than this value will display ``\"array of # bytes\"``\n158         (default ``16``).\n159     showVR : bool\n160         For string display, include the element's VR just before it's value\n161         (default ``True``).\n162     tag : pydicom.tag.BaseTag\n163         The element's tag.\n164     VR : str\n165         The element's Value Representation.\n166     \"\"\"\n167 \n168     descripWidth = 35\n169     maxBytesToDisplay = 16\n170     showVR = True\n171     is_raw = False\n172 \n173     def __init__(\n174         self,\n175         tag: Union[int, str, Tuple[int, int]],\n176         VR: str,\n177         value: object,\n178         file_value_tell: Optional[int] = None,\n179         is_undefined_length: bool = False,\n180         already_converted: bool = False\n181     ) -> None:\n182         \"\"\"Create a new :class:`DataElement`.\n183 \n184         Parameters\n185         ----------\n186         tag : int or str or 2-tuple of int\n187             The DICOM (group, element) tag in any form accepted by\n188             :func:`~pydicom.tag.Tag` such as ``'PatientName'``,\n189             ``(0x10, 0x10)``, ``0x00100010``, etc.\n190         VR : str\n191             The 2 character DICOM value representation (see DICOM Standard,\n192             Part 5, :dcm:`Section 6.2<part05/sect_6.2.html>`).\n193         value\n194             The value of the data element. One of the following:\n195 \n196             * a single string value\n197             * a number\n198             * a :class:`list` or :class:`tuple` with all strings or all numbers\n199             * a multi-value string with backslash separator\n200         file_value_tell : int, optional\n201             The byte offset to the start of the encoded element value.\n202         is_undefined_length : bool\n203             Used internally to store whether the length field for this element\n204             was ``0xFFFFFFFF``, i.e. 'undefined length'. Default is ``False``.\n205         already_converted : bool\n206             Used to determine whether or not the element's value requires\n207             conversion to a value with VM > 1. Default is ``False``.\n208         \"\"\"\n209         if not isinstance(tag, BaseTag):\n210             tag = Tag(tag)\n211         self.tag = tag\n212 \n213         # a known tag shall only have the VR 'UN' if it has a length that\n214         # exceeds the size that can be encoded in 16 bit - all other cases\n215         # can be seen as an encoding error and can be corrected\n216         if (\n217             VR == 'UN'\n218             and not tag.is_private\n219             and config.replace_un_with_known_vr\n220             and (is_undefined_length or value is None or len(value) < 0xffff)\n221         ):\n222             try:\n223                 VR = dictionary_VR(tag)\n224             except KeyError:\n225                 pass\n226 \n227         self.VR = VR  # Note: you must set VR before setting value\n228         if already_converted:\n229             self._value = value\n230         else:\n231             self.value = value  # calls property setter which will convert\n232         self.file_tell = file_value_tell\n233         self.is_undefined_length = is_undefined_length\n234         self.private_creator: Optional[str] = None\n235         self.parent: Optional[\"Dataset\"] = None\n236 \n237     @classmethod\n238     def from_json(\n239         cls: Type[_DataElement],\n240         dataset_class: Type[_Dataset],\n241         tag: Union[BaseTag, int],\n242         vr: str,\n243         value: object,\n244         value_key: Union[str, None],\n245         bulk_data_uri_handler: Optional[\n246             Union[\n247                 Callable[[BaseTag, str, str], object],\n248                 Callable[[str], object]\n249             ]\n250         ] = None\n251     ) -> _DataElement:\n252         \"\"\"Return a :class:`DataElement` from JSON.\n253 \n254         .. versionadded:: 1.3\n255 \n256         Parameters\n257         ----------\n258         dataset_class : dataset.Dataset derived class\n259             Class used to create sequence items.\n260         tag : pydicom.tag.BaseTag or int\n261             The data element tag.\n262         vr : str\n263             The data element value representation.\n264         value : list\n265             The data element's value(s).\n266         value_key : str or None\n267             Key of the data element that contains the value\n268             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n269         bulk_data_uri_handler: callable or None\n270             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n271             or just the \"BulkDataURI\" of the JSON\n272             representation of a data element and returns the actual value of\n273             that data element (retrieved via DICOMweb WADO-RS)\n274 \n275         Returns\n276         -------\n277         DataElement\n278         \"\"\"\n279         # TODO: test wado-rs retrieve wrapper\n280         converter = JsonDataElementConverter(\n281             dataset_class, tag, vr, value, value_key, bulk_data_uri_handler\n282         )\n283         elem_value = converter.get_element_values()\n284         try:\n285             return cls(tag=tag, value=elem_value, VR=vr)\n286         except Exception as exc:\n287             raise ValueError(\n288                 f\"Data element '{tag}' could not be loaded from JSON: \"\n289                 f\"{elem_value}\"\n290             ) from exc\n291 \n292     def to_json_dict(\n293         self,\n294         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]],\n295         bulk_data_threshold: int\n296     ) -> Dict[str, object]:\n297         \"\"\"Return a dictionary representation of the :class:`DataElement`\n298         conforming to the DICOM JSON Model as described in the DICOM\n299         Standard, Part 18, :dcm:`Annex F<part18/chaptr_F.html>`.\n300 \n301         .. versionadded:: 1.4\n302 \n303         Parameters\n304         ----------\n305         bulk_data_element_handler: callable or None\n306             Callable that accepts a bulk data element and returns the\n307             \"BulkDataURI\" for retrieving the value of the data element\n308             via DICOMweb WADO-RS\n309         bulk_data_threshold: int\n310             Size of base64 encoded data element above which a value will be\n311             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n312             Ignored if no bulk data handler is given.\n313 \n314         Returns\n315         -------\n316         dict\n317             Mapping representing a JSON encoded data element\n318         \"\"\"\n319         json_element = {'vr': self.VR, }\n320         if self.VR in jsonrep.BINARY_VR_VALUES:\n321             if not self.is_empty:\n322                 binary_value = self.value\n323                 encoded_value = base64.b64encode(binary_value).decode('utf-8')\n324                 if (\n325                     bulk_data_element_handler is not None\n326                     and len(encoded_value) > bulk_data_threshold\n327                 ):\n328                     json_element['BulkDataURI'] = (\n329                         bulk_data_element_handler(self)\n330                     )\n331                 else:\n332                     logger.info(\n333                         f\"encode bulk data element '{self.name}' inline\"\n334                     )\n335                     json_element['InlineBinary'] = encoded_value\n336         elif self.VR == 'SQ':\n337             # recursive call to get sequence item JSON dicts\n338             value = [\n339                 ds.to_json(\n340                     bulk_data_element_handler=bulk_data_element_handler,\n341                     bulk_data_threshold=bulk_data_threshold,\n342                     dump_handler=lambda d: d\n343                 )\n344                 for ds in self.value\n345             ]\n346             json_element['Value'] = value\n347         elif self.VR == 'PN':\n348             if not self.is_empty:\n349                 elem_value = []\n350                 if self.VM > 1:\n351                     value = self.value\n352                 else:\n353                     value = [self.value]\n354                 for v in value:\n355                     comps = {'Alphabetic': v.components[0]}\n356                     if len(v.components) > 1:\n357                         comps['Ideographic'] = v.components[1]\n358                     if len(v.components) > 2:\n359                         comps['Phonetic'] = v.components[2]\n360                     elem_value.append(comps)\n361                 json_element['Value'] = elem_value\n362         elif self.VR == 'AT':\n363             if not self.is_empty:\n364                 value = self.value\n365                 if self.VM == 1:\n366                     value = [value]\n367                 json_element['Value'] = [format(v, '08X') for v in value]\n368         else:\n369             if not self.is_empty:\n370                 if self.VM > 1:\n371                     value = self.value\n372                 else:\n373                     value = [self.value]\n374                 json_element['Value'] = [v for v in value]\n375         if 'Value' in json_element:\n376             json_element['Value'] = jsonrep.convert_to_python_number(\n377                 json_element['Value'], self.VR\n378             )\n379         return json_element\n380 \n381     def to_json(\n382         self,\n383         bulk_data_threshold: int = 1024,\n384         bulk_data_element_handler: Optional[Callable[[\"DataElement\"], str]] = None,  # noqa\n385         dump_handler: Optional[Callable[[Dict[object, object]], str]] = None\n386     ) -> Dict[str, object]:\n387         \"\"\"Return a JSON representation of the :class:`DataElement`.\n388 \n389         .. versionadded:: 1.3\n390 \n391         Parameters\n392         ----------\n393         bulk_data_element_handler: callable, optional\n394             Callable that accepts a bulk data element and returns the\n395             \"BulkDataURI\" for retrieving the value of the data element\n396             via DICOMweb WADO-RS\n397         bulk_data_threshold: int, optional\n398             Size of base64 encoded data element above which a value will be\n399             provided in form of a \"BulkDataURI\" rather than \"InlineBinary\".\n400             Ignored if no bulk data handler is given.\n401         dump_handler : callable, optional\n402             Callable function that accepts a :class:`dict` and returns the\n403             serialized (dumped) JSON string (by default uses\n404             :func:`json.dumps`).\n405 \n406         Returns\n407         -------\n408         dict\n409             Mapping representing a JSON encoded data element\n410 \n411         See also\n412         --------\n413         Dataset.to_json\n414         \"\"\"\n415         if dump_handler is None:\n416             def json_dump(d):\n417                 return json.dumps(d, sort_keys=True)\n418 \n419             dump_handler = json_dump\n420 \n421         return dump_handler(\n422             self.to_json_dict(bulk_data_element_handler, bulk_data_threshold)\n423         )\n424 \n425     @property\n426     def value(self) -> object:\n427         \"\"\"Return the element's value.\"\"\"\n428         return self._value\n429 \n430     @value.setter\n431     def value(self, val: object) -> None:\n432         \"\"\"Convert (if necessary) and set the value of the element.\"\"\"\n433         # Check if is a string with multiple values separated by '\\'\n434         # If so, turn them into a list of separate strings\n435         #  Last condition covers 'US or SS' etc\n436         if isinstance(val, (str, bytes)) and self.VR not in \\\n437                 ['UT', 'ST', 'LT', 'FL', 'FD', 'AT', 'OB', 'OW', 'OF', 'SL',\n438                  'SQ', 'SS', 'UL', 'OB/OW', 'OW/OB', 'OB or OW',\n439                  'OW or OB', 'UN'] and 'US' not in self.VR:\n440             try:\n441                 if _backslash_str in val:\n442                     val = val.split(_backslash_str)\n443             except TypeError:\n444                 if _backslash_byte in val:\n445                     val = val.split(_backslash_byte)\n446         self._value = self._convert_value(val)\n447 \n448     @property\n449     def VM(self) -> int:\n450         \"\"\"Return the value multiplicity of the element as :class:`int`.\"\"\"\n451         if self.value is None:\n452             return 0\n453         if isinstance(self.value, (str, bytes, PersonName)):\n454             return 1 if self.value else 0\n455         try:\n456             iter(self.value)\n457         except TypeError:\n458             return 1\n459         return len(self.value)\n460 \n461     @property\n462     def is_empty(self) -> bool:\n463         \"\"\"Return ``True`` if the element has no value.\n464 \n465         .. versionadded:: 1.4\n466         \"\"\"\n467         return self.VM == 0\n468 \n469     @property\n470     def empty_value(self) -> Union[bytes, List[str], None, str]:\n471         \"\"\"Return the value for an empty element.\n472 \n473         .. versionadded:: 1.4\n474 \n475         See :func:`empty_value_for_VR` for more information.\n476 \n477         Returns\n478         -------\n479         str or None\n480             The value this data element is assigned on decoding if it is empty.\n481         \"\"\"\n482         return empty_value_for_VR(self.VR)\n483 \n484     def clear(self) -> None:\n485         \"\"\"Clears the value, e.g. sets it to the configured empty value.\n486 \n487         .. versionadded:: 1.4\n488 \n489         See :func:`empty_value_for_VR`.\n490         \"\"\"\n491         self._value = self.empty_value\n492 \n493     def _convert_value(self, val: object) -> object:\n494         \"\"\"Convert `val` to an appropriate type and return the result.\n495 \n496         Uses the element's VR in order to determine the conversion method and\n497         resulting type.\n498         \"\"\"\n499         if self.VR == 'SQ':  # a sequence - leave it alone\n500             from pydicom.sequence import Sequence\n501             if isinstance(val, Sequence):\n502                 return val\n503             else:\n504                 return Sequence(val)\n505 \n506         # if the value is a list, convert each element\n507         try:\n508             val.append\n509         except AttributeError:  # not a list\n510             return self._convert(val)\n511         else:\n512             return MultiValue(self._convert, val)\n513 \n514     def _convert(self, val: object) -> object:\n515         \"\"\"Convert `val` to an appropriate type for the element's VR.\"\"\"\n516         # If the value is a byte string and has a VR that can only be encoded\n517         # using the default character repertoire, we convert it to a string\n518         # here to allow for byte string input in these cases\n519         if _is_bytes(val) and self.VR in (\n520                 'AE', 'AS', 'CS', 'DA', 'DS', 'DT', 'IS', 'TM', 'UI', 'UR'):\n521             val = val.decode()\n522 \n523         if self.VR == 'IS':\n524             return pydicom.valuerep.IS(val)\n525         elif self.VR == 'DA' and config.datetime_conversion:\n526             return pydicom.valuerep.DA(val)\n527         elif self.VR == 'DS':\n528             return pydicom.valuerep.DS(val)\n529         elif self.VR == 'DT' and config.datetime_conversion:\n530             return pydicom.valuerep.DT(val)\n531         elif self.VR == 'TM' and config.datetime_conversion:\n532             return pydicom.valuerep.TM(val)\n533         elif self.VR == \"UI\":\n534             return UID(val) if val is not None else None\n535         elif self.VR == \"PN\":\n536             return PersonName(val)\n537         elif self.VR == \"AT\" and (val == 0 or val):\n538             return val if isinstance(val, BaseTag) else Tag(val)\n539         # Later may need this for PersonName as for UI,\n540         #    but needs more thought\n541         # elif self.VR == \"PN\":\n542         #    return PersonName(val)\n543         else:  # is either a string or a type 2 optionally blank string\n544             return val  # this means a \"numeric\" value could be empty string \"\"\n545         # except TypeError:\n546             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n547             # % (repr(val), self.VR, self.tag)\n548         # except ValueError:\n549             # print \"Could not convert value '%s' to VR '%s' in tag %s\" \\\n550             # % (repr(val), self.VR, self.tag)\n551 \n552     def __eq__(self, other: object) -> bool:\n553         \"\"\"Compare `self` and `other` for equality.\n554 \n555         Returns\n556         -------\n557         bool\n558             The result if `self` and `other` are the same class\n559         NotImplemented\n560             If `other` is not the same class as `self` then returning\n561             :class:`NotImplemented` delegates the result to\n562             ``superclass.__eq__(subclass)``.\n563         \"\"\"\n564         # Faster result if same object\n565         if other is self:\n566             return True\n567 \n568         if isinstance(other, self.__class__):\n569             if self.tag != other.tag or self.VR != other.VR:\n570                 return False\n571 \n572             # tag and VR match, now check the value\n573             if config.have_numpy and isinstance(self.value, numpy.ndarray):\n574                 return (len(self.value) == len(other.value)\n575                         and numpy.allclose(self.value, other.value))\n576             else:\n577                 return self.value == other.value\n578 \n579         return NotImplemented\n580 \n581     def __ne__(self, other: object) -> bool:\n582         \"\"\"Compare `self` and `other` for inequality.\"\"\"\n583         return not (self == other)\n584 \n585     def __str__(self) -> str:\n586         \"\"\"Return :class:`str` representation of the element.\"\"\"\n587         repVal = self.repval or ''\n588         if self.showVR:\n589             s = \"%s %-*s %s: %s\" % (str(self.tag), self.descripWidth,\n590                                     self.description()[:self.descripWidth],\n591                                     self.VR, repVal)\n592         else:\n593             s = \"%s %-*s %s\" % (str(self.tag), self.descripWidth,\n594                                 self.description()[:self.descripWidth], repVal)\n595         return s\n596 \n597     @property\n598     def repval(self) -> str:\n599         \"\"\"Return a :class:`str` representation of the element's value.\"\"\"\n600         long_VRs = {\"OB\", \"OD\", \"OF\", \"OW\", \"UN\", \"UT\"}\n601         if set(self.VR.split(\" or \")) & long_VRs:\n602             try:\n603                 length = len(self.value)\n604             except TypeError:\n605                 pass\n606             else:\n607                 if length > self.maxBytesToDisplay:\n608                     return \"Array of %d elements\" % length\n609         if self.VM > self.maxBytesToDisplay:\n610             repVal = \"Array of %d elements\" % self.VM\n611         elif isinstance(self.value, UID):\n612             repVal = self.value.name\n613         else:\n614             repVal = repr(self.value)  # will tolerate unicode too\n615         return repVal\n616 \n617     def __getitem__(self, key: int) -> object:\n618         \"\"\"Return the item at `key` if the element's value is indexable.\"\"\"\n619         try:\n620             return self.value[key]\n621         except TypeError:\n622             raise TypeError(\"DataElement value is unscriptable \"\n623                             \"(not a Sequence)\")\n624 \n625     @property\n626     def name(self) -> str:\n627         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\n628 \n629         For officially registered DICOM Data Elements this will be the *Name*\n630         as given in :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`.\n631         For private elements known to *pydicom*\n632         this will be the *Name* in the format ``'[name]'``. For unknown\n633         private elements this will be ``'Private Creator'``. For unknown\n634         elements this will return an empty string ``''``.\n635         \"\"\"\n636         return self.description()\n637 \n638     def description(self) -> str:\n639         \"\"\"Return the DICOM dictionary name for the element as :class:`str`.\"\"\"\n640         if self.tag.is_private:\n641             name = \"Private tag data\"  # default\n642             if self.private_creator:\n643                 try:\n644                     # If have name from private dictionary, use it, but\n645                     #   but put in square brackets so is differentiated,\n646                     #   and clear that cannot access it by name\n647                     name = private_dictionary_description(\n648                         self.tag, self.private_creator)\n649                     name = \"[%s]\" % (name)\n650                 except KeyError:\n651                     pass\n652             elif self.tag.element >> 8 == 0:\n653                 name = \"Private Creator\"\n654         elif dictionary_has_tag(self.tag) or repeater_has_tag(self.tag):\n655             name = dictionary_description(self.tag)\n656 \n657         # implied Group Length dicom versions < 3\n658         elif self.tag.element == 0:\n659             name = \"Group Length\"\n660         else:\n661             name = \"\"\n662         return name\n663 \n664     @property\n665     def is_private(self) -> bool:\n666         \"\"\"Return ``True`` if the element's tag is private.\n667 \n668         .. versionadded:: 2.1\n669         \"\"\"\n670         return self.tag.is_private\n671 \n672     @property\n673     def is_retired(self) -> bool:\n674         \"\"\"Return the element's retired status as :class:`bool`.\n675 \n676         For officially registered DICOM Data Elements this will be ``True`` if\n677         the retired status as given in the DICOM Standard, Part 6,\n678         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>` is 'RET'. For private\n679         or unknown elements this will always be ``False``.\n680         \"\"\"\n681         if dictionary_has_tag(self.tag):\n682             return dictionary_is_retired(self.tag)\n683 \n684         return False\n685 \n686     @property\n687     def keyword(self) -> str:\n688         \"\"\"Return the element's keyword (if known) as :class:`str`.\n689 \n690         For officially registered DICOM Data Elements this will be the\n691         *Keyword* as given in\n692         :dcm:`Table 6-1<part06/chapter_6.html#table_6-1>`. For private or\n693         unknown elements this will return an empty string ``''``.\n694         \"\"\"\n695         if dictionary_has_tag(self.tag):\n696             return dictionary_keyword(self.tag)\n697 \n698         return ''\n699 \n700     def __repr__(self) -> str:\n701         \"\"\"Return the representation of the element.\"\"\"\n702         if self.VR == \"SQ\":\n703             return repr(self.value)\n704 \n705         return str(self)\n706 \n707 \n708 class RawDataElement(NamedTuple):\n709     \"\"\"Container for the data from a raw (mostly) undecoded element.\"\"\"\n710     tag: BaseTag\n711     VR: Optional[str]\n712     length: int\n713     value: bytes\n714     value_tell: int\n715     is_implicit_VR: bool\n716     is_little_endian: bool\n717     is_raw: bool = True\n718 \n719 \n720 # The first and third values of the following elements are always US\n721 #   even if the VR is SS (PS3.3 C.7.6.3.1.5, C.11.1, C.11.2).\n722 # (0028,1101-1103) RGB Palette Color LUT Descriptor\n723 # (0028,3002) LUT Descriptor\n724 _LUT_DESCRIPTOR_TAGS = (0x00281101, 0x00281102, 0x00281103, 0x00283002)\n725 \n726 \n727 def _private_vr_for_tag(ds: Optional[\"Dataset\"], tag: BaseTag) -> str:\n728     \"\"\"Return the VR for a known private tag, otherwise \"UN\".\n729 \n730     Parameters\n731     ----------\n732     ds : Dataset, optional\n733         The dataset needed for the private creator lookup.\n734         If not given, \"UN\" is returned.\n735     tag : BaseTag\n736         The private tag to lookup. The caller has to ensure that the\n737         tag is private.\n738 \n739     Returns\n740     -------\n741     str\n742         \"LO\" if the tag is a private creator, the VR of the private tag if\n743         found in the private dictionary, or \"UN\".\n744     \"\"\"\n745     if tag.is_private_creator:\n746         return \"LO\"\n747     # invalid private tags are handled as UN\n748     if ds is not None and (tag.element & 0xff00):\n749         private_creator_tag = tag.group << 16 | (tag.element >> 8)\n750         private_creator = ds.get(private_creator_tag, \"\")\n751         if private_creator:\n752             try:\n753                 return private_dictionary_VR(tag, private_creator.value)\n754             except KeyError:\n755                 pass\n756     return \"UN\"\n757 \n758 \n759 def DataElement_from_raw(\n760     raw_data_element: RawDataElement,\n761         encoding: Optional[List[str]] = None,\n762         dataset: Optional[\"Dataset\"] = None\n763 ) -> DataElement:\n764     \"\"\"Return a :class:`DataElement` created from `raw_data_element`.\n765 \n766     Parameters\n767     ----------\n768     raw_data_element : RawDataElement\n769         The raw data to convert to a :class:`DataElement`.\n770     encoding : list of str, optional\n771         The character encoding of the raw data.\n772     dataset : Dataset, optional\n773         If given, used to resolve the VR for known private tags.\n774 \n775     Returns\n776     -------\n777     DataElement\n778 \n779     Raises\n780     ------\n781     KeyError\n782         If `raw_data_element` belongs to an unknown non-private tag and\n783         `config.enforce_valid_values` is set.\n784     \"\"\"\n785     # XXX buried here to avoid circular import\n786     # filereader->Dataset->convert_value->filereader\n787     # (for SQ parsing)\n788 \n789     from pydicom.values import convert_value\n790     raw = raw_data_element\n791 \n792     # If user has hooked into conversion of raw values, call his/her routine\n793     if config.data_element_callback:\n794         raw = config.data_element_callback(\n795             raw_data_element,\n796             encoding=encoding,\n797             **config.data_element_callback_kwargs\n798         )\n799 \n800     VR = raw.VR\n801     if VR is None:  # Can be if was implicit VR\n802         try:\n803             VR = dictionary_VR(raw.tag)\n804         except KeyError:\n805             # just read the bytes, no way to know what they mean\n806             if raw.tag.is_private:\n807                 # for VR for private tags see PS3.5, 6.2.2\n808                 VR = _private_vr_for_tag(dataset, raw.tag)\n809 \n810             # group length tag implied in versions < 3.0\n811             elif raw.tag.element == 0:\n812                 VR = 'UL'\n813             else:\n814                 msg = \"Unknown DICOM tag {0:s}\".format(str(raw.tag))\n815                 if config.enforce_valid_values:\n816                     msg += \" can't look up VR\"\n817                     raise KeyError(msg)\n818                 else:\n819                     VR = 'UN'\n820                     msg += \" - setting VR to 'UN'\"\n821                     warnings.warn(msg)\n822     elif VR == 'UN' and config.replace_un_with_known_vr:\n823         # handle rare case of incorrectly set 'UN' in explicit encoding\n824         # see also DataElement.__init__()\n825         if raw.tag.is_private:\n826             VR = _private_vr_for_tag(dataset, raw.tag)\n827         elif raw.value is None or len(raw.value) < 0xffff:\n828             try:\n829                 VR = dictionary_VR(raw.tag)\n830             except KeyError:\n831                 pass\n832     try:\n833         value = convert_value(VR, raw, encoding)\n834     except NotImplementedError as e:\n835         raise NotImplementedError(\"{0:s} in tag {1!r}\".format(str(e), raw.tag))\n836     except BytesLengthException as e:\n837         message = (f\"{e} This occurred while trying to parse \"\n838                    f\"{raw.tag} according to VR '{VR}'.\")\n839         if config.convert_wrong_length_to_UN:\n840             warnings.warn(f\"{message} Setting VR to 'UN'.\")\n841             VR = \"UN\"\n842             value = raw.value\n843         else:\n844             raise BytesLengthException(\n845                 f\"{message} To replace this error with a warning set \"\n846                 \"pydicom.config.convert_wrong_length_to_UN = True.\"\n847             )\n848 \n849     if raw.tag in _LUT_DESCRIPTOR_TAGS and value:\n850         # We only fix the first value as the third value is 8 or 16\n851         try:\n852             if value[0] < 0:\n853                 value[0] += 65536\n854         except TypeError:\n855             pass\n856 \n857     return DataElement(raw.tag, VR, value, raw.value_tell,\n858                        raw.length == 0xFFFFFFFF, already_converted=True)\n859 \n[end of pydicom/dataelem.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pydicom/pydicom", "base_commit": "c14bf96040e4cc930db890638b9f190d4ede0a21", "problem_statement": "Pickling/unpickling timezone in DT does not work\n**Describe the bug**\r\n\r\nThe following tests fail because the timezone is not set in the unpickled `DT`:\r\n```py\r\n    def test_pickling_with_timezone():\r\n        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n\r\n    def test_pickling_dt_from_datetime_with_timezone():\r\n        tz_info = timezone(timedelta(seconds=-23400), '-0630')\r\n        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\r\n        dt = pydicom.valuerep.DT(dt_object)\r\n        loaded_dt = pickle.loads(pickle.dumps(dt))\r\n        assert dt == loaded_dt\r\n```\r\n\r\nThis is a spin-off of PR #1365, see [this comment](https://github.com/pydicom/pydicom/pull/1365#issuecomment-829544827).\n", "hints_text": "", "created_at": "2021-05-03T18:27:35Z", "patch": "<patch>\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -2,23 +2,19 @@\n \"\"\"Special classes for DICOM value representations (VR)\"\"\"\n \n import datetime\n-from decimal import Decimal\n-from math import floor, isfinite, log10\n-import platform\n import re\n import sys\n+import warnings\n+from decimal import Decimal\n+from math import floor, isfinite, log10\n+from typing import Sequence as SequenceType\n from typing import (\n-    TypeVar, Type, Tuple, Optional, List, Dict, Union, Any, Generator, AnyStr,\n-    Callable, Iterator, overload\n+    TypeVar, Type, Tuple, Optional, List, Dict, Union, Any, Generator, Callable\n )\n-from typing import Sequence as SequenceType\n-import warnings\n \n # don't import datetime_conversion directly\n from pydicom import config\n from pydicom.multival import MultiValue\n-from pydicom.uid import UID\n-\n \n # Types\n _T = TypeVar('_T')\n@@ -84,23 +80,23 @@ class DA(_DateTimeBase, datetime.date):\n \n     Note that the :class:`datetime.date` base class is immutable.\n     \"\"\"\n-    def __new__(\n-        cls: Type[_DA], val: Union[None, str, _DA, datetime.date]\n-    ) -> Optional[_DA]:\n+    def __new__(cls: Type[_DA], *args, **kwargs) -> Optional[_DA]:\n         \"\"\"Create an instance of DA object.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the DA definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.date`, or the first argument is\n+        a string conformant to the DA definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.date` object, or an object of type\n+        :class:`~pydicom.valuerep.DA`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None  # empty date\n@@ -123,14 +119,15 @@ def __new__(\n             return super().__new__(cls, val.year, val.month, val.day)\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'DA' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _DA, datetime.date]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n         \"\"\"Create a new **DA** element value.\"\"\"\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, DA) and hasattr(val, 'original_string'):\n@@ -171,23 +168,23 @@ def _utc_offset(value: str) -> datetime.timezone:\n             name=value\n         )\n \n-    def __new__(\n-        cls: Type[_DT], val: Union[None, str, _DT, datetime.datetime]\n-    ) -> Optional[_DT]:\n+    def __new__(cls: Type[_DT], *args, **kwargs) -> Optional[_DT]:\n         \"\"\"Create an instance of DT object.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the DT definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.datetime`, or the first argument is\n+        a string conformant to the DT definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.datetime` object, or an object of type\n+        :class:`~pydicom.valuerep.DT`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None\n@@ -233,13 +230,15 @@ def __new__(\n             )\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'DT' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _DT, datetime.datetime]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n+        \"\"\"Create a new **DT** element value.\"\"\"\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, DT) and hasattr(val, 'original_string'):\n@@ -274,23 +273,23 @@ class TM(_DateTimeBase, datetime.time):\n         r\"(?(7)(\\.(?P<ms>([0-9]{1,6})?))?))$\"\n     )\n \n-    def __new__(\n-        cls: Type[_TM], val: Union[None, str, _TM, datetime.time]\n-    ) -> Optional[_TM]:\n+    def __new__(cls: Type[_TM], *args, **kwargs) -> Optional[_TM]:\n         \"\"\"Create an instance of TM object from a string.\n \n         Raise an exception if the string cannot be parsed or the argument\n         is otherwise incompatible.\n \n-        Parameters\n-        ----------\n-        val : str\n-            A string conformant to the TM definition in the DICOM Standard,\n-            Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`.\n+        The arguments (``*args`` and ``**kwargs``) are either the ones\n+        inherited from :class:`datetime.time`, or the first argument is\n+        a string conformant to the TM definition in the DICOM Standard,\n+        Part 5, :dcm:`Table 6.2-1<part05/sect_6.2.html#table_6.2-1>`,\n+        or it is a :class:`datetime.time` object, or an object of type\n+        :class:`~pydicom.valuerep.TM`.\n         \"\"\"\n-        if val is None:\n+        if not args or args[0] is None:\n             return None\n \n+        val = args[0]\n         if isinstance(val, str):\n             if val.strip() == '':\n                 return None  # empty time\n@@ -325,13 +324,15 @@ def __new__(\n             )\n \n         try:\n-            return super().__new__(cls, val)\n+            return super().__new__(cls, *args, **kwargs)\n         except Exception as exc:\n             raise ValueError(\n                 f\"Unable to convert '{val}' to 'TM' object\"\n             ) from exc\n \n-    def __init__(self, val: Union[str, _TM, datetime.time]) -> None:\n+    def __init__(self, *args, **kwargs) -> None:\n+        super().__init__()\n+        val = args[0]\n         if isinstance(val, str):\n             self.original_string = val\n         elif isinstance(val, TM) and hasattr(val, 'original_string'):\n@@ -344,16 +345,6 @@ def __init__(self, val: Union[str, _TM, datetime.time]) -> None:\n             if val.microsecond > 0:\n                 self.original_string += f\".{val.microsecond:06}\"\n \n-    if platform.python_implementation() == \"PyPy\":\n-        # Workaround for CPython/PyPy bug in time.__reduce_ex__()\n-        #   caused by returning (time, ...) rather than (self.__class__, ...)\n-        def __reduce_ex__(self, protocol: int) -> Union[str, Tuple[Any, ...]]:\n-            return (\n-                self.__class__,\n-                super()._getstate(protocol),\n-                self.__getstate__()\n-            )\n-\n \n # Regex to match strings that represent valid DICOM decimal strings (DS)\n _DS_REGEX = re.compile(r'\\s*[\\+\\-]?\\d+(\\.\\d+)?([eE][\\+\\-]?\\d+)?\\s*$')\n\n</patch>", "test_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -5,10 +5,7 @@\n import copy\n from datetime import datetime, date, time, timedelta, timezone\n from decimal import Decimal\n-try:\n-    import cPickle as pickle\n-except ImportError:\n-    import pickle\n+import pickle\n import math\n import sys\n from typing import Union\n@@ -17,7 +14,6 @@\n from pydicom.values import convert_value\n \n import pydicom\n-import platform\n from pydicom import config\n from pydicom import valuerep\n from pydicom.data import get_testdata_file\n@@ -56,68 +52,70 @@ class TestTM:\n     \"\"\"Unit tests for pickling TM\"\"\"\n     def test_pickling(self):\n         # Check that a pickled TM is read back properly\n-        x = pydicom.valuerep.TM(\"212223\")\n-        assert time(21, 22, 23) == x\n-        x.original_string = \"hello\"\n-        assert \"hello\" == x.original_string\n-        assert time(21, 22, 23) == x\n-        data1_string = pickle.dumps(x)\n-        x2 = pickle.loads(data1_string)\n-        assert x == x2\n-        assert x.original_string == x2.original_string\n-        assert str(x) == str(x2)\n-\n-    def test_str(self):\n-        \"\"\"Test str(TM).\"\"\"\n-        assert \"212223.1234\" == str(pydicom.valuerep.TM(\"212223.1234\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(\"212223\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(\"212223\"))\n-        assert \"2122\" == str(pydicom.valuerep.TM(\"2122\"))\n-        assert \"21\" == str(pydicom.valuerep.TM(\"21\"))\n-        assert \"212223\" == str(pydicom.valuerep.TM(time(21, 22, 23)))\n-        assert \"212223.000024\" == str(\n-            pydicom.valuerep.TM(time(21, 22, 23, 24)))\n-        assert \"010203\" == str(pydicom.valuerep.TM(time(1, 2, 3)))\n+        tm = pydicom.valuerep.TM(\"212223\")\n+        assert tm == time(21, 22, 23)\n+        assert tm.original_string == \"212223\"\n+        assert tm == time(21, 22, 23)\n+        loaded_tm = pickle.loads(pickle.dumps(tm))\n+        assert loaded_tm == tm\n+        assert loaded_tm.original_string == tm.original_string\n+        assert str(loaded_tm) == str(tm)\n+\n+    def test_pickling_tm_from_time(self):\n+        tm = pydicom.valuerep.TM(time(21, 22, 23))\n+        assert tm.original_string == \"212223\"\n+        time_string = pickle.dumps(tm)\n+        loaded_tm = pickle.loads(time_string)\n+        assert loaded_tm == tm\n+        assert loaded_tm.original_string == tm.original_string\n+        assert str(loaded_tm) == str(tm)\n+\n+    def test_str_and_repr(self):\n+        assert str(pydicom.valuerep.TM(\"212223.1234\")) == \"212223.1234\"\n+        assert repr(pydicom.valuerep.TM(\"212223.1234\")) == '\"212223.1234\"'\n+        assert str(pydicom.valuerep.TM(\"212223\")) == \"212223\"\n+        assert repr(pydicom.valuerep.TM(\"212223\")) == '\"212223\"'\n+        assert str(pydicom.valuerep.TM(\"2122\")) == \"2122\"\n+        assert repr(pydicom.valuerep.TM(\"2122\")) == '\"2122\"'\n+        assert str(pydicom.valuerep.TM(\"21\")) == \"21\"\n+        assert str(pydicom.valuerep.TM(time(21, 22, 23))) == \"212223\"\n+        assert str(pydicom.valuerep.TM(\n+            time(21, 22, 23, 24))) == \"212223.000024\"\n+        assert str(pydicom.valuerep.TM(time(1, 2, 3))) == \"010203\"\n+        assert repr(pydicom.valuerep.TM(time(1, 2, 3))) == '\"010203\"'\n \n     def test_new_empty_str(self):\n         \"\"\"Test converting an empty string.\"\"\"\n-        x = pydicom.valuerep.TM('')\n-        assert x is None\n+        assert pydicom.valuerep.TM('') is None\n \n     def test_new_str_conversion(self):\n         \"\"\"Test converting strings to times.\"\"\"\n-        x = pydicom.valuerep.TM('00')\n-        assert \"00\" == str(x)\n-        assert time(0, 0, 0) == x\n-        x = pydicom.valuerep.TM('23')\n-        assert \"23\" == str(x)\n-        assert time(23, 0, 0) == x\n+        tm = pydicom.valuerep.TM('00')\n+        assert tm == time(0, 0, 0)\n+        tm = pydicom.valuerep.TM('23')\n+        assert tm == time(23, 0, 0)\n         msg = r\"Unable to convert non-conformant value '24' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM('24')\n \n-        x = pydicom.valuerep.TM('0000')\n-        assert \"0000\" == str(x)\n-        assert time(0, 0, 0) == x\n-        x = pydicom.valuerep.TM('2359')\n-        assert \"2359\" == str(x)\n-        assert time(23, 59, 0) == x\n+        tm = pydicom.valuerep.TM('0000')\n+        assert tm == time(0, 0, 0)\n+        tm = pydicom.valuerep.TM('2359')\n+        assert tm == time(23, 59, 0)\n         msg = r\"Unable to convert non-conformant value '2360' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM('2360')\n \n-        x = pydicom.valuerep.TM('000000')\n-        assert \"000000\" == str(x)\n-        assert time(0, 0, 0) == x\n+        tm = pydicom.valuerep.TM('000000')\n+        assert tm == time(0, 0, 0)\n         # Valid DICOM TM seconds range is 0..60, but time is 0..59\n         msg = (\n             r\"'datetime.time' doesn't allow a value of '60' for the \"\n             r\"seconds component, changing to '59'\"\n         )\n         with pytest.warns(UserWarning, match=msg):\n-            x = pydicom.valuerep.TM('235960')\n-        assert \"235960\" == str(x)\n-        assert time(23, 59, 59) == x\n+            tm = pydicom.valuerep.TM('235960')\n+        assert tm == time(23, 59, 59)\n \n         msg = r\"Unable to convert non-conformant value '235' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n@@ -126,45 +124,101 @@ def test_new_str_conversion(self):\n     def test_new_obj_conversion(self):\n         \"\"\"Test other conversion attempts.\"\"\"\n         assert pydicom.valuerep.TM(None) is None\n-        x = pydicom.valuerep.TM(\"010203.123456\")\n-        assert time(1, 2, 3, 123456) == pydicom.valuerep.TM(x)\n-        assert x == pydicom.valuerep.TM(x)\n-        x = pydicom.valuerep.TM(time(1, 2, 3))\n-        assert isinstance(x, pydicom.valuerep.TM)\n-        assert time(1, 2, 3) == x\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        assert pydicom.valuerep.TM(tm) == time(1, 2, 3, 123456)\n+        assert tm == pydicom.valuerep.TM(tm)\n+        tm = pydicom.valuerep.TM(time(1, 2, 3))\n+        assert isinstance(tm, pydicom.valuerep.TM)\n+        assert tm == time(1, 2, 3)\n \n         msg = r\"Unable to convert '123456' to 'TM' object\"\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.TM(123456)\n \n+    def test_comparison(self):\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        tm_object = time(1, 2, 3, 123456)\n+        assert tm == tm\n+        assert tm != 1\n+        assert tm == tm_object\n+        assert tm_object == tm\n+        assert hash(tm) == hash(tm_object)\n+        assert tm == pydicom.valuerep.TM(tm_object)\n+        assert tm < time(1, 2, 3, 123457)\n+        assert tm != time(1, 2, 3, 123457)\n+        assert tm < pydicom.valuerep.TM(time(1, 2, 3, 123457))\n+        assert tm <= time(1, 2, 3, 123457)\n+        assert tm <= tm_object\n+        assert tm > time(1, 2, 3)\n+        assert tm > pydicom.valuerep.TM(time(1, 2, 3))\n+        assert tm >= time(1, 2, 3)\n+        assert time(1, 2, 3, 123457) > tm\n+        assert tm_object >= tm\n+        assert time(1, 2, 3) < tm\n+        with pytest.raises(TypeError):\n+            tm > 5\n+\n+    def test_time_behavior(self):\n+        \"\"\"Test that TM behaves like time.\"\"\"\n+        tm = pydicom.valuerep.TM(\"010203.123456\")\n+        assert tm.hour == 1\n+        assert tm.second == 3\n+        assert tm.microsecond == 123456\n+        assert tm.replace(hour=23) == time(23, 2, 3, 123456)\n+        assert \"minute\" in dir(tm)\n+        assert \"original_string\" in dir(tm)\n+\n \n class TestDT:\n     \"\"\"Unit tests for pickling DT\"\"\"\n     def test_pickling(self):\n         # Check that a pickled DT is read back properly\n-        x = pydicom.valuerep.DT(\"19111213212123\")\n-        assert datetime(1911, 12, 13, 21, 21, 23) == x\n-        x.original_string = \"hello\"\n-        data1_string = pickle.dumps(x)\n-        x2 = pickle.loads(data1_string)\n-        assert x == x2\n-        assert x.original_string == x2.original_string\n-        assert str(x) == str(x2)\n+        dt = pydicom.valuerep.DT(\"19111213212123\")\n+        assert dt == datetime(1911, 12, 13, 21, 21, 23)\n+        data1_string = pickle.dumps(dt)\n+        loaded_dt = pickle.loads(data1_string)\n+        assert loaded_dt == dt\n+        assert dt.original_string == loaded_dt.original_string\n+        assert str(loaded_dt) == str(dt)\n+\n+    def test_pickling_with_timezone(self):\n+        dt = pydicom.valuerep.DT(\"19111213212123-0630\")\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert loaded_dt == dt\n+        assert loaded_dt.original_string == dt.original_string\n+        assert str(loaded_dt) == str(dt)\n+\n+    def test_pickling_dt_from_datetime(self):\n+        dt = pydicom.valuerep.DT(datetime(2222, 11, 23, 1, 2, 3, 4))\n+        assert dt.original_string == \"22221123010203.000004\"\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert loaded_dt == dt\n+        assert loaded_dt.original_string == dt.original_string\n+        assert str(dt) == str(loaded_dt)\n+\n+    def test_pickling_dt_from_datetime_with_timezone(self):\n+        tz_info = timezone(timedelta(seconds=-23400), '-0630')\n+        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n+        dt = pydicom.valuerep.DT(dt_object)\n+        assert dt.original_string == \"20221231235959.000042-0630\"\n+        loaded_dt = pickle.loads(pickle.dumps(dt))\n+        assert dt == loaded_dt\n+        assert dt.original_string == loaded_dt.original_string\n+        assert str(dt) == str(loaded_dt)\n \n     def test_new_empty_str(self):\n         \"\"\"Test converting an empty string.\"\"\"\n-        x = pydicom.valuerep.DT('')\n-        assert x is None\n+        assert pydicom.valuerep.DT('') is None\n \n     def test_new_obj_conversion(self):\n         \"\"\"Test other conversion attempts.\"\"\"\n         assert pydicom.valuerep.DT(None) is None\n-        x = pydicom.valuerep.DT(\"10010203\")\n-        assert datetime(1001, 2, 3) == pydicom.valuerep.DT(x)\n-        assert x == pydicom.valuerep.DT(x)\n-        x = pydicom.valuerep.DT(datetime(1001, 2, 3))\n-        assert isinstance(x, pydicom.valuerep.DT)\n-        assert datetime(1001, 2, 3) == x\n+        dt = pydicom.valuerep.DT(\"10010203\")\n+        assert pydicom.valuerep.DT(dt) == datetime(1001, 2, 3)\n+        assert dt == pydicom.valuerep.DT(dt)\n+        dt = pydicom.valuerep.DT(datetime(1001, 2, 3))\n+        assert isinstance(dt, pydicom.valuerep.DT)\n+        assert dt == datetime(1001, 2, 3)\n \n         msg = r\"Unable to convert '123456' to 'DT' object\"\n         with pytest.raises(ValueError, match=msg):\n@@ -178,9 +232,9 @@ def test_new_str_conversion(self):\n             r\"seconds component, changing to '59'\"\n         )\n         with pytest.warns(UserWarning, match=msg):\n-            x = pydicom.valuerep.DT('20010101235960')\n-        assert \"20010101235960\" == str(x)\n-        assert datetime(2001, 1, 1, 23, 59, 59) == x\n+            dt = pydicom.valuerep.DT('20010101235960')\n+        assert str(dt) == \"20010101235960\"\n+        assert dt == datetime(2001, 1, 1, 23, 59, 59)\n \n         msg = (\n             r\"Unable to convert non-conformant value 'a2000,00,00' to 'DT' \"\n@@ -189,17 +243,61 @@ def test_new_str_conversion(self):\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.DT(\"a2000,00,00\")\n \n-    def test_str(self):\n+    def test_str_and_repr(self):\n         dt = datetime(1911, 12, 13, 21, 21, 23)\n-        assert \"19111213212123\" == str(pydicom.valuerep.DT(dt))\n-        assert \"19111213212123\" == str(pydicom.valuerep.DT(\"19111213212123\"))\n-        assert \"1001.02.03\" == str(pydicom.valuerep.DA(\"1001.02.03\"))\n+        assert str(pydicom.valuerep.DT(dt)) == \"19111213212123\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"19111213212123\"'\n+        assert str(pydicom.valuerep.DT(\"19111213212123\")) == \"19111213212123\"\n+        assert str(pydicom.valuerep.DA(\"1001.02.03\")) == \"1001.02.03\"\n+        assert repr(pydicom.valuerep.DA(\"1001.02.03\")) == '\"1001.02.03\"'\n         tz_info = timezone(timedelta(seconds=21600), '+0600')\n         dt = datetime(2022, 1, 2, 8, 9, 7, 123456, tzinfo=tz_info)\n-        assert \"20220102080907.123456+0600\" == str(pydicom.valuerep.DT(dt))\n+        assert str(pydicom.valuerep.DT(dt)) == \"20220102080907.123456+0600\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"20220102080907.123456+0600\"'\n         tz_info = timezone(timedelta(seconds=-23400), '-0630')\n         dt = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n-        assert \"20221231235959.000042-0630\" == str(pydicom.valuerep.DT(dt))\n+        assert str(pydicom.valuerep.DT(dt)) == \"20221231235959.000042-0630\"\n+        assert repr(pydicom.valuerep.DT(dt)) == '\"20221231235959.000042-0630\"'\n+\n+    def test_comparison(self):\n+        dt = pydicom.valuerep.DT(\"19111213212123\")\n+        dt_object = datetime(1911, 12, 13, 21, 21, 23)\n+        assert dt == dt\n+        assert dt != 1\n+        assert dt == dt_object\n+        assert dt_object == dt\n+        assert hash(dt) == hash(dt_object)\n+        assert dt == pydicom.valuerep.DT(dt_object)\n+        assert dt < datetime(1911, 12, 13, 21, 21, 23, 123)\n+        assert dt != datetime(1911, 12, 13, 21, 21, 24)\n+        assert dt < pydicom.valuerep.DT(datetime(1911, 12, 13, 21, 21, 24))\n+        assert dt <= datetime(1911, 12, 13, 21, 21, 23)\n+        assert dt <= dt_object\n+        assert dt > datetime(1911, 12, 13, 21, 21, 22)\n+        assert dt > pydicom.valuerep.DT(datetime(1911, 12, 13, 21, 21, 22))\n+        assert dt >= datetime(1911, 12, 13, 21, 21, 23)\n+        assert datetime(1911, 12, 13, 21, 21, 24) > dt\n+        assert dt_object >= dt\n+        assert datetime(1911, 12, 13, 21, 21, 22) < dt\n+        with pytest.raises(TypeError):\n+            dt > 5\n+\n+    def test_datetime_behavior(self):\n+        \"\"\"Test that DT behaves like datetime.\"\"\"\n+        tz_info = timezone(timedelta(seconds=-23400), '-0630')\n+        dt_object = datetime(2022, 12, 31, 23, 59, 59, 42, tzinfo=tz_info)\n+        dt = pydicom.valuerep.DT(dt_object)\n+        assert dt == dt_object\n+        assert dt_object == dt\n+        assert dt.year == 2022\n+        assert dt.month == 12\n+        assert dt.hour == 23\n+        assert dt.second == 59\n+        assert dt.microsecond == 42\n+        assert dt.tzinfo == tz_info\n+        assert dt.today().date() == dt_object.today().date()\n+        assert \"hour\" in dir(dt)\n+        assert \"original_string\" in dir(dt)\n \n \n class TestDA:\n@@ -229,10 +327,48 @@ def test_new_obj_conversion(self):\n         with pytest.raises(ValueError, match=msg):\n             pydicom.valuerep.DA(123456)\n \n-    def test_str(self):\n-        assert \"10010203\" == str(pydicom.valuerep.DA(date(1001, 2, 3)))\n-        assert \"10010203\" == str(pydicom.valuerep.DA(\"10010203\"))\n-        assert \"1001.02.03\" == str(pydicom.valuerep.DA(\"1001.02.03\"))\n+    def test_str_and_repr(self):\n+        assert str(pydicom.valuerep.DA(date(1001, 2, 3))) == \"10010203\"\n+        assert repr(pydicom.valuerep.DA(date(1001, 2, 3))) == '\"10010203\"'\n+        assert str(pydicom.valuerep.DA(\"10010203\")) == \"10010203\"\n+        assert repr(pydicom.valuerep.DA(\"10010203\")) == '\"10010203\"'\n+        assert str(pydicom.valuerep.DA(\"1001.02.03\")) == \"1001.02.03\"\n+        assert repr(pydicom.valuerep.DA(\"1001.02.03\")) == '\"1001.02.03\"'\n+\n+    def test_comparison(self):\n+        da = pydicom.valuerep.DA(\"19111213\")\n+        da_object = date(1911, 12, 13)\n+        assert da == da\n+        assert da != 1\n+        assert da == da_object\n+        assert hash(da) == hash(da_object)\n+        assert da_object == da\n+        assert da == pydicom.valuerep.DA(da_object)\n+        assert da < date(1911, 12, 14)\n+        assert da != date(1901, 12, 13)\n+        assert da < pydicom.valuerep.DA(date(1912, 12, 13))\n+        assert da <= date(1911, 12, 13)\n+        assert da <= da_object\n+        assert da > date(1911, 12, 12)\n+        assert da > pydicom.valuerep.DA(date(1911, 12, 12))\n+        assert da >= date(1911, 12, 13)\n+        assert date(1911, 12, 14) > da\n+        assert da_object >= da\n+        assert date(1911, 12, 12) < da\n+        with pytest.raises(TypeError):\n+            da > 5\n+\n+    def test_date_behavior(self):\n+        da = pydicom.valuerep.DA(\"10010203\")\n+        da_object = date(1001, 2, 3)\n+        assert da == da_object\n+        assert da_object == da\n+        assert da.year == 1001\n+        assert da.month == 2\n+        assert da.day == 3\n+        assert da.today() == da_object.today()\n+        assert \"day\" in dir(da)\n+        assert \"original_string\" in dir(da)\n \n \n class TestIsValidDS:\n@@ -338,8 +474,8 @@ def test_invalid(self, val: float):\n     def test_wrong_type(self):\n         \"\"\"Test calling with a string raises an error\"\"\"\n         with pytest.raises(\n-            TypeError,\n-            match=\"'val' must be of type float or decimal.Decimal\"\n+                TypeError,\n+                match=\"'val' must be of type float or decimal.Decimal\"\n         ):\n             pydicom.valuerep.format_number_as_ds('1.0')\n \n@@ -470,9 +606,9 @@ def test_DSfloat_auto_format(self):\n         ]\n     )\n     def test_enforce_valid_values_value(\n-        self,\n-        val: Union[float, str],\n-        enforce_valid_true_fixture\n+            self,\n+            val: Union[float, str],\n+            enforce_valid_true_fixture\n     ):\n         \"\"\"Test that errors are raised when value is invalid.\"\"\"\n         with pytest.raises(ValueError):\n@@ -568,9 +704,9 @@ def test_auto_format_invalid_string(self, enforce_valid_both_fixture):\n         ]\n     )\n     def test_enforce_valid_values_value(\n-        self,\n-        val: Union[Decimal, str],\n-        enforce_valid_true_fixture\n+            self,\n+            val: Union[Decimal, str],\n+            enforce_valid_true_fixture\n     ):\n         \"\"\"Test that errors are raised when value is invalid.\"\"\"\n         with pytest.raises(ValueError):\n", "version": "2.1", "FAIL_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestDT::test_pickling_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime_with_timezone\", \"pydicom/tests/test_valuerep.py::TestDT::test_datetime_behavior\", \"pydicom/tests/test_valuerep.py::TestDA::test_date_behavior\"]", "PASS_TO_PASS": "[\"pydicom/tests/test_valuerep.py::TestTM::test_pickling\", \"pydicom/tests/test_valuerep.py::TestTM::test_pickling_tm_from_time\", \"pydicom/tests/test_valuerep.py::TestTM::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestTM::test_comparison\", \"pydicom/tests/test_valuerep.py::TestTM::test_time_behavior\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDT::test_pickling_dt_from_datetime\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_new_str_conversion\", \"pydicom/tests/test_valuerep.py::TestDT::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDT::test_comparison\", \"pydicom/tests/test_valuerep.py::TestDA::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDA::test_new_obj_conversion\", \"pydicom/tests/test_valuerep.py::TestDA::test_str_and_repr\", \"pydicom/tests/test_valuerep.py::TestDA::test_comparison\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[-1234.456e78]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E-5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[1.234E+5]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[+1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_valid[42\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[nan]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[3.141592653589793]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1,000]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[127.0.0.1]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[1.e]\", \"pydicom/tests/test_valuerep.py::TestIsValidDS::test_invalid[]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.0-1.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.0-0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.0--0.0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[0.123-0.123]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-0.321--0.321]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1e-05-1e-05]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[3.141592653589793-3.14159265358979]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-3.141592653589793--3.1415926535898]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[5.385940192876374e-07-5.3859401929e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[-5.385940192876374e-07--5.385940193e-07]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[12342534378.125532-12342534378.1255]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[64070869985876.78-64070869985876.8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_auto_format[1.7976931348623157e+308-1.797693135e+308]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[100]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[101]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[-1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[2]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[3]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[4]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[5]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[6]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[7]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[8]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[9]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[10]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[11]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[12]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[13]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[14]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[15]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_powers_of_negative_pi[16]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan0]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[nan1]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[-inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_invalid[inf]\", \"pydicom/tests/test_valuerep.py::TestTruncateFloatForDS::test_wrong_type\", \"pydicom/tests/test_valuerep.py::TestDS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestDS::test_float_values\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_str\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_length\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_DSfloat_auto_format\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-nan]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf0]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[nan2]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[-inf1]\", \"pydicom/tests/test_valuerep.py::TestDSfloat::test_enforce_valid_values_value[inf1]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_pickling\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_float_value\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_new_empty_str\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSfloat\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_repr\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_from_invalid_DS\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_invalid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-NaN]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[-Infinity]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val4]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val5]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val6]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_enforce_valid_values_value[val7]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[True]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_auto_format_valid_string[False]\", \"pydicom/tests/test_valuerep.py::TestDSdecimal::test_DSdecimal_auto_format\", \"pydicom/tests/test_valuerep.py::TestIS::test_empty_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_valid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_invalid_value\", \"pydicom/tests/test_valuerep.py::TestIS::test_pickling\", \"pydicom/tests/test_valuerep.py::TestIS::test_longint\", \"pydicom/tests/test_valuerep.py::TestIS::test_overflow\", \"pydicom/tests/test_valuerep.py::TestIS::test_str\", \"pydicom/tests/test_valuerep.py::TestIS::test_repr\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_default\", \"pydicom/tests/test_valuerep.py::TestBadValueRead::test_read_bad_value_in_VR_enforce_valid_value\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_DS_decimal_set\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_valid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestDecimalString::test_invalid_decimal_strings\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_last_first\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_copy\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_three_component\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_formatting\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_kr\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_comp_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_bytes_caret_delimiter\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_unicode_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_not_equal\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_encoding_carried\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_hash\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_next\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_iterator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_contains\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_kr_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_bytes\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_jp_from_unicode\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_veterinary\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator\", \"pydicom/tests/test_valuerep.py::TestPersonName::test_from_named_components_with_separator_from_bytes\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_date_time\", \"pydicom/tests/test_valuerep.py::TestDateTime::test_time\", \"pydicom/tests/test_valuerep.py::test_person_name_unicode_warns\"]", "environment_setup_commit": "506ecea8f378dc687d5c504788fc78810a190b7a"}
{"instance_id": "pvlib__pvlib-python-1218_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nchange eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n32       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n33     </a>\n34   </td>\n35 </tr>\n36 <tr>\n37   <td>Code Quality</td>\n38  \u00a0<td>\n39     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n40     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n41     </a>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n43     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Coverage</td>\n49  \u00a0<td>\n50     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n51     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n52     </a>\n53     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n54     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Publications</td>\n60   <td>\n61     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n62     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n63     </a>\n64     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n65     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n66     </a>\n67   </td>\n68 </tr>\n69 <tr>\n70   <td>Downloads</td>\n71   <td>\n72     <a href=\"https://pypi.org/project/pvlib/\">\n73     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n74     </a>\n75     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n76     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n77     </a>\n78   </td>\n79 </tr>\n80 </table>\n81 \n82 \n83 pvlib python is a community supported tool that provides a set of\n84 functions and classes for simulating the performance of photovoltaic\n85 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n86 toolbox developed at Sandia National Laboratories and it implements many\n87 of the models and methods developed at the Labs. More information on\n88 Sandia Labs PV performance modeling programs can be found at\n89 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n90 but operate independently of it.\n91 \n92 \n93 Documentation\n94 =============\n95 \n96 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n97 \n98 \n99 Installation\n100 ============\n101 \n102 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n103 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n104 \n105 \n106 Contributing\n107 ============\n108 \n109 We need your help to make pvlib-python a great tool!\n110 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n111 The long-term success of pvlib-python requires substantial community support.\n112 \n113 \n114 License\n115 =======\n116 \n117 BSD 3-clause\n118 \n119 \n120 Getting support\n121 ===============\n122 \n123 pvlib usage questions can be asked on\n124 [Stack Overflow](http://stackoverflow.com) and tagged with\n125 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n126 \n127 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n128 is used for discussing various topics of interest to the pvlib-python\n129 community. We also make new version announcements on the google group.\n130 \n131 If you suspect that you may have discovered a bug or if you'd like to\n132 change something about pvlib, then please make an issue on our\n133 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n134 \n135 \n136 Citing\n137 ======\n138 \n139 If you use pvlib-python in a published work, please cite:\n140 \n141   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n142   \"pvlib python: a python package for modeling solar energy systems.\"\n143   Journal of Open Source Software, 3(29), 884, (2018).\n144   https://doi.org/10.21105/joss.00884\n145 \n146 Please also cite the DOI corresponding to the specific version of\n147 pvlib-python that you used. pvlib-python DOIs are listed at\n148 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n149 \n150 NumFOCUS\n151 ========\n152 \n153 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n154 \n155 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n156 \n[end of README.md]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 import pandas as pd\n8 from pvlib.tools import sind\n9 \n10 TEMPERATURE_MODEL_PARAMETERS = {\n11     'sapm': {\n12         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n13         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n14         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n15         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n16     },\n17     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n18                'insulated': {'u_c': 15.0, 'u_v': 0}}\n19 }\n20 \"\"\"Dictionary of temperature parameters organized by model.\n21 \n22 There are keys for each model at the top level. Currently there are two models,\n23 ``'sapm'`` for the Sandia Array Performance Model, and ``'pvsyst'``. Each model\n24 has a dictionary of configurations; a value is itself a dictionary containing\n25 model parameters. Retrieve parameters by indexing the model and configuration\n26 by name. Note: the keys are lower-cased and case sensitive.\n27 \n28 Example\n29 -------\n30 Retrieve the open rack glass-polymer configuration for SAPM::\n31 \n32     from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n33     temperature_model_parameters = (\n34         TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'])\n35     # {'a': -3.56, 'b': -0.075, 'deltaT': 3}\n36 \"\"\"\n37 \n38 \n39 def _temperature_model_params(model, parameter_set):\n40     try:\n41         params = TEMPERATURE_MODEL_PARAMETERS[model]\n42         return params[parameter_set]\n43     except KeyError:\n44         msg = ('{} is not a named set of parameters for the {} cell'\n45                ' temperature model.'\n46                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n47                ' for names'.format(parameter_set, model))\n48         raise KeyError(msg)\n49 \n50 \n51 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n52               irrad_ref=1000.):\n53     r'''\n54     Calculate cell temperature per the Sandia Array Performance Model.\n55 \n56     See [1]_ for details on the Sandia Array Performance Model.\n57 \n58     Parameters\n59     ----------\n60     poa_global : numeric\n61         Total incident irradiance [W/m^2].\n62 \n63     temp_air : numeric\n64         Ambient dry bulb temperature [C].\n65 \n66     wind_speed : numeric\n67         Wind speed at a height of 10 meters [m/s].\n68 \n69     a : float\n70         Parameter :math:`a` in :eq:`sapm1`.\n71 \n72     b : float\n73         Parameter :math:`b` in :eq:`sapm1`.\n74 \n75     deltaT : float\n76         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n77 \n78     irrad_ref : float, default 1000\n79         Reference irradiance, parameter :math:`E_{0}` in\n80         :eq:`sapm2` [W/m^2].\n81 \n82     Returns\n83     -------\n84     numeric, values in degrees C.\n85 \n86     Notes\n87     -----\n88     The model for cell temperature :math:`T_{C}` is given by a pair of\n89     equations (Eq. 11 and 12 in [1]_).\n90 \n91     .. math::\n92        :label: sapm1\n93 \n94        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n95 \n96     .. math::\n97        :label: sapm2\n98 \n99        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n100 \n101     The module back surface temperature :math:`T_{m}` is implemented in\n102     :py:func:`~pvlib.temperature.sapm_module`.\n103 \n104     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n105     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n106     the module construction and its mounting. Parameter sets are provided in\n107     [1]_ for representative modules and mounting, and are coded for convenience\n108     in :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n109 \n110     +---------------+----------------+-------+---------+---------------------+\n111     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n112     +===============+================+=======+=========+=====================+\n113     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n114     +---------------+----------------+-------+---------+---------------------+\n115     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n116     +---------------+----------------+-------+---------+---------------------+\n117     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n118     +---------------+----------------+-------+---------+---------------------+\n119     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n120     +---------------+----------------+-------+---------+---------------------+\n121 \n122     References\n123     ----------\n124     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n125        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n126        NM.\n127 \n128     See also\n129     --------\n130     sapm_cell_from_module\n131     sapm_module\n132 \n133     Examples\n134     --------\n135     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n136     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n137     >>> sapm_cell(1000, 10, 0, **params)\n138     44.11703066106086\n139     '''\n140     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n141                                      a, b)\n142     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n143                                  irrad_ref)\n144 \n145 \n146 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n147     r'''\n148     Calculate module back surface temperature per the Sandia Array\n149     Performance Model.\n150 \n151     See [1]_ for details on the Sandia Array Performance Model.\n152 \n153     Parameters\n154     ----------\n155     poa_global : numeric\n156         Total incident irradiance [W/m^2].\n157 \n158     temp_air : numeric\n159         Ambient dry bulb temperature [C].\n160 \n161     wind_speed : numeric\n162         Wind speed at a height of 10 meters [m/s].\n163 \n164     a : float\n165         Parameter :math:`a` in :eq:`sapm1mod`.\n166 \n167     b : float\n168         Parameter :math:`b` in :eq:`sapm1mod`.\n169 \n170     Returns\n171     -------\n172     numeric, values in degrees C.\n173 \n174     Notes\n175     -----\n176     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n177 \n178     .. math::\n179        :label: sapm1mod\n180 \n181        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n182 \n183     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n184     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n185     temperature at the back of the module :math:`T_{m}` and cell temperature\n186     :math:`T_{C}`. Model parameters depend both on the module construction and\n187     its mounting. Parameter sets are provided in [1]_ for representative\n188     modules and mounting, and are coded for convenience in\n189     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n190 \n191     +---------------+----------------+-------+---------+---------------------+\n192     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n193     +===============+================+=======+=========+=====================+\n194     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n195     +---------------+----------------+-------+---------+---------------------+\n196     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n197     +---------------+----------------+-------+---------+---------------------+\n198     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n199     +---------------+----------------+-------+---------+---------------------+\n200     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n201     +---------------+----------------+-------+---------+---------------------+\n202 \n203     References\n204     ----------\n205     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n206        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n207        NM.\n208 \n209     See also\n210     --------\n211     sapm_cell\n212     sapm_cell_from_module\n213     '''\n214     return poa_global * np.exp(a + b * wind_speed) + temp_air\n215 \n216 \n217 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n218                           irrad_ref=1000.):\n219     r'''\n220     Calculate cell temperature from module temperature using the Sandia Array\n221     Performance Model.\n222 \n223     See [1]_ for details on the Sandia Array Performance Model.\n224 \n225     Parameters\n226     ----------\n227     module_temperature : numeric\n228         Temperature of back of module surface [C].\n229 \n230     poa_global : numeric\n231         Total incident irradiance [W/m^2].\n232 \n233     deltaT : float\n234         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n235 \n236     irrad_ref : float, default 1000\n237         Reference irradiance, parameter :math:`E_{0}` in\n238         :eq:`sapm2` [W/m^2].\n239 \n240     Returns\n241     -------\n242     numeric, values in degrees C.\n243 \n244     Notes\n245     -----\n246     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n247 \n248     .. math::\n249        :label: sapm2_cell_from_mod\n250 \n251        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n252 \n253     The module back surface temperature :math:`T_{m}` is implemented in\n254     :py:func:`~pvlib.temperature.sapm_module`.\n255 \n256     Model parameters depend both on the module construction and its mounting.\n257     Parameter sets are provided in [1]_ for representative modules and\n258     mounting, and are coded for convenience in\n259     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n260 \n261     +---------------+----------------+-------+---------+---------------------+\n262     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n263     +===============+================+=======+=========+=====================+\n264     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n265     +---------------+----------------+-------+---------+---------------------+\n266     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n267     +---------------+----------------+-------+---------+---------------------+\n268     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n269     +---------------+----------------+-------+---------+---------------------+\n270     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n271     +---------------+----------------+-------+---------+---------------------+\n272 \n273     References\n274     ----------\n275     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n276        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n277        NM.\n278 \n279     See also\n280     --------\n281     sapm_cell\n282     sapm_module\n283     '''\n284     return module_temperature + (poa_global / irrad_ref) * deltaT\n285 \n286 \n287 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n288                 eta_m=0.1, alpha_absorption=0.9):\n289     r\"\"\"\n290     Calculate cell temperature using an empirical heat loss factor model\n291     as implemented in PVsyst.\n292 \n293     Parameters\n294     ----------\n295     poa_global : numeric\n296         Total incident irradiance [W/m^2].\n297 \n298     temp_air : numeric\n299         Ambient dry bulb temperature [C].\n300 \n301     wind_speed : numeric, default 1.0\n302         Wind speed in m/s measured at the same height for which the wind loss\n303         factor was determined.  The default value 1.0 m/2 is the wind\n304         speed at module height used to determine NOCT. [m/s]\n305 \n306     u_c : float, default 29.0\n307         Combined heat loss factor coefficient. The default value is\n308         representative of freestanding modules with the rear surfaces exposed\n309         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n310         :eq:`pvsyst`.\n311         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n312 \n313     u_v : float, default 0.0\n314         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n315         in :eq:`pvsyst`.\n316         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n317 \n318     eta_m : numeric, default 0.1\n319         Module external efficiency as a fraction, i.e.,\n320         :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n321         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n322 \n323     alpha_absorption : numeric, default 0.9\n324         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n325 \n326     Returns\n327     -------\n328     numeric, values in degrees Celsius\n329 \n330     Notes\n331     -----\n332     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n333 \n334     .. math::\n335        :label: pvsyst\n336 \n337         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n338 \n339     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n340     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n341     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n342     the module construction and its mounting. Parameters are provided in\n343     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n344     , and are coded for convenience in\n345     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`. The heat loss\n346     factors provided represent the combined effect of convection, radiation and\n347     conduction, and their values are experimentally determined.\n348 \n349     +--------------+---------------+---------------+\n350     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n351     +==============+===============+===============+\n352     | freestanding | 29.0          | 0.0           |\n353     +--------------+---------------+---------------+\n354     | insulated    | 15.0          | 0.0           |\n355     +--------------+---------------+---------------+\n356 \n357     References\n358     ----------\n359     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n360        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n361 \n362     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n363        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n364 \n365     Examples\n366     --------\n367     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n368     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n369     >>> pvsyst_cell(1000, 10, **params)\n370     37.93103448275862\n371     \"\"\"\n372 \n373     total_loss_factor = u_c + u_v * wind_speed\n374     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n375     temp_difference = heat_input / total_loss_factor\n376     return temp_air + temp_difference\n377 \n378 \n379 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n380     r'''\n381     Calculate cell or module temperature using the Faiman model.\n382 \n383     The Faiman model uses an empirical heat loss factor model [1]_ and is\n384     adopted in the IEC 61853 standards [2]_ and [3]_.\n385 \n386     Usage of this model in the IEC 61853 standard does not distinguish\n387     between cell and module temperature.\n388 \n389     Parameters\n390     ----------\n391     poa_global : numeric\n392         Total incident irradiance [W/m^2].\n393 \n394     temp_air : numeric\n395         Ambient dry bulb temperature [C].\n396 \n397     wind_speed : numeric, default 1.0\n398         Wind speed in m/s measured at the same height for which the wind loss\n399         factor was determined.  The default value 1.0 m/s is the wind\n400         speed at module height used to determine NOCT. [m/s]\n401 \n402     u0 : numeric, default 25.0\n403         Combined heat loss factor coefficient. The default value is one\n404         determined by Faiman for 7 silicon modules.\n405         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n406 \n407     u1 : numeric, default 6.84\n408         Combined heat loss factor influenced by wind. The default value is one\n409         determined by Faiman for 7 silicon modules.\n410         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n411 \n412     Returns\n413     -------\n414     numeric, values in degrees Celsius\n415 \n416     Notes\n417     -----\n418     All arguments may be scalars or vectors. If multiple arguments\n419     are vectors they must be the same length.\n420 \n421     References\n422     ----------\n423     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n424        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n425 \n426     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n427        rating - Part 2: Spectral responsivity, incidence angle and module\n428        operating temperature measurements\". IEC, Geneva, 2018.\n429 \n430     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n431        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n432 \n433     '''\n434     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n435 \n436     # The following lines may seem odd since u0 & u1 are probably scalar,\n437     # but it serves an indirect and easy way of allowing lists and\n438     # tuples for the other function arguments.\n439     u0 = np.asanyarray(u0)\n440     u1 = np.asanyarray(u1)\n441 \n442     total_loss_factor = u0 + u1 * wind_speed\n443     heat_input = poa_global\n444     temp_difference = heat_input / total_loss_factor\n445     return temp_air + temp_difference\n446 \n447 \n448 def ross(poa_global, temp_air, noct):\n449     r'''\n450     Calculate cell temperature using the Ross model.\n451 \n452     The Ross model [1]_ assumes the difference between cell temperature\n453     and ambient temperature is proportional to the plane of array irradiance,\n454     and assumes wind speed of 1 m/s. The model implicitly assumes steady or\n455     slowly changing irradiance conditions.\n456 \n457     Parameters\n458     ----------\n459     poa_global : numeric\n460         Total incident irradiance. [W/m^2]\n461 \n462     temp_air : numeric\n463         Ambient dry bulb temperature. [C]\n464 \n465     noct : numeric\n466         Nominal operating cell temperature [C], determined at conditions of\n467         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n468 \n469     Returns\n470     -------\n471     cell_temperature : numeric\n472         Cell temperature. [C]\n473 \n474     Notes\n475     -----\n476     The Ross model for cell temperature :math:`T_{C}` is given in [1]_ as\n477 \n478     .. math::\n479 \n480         T_{C} = T_{a} + \\frac{NOCT - 20}{80} S\n481 \n482     where :math:`S` is the plane of array irradiance in :math:`mW/{cm}^2`.\n483     This function expects irradiance in :math:`W/m^2`.\n484 \n485     References\n486     ----------\n487     .. [1] Ross, R. G. Jr., (1981). \"Design Techniques for Flat-Plate\n488        Photovoltaic Arrays\". 15th IEEE Photovoltaic Specialist Conference,\n489        Orlando, FL.\n490     '''\n491     # factor of 0.1 converts irradiance from W/m2 to mW/cm2\n492     return temp_air + (noct - 20.) / 80. * poa_global * 0.1\n493 \n494 \n495 def _fuentes_hconv(tave, windmod, tinoct, temp_delta, xlen, tilt,\n496                    check_reynold):\n497     # Calculate the convective coefficient as in Fuentes 1987 -- a mixture of\n498     # free, laminar, and turbulent convection.\n499     densair = 0.003484 * 101325.0 / tave  # density\n500     visair = 0.24237e-6 * tave**0.76 / densair  # kinematic viscosity\n501     condair = 2.1695e-4 * tave**0.84  # thermal conductivity\n502     reynold = windmod * xlen / visair\n503     # the boundary between laminar and turbulent is modeled as an abrupt\n504     # change at Re = 1.2e5:\n505     if check_reynold and reynold > 1.2e5:\n506         # turbulent convection\n507         hforce = 0.0282 / reynold**0.2 * densair * windmod * 1007 / 0.71**0.4\n508     else:\n509         # laminar convection\n510         hforce = 0.8600 / reynold**0.5 * densair * windmod * 1007 / 0.71**0.67\n511     # free convection via Grashof number\n512     # NB: Fuentes hardwires sind(tilt) as 0.5 for tilt=30\n513     grashof = 9.8 / tave * temp_delta * xlen**3 / visair**2 * sind(tilt)\n514     # product of Nusselt number and (k/l)\n515     hfree = 0.21 * (grashof * 0.71)**0.32 * condair / xlen\n516     # combine free and forced components\n517     hconv = (hfree**3 + hforce**3)**(1/3)\n518     return hconv\n519 \n520 \n521 def _hydraulic_diameter(width, height):\n522     # calculate the hydraulic diameter of a rectangle\n523     return 2 * (width * height) / (width + height)\n524 \n525 \n526 def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n527             wind_height=9.144, emissivity=0.84, absorption=0.83,\n528             surface_tilt=30, module_width=0.31579, module_length=1.2):\n529     \"\"\"\n530     Calculate cell or module temperature using the Fuentes model.\n531 \n532     The Fuentes model is a first-principles heat transfer energy balance\n533     model [1]_ that is used in PVWatts for cell temperature modeling [2]_.\n534 \n535     Parameters\n536     ----------\n537     poa_global : pandas Series\n538         Total incident irradiance [W/m^2]\n539 \n540     temp_air : pandas Series\n541         Ambient dry bulb temperature [C]\n542 \n543     wind_speed : pandas Series\n544         Wind speed [m/s]\n545 \n546     noct_installed : float\n547         The \"installed\" nominal operating cell temperature as defined in [1]_.\n548         PVWatts assumes this value to be 45 C for rack-mounted arrays and\n549         49 C for roof mount systems with restricted air flow around the\n550         module.  [C]\n551 \n552     module_height : float, default 5.0\n553         The height above ground of the center of the module. The PVWatts\n554         default is 5.0 [m]\n555 \n556     wind_height : float, default 9.144\n557         The height above ground at which ``wind_speed`` is measured. The\n558         PVWatts defauls is 9.144 [m]\n559 \n560     emissivity : float, default 0.84\n561         The effectiveness of the module at radiating thermal energy. [unitless]\n562 \n563     absorption : float, default 0.83\n564         The fraction of incident irradiance that is converted to thermal\n565         energy in the module. [unitless]\n566 \n567     surface_tilt : float, default 30\n568         Module tilt from horizontal. If not provided, the default value\n569         of 30 degrees from [1]_ and [2]_ is used. [degrees]\n570 \n571     module_width : float, default 0.31579\n572         Module width. The default value of 0.31579 meters in combination with\n573         the default `module_length` gives a hydraulic diameter of 0.5 as\n574         assumed in [1]_ and [2]_. [m]\n575 \n576     module_length : float, default 1.2\n577         Module length. The default value of 1.2 meters in combination with\n578         the default `module_width` gives a hydraulic diameter of 0.5 as\n579         assumed in [1]_ and [2]_. [m]\n580 \n581     Returns\n582     -------\n583     temperature_cell : pandas Series\n584         The modeled cell temperature [C]\n585 \n586     Notes\n587     -----\n588     This function returns slightly different values from PVWatts at night\n589     and just after dawn. This is because the SAM SSC assumes that module\n590     temperature equals ambient temperature when irradiance is zero so it can\n591     skip the heat balance calculation at night.\n592 \n593     References\n594     ----------\n595     .. [1] Fuentes, M. K., 1987, \"A Simplifed Thermal Model for Flat-Plate\n596            Photovoltaic Arrays\", SAND85-0330, Sandia National Laboratories,\n597            Albuquerque NM.\n598            http://prod.sandia.gov/techlib/access-control.cgi/1985/850330.pdf\n599     .. [2] Dobos, A. P., 2014, \"PVWatts Version 5 Manual\", NREL/TP-6A20-62641,\n600            National Renewable Energy Laboratory, Golden CO.\n601            doi:10.2172/1158421.\n602     \"\"\"\n603     # ported from the FORTRAN77 code provided in Appendix A of Fuentes 1987;\n604     # nearly all variable names are kept the same for ease of comparison.\n605 \n606     boltz = 5.669e-8\n607     emiss = emissivity\n608     absorp = absorption\n609     xlen = _hydraulic_diameter(module_width, module_length)\n610     # cap0 has units of [J / (m^2 K)], equal to mass per unit area times\n611     # specific heat of the module.\n612     cap0 = 11000\n613     tinoct = noct_installed + 273.15\n614 \n615     # convective coefficient of top surface of module at NOCT\n616     windmod = 1.0\n617     tave = (tinoct + 293.15) / 2\n618     hconv = _fuentes_hconv(tave, windmod, tinoct, tinoct - 293.15, xlen,\n619                            surface_tilt, False)\n620 \n621     # determine the ground temperature ratio and the ratio of the total\n622     # convection to the top side convection\n623     hground = emiss * boltz * (tinoct**2 + 293.15**2) * (tinoct + 293.15)\n624     backrat = (\n625         absorp * 800.0\n626         - emiss * boltz * (tinoct**4 - 282.21**4)\n627         - hconv * (tinoct - 293.15)\n628     ) / ((hground + hconv) * (tinoct - 293.15))\n629     tground = (tinoct**4 - backrat * (tinoct**4 - 293.15**4))**0.25\n630     tground = np.clip(tground, 293.15, tinoct)\n631 \n632     tgrat = (tground - 293.15) / (tinoct - 293.15)\n633     convrat = (absorp * 800 - emiss * boltz * (\n634         2 * tinoct**4 - 282.21**4 - tground**4)) / (hconv * (tinoct - 293.15))\n635 \n636     # adjust the capacitance (thermal mass) of the module based on the INOCT.\n637     # It is a function of INOCT because high INOCT implies thermal coupling\n638     # with the racking (e.g. roofmount), so the thermal mass is increased.\n639     # `cap` has units J/(m^2 C) -- see Table 3, Equations 26 & 27\n640     cap = cap0\n641     if tinoct > 321.15:\n642         cap = cap * (1 + (tinoct - 321.15) / 12)\n643 \n644     # iterate through timeseries inputs\n645     sun0 = 0\n646     tmod0 = 293.15\n647 \n648     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n649     # the value doesn't matter -- rather than recreate it here, just assume\n650     # it's the same as the second timedelta:\n651     timedelta_seconds = poa_global.index.to_series().diff().dt.total_seconds()\n652     timedelta_hours = timedelta_seconds / 3600\n653     timedelta_hours.iloc[0] = timedelta_hours.iloc[1]\n654 \n655     tamb_array = temp_air + 273.15\n656     sun_array = poa_global * absorp\n657 \n658     # Two of the calculations are easily vectorized, so precalculate them:\n659     # sky temperature -- Equation 24\n660     tsky_array = 0.68 * (0.0552 * tamb_array**1.5) + 0.32 * tamb_array\n661     # wind speed at module height -- Equation 22\n662     # not sure why the 1e-4 factor is included -- maybe the equations don't\n663     # behave well if wind == 0?\n664     windmod_array = wind_speed * (module_height/wind_height)**0.2 + 1e-4\n665 \n666     tmod0 = 293.15\n667     tmod_array = np.zeros_like(poa_global)\n668 \n669     iterator = zip(tamb_array, sun_array, windmod_array, tsky_array,\n670                    timedelta_hours)\n671     for i, (tamb, sun, windmod, tsky, dtime) in enumerate(iterator):\n672         # solve the heat transfer equation, iterating because the heat loss\n673         # terms depend on tmod. NB Fuentes doesn't show that 10 iterations is\n674         # sufficient for convergence.\n675         tmod = tmod0\n676         for j in range(10):\n677             # overall convective coefficient\n678             tave = (tmod + tamb) / 2\n679             hconv = convrat * _fuentes_hconv(tave, windmod, tinoct,\n680                                              abs(tmod-tamb), xlen,\n681                                              surface_tilt, True)\n682             # sky radiation coefficient (Equation 3)\n683             hsky = emiss * boltz * (tmod**2 + tsky**2) * (tmod + tsky)\n684             # ground radiation coeffieicient (Equation 4)\n685             tground = tamb + tgrat * (tmod - tamb)\n686             hground = emiss * boltz * (tmod**2 + tground**2) * (tmod + tground)\n687             # thermal lag -- Equation 8\n688             eigen = - (hconv + hsky + hground) / cap * dtime * 3600\n689             # not sure why this check is done, maybe as a speed optimization?\n690             if eigen > -10:\n691                 ex = np.exp(eigen)\n692             else:\n693                 ex = 0\n694             # Equation 7 -- note that `sun` and `sun0` already account for\n695             # absorption (alpha)\n696             tmod = tmod0 * ex + (\n697                 (1 - ex) * (\n698                     hconv * tamb\n699                     + hsky * tsky\n700                     + hground * tground\n701                     + sun0\n702                     + (sun - sun0) / eigen\n703                 ) + sun - sun0\n704             ) / (hconv + hsky + hground)\n705         tmod_array[i] = tmod\n706         tmod0 = tmod\n707         sun0 = sun\n708 \n709     return pd.Series(tmod_array - 273.15, index=poa_global.index, name='tmod')\n710 \n711 \n712 def _adj_for_mounting_standoff(x):\n713     # supports noct cell temperature function. Except for x > 3.5, the SAM code\n714     # and documentation aren't clear on the precise intervals. The choice of\n715     # < or <= here is pvlib's.\n716     return np.piecewise(x, [x <= 0, (x > 0) & (x < 0.5),\n717                             (x >= 0.5) & (x < 1.5), (x >= 1.5) & (x < 2.5),\n718                             (x >= 2.5) & (x <= 3.5), x > 3.5],\n719                         [0., 18., 11., 6., 2., 0.])\n720 \n721 \n722 def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n723              effective_irradiance=None, transmittance_absorptance=0.9,\n724              array_height=1, mount_standoff=4):\n725     r'''\n726     Cell temperature model from the System Advisor Model (SAM).\n727 \n728     The model is described in [1]_, Section 10.6.\n729 \n730     Parameters\n731     ----------\n732     poa_global : numeric\n733         Total incident irradiance. [W/m^2]\n734 \n735     temp_air : numeric\n736         Ambient dry bulb temperature. [C]\n737 \n738     wind_speed : numeric\n739         Wind speed in m/s measured at the same height for which the wind loss\n740         factor was determined.  The default value 1.0 m/s is the wind\n741         speed at module height used to determine NOCT. [m/s]\n742 \n743     noct : float\n744         Nominal operating cell temperature [C], determined at conditions of\n745         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n746 \n747     eta_m_ref : float\n748         Module external efficiency [unitless] at reference conditions of\n749         1000 W/m^2 and 20C. Calculate as\n750         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n751         where A is module area [m^2].\n752 \n753     effective_irradiance : numeric, default None.\n754         The irradiance that is converted to photocurrent. If None,\n755         assumed equal to poa_global. [W/m^2]\n756 \n757     transmittance_absorptance : numeric, default 0.9\n758         Coefficient for combined transmittance and absorptance effects.\n759         [unitless]\n760 \n761     array_height : int, default 1\n762         Height of array above ground in stories (one story is about 3m). Must\n763         be either 1 or 2. For systems elevated less than one story, use 1.\n764         If system is elevated more than two stories, use 2.\n765 \n766     mount_standoff : numeric, default 4\n767         Distance between array mounting and mounting surface. Use default\n768         if system is ground-mounted. [inches]\n769 \n770     Returns\n771     -------\n772     cell_temperature : numeric\n773         Cell temperature. [C]\n774 \n775     Raises\n776     ------\n777     ValueError\n778         If array_height is an invalid value (must be 1 or 2).\n779 \n780     References\n781     ----------\n782     .. [1] Gilman, P., Dobos, A., DiOrio, N., Freeman, J., Janzou, S.,\n783            Ryberg, D., 2018, \"SAM Photovoltaic Model Technical Reference\n784            Update\", National Renewable Energy Laboratory Report\n785            NREL/TP-6A20-67399.\n786     '''\n787     # in [1] the denominator for irr_ratio isn't precisely clear. From\n788     # reproducing output of the SAM function noct_celltemp_t, we determined\n789     # that:\n790     #  - G_total (SAM) is broadband plane-of-array irradiance before\n791     #    reflections. Equivalent to pvlib variable poa_global\n792     #  - Geff_total (SAM) is POA irradiance after reflections and\n793     #    adjustment for spectrum. Equivalent to effective_irradiance\n794     if effective_irradiance is None:\n795         irr_ratio = 1.\n796     else:\n797         irr_ratio = effective_irradiance / poa_global\n798 \n799     if array_height == 1:\n800         wind_adj = 0.51 * wind_speed\n801     elif array_height == 2:\n802         wind_adj = 0.61 * wind_speed\n803     else:\n804         raise ValueError(\n805             f'array_height must be 1 or 2, {array_height} was given')\n806 \n807     noct_adj = noct + _adj_for_mounting_standoff(mount_standoff)\n808     tau_alpha = transmittance_absorptance * irr_ratio\n809 \n810     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n811     # poa_global where G appears\n812     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n813     heat_loss = 1 - eta_m_ref / tau_alpha\n814     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n815     return temp_air + cell_temp_init * heat_loss * wind_loss\n816 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "40ba4bd5c8b91754aa73e638ed984ab9657847cd", "problem_statement": "change eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n", "hints_text": "I support this change.", "created_at": "2021-05-06T16:02:38Z", "patch": "<patch>\ndiff --git a/pvlib/modelchain.py b/pvlib/modelchain.py\n--- a/pvlib/modelchain.py\n+++ b/pvlib/modelchain.py\n@@ -977,7 +977,7 @@ def infer_temperature_model(self):\n             return self.faiman_temp\n         elif {'noct_installed'} <= params:\n             return self.fuentes_temp\n-        elif {'noct', 'eta_m_ref'} <= params:\n+        elif {'noct', 'module_efficiency'} <= params:\n             return self.noct_sam_temp\n         else:\n             raise ValueError(f'could not infer temperature model from '\ndiff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -671,7 +671,9 @@ def pvsyst_celltemp(self, poa_global, temp_air, wind_speed=1.0):\n         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n \n         def build_celltemp_kwargs(array):\n-            return {**_build_kwargs(['eta_m', 'alpha_absorption'],\n+            # TODO remove 'eta_m' after deprecation of this parameter\n+            return {**_build_kwargs(['eta_m', 'module_efficiency',\n+                                     'alpha_absorption'],\n                                     array.module_parameters),\n                     **_build_kwargs(['u_c', 'u_v'],\n                                     array.temperature_model_parameters)}\n@@ -843,10 +845,10 @@ def _build_kwargs_noct_sam(array):\n                 # bundled with kwargs for simplicity\n                 temp_model_kwargs['noct'] = \\\n                     array.temperature_model_parameters['noct']\n-                temp_model_kwargs['eta_m_ref'] = \\\n-                    array.temperature_model_parameters['eta_m_ref']\n+                temp_model_kwargs['module_efficiency'] = \\\n+                    array.temperature_model_parameters['module_efficiency']\n             except KeyError:\n-                msg = ('Parameters noct and eta_m_ref are required.'\n+                msg = ('Parameters noct and module_efficiency are required.'\n                        ' Found {} in temperature_model_parameters.'\n                        .format(array.temperature_model_parameters))\n                 raise KeyError(msg)\ndiff --git a/pvlib/temperature.py b/pvlib/temperature.py\n--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -6,6 +6,7 @@\n import numpy as np\n import pandas as pd\n from pvlib.tools import sind\n+from pvlib._deprecation import warn_deprecated\n \n TEMPERATURE_MODEL_PARAMETERS = {\n     'sapm': {\n@@ -285,7 +286,7 @@ def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n \n \n def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n-                eta_m=0.1, alpha_absorption=0.9):\n+                eta_m=None, module_efficiency=0.1, alpha_absorption=0.9):\n     r\"\"\"\n     Calculate cell temperature using an empirical heat loss factor model\n     as implemented in PVsyst.\n@@ -313,12 +314,14 @@ def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n     u_v : float, default 0.0\n         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n         in :eq:`pvsyst`.\n-        :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n+        :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`  # noQA: E501\n+\n+    eta_m : numeric, default None (deprecated, use module_efficiency instead)\n \n-    eta_m : numeric, default 0.1\n-        Module external efficiency as a fraction, i.e.,\n-        :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n-        Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n+    module_efficiency : numeric, default 0.1\n+        Module external efficiency as a fraction. Parameter :math:`\\eta_{m}`\n+        in :eq:`pvsyst`. Calculate as\n+        :math:`\\eta_{m} = DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n \n     alpha_absorption : numeric, default 0.9\n         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n@@ -370,8 +373,13 @@ def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n     37.93103448275862\n     \"\"\"\n \n+    if eta_m:\n+        warn_deprecated(\n+            since='v0.9', message='eta_m overwriting module_efficiency',\n+            name='eta_m', alternative='module_efficiency', removal='v0.10')\n+        module_efficiency = eta_m\n     total_loss_factor = u_c + u_v * wind_speed\n-    heat_input = poa_global * alpha_absorption * (1 - eta_m)\n+    heat_input = poa_global * alpha_absorption * (1 - module_efficiency)\n     temp_difference = heat_input / total_loss_factor\n     return temp_air + temp_difference\n \n@@ -719,7 +727,7 @@ def _adj_for_mounting_standoff(x):\n                         [0., 18., 11., 6., 2., 0.])\n \n \n-def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n+def noct_sam(poa_global, temp_air, wind_speed, noct, module_efficiency,\n              effective_irradiance=None, transmittance_absorptance=0.9,\n              array_height=1, mount_standoff=4):\n     r'''\n@@ -744,9 +752,9 @@ def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n         Nominal operating cell temperature [C], determined at conditions of\n         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n \n-    eta_m_ref : float\n+    module_efficiency : float\n         Module external efficiency [unitless] at reference conditions of\n-        1000 W/m^2 and 20C. Calculate as\n+        1000 W/m^2 and 20C. Denoted as :math:`eta_{m}` in [1]_. Calculate as\n         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n         where A is module area [m^2].\n \n@@ -810,6 +818,6 @@ def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n     # poa_global where G appears\n     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n-    heat_loss = 1 - eta_m_ref / tau_alpha\n+    heat_loss = 1 - module_efficiency / tau_alpha\n     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n     return temp_air + cell_temp_init * heat_loss * wind_loss\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_modelchain.py b/pvlib/tests/test_modelchain.py\n--- a/pvlib/tests/test_modelchain.py\n+++ b/pvlib/tests/test_modelchain.py\n@@ -201,7 +201,7 @@ def pvwatts_dc_pvwatts_ac_faiman_temp_system():\n @pytest.fixture(scope=\"function\")\n def pvwatts_dc_pvwatts_ac_pvsyst_temp_system():\n     module_parameters = {'pdc0': 220, 'gamma_pdc': -0.003}\n-    temp_model_params = {'u_c': 29.0, 'u_v': 0.0, 'eta_m': 0.1,\n+    temp_model_params = {'u_c': 29.0, 'u_v': 0.0, 'module_efficiency': 0.1,\n                          'alpha_absorption': 0.9}\n     inverter_parameters = {'pdc0': 220, 'eta_inv_nom': 0.95}\n     system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n@@ -226,7 +226,7 @@ def pvwatts_dc_pvwatts_ac_fuentes_temp_system():\n @pytest.fixture(scope=\"function\")\n def pvwatts_dc_pvwatts_ac_noct_sam_temp_system():\n     module_parameters = {'pdc0': 220, 'gamma_pdc': -0.003}\n-    temp_model_params = {'noct': 45, 'eta_m_ref': 0.2}\n+    temp_model_params = {'noct': 45, 'module_efficiency': 0.2}\n     inverter_parameters = {'pdc0': 220, 'eta_inv_nom': 0.95}\n     system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n                       module_parameters=module_parameters,\n@@ -710,7 +710,7 @@ def test_run_model_with_weather_noct_sam_temp(sapm_dc_snl_ac_system, location,\n     weather['wind_speed'] = 5\n     weather['temp_air'] = 10\n     sapm_dc_snl_ac_system.temperature_model_parameters = {\n-        'noct': 45, 'eta_m_ref': 0.2\n+        'noct': 45, 'module_efficiency': 0.2\n     }\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     mc.temperature_model = 'noct_sam'\n@@ -941,7 +941,7 @@ def test__prepare_temperature_arrays_weather(sapm_dc_snl_ac_system_same_arrays,\n                            ModelChain.faiman_temp),\n                           ({'noct_installed': 45},\n                            ModelChain.fuentes_temp),\n-                          ({'noct': 45, 'eta_m_ref': 0.2},\n+                          ({'noct': 45, 'module_efficiency': 0.2},\n                            ModelChain.noct_sam_temp)])\n def test_temperature_models_arrays_multi_weather(\n         temp_params, temp_model,\ndiff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -392,7 +392,7 @@ def two_array_system(pvsyst_module_params, cec_module_params):\n     temperature_model['noct_installed'] = 45\n     # parameters for noct_sam temperature model\n     temperature_model['noct'] = 45.\n-    temperature_model['eta_m_ref'] = 0.2\n+    temperature_model['module_efficiency'] = 0.2\n     module_params = {**pvsyst_module_params, **cec_module_params}\n     return pvsystem.PVSystem(\n         arrays=[\n@@ -471,8 +471,9 @@ def test_PVSystem_pvsyst_celltemp(mocker):\n     temp_model_params = temperature.TEMPERATURE_MODEL_PARAMETERS['pvsyst'][\n         parameter_set]\n     alpha_absorption = 0.85\n-    eta_m = 0.17\n-    module_parameters = {'alpha_absorption': alpha_absorption, 'eta_m': eta_m}\n+    module_efficiency = 0.17\n+    module_parameters = {'alpha_absorption': alpha_absorption,\n+                         'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(module_parameters=module_parameters,\n                                temperature_model_parameters=temp_model_params)\n     mocker.spy(temperature, 'pvsyst_cell')\n@@ -481,8 +482,9 @@ def test_PVSystem_pvsyst_celltemp(mocker):\n     wind = 0.5\n     out = system.pvsyst_celltemp(irrad, temp, wind_speed=wind)\n     temperature.pvsyst_cell.assert_called_once_with(\n-        irrad, temp, wind, temp_model_params['u_c'], temp_model_params['u_v'],\n-        eta_m, alpha_absorption)\n+        irrad, temp, wind_speed=wind, u_c=temp_model_params['u_c'],\n+        u_v=temp_model_params['u_v'], module_efficiency=module_efficiency,\n+        alpha_absorption=alpha_absorption)\n     assert (out < 90) and (out > 70)\n \n \n@@ -500,16 +502,16 @@ def test_PVSystem_faiman_celltemp(mocker):\n \n \n def test_PVSystem_noct_celltemp(mocker):\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     expected = 55.230790492\n-    temp_model_params = {'noct': noct, 'eta_m_ref': eta_m_ref}\n+    temp_model_params = {'noct': noct, 'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(temperature_model_parameters=temp_model_params)\n     mocker.spy(temperature, 'noct_sam')\n     out = system.noct_sam_celltemp(poa_global, temp_air, wind_speed)\n     temperature.noct_sam.assert_called_once_with(\n         poa_global, temp_air, wind_speed, effective_irradiance=None, noct=noct,\n-        eta_m_ref=eta_m_ref)\n+        module_efficiency=module_efficiency)\n     assert_allclose(out, expected)\n     # dufferent types\n     out = system.noct_sam_celltemp(np.array(poa_global), np.array(temp_air),\n@@ -533,8 +535,8 @@ def test_PVSystem_noct_celltemp(mocker):\n \n \n def test_PVSystem_noct_celltemp_error():\n-    poa_global, temp_air, wind_speed, eta_m_ref = (1000., 25., 1., 0.2)\n-    temp_model_params = {'eta_m_ref': eta_m_ref}\n+    poa_global, temp_air, wind_speed, module_efficiency = (1000., 25., 1., 0.2)\n+    temp_model_params = {'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(temperature_model_parameters=temp_model_params)\n     with pytest.raises(KeyError):\n         system.noct_sam_celltemp(poa_global, temp_air, wind_speed)\ndiff --git a/pvlib/tests/test_temperature.py b/pvlib/tests/test_temperature.py\n--- a/pvlib/tests/test_temperature.py\n+++ b/pvlib/tests/test_temperature.py\n@@ -6,6 +6,7 @@\n from numpy.testing import assert_allclose\n \n from pvlib import temperature, tools\n+from pvlib._deprecation import pvlibDeprecationWarning\n \n \n @pytest.fixture\n@@ -72,7 +73,7 @@ def test_pvsyst_cell_default():\n \n def test_pvsyst_cell_kwargs():\n     result = temperature.pvsyst_cell(900, 20, wind_speed=5.0, u_c=23.5,\n-                                     u_v=6.25, eta_m=0.1)\n+                                     u_v=6.25, module_efficiency=0.1)\n     assert_allclose(result, 33.315, 0.001)\n \n \n@@ -96,6 +97,13 @@ def test_pvsyst_cell_series():\n     assert_series_equal(expected, result)\n \n \n+def test_pvsyst_cell_eta_m_deprecated():\n+    with pytest.warns(pvlibDeprecationWarning):\n+        result = temperature.pvsyst_cell(900, 20, wind_speed=5.0, u_c=23.5,\n+                                         u_v=6.25, eta_m=0.1)\n+        assert_allclose(result, 33.315, 0.001)\n+\n+\n def test_faiman_default():\n     result = temperature.faiman(900, 20, 5)\n     assert_allclose(result, 35.203, 0.001)\n@@ -215,16 +223,16 @@ def test_fuentes_timezone(tz):\n \n \n def test_noct_sam():\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     expected = 55.230790492\n     result = temperature.noct_sam(poa_global, temp_air, wind_speed, noct,\n-                                  eta_m_ref)\n+                                  module_efficiency)\n     assert_allclose(result, expected)\n     # test with different types\n     result = temperature.noct_sam(np.array(poa_global), np.array(temp_air),\n                                   np.array(wind_speed), np.array(noct),\n-                                  np.array(eta_m_ref))\n+                                  np.array(module_efficiency))\n     assert_allclose(result, expected)\n     dr = pd.date_range(start='2020-01-01 12:00:00', end='2020-01-01 13:00:00',\n                        freq='1H')\n@@ -232,7 +240,7 @@ def test_noct_sam():\n                                   pd.Series(index=dr, data=temp_air),\n                                   pd.Series(index=dr, data=wind_speed),\n                                   pd.Series(index=dr, data=noct),\n-                                  eta_m_ref)\n+                                  module_efficiency)\n     assert_series_equal(result, pd.Series(index=dr, data=expected))\n \n \n@@ -242,7 +250,7 @@ def test_noct_sam_against_sam():\n     # NOCT cell temperature model), with the only change being the soiling\n     # loss is set to 0. Weather input is TMY3 for Phoenix AZ.\n     # Values are taken from the Jan 1 12:00:00 timestamp.\n-    poa_total, temp_air, wind_speed, noct, eta_m_ref = (\n+    poa_total, temp_air, wind_speed, noct, module_efficiency = (\n         860.673, 25, 3, 46.4, 0.20551)\n     poa_total_after_refl = 851.458  # from SAM output\n     # compute effective irradiance\n@@ -259,7 +267,7 @@ def test_noct_sam_against_sam():\n     array_height = 1\n     mount_standoff = 4.0\n     result = temperature.noct_sam(poa_total, temp_air, wind_speed, noct,\n-                                  eta_m_ref, effective_irradiance,\n+                                  module_efficiency, effective_irradiance,\n                                   transmittance_absorptance, array_height,\n                                   mount_standoff)\n     expected = 43.0655\n@@ -268,14 +276,14 @@ def test_noct_sam_against_sam():\n \n \n def test_noct_sam_options():\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     effective_irradiance = 1100.\n     transmittance_absorptance = 0.8\n     array_height = 2\n     mount_standoff = 2.0\n     result = temperature.noct_sam(poa_global, temp_air, wind_speed, noct,\n-                                  eta_m_ref, effective_irradiance,\n+                                  module_efficiency, effective_irradiance,\n                                   transmittance_absorptance, array_height,\n                                   mount_standoff)\n     expected = 60.477703576\n", "version": "0.8", "FAIL_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_run_model_with_weather_noct_sam_temp\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params4-noct_sam_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[noct_sam_temp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[noct_sam_celltemp]\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_kwargs\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_eta_m_deprecated\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_ModelChain_creation\", \"pvlib/tests/test_modelchain.py::test_with_sapm\", \"pvlib/tests/test_modelchain.py::test_with_pvwatts\", \"pvlib/tests/test_modelchain.py::test_run_model_with_irradiance\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss_input_type[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss_input_type[list]\", \"pvlib/tests/test_modelchain.py::test_ModelChain_invalid_inverter_params_arrays[adr]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_multi_weather[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_multi_weather[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_no_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_arrays_one_missing_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_weather_wrong_length[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_weather_wrong_length[list]\", \"pvlib/tests/test_modelchain.py::test_ModelChain_times_error_arrays\", \"pvlib/tests/test_modelchain.py::test_ModelChain_times_arrays\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[dhi]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[ghi]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[dni]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[tuple-sandia]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[tuple-pvwatts]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[list-sandia]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[list-pvwatts]\", \"pvlib/tests/test_modelchain.py::test_run_model_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_gueymard_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_sapm_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_pvsyst_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_faiman_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_fuentes_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker_list\", \"pvlib/tests/test_modelchain.py::test__assign_total_irrad\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_multi_data[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_multi_data[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_wrong_number_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_wrong_number_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_arrays_different_indices\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_arrays_missing_column\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature_len1_weather_tuple\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature_arrays_weather\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params0-sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params1-pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params2-faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params3-fuentes_temp]\", \"pvlib/tests/test_modelchain.py::test_run_model_solar_position_weather\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays_solar_position_weather\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_tracking\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[<lambda>]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_multi_array[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_multi_array[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[<lambda>]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_poa_global_differs\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays_error[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays_error[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_minimal_input\", \"pvlib/tests/test_modelchain.py::test_run_model_singleton_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_singleton_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[desoto]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[singlediode]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvwatts_dc]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[cec]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[desoto]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec_native]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[fuentes_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model_invalid\", \"pvlib/tests/test_modelchain.py::test_temperature_model_inconsistent\", \"pvlib/tests/test_modelchain.py::test_dc_model_user_func\", \"pvlib/tests/test_modelchain.py::test_pvwatts_dc_multiple_strings\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia]\", \"pvlib/tests/test_modelchain.py::test_ac_models[adr]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts]\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia_multi]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts_multi]\", \"pvlib/tests/test_modelchain.py::test_ac_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_model_not_a_model\", \"pvlib/tests/test_modelchain.py::test_infer_ac_model_invalid_params\", \"pvlib/tests/test_modelchain.py::test_aoi_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_model_no_loss\", \"pvlib/tests/test_modelchain.py::test_aoi_model_user_func\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[ashrae]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[physical]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model_invalid\", \"pvlib/tests/test_modelchain.py::test_spectral_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_model_ohms_from_percent\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_model_no_dc_ohmic_loss\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_ext_def\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_not_a_model\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts_arrays\", \"pvlib/tests/test_modelchain.py::test_losses_models_ext_def\", \"pvlib/tests/test_modelchain.py::test_losses_models_no_loss\", \"pvlib/tests/test_modelchain.py::test_invalid_dc_model_params\", \"pvlib/tests/test_modelchain.py::test_invalid_models[dc_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[ac_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[aoi_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[spectral_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[temperature_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[losses_model]\", \"pvlib/tests/test_modelchain.py::test_bad_get_orientation\", \"pvlib/tests/test_modelchain.py::test_with_sapm_pvsystem_arrays\", \"pvlib/tests/test_modelchain.py::test_ModelChain_no_extra_kwargs\", \"pvlib/tests/test_modelchain.py::test_ModelChain_attributes_deprecated_10\", \"pvlib/tests/test_modelchain.py::test_basic_chain_alt_az\", \"pvlib/tests/test_modelchain.py::test_basic_chain_altitude_pressure\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_clean_run\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays_wrong_length[tuple]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays_wrong_length[list]\", \"pvlib/tests/test_modelchain.py::test_unknown_attribute\", \"pvlib/tests/test_modelchain.py::test_inconsistent_array_params\", \"pvlib/tests/test_modelchain.py::test_modelchain__common_keys\", \"pvlib/tests/test_modelchain.py::test__irrad_for_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_iam\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[1.5-1.00028714375]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_first_solar_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[20-poa_diffuse0-aoi0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct1-poa_diffuse1-aoi1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct2-poa_diffuse2-20]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_celltemp_different_arrays\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp_override\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_cell_type\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_desoto]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_cec]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-1-celltemp0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-irrad1-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-1-celltemp2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-irrad3-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-1-celltemp4]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-irrad5-1]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_snlinverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[sandia]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[adr]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[pvwatts]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_invalid\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance_model\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance_multi_irrad\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_change_surface_azimuth\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_albedo\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_modules_per_string\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_strings_per_inverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array___repr__\", \"pvlib/tests/test_pvsystem.py::test_Array___repr__\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc_value_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_num_arrays\", \"pvlib/tests/test_pvsystem.py::test_combine_loss_factors\", \"pvlib/tests/test_pvsystem.py::test_no_extra_kwargs\", \"pvlib/tests/test_pvsystem.py::test_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_dc_ohmic_losses\", \"pvlib/tests/test_pvsystem.py::test_Array_dc_ohms_from_percent\", \"pvlib/tests/test_temperature.py::test_sapm_cell\", \"pvlib/tests/test_temperature.py::test_sapm_module\", \"pvlib/tests/test_temperature.py::test_sapm_cell_from_module\", \"pvlib/tests/test_temperature.py::test_sapm_ndarray\", \"pvlib/tests/test_temperature.py::test_sapm_series\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_default\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_ndarray\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_series\", \"pvlib/tests/test_temperature.py::test_faiman_default\", \"pvlib/tests/test_temperature.py::test_faiman_kwargs\", \"pvlib/tests/test_temperature.py::test_faiman_list\", \"pvlib/tests/test_temperature.py::test_faiman_ndarray\", \"pvlib/tests/test_temperature.py::test_ross\", \"pvlib/tests/test_temperature.py::test_faiman_series\", \"pvlib/tests/test_temperature.py::test__temperature_model_params\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_rackmount.csv-45]\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_roofmount.csv-49]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[None]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[Etc/GMT+5]\", \"pvlib/tests/test_temperature.py::test_noct_sam\", \"pvlib/tests/test_temperature.py::test_noct_sam_against_sam\", \"pvlib/tests/test_temperature.py::test_noct_sam_options\", \"pvlib/tests/test_temperature.py::test_noct_sam_errors\"]", "environment_setup_commit": "ef8ad2fee9840a77d14b0dfd17fc489dd85c9b91"}
{"instance_id": "pvlib__pvlib-python-1218_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nchange eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n32       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n33     </a>\n34   </td>\n35 </tr>\n36 <tr>\n37   <td>Code Quality</td>\n38  \u00a0<td>\n39     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n40     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n41     </a>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n43     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Coverage</td>\n49  \u00a0<td>\n50     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n51     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n52     </a>\n53     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n54     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Publications</td>\n60   <td>\n61     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n62     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n63     </a>\n64     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n65     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n66     </a>\n67   </td>\n68 </tr>\n69 <tr>\n70   <td>Downloads</td>\n71   <td>\n72     <a href=\"https://pypi.org/project/pvlib/\">\n73     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n74     </a>\n75     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n76     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n77     </a>\n78   </td>\n79 </tr>\n80 </table>\n81 \n82 \n83 pvlib python is a community supported tool that provides a set of\n84 functions and classes for simulating the performance of photovoltaic\n85 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n86 toolbox developed at Sandia National Laboratories and it implements many\n87 of the models and methods developed at the Labs. More information on\n88 Sandia Labs PV performance modeling programs can be found at\n89 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n90 but operate independently of it.\n91 \n92 \n93 Documentation\n94 =============\n95 \n96 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n97 \n98 \n99 Installation\n100 ============\n101 \n102 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n103 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n104 \n105 \n106 Contributing\n107 ============\n108 \n109 We need your help to make pvlib-python a great tool!\n110 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n111 The long-term success of pvlib-python requires substantial community support.\n112 \n113 \n114 License\n115 =======\n116 \n117 BSD 3-clause\n118 \n119 \n120 Getting support\n121 ===============\n122 \n123 pvlib usage questions can be asked on\n124 [Stack Overflow](http://stackoverflow.com) and tagged with\n125 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n126 \n127 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n128 is used for discussing various topics of interest to the pvlib-python\n129 community. We also make new version announcements on the google group.\n130 \n131 If you suspect that you may have discovered a bug or if you'd like to\n132 change something about pvlib, then please make an issue on our\n133 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n134 \n135 \n136 Citing\n137 ======\n138 \n139 If you use pvlib-python in a published work, please cite:\n140 \n141   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n142   \"pvlib python: a python package for modeling solar energy systems.\"\n143   Journal of Open Source Software, 3(29), 884, (2018).\n144   https://doi.org/10.21105/joss.00884\n145 \n146 Please also cite the DOI corresponding to the specific version of\n147 pvlib-python that you used. pvlib-python DOIs are listed at\n148 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n149 \n150 NumFOCUS\n151 ========\n152 \n153 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n154 \n155 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n156 \n[end of README.md]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 import pandas as pd\n8 from pvlib.tools import sind\n9 \n10 TEMPERATURE_MODEL_PARAMETERS = {\n11     'sapm': {\n12         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n13         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n14         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n15         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n16     },\n17     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n18                'insulated': {'u_c': 15.0, 'u_v': 0}}\n19 }\n20 \"\"\"Dictionary of temperature parameters organized by model.\n21 \n22 There are keys for each model at the top level. Currently there are two models,\n23 ``'sapm'`` for the Sandia Array Performance Model, and ``'pvsyst'``. Each model\n24 has a dictionary of configurations; a value is itself a dictionary containing\n25 model parameters. Retrieve parameters by indexing the model and configuration\n26 by name. Note: the keys are lower-cased and case sensitive.\n27 \n28 Example\n29 -------\n30 Retrieve the open rack glass-polymer configuration for SAPM::\n31 \n32     from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n33     temperature_model_parameters = (\n34         TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'])\n35     # {'a': -3.56, 'b': -0.075, 'deltaT': 3}\n36 \"\"\"\n37 \n38 \n39 def _temperature_model_params(model, parameter_set):\n40     try:\n41         params = TEMPERATURE_MODEL_PARAMETERS[model]\n42         return params[parameter_set]\n43     except KeyError:\n44         msg = ('{} is not a named set of parameters for the {} cell'\n45                ' temperature model.'\n46                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n47                ' for names'.format(parameter_set, model))\n48         raise KeyError(msg)\n49 \n50 \n51 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n52               irrad_ref=1000.):\n53     r'''\n54     Calculate cell temperature per the Sandia Array Performance Model.\n55 \n56     See [1]_ for details on the Sandia Array Performance Model.\n57 \n58     Parameters\n59     ----------\n60     poa_global : numeric\n61         Total incident irradiance [W/m^2].\n62 \n63     temp_air : numeric\n64         Ambient dry bulb temperature [C].\n65 \n66     wind_speed : numeric\n67         Wind speed at a height of 10 meters [m/s].\n68 \n69     a : float\n70         Parameter :math:`a` in :eq:`sapm1`.\n71 \n72     b : float\n73         Parameter :math:`b` in :eq:`sapm1`.\n74 \n75     deltaT : float\n76         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n77 \n78     irrad_ref : float, default 1000\n79         Reference irradiance, parameter :math:`E_{0}` in\n80         :eq:`sapm2` [W/m^2].\n81 \n82     Returns\n83     -------\n84     numeric, values in degrees C.\n85 \n86     Notes\n87     -----\n88     The model for cell temperature :math:`T_{C}` is given by a pair of\n89     equations (Eq. 11 and 12 in [1]_).\n90 \n91     .. math::\n92        :label: sapm1\n93 \n94        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n95 \n96     .. math::\n97        :label: sapm2\n98 \n99        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n100 \n101     The module back surface temperature :math:`T_{m}` is implemented in\n102     :py:func:`~pvlib.temperature.sapm_module`.\n103 \n104     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n105     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n106     the module construction and its mounting. Parameter sets are provided in\n107     [1]_ for representative modules and mounting, and are coded for convenience\n108     in :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n109 \n110     +---------------+----------------+-------+---------+---------------------+\n111     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n112     +===============+================+=======+=========+=====================+\n113     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n114     +---------------+----------------+-------+---------+---------------------+\n115     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n116     +---------------+----------------+-------+---------+---------------------+\n117     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n118     +---------------+----------------+-------+---------+---------------------+\n119     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n120     +---------------+----------------+-------+---------+---------------------+\n121 \n122     References\n123     ----------\n124     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n125        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n126        NM.\n127 \n128     See also\n129     --------\n130     sapm_cell_from_module\n131     sapm_module\n132 \n133     Examples\n134     --------\n135     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n136     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n137     >>> sapm_cell(1000, 10, 0, **params)\n138     44.11703066106086\n139     '''\n140     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n141                                      a, b)\n142     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n143                                  irrad_ref)\n144 \n145 \n146 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n147     r'''\n148     Calculate module back surface temperature per the Sandia Array\n149     Performance Model.\n150 \n151     See [1]_ for details on the Sandia Array Performance Model.\n152 \n153     Parameters\n154     ----------\n155     poa_global : numeric\n156         Total incident irradiance [W/m^2].\n157 \n158     temp_air : numeric\n159         Ambient dry bulb temperature [C].\n160 \n161     wind_speed : numeric\n162         Wind speed at a height of 10 meters [m/s].\n163 \n164     a : float\n165         Parameter :math:`a` in :eq:`sapm1mod`.\n166 \n167     b : float\n168         Parameter :math:`b` in :eq:`sapm1mod`.\n169 \n170     Returns\n171     -------\n172     numeric, values in degrees C.\n173 \n174     Notes\n175     -----\n176     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n177 \n178     .. math::\n179        :label: sapm1mod\n180 \n181        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n182 \n183     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n184     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n185     temperature at the back of the module :math:`T_{m}` and cell temperature\n186     :math:`T_{C}`. Model parameters depend both on the module construction and\n187     its mounting. Parameter sets are provided in [1]_ for representative\n188     modules and mounting, and are coded for convenience in\n189     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n190 \n191     +---------------+----------------+-------+---------+---------------------+\n192     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n193     +===============+================+=======+=========+=====================+\n194     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n195     +---------------+----------------+-------+---------+---------------------+\n196     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n197     +---------------+----------------+-------+---------+---------------------+\n198     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n199     +---------------+----------------+-------+---------+---------------------+\n200     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n201     +---------------+----------------+-------+---------+---------------------+\n202 \n203     References\n204     ----------\n205     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n206        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n207        NM.\n208 \n209     See also\n210     --------\n211     sapm_cell\n212     sapm_cell_from_module\n213     '''\n214     return poa_global * np.exp(a + b * wind_speed) + temp_air\n215 \n216 \n217 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n218                           irrad_ref=1000.):\n219     r'''\n220     Calculate cell temperature from module temperature using the Sandia Array\n221     Performance Model.\n222 \n223     See [1]_ for details on the Sandia Array Performance Model.\n224 \n225     Parameters\n226     ----------\n227     module_temperature : numeric\n228         Temperature of back of module surface [C].\n229 \n230     poa_global : numeric\n231         Total incident irradiance [W/m^2].\n232 \n233     deltaT : float\n234         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n235 \n236     irrad_ref : float, default 1000\n237         Reference irradiance, parameter :math:`E_{0}` in\n238         :eq:`sapm2` [W/m^2].\n239 \n240     Returns\n241     -------\n242     numeric, values in degrees C.\n243 \n244     Notes\n245     -----\n246     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n247 \n248     .. math::\n249        :label: sapm2_cell_from_mod\n250 \n251        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n252 \n253     The module back surface temperature :math:`T_{m}` is implemented in\n254     :py:func:`~pvlib.temperature.sapm_module`.\n255 \n256     Model parameters depend both on the module construction and its mounting.\n257     Parameter sets are provided in [1]_ for representative modules and\n258     mounting, and are coded for convenience in\n259     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n260 \n261     +---------------+----------------+-------+---------+---------------------+\n262     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n263     +===============+================+=======+=========+=====================+\n264     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n265     +---------------+----------------+-------+---------+---------------------+\n266     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n267     +---------------+----------------+-------+---------+---------------------+\n268     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n269     +---------------+----------------+-------+---------+---------------------+\n270     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n271     +---------------+----------------+-------+---------+---------------------+\n272 \n273     References\n274     ----------\n275     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n276        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n277        NM.\n278 \n279     See also\n280     --------\n281     sapm_cell\n282     sapm_module\n283     '''\n284     return module_temperature + (poa_global / irrad_ref) * deltaT\n285 \n286 \n287 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n288                 eta_m=0.1, alpha_absorption=0.9):\n289     r\"\"\"\n290     Calculate cell temperature using an empirical heat loss factor model\n291     as implemented in PVsyst.\n292 \n293     Parameters\n294     ----------\n295     poa_global : numeric\n296         Total incident irradiance [W/m^2].\n297 \n298     temp_air : numeric\n299         Ambient dry bulb temperature [C].\n300 \n301     wind_speed : numeric, default 1.0\n302         Wind speed in m/s measured at the same height for which the wind loss\n303         factor was determined.  The default value 1.0 m/2 is the wind\n304         speed at module height used to determine NOCT. [m/s]\n305 \n306     u_c : float, default 29.0\n307         Combined heat loss factor coefficient. The default value is\n308         representative of freestanding modules with the rear surfaces exposed\n309         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n310         :eq:`pvsyst`.\n311         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n312 \n313     u_v : float, default 0.0\n314         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n315         in :eq:`pvsyst`.\n316         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n317 \n318     eta_m : numeric, default 0.1\n319         Module external efficiency as a fraction, i.e.,\n320         :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n321         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n322 \n323     alpha_absorption : numeric, default 0.9\n324         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n325 \n326     Returns\n327     -------\n328     numeric, values in degrees Celsius\n329 \n330     Notes\n331     -----\n332     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n333 \n334     .. math::\n335        :label: pvsyst\n336 \n337         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n338 \n339     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n340     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n341     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n342     the module construction and its mounting. Parameters are provided in\n343     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n344     , and are coded for convenience in\n345     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`. The heat loss\n346     factors provided represent the combined effect of convection, radiation and\n347     conduction, and their values are experimentally determined.\n348 \n349     +--------------+---------------+---------------+\n350     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n351     +==============+===============+===============+\n352     | freestanding | 29.0          | 0.0           |\n353     +--------------+---------------+---------------+\n354     | insulated    | 15.0          | 0.0           |\n355     +--------------+---------------+---------------+\n356 \n357     References\n358     ----------\n359     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n360        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n361 \n362     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n363        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n364 \n365     Examples\n366     --------\n367     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n368     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n369     >>> pvsyst_cell(1000, 10, **params)\n370     37.93103448275862\n371     \"\"\"\n372 \n373     total_loss_factor = u_c + u_v * wind_speed\n374     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n375     temp_difference = heat_input / total_loss_factor\n376     return temp_air + temp_difference\n377 \n378 \n379 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n380     r'''\n381     Calculate cell or module temperature using the Faiman model.\n382 \n383     The Faiman model uses an empirical heat loss factor model [1]_ and is\n384     adopted in the IEC 61853 standards [2]_ and [3]_.\n385 \n386     Usage of this model in the IEC 61853 standard does not distinguish\n387     between cell and module temperature.\n388 \n389     Parameters\n390     ----------\n391     poa_global : numeric\n392         Total incident irradiance [W/m^2].\n393 \n394     temp_air : numeric\n395         Ambient dry bulb temperature [C].\n396 \n397     wind_speed : numeric, default 1.0\n398         Wind speed in m/s measured at the same height for which the wind loss\n399         factor was determined.  The default value 1.0 m/s is the wind\n400         speed at module height used to determine NOCT. [m/s]\n401 \n402     u0 : numeric, default 25.0\n403         Combined heat loss factor coefficient. The default value is one\n404         determined by Faiman for 7 silicon modules.\n405         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n406 \n407     u1 : numeric, default 6.84\n408         Combined heat loss factor influenced by wind. The default value is one\n409         determined by Faiman for 7 silicon modules.\n410         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n411 \n412     Returns\n413     -------\n414     numeric, values in degrees Celsius\n415 \n416     Notes\n417     -----\n418     All arguments may be scalars or vectors. If multiple arguments\n419     are vectors they must be the same length.\n420 \n421     References\n422     ----------\n423     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n424        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n425 \n426     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n427        rating - Part 2: Spectral responsivity, incidence angle and module\n428        operating temperature measurements\". IEC, Geneva, 2018.\n429 \n430     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n431        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n432 \n433     '''\n434     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n435 \n436     # The following lines may seem odd since u0 & u1 are probably scalar,\n437     # but it serves an indirect and easy way of allowing lists and\n438     # tuples for the other function arguments.\n439     u0 = np.asanyarray(u0)\n440     u1 = np.asanyarray(u1)\n441 \n442     total_loss_factor = u0 + u1 * wind_speed\n443     heat_input = poa_global\n444     temp_difference = heat_input / total_loss_factor\n445     return temp_air + temp_difference\n446 \n447 \n448 def ross(poa_global, temp_air, noct):\n449     r'''\n450     Calculate cell temperature using the Ross model.\n451 \n452     The Ross model [1]_ assumes the difference between cell temperature\n453     and ambient temperature is proportional to the plane of array irradiance,\n454     and assumes wind speed of 1 m/s. The model implicitly assumes steady or\n455     slowly changing irradiance conditions.\n456 \n457     Parameters\n458     ----------\n459     poa_global : numeric\n460         Total incident irradiance. [W/m^2]\n461 \n462     temp_air : numeric\n463         Ambient dry bulb temperature. [C]\n464 \n465     noct : numeric\n466         Nominal operating cell temperature [C], determined at conditions of\n467         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n468 \n469     Returns\n470     -------\n471     cell_temperature : numeric\n472         Cell temperature. [C]\n473 \n474     Notes\n475     -----\n476     The Ross model for cell temperature :math:`T_{C}` is given in [1]_ as\n477 \n478     .. math::\n479 \n480         T_{C} = T_{a} + \\frac{NOCT - 20}{80} S\n481 \n482     where :math:`S` is the plane of array irradiance in :math:`mW/{cm}^2`.\n483     This function expects irradiance in :math:`W/m^2`.\n484 \n485     References\n486     ----------\n487     .. [1] Ross, R. G. Jr., (1981). \"Design Techniques for Flat-Plate\n488        Photovoltaic Arrays\". 15th IEEE Photovoltaic Specialist Conference,\n489        Orlando, FL.\n490     '''\n491     # factor of 0.1 converts irradiance from W/m2 to mW/cm2\n492     return temp_air + (noct - 20.) / 80. * poa_global * 0.1\n493 \n494 \n495 def _fuentes_hconv(tave, windmod, tinoct, temp_delta, xlen, tilt,\n496                    check_reynold):\n497     # Calculate the convective coefficient as in Fuentes 1987 -- a mixture of\n498     # free, laminar, and turbulent convection.\n499     densair = 0.003484 * 101325.0 / tave  # density\n500     visair = 0.24237e-6 * tave**0.76 / densair  # kinematic viscosity\n501     condair = 2.1695e-4 * tave**0.84  # thermal conductivity\n502     reynold = windmod * xlen / visair\n503     # the boundary between laminar and turbulent is modeled as an abrupt\n504     # change at Re = 1.2e5:\n505     if check_reynold and reynold > 1.2e5:\n506         # turbulent convection\n507         hforce = 0.0282 / reynold**0.2 * densair * windmod * 1007 / 0.71**0.4\n508     else:\n509         # laminar convection\n510         hforce = 0.8600 / reynold**0.5 * densair * windmod * 1007 / 0.71**0.67\n511     # free convection via Grashof number\n512     # NB: Fuentes hardwires sind(tilt) as 0.5 for tilt=30\n513     grashof = 9.8 / tave * temp_delta * xlen**3 / visair**2 * sind(tilt)\n514     # product of Nusselt number and (k/l)\n515     hfree = 0.21 * (grashof * 0.71)**0.32 * condair / xlen\n516     # combine free and forced components\n517     hconv = (hfree**3 + hforce**3)**(1/3)\n518     return hconv\n519 \n520 \n521 def _hydraulic_diameter(width, height):\n522     # calculate the hydraulic diameter of a rectangle\n523     return 2 * (width * height) / (width + height)\n524 \n525 \n526 def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n527             wind_height=9.144, emissivity=0.84, absorption=0.83,\n528             surface_tilt=30, module_width=0.31579, module_length=1.2):\n529     \"\"\"\n530     Calculate cell or module temperature using the Fuentes model.\n531 \n532     The Fuentes model is a first-principles heat transfer energy balance\n533     model [1]_ that is used in PVWatts for cell temperature modeling [2]_.\n534 \n535     Parameters\n536     ----------\n537     poa_global : pandas Series\n538         Total incident irradiance [W/m^2]\n539 \n540     temp_air : pandas Series\n541         Ambient dry bulb temperature [C]\n542 \n543     wind_speed : pandas Series\n544         Wind speed [m/s]\n545 \n546     noct_installed : float\n547         The \"installed\" nominal operating cell temperature as defined in [1]_.\n548         PVWatts assumes this value to be 45 C for rack-mounted arrays and\n549         49 C for roof mount systems with restricted air flow around the\n550         module.  [C]\n551 \n552     module_height : float, default 5.0\n553         The height above ground of the center of the module. The PVWatts\n554         default is 5.0 [m]\n555 \n556     wind_height : float, default 9.144\n557         The height above ground at which ``wind_speed`` is measured. The\n558         PVWatts defauls is 9.144 [m]\n559 \n560     emissivity : float, default 0.84\n561         The effectiveness of the module at radiating thermal energy. [unitless]\n562 \n563     absorption : float, default 0.83\n564         The fraction of incident irradiance that is converted to thermal\n565         energy in the module. [unitless]\n566 \n567     surface_tilt : float, default 30\n568         Module tilt from horizontal. If not provided, the default value\n569         of 30 degrees from [1]_ and [2]_ is used. [degrees]\n570 \n571     module_width : float, default 0.31579\n572         Module width. The default value of 0.31579 meters in combination with\n573         the default `module_length` gives a hydraulic diameter of 0.5 as\n574         assumed in [1]_ and [2]_. [m]\n575 \n576     module_length : float, default 1.2\n577         Module length. The default value of 1.2 meters in combination with\n578         the default `module_width` gives a hydraulic diameter of 0.5 as\n579         assumed in [1]_ and [2]_. [m]\n580 \n581     Returns\n582     -------\n583     temperature_cell : pandas Series\n584         The modeled cell temperature [C]\n585 \n586     Notes\n587     -----\n588     This function returns slightly different values from PVWatts at night\n589     and just after dawn. This is because the SAM SSC assumes that module\n590     temperature equals ambient temperature when irradiance is zero so it can\n591     skip the heat balance calculation at night.\n592 \n593     References\n594     ----------\n595     .. [1] Fuentes, M. K., 1987, \"A Simplifed Thermal Model for Flat-Plate\n596            Photovoltaic Arrays\", SAND85-0330, Sandia National Laboratories,\n597            Albuquerque NM.\n598            http://prod.sandia.gov/techlib/access-control.cgi/1985/850330.pdf\n599     .. [2] Dobos, A. P., 2014, \"PVWatts Version 5 Manual\", NREL/TP-6A20-62641,\n600            National Renewable Energy Laboratory, Golden CO.\n601            doi:10.2172/1158421.\n602     \"\"\"\n603     # ported from the FORTRAN77 code provided in Appendix A of Fuentes 1987;\n604     # nearly all variable names are kept the same for ease of comparison.\n605 \n606     boltz = 5.669e-8\n607     emiss = emissivity\n608     absorp = absorption\n609     xlen = _hydraulic_diameter(module_width, module_length)\n610     # cap0 has units of [J / (m^2 K)], equal to mass per unit area times\n611     # specific heat of the module.\n612     cap0 = 11000\n613     tinoct = noct_installed + 273.15\n614 \n615     # convective coefficient of top surface of module at NOCT\n616     windmod = 1.0\n617     tave = (tinoct + 293.15) / 2\n618     hconv = _fuentes_hconv(tave, windmod, tinoct, tinoct - 293.15, xlen,\n619                            surface_tilt, False)\n620 \n621     # determine the ground temperature ratio and the ratio of the total\n622     # convection to the top side convection\n623     hground = emiss * boltz * (tinoct**2 + 293.15**2) * (tinoct + 293.15)\n624     backrat = (\n625         absorp * 800.0\n626         - emiss * boltz * (tinoct**4 - 282.21**4)\n627         - hconv * (tinoct - 293.15)\n628     ) / ((hground + hconv) * (tinoct - 293.15))\n629     tground = (tinoct**4 - backrat * (tinoct**4 - 293.15**4))**0.25\n630     tground = np.clip(tground, 293.15, tinoct)\n631 \n632     tgrat = (tground - 293.15) / (tinoct - 293.15)\n633     convrat = (absorp * 800 - emiss * boltz * (\n634         2 * tinoct**4 - 282.21**4 - tground**4)) / (hconv * (tinoct - 293.15))\n635 \n636     # adjust the capacitance (thermal mass) of the module based on the INOCT.\n637     # It is a function of INOCT because high INOCT implies thermal coupling\n638     # with the racking (e.g. roofmount), so the thermal mass is increased.\n639     # `cap` has units J/(m^2 C) -- see Table 3, Equations 26 & 27\n640     cap = cap0\n641     if tinoct > 321.15:\n642         cap = cap * (1 + (tinoct - 321.15) / 12)\n643 \n644     # iterate through timeseries inputs\n645     sun0 = 0\n646     tmod0 = 293.15\n647 \n648     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n649     # the value doesn't matter -- rather than recreate it here, just assume\n650     # it's the same as the second timedelta:\n651     timedelta_seconds = poa_global.index.to_series().diff().dt.total_seconds()\n652     timedelta_hours = timedelta_seconds / 3600\n653     timedelta_hours.iloc[0] = timedelta_hours.iloc[1]\n654 \n655     tamb_array = temp_air + 273.15\n656     sun_array = poa_global * absorp\n657 \n658     # Two of the calculations are easily vectorized, so precalculate them:\n659     # sky temperature -- Equation 24\n660     tsky_array = 0.68 * (0.0552 * tamb_array**1.5) + 0.32 * tamb_array\n661     # wind speed at module height -- Equation 22\n662     # not sure why the 1e-4 factor is included -- maybe the equations don't\n663     # behave well if wind == 0?\n664     windmod_array = wind_speed * (module_height/wind_height)**0.2 + 1e-4\n665 \n666     tmod0 = 293.15\n667     tmod_array = np.zeros_like(poa_global)\n668 \n669     iterator = zip(tamb_array, sun_array, windmod_array, tsky_array,\n670                    timedelta_hours)\n671     for i, (tamb, sun, windmod, tsky, dtime) in enumerate(iterator):\n672         # solve the heat transfer equation, iterating because the heat loss\n673         # terms depend on tmod. NB Fuentes doesn't show that 10 iterations is\n674         # sufficient for convergence.\n675         tmod = tmod0\n676         for j in range(10):\n677             # overall convective coefficient\n678             tave = (tmod + tamb) / 2\n679             hconv = convrat * _fuentes_hconv(tave, windmod, tinoct,\n680                                              abs(tmod-tamb), xlen,\n681                                              surface_tilt, True)\n682             # sky radiation coefficient (Equation 3)\n683             hsky = emiss * boltz * (tmod**2 + tsky**2) * (tmod + tsky)\n684             # ground radiation coeffieicient (Equation 4)\n685             tground = tamb + tgrat * (tmod - tamb)\n686             hground = emiss * boltz * (tmod**2 + tground**2) * (tmod + tground)\n687             # thermal lag -- Equation 8\n688             eigen = - (hconv + hsky + hground) / cap * dtime * 3600\n689             # not sure why this check is done, maybe as a speed optimization?\n690             if eigen > -10:\n691                 ex = np.exp(eigen)\n692             else:\n693                 ex = 0\n694             # Equation 7 -- note that `sun` and `sun0` already account for\n695             # absorption (alpha)\n696             tmod = tmod0 * ex + (\n697                 (1 - ex) * (\n698                     hconv * tamb\n699                     + hsky * tsky\n700                     + hground * tground\n701                     + sun0\n702                     + (sun - sun0) / eigen\n703                 ) + sun - sun0\n704             ) / (hconv + hsky + hground)\n705         tmod_array[i] = tmod\n706         tmod0 = tmod\n707         sun0 = sun\n708 \n709     return pd.Series(tmod_array - 273.15, index=poa_global.index, name='tmod')\n710 \n711 \n712 def _adj_for_mounting_standoff(x):\n713     # supports noct cell temperature function. Except for x > 3.5, the SAM code\n714     # and documentation aren't clear on the precise intervals. The choice of\n715     # < or <= here is pvlib's.\n716     return np.piecewise(x, [x <= 0, (x > 0) & (x < 0.5),\n717                             (x >= 0.5) & (x < 1.5), (x >= 1.5) & (x < 2.5),\n718                             (x >= 2.5) & (x <= 3.5), x > 3.5],\n719                         [0., 18., 11., 6., 2., 0.])\n720 \n721 \n722 def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n723              effective_irradiance=None, transmittance_absorptance=0.9,\n724              array_height=1, mount_standoff=4):\n725     r'''\n726     Cell temperature model from the System Advisor Model (SAM).\n727 \n728     The model is described in [1]_, Section 10.6.\n729 \n730     Parameters\n731     ----------\n732     poa_global : numeric\n733         Total incident irradiance. [W/m^2]\n734 \n735     temp_air : numeric\n736         Ambient dry bulb temperature. [C]\n737 \n738     wind_speed : numeric\n739         Wind speed in m/s measured at the same height for which the wind loss\n740         factor was determined.  The default value 1.0 m/s is the wind\n741         speed at module height used to determine NOCT. [m/s]\n742 \n743     noct : float\n744         Nominal operating cell temperature [C], determined at conditions of\n745         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n746 \n747     eta_m_ref : float\n748         Module external efficiency [unitless] at reference conditions of\n749         1000 W/m^2 and 20C. Calculate as\n750         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n751         where A is module area [m^2].\n752 \n753     effective_irradiance : numeric, default None.\n754         The irradiance that is converted to photocurrent. If None,\n755         assumed equal to poa_global. [W/m^2]\n756 \n757     transmittance_absorptance : numeric, default 0.9\n758         Coefficient for combined transmittance and absorptance effects.\n759         [unitless]\n760 \n761     array_height : int, default 1\n762         Height of array above ground in stories (one story is about 3m). Must\n763         be either 1 or 2. For systems elevated less than one story, use 1.\n764         If system is elevated more than two stories, use 2.\n765 \n766     mount_standoff : numeric, default 4\n767         Distance between array mounting and mounting surface. Use default\n768         if system is ground-mounted. [inches]\n769 \n770     Returns\n771     -------\n772     cell_temperature : numeric\n773         Cell temperature. [C]\n774 \n775     Raises\n776     ------\n777     ValueError\n778         If array_height is an invalid value (must be 1 or 2).\n779 \n780     References\n781     ----------\n782     .. [1] Gilman, P., Dobos, A., DiOrio, N., Freeman, J., Janzou, S.,\n783            Ryberg, D., 2018, \"SAM Photovoltaic Model Technical Reference\n784            Update\", National Renewable Energy Laboratory Report\n785            NREL/TP-6A20-67399.\n786     '''\n787     # in [1] the denominator for irr_ratio isn't precisely clear. From\n788     # reproducing output of the SAM function noct_celltemp_t, we determined\n789     # that:\n790     #  - G_total (SAM) is broadband plane-of-array irradiance before\n791     #    reflections. Equivalent to pvlib variable poa_global\n792     #  - Geff_total (SAM) is POA irradiance after reflections and\n793     #    adjustment for spectrum. Equivalent to effective_irradiance\n794     if effective_irradiance is None:\n795         irr_ratio = 1.\n796     else:\n797         irr_ratio = effective_irradiance / poa_global\n798 \n799     if array_height == 1:\n800         wind_adj = 0.51 * wind_speed\n801     elif array_height == 2:\n802         wind_adj = 0.61 * wind_speed\n803     else:\n804         raise ValueError(\n805             f'array_height must be 1 or 2, {array_height} was given')\n806 \n807     noct_adj = noct + _adj_for_mounting_standoff(mount_standoff)\n808     tau_alpha = transmittance_absorptance * irr_ratio\n809 \n810     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n811     # poa_global where G appears\n812     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n813     heat_loss = 1 - eta_m_ref / tau_alpha\n814     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n815     return temp_air + cell_temp_init * heat_loss * wind_loss\n816 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "40ba4bd5c8b91754aa73e638ed984ab9657847cd", "problem_statement": "change eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n", "hints_text": "I support this change.", "created_at": "2021-05-06T16:02:38Z", "patch": "<patch>\ndiff --git a/pvlib/modelchain.py b/pvlib/modelchain.py\n--- a/pvlib/modelchain.py\n+++ b/pvlib/modelchain.py\n@@ -977,7 +977,7 @@ def infer_temperature_model(self):\n             return self.faiman_temp\n         elif {'noct_installed'} <= params:\n             return self.fuentes_temp\n-        elif {'noct', 'eta_m_ref'} <= params:\n+        elif {'noct', 'module_efficiency'} <= params:\n             return self.noct_sam_temp\n         else:\n             raise ValueError(f'could not infer temperature model from '\ndiff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -671,7 +671,9 @@ def pvsyst_celltemp(self, poa_global, temp_air, wind_speed=1.0):\n         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n \n         def build_celltemp_kwargs(array):\n-            return {**_build_kwargs(['eta_m', 'alpha_absorption'],\n+            # TODO remove 'eta_m' after deprecation of this parameter\n+            return {**_build_kwargs(['eta_m', 'module_efficiency',\n+                                     'alpha_absorption'],\n                                     array.module_parameters),\n                     **_build_kwargs(['u_c', 'u_v'],\n                                     array.temperature_model_parameters)}\n@@ -843,10 +845,10 @@ def _build_kwargs_noct_sam(array):\n                 # bundled with kwargs for simplicity\n                 temp_model_kwargs['noct'] = \\\n                     array.temperature_model_parameters['noct']\n-                temp_model_kwargs['eta_m_ref'] = \\\n-                    array.temperature_model_parameters['eta_m_ref']\n+                temp_model_kwargs['module_efficiency'] = \\\n+                    array.temperature_model_parameters['module_efficiency']\n             except KeyError:\n-                msg = ('Parameters noct and eta_m_ref are required.'\n+                msg = ('Parameters noct and module_efficiency are required.'\n                        ' Found {} in temperature_model_parameters.'\n                        .format(array.temperature_model_parameters))\n                 raise KeyError(msg)\ndiff --git a/pvlib/temperature.py b/pvlib/temperature.py\n--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -6,6 +6,7 @@\n import numpy as np\n import pandas as pd\n from pvlib.tools import sind\n+from pvlib._deprecation import warn_deprecated\n \n TEMPERATURE_MODEL_PARAMETERS = {\n     'sapm': {\n@@ -285,7 +286,7 @@ def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n \n \n def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n-                eta_m=0.1, alpha_absorption=0.9):\n+                eta_m=None, module_efficiency=0.1, alpha_absorption=0.9):\n     r\"\"\"\n     Calculate cell temperature using an empirical heat loss factor model\n     as implemented in PVsyst.\n@@ -313,12 +314,14 @@ def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n     u_v : float, default 0.0\n         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n         in :eq:`pvsyst`.\n-        :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n+        :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`  # noQA: E501\n+\n+    eta_m : numeric, default None (deprecated, use module_efficiency instead)\n \n-    eta_m : numeric, default 0.1\n-        Module external efficiency as a fraction, i.e.,\n-        :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n-        Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n+    module_efficiency : numeric, default 0.1\n+        Module external efficiency as a fraction. Parameter :math:`\\eta_{m}`\n+        in :eq:`pvsyst`. Calculate as\n+        :math:`\\eta_{m} = DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n \n     alpha_absorption : numeric, default 0.9\n         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n@@ -370,8 +373,13 @@ def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n     37.93103448275862\n     \"\"\"\n \n+    if eta_m:\n+        warn_deprecated(\n+            since='v0.9', message='eta_m overwriting module_efficiency',\n+            name='eta_m', alternative='module_efficiency', removal='v0.10')\n+        module_efficiency = eta_m\n     total_loss_factor = u_c + u_v * wind_speed\n-    heat_input = poa_global * alpha_absorption * (1 - eta_m)\n+    heat_input = poa_global * alpha_absorption * (1 - module_efficiency)\n     temp_difference = heat_input / total_loss_factor\n     return temp_air + temp_difference\n \n@@ -719,7 +727,7 @@ def _adj_for_mounting_standoff(x):\n                         [0., 18., 11., 6., 2., 0.])\n \n \n-def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n+def noct_sam(poa_global, temp_air, wind_speed, noct, module_efficiency,\n              effective_irradiance=None, transmittance_absorptance=0.9,\n              array_height=1, mount_standoff=4):\n     r'''\n@@ -744,9 +752,9 @@ def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n         Nominal operating cell temperature [C], determined at conditions of\n         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n \n-    eta_m_ref : float\n+    module_efficiency : float\n         Module external efficiency [unitless] at reference conditions of\n-        1000 W/m^2 and 20C. Calculate as\n+        1000 W/m^2 and 20C. Denoted as :math:`eta_{m}` in [1]_. Calculate as\n         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n         where A is module area [m^2].\n \n@@ -810,6 +818,6 @@ def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n     # poa_global where G appears\n     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n-    heat_loss = 1 - eta_m_ref / tau_alpha\n+    heat_loss = 1 - module_efficiency / tau_alpha\n     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n     return temp_air + cell_temp_init * heat_loss * wind_loss\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_modelchain.py b/pvlib/tests/test_modelchain.py\n--- a/pvlib/tests/test_modelchain.py\n+++ b/pvlib/tests/test_modelchain.py\n@@ -201,7 +201,7 @@ def pvwatts_dc_pvwatts_ac_faiman_temp_system():\n @pytest.fixture(scope=\"function\")\n def pvwatts_dc_pvwatts_ac_pvsyst_temp_system():\n     module_parameters = {'pdc0': 220, 'gamma_pdc': -0.003}\n-    temp_model_params = {'u_c': 29.0, 'u_v': 0.0, 'eta_m': 0.1,\n+    temp_model_params = {'u_c': 29.0, 'u_v': 0.0, 'module_efficiency': 0.1,\n                          'alpha_absorption': 0.9}\n     inverter_parameters = {'pdc0': 220, 'eta_inv_nom': 0.95}\n     system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n@@ -226,7 +226,7 @@ def pvwatts_dc_pvwatts_ac_fuentes_temp_system():\n @pytest.fixture(scope=\"function\")\n def pvwatts_dc_pvwatts_ac_noct_sam_temp_system():\n     module_parameters = {'pdc0': 220, 'gamma_pdc': -0.003}\n-    temp_model_params = {'noct': 45, 'eta_m_ref': 0.2}\n+    temp_model_params = {'noct': 45, 'module_efficiency': 0.2}\n     inverter_parameters = {'pdc0': 220, 'eta_inv_nom': 0.95}\n     system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n                       module_parameters=module_parameters,\n@@ -710,7 +710,7 @@ def test_run_model_with_weather_noct_sam_temp(sapm_dc_snl_ac_system, location,\n     weather['wind_speed'] = 5\n     weather['temp_air'] = 10\n     sapm_dc_snl_ac_system.temperature_model_parameters = {\n-        'noct': 45, 'eta_m_ref': 0.2\n+        'noct': 45, 'module_efficiency': 0.2\n     }\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     mc.temperature_model = 'noct_sam'\n@@ -941,7 +941,7 @@ def test__prepare_temperature_arrays_weather(sapm_dc_snl_ac_system_same_arrays,\n                            ModelChain.faiman_temp),\n                           ({'noct_installed': 45},\n                            ModelChain.fuentes_temp),\n-                          ({'noct': 45, 'eta_m_ref': 0.2},\n+                          ({'noct': 45, 'module_efficiency': 0.2},\n                            ModelChain.noct_sam_temp)])\n def test_temperature_models_arrays_multi_weather(\n         temp_params, temp_model,\ndiff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -392,7 +392,7 @@ def two_array_system(pvsyst_module_params, cec_module_params):\n     temperature_model['noct_installed'] = 45\n     # parameters for noct_sam temperature model\n     temperature_model['noct'] = 45.\n-    temperature_model['eta_m_ref'] = 0.2\n+    temperature_model['module_efficiency'] = 0.2\n     module_params = {**pvsyst_module_params, **cec_module_params}\n     return pvsystem.PVSystem(\n         arrays=[\n@@ -471,8 +471,9 @@ def test_PVSystem_pvsyst_celltemp(mocker):\n     temp_model_params = temperature.TEMPERATURE_MODEL_PARAMETERS['pvsyst'][\n         parameter_set]\n     alpha_absorption = 0.85\n-    eta_m = 0.17\n-    module_parameters = {'alpha_absorption': alpha_absorption, 'eta_m': eta_m}\n+    module_efficiency = 0.17\n+    module_parameters = {'alpha_absorption': alpha_absorption,\n+                         'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(module_parameters=module_parameters,\n                                temperature_model_parameters=temp_model_params)\n     mocker.spy(temperature, 'pvsyst_cell')\n@@ -481,8 +482,9 @@ def test_PVSystem_pvsyst_celltemp(mocker):\n     wind = 0.5\n     out = system.pvsyst_celltemp(irrad, temp, wind_speed=wind)\n     temperature.pvsyst_cell.assert_called_once_with(\n-        irrad, temp, wind, temp_model_params['u_c'], temp_model_params['u_v'],\n-        eta_m, alpha_absorption)\n+        irrad, temp, wind_speed=wind, u_c=temp_model_params['u_c'],\n+        u_v=temp_model_params['u_v'], module_efficiency=module_efficiency,\n+        alpha_absorption=alpha_absorption)\n     assert (out < 90) and (out > 70)\n \n \n@@ -500,16 +502,16 @@ def test_PVSystem_faiman_celltemp(mocker):\n \n \n def test_PVSystem_noct_celltemp(mocker):\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     expected = 55.230790492\n-    temp_model_params = {'noct': noct, 'eta_m_ref': eta_m_ref}\n+    temp_model_params = {'noct': noct, 'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(temperature_model_parameters=temp_model_params)\n     mocker.spy(temperature, 'noct_sam')\n     out = system.noct_sam_celltemp(poa_global, temp_air, wind_speed)\n     temperature.noct_sam.assert_called_once_with(\n         poa_global, temp_air, wind_speed, effective_irradiance=None, noct=noct,\n-        eta_m_ref=eta_m_ref)\n+        module_efficiency=module_efficiency)\n     assert_allclose(out, expected)\n     # dufferent types\n     out = system.noct_sam_celltemp(np.array(poa_global), np.array(temp_air),\n@@ -533,8 +535,8 @@ def test_PVSystem_noct_celltemp(mocker):\n \n \n def test_PVSystem_noct_celltemp_error():\n-    poa_global, temp_air, wind_speed, eta_m_ref = (1000., 25., 1., 0.2)\n-    temp_model_params = {'eta_m_ref': eta_m_ref}\n+    poa_global, temp_air, wind_speed, module_efficiency = (1000., 25., 1., 0.2)\n+    temp_model_params = {'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(temperature_model_parameters=temp_model_params)\n     with pytest.raises(KeyError):\n         system.noct_sam_celltemp(poa_global, temp_air, wind_speed)\ndiff --git a/pvlib/tests/test_temperature.py b/pvlib/tests/test_temperature.py\n--- a/pvlib/tests/test_temperature.py\n+++ b/pvlib/tests/test_temperature.py\n@@ -6,6 +6,7 @@\n from numpy.testing import assert_allclose\n \n from pvlib import temperature, tools\n+from pvlib._deprecation import pvlibDeprecationWarning\n \n \n @pytest.fixture\n@@ -72,7 +73,7 @@ def test_pvsyst_cell_default():\n \n def test_pvsyst_cell_kwargs():\n     result = temperature.pvsyst_cell(900, 20, wind_speed=5.0, u_c=23.5,\n-                                     u_v=6.25, eta_m=0.1)\n+                                     u_v=6.25, module_efficiency=0.1)\n     assert_allclose(result, 33.315, 0.001)\n \n \n@@ -96,6 +97,13 @@ def test_pvsyst_cell_series():\n     assert_series_equal(expected, result)\n \n \n+def test_pvsyst_cell_eta_m_deprecated():\n+    with pytest.warns(pvlibDeprecationWarning):\n+        result = temperature.pvsyst_cell(900, 20, wind_speed=5.0, u_c=23.5,\n+                                         u_v=6.25, eta_m=0.1)\n+        assert_allclose(result, 33.315, 0.001)\n+\n+\n def test_faiman_default():\n     result = temperature.faiman(900, 20, 5)\n     assert_allclose(result, 35.203, 0.001)\n@@ -215,16 +223,16 @@ def test_fuentes_timezone(tz):\n \n \n def test_noct_sam():\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     expected = 55.230790492\n     result = temperature.noct_sam(poa_global, temp_air, wind_speed, noct,\n-                                  eta_m_ref)\n+                                  module_efficiency)\n     assert_allclose(result, expected)\n     # test with different types\n     result = temperature.noct_sam(np.array(poa_global), np.array(temp_air),\n                                   np.array(wind_speed), np.array(noct),\n-                                  np.array(eta_m_ref))\n+                                  np.array(module_efficiency))\n     assert_allclose(result, expected)\n     dr = pd.date_range(start='2020-01-01 12:00:00', end='2020-01-01 13:00:00',\n                        freq='1H')\n@@ -232,7 +240,7 @@ def test_noct_sam():\n                                   pd.Series(index=dr, data=temp_air),\n                                   pd.Series(index=dr, data=wind_speed),\n                                   pd.Series(index=dr, data=noct),\n-                                  eta_m_ref)\n+                                  module_efficiency)\n     assert_series_equal(result, pd.Series(index=dr, data=expected))\n \n \n@@ -242,7 +250,7 @@ def test_noct_sam_against_sam():\n     # NOCT cell temperature model), with the only change being the soiling\n     # loss is set to 0. Weather input is TMY3 for Phoenix AZ.\n     # Values are taken from the Jan 1 12:00:00 timestamp.\n-    poa_total, temp_air, wind_speed, noct, eta_m_ref = (\n+    poa_total, temp_air, wind_speed, noct, module_efficiency = (\n         860.673, 25, 3, 46.4, 0.20551)\n     poa_total_after_refl = 851.458  # from SAM output\n     # compute effective irradiance\n@@ -259,7 +267,7 @@ def test_noct_sam_against_sam():\n     array_height = 1\n     mount_standoff = 4.0\n     result = temperature.noct_sam(poa_total, temp_air, wind_speed, noct,\n-                                  eta_m_ref, effective_irradiance,\n+                                  module_efficiency, effective_irradiance,\n                                   transmittance_absorptance, array_height,\n                                   mount_standoff)\n     expected = 43.0655\n@@ -268,14 +276,14 @@ def test_noct_sam_against_sam():\n \n \n def test_noct_sam_options():\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     effective_irradiance = 1100.\n     transmittance_absorptance = 0.8\n     array_height = 2\n     mount_standoff = 2.0\n     result = temperature.noct_sam(poa_global, temp_air, wind_speed, noct,\n-                                  eta_m_ref, effective_irradiance,\n+                                  module_efficiency, effective_irradiance,\n                                   transmittance_absorptance, array_height,\n                                   mount_standoff)\n     expected = 60.477703576\n", "version": "0.8", "FAIL_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_run_model_with_weather_noct_sam_temp\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params4-noct_sam_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[noct_sam_temp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[noct_sam_celltemp]\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_kwargs\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_eta_m_deprecated\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_ModelChain_creation\", \"pvlib/tests/test_modelchain.py::test_with_sapm\", \"pvlib/tests/test_modelchain.py::test_with_pvwatts\", \"pvlib/tests/test_modelchain.py::test_run_model_with_irradiance\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss_input_type[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss_input_type[list]\", \"pvlib/tests/test_modelchain.py::test_ModelChain_invalid_inverter_params_arrays[adr]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_multi_weather[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_multi_weather[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_no_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_arrays_one_missing_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_weather_wrong_length[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_weather_wrong_length[list]\", \"pvlib/tests/test_modelchain.py::test_ModelChain_times_error_arrays\", \"pvlib/tests/test_modelchain.py::test_ModelChain_times_arrays\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[dhi]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[ghi]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[dni]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[tuple-sandia]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[tuple-pvwatts]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[list-sandia]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[list-pvwatts]\", \"pvlib/tests/test_modelchain.py::test_run_model_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_gueymard_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_sapm_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_pvsyst_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_faiman_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_fuentes_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker_list\", \"pvlib/tests/test_modelchain.py::test__assign_total_irrad\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_multi_data[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_multi_data[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_wrong_number_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_wrong_number_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_arrays_different_indices\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_arrays_missing_column\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature_len1_weather_tuple\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature_arrays_weather\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params0-sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params1-pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params2-faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params3-fuentes_temp]\", \"pvlib/tests/test_modelchain.py::test_run_model_solar_position_weather\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays_solar_position_weather\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_tracking\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[<lambda>]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_multi_array[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_multi_array[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[<lambda>]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_poa_global_differs\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays_error[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays_error[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_minimal_input\", \"pvlib/tests/test_modelchain.py::test_run_model_singleton_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_singleton_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[desoto]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[singlediode]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvwatts_dc]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[cec]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[desoto]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec_native]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[fuentes_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model_invalid\", \"pvlib/tests/test_modelchain.py::test_temperature_model_inconsistent\", \"pvlib/tests/test_modelchain.py::test_dc_model_user_func\", \"pvlib/tests/test_modelchain.py::test_pvwatts_dc_multiple_strings\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia]\", \"pvlib/tests/test_modelchain.py::test_ac_models[adr]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts]\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia_multi]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts_multi]\", \"pvlib/tests/test_modelchain.py::test_ac_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_model_not_a_model\", \"pvlib/tests/test_modelchain.py::test_infer_ac_model_invalid_params\", \"pvlib/tests/test_modelchain.py::test_aoi_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_model_no_loss\", \"pvlib/tests/test_modelchain.py::test_aoi_model_user_func\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[ashrae]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[physical]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model_invalid\", \"pvlib/tests/test_modelchain.py::test_spectral_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_model_ohms_from_percent\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_model_no_dc_ohmic_loss\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_ext_def\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_not_a_model\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts_arrays\", \"pvlib/tests/test_modelchain.py::test_losses_models_ext_def\", \"pvlib/tests/test_modelchain.py::test_losses_models_no_loss\", \"pvlib/tests/test_modelchain.py::test_invalid_dc_model_params\", \"pvlib/tests/test_modelchain.py::test_invalid_models[dc_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[ac_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[aoi_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[spectral_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[temperature_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[losses_model]\", \"pvlib/tests/test_modelchain.py::test_bad_get_orientation\", \"pvlib/tests/test_modelchain.py::test_with_sapm_pvsystem_arrays\", \"pvlib/tests/test_modelchain.py::test_ModelChain_no_extra_kwargs\", \"pvlib/tests/test_modelchain.py::test_ModelChain_attributes_deprecated_10\", \"pvlib/tests/test_modelchain.py::test_basic_chain_alt_az\", \"pvlib/tests/test_modelchain.py::test_basic_chain_altitude_pressure\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_clean_run\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays_wrong_length[tuple]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays_wrong_length[list]\", \"pvlib/tests/test_modelchain.py::test_unknown_attribute\", \"pvlib/tests/test_modelchain.py::test_inconsistent_array_params\", \"pvlib/tests/test_modelchain.py::test_modelchain__common_keys\", \"pvlib/tests/test_modelchain.py::test__irrad_for_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_iam\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[1.5-1.00028714375]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_first_solar_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[20-poa_diffuse0-aoi0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct1-poa_diffuse1-aoi1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct2-poa_diffuse2-20]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_celltemp_different_arrays\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp_override\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_cell_type\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_desoto]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_cec]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-1-celltemp0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-irrad1-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-1-celltemp2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-irrad3-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-1-celltemp4]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-irrad5-1]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_snlinverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[sandia]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[adr]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[pvwatts]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_invalid\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance_model\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance_multi_irrad\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_change_surface_azimuth\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_albedo\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_modules_per_string\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_strings_per_inverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array___repr__\", \"pvlib/tests/test_pvsystem.py::test_Array___repr__\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc_value_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_num_arrays\", \"pvlib/tests/test_pvsystem.py::test_combine_loss_factors\", \"pvlib/tests/test_pvsystem.py::test_no_extra_kwargs\", \"pvlib/tests/test_pvsystem.py::test_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_dc_ohmic_losses\", \"pvlib/tests/test_pvsystem.py::test_Array_dc_ohms_from_percent\", \"pvlib/tests/test_temperature.py::test_sapm_cell\", \"pvlib/tests/test_temperature.py::test_sapm_module\", \"pvlib/tests/test_temperature.py::test_sapm_cell_from_module\", \"pvlib/tests/test_temperature.py::test_sapm_ndarray\", \"pvlib/tests/test_temperature.py::test_sapm_series\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_default\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_ndarray\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_series\", \"pvlib/tests/test_temperature.py::test_faiman_default\", \"pvlib/tests/test_temperature.py::test_faiman_kwargs\", \"pvlib/tests/test_temperature.py::test_faiman_list\", \"pvlib/tests/test_temperature.py::test_faiman_ndarray\", \"pvlib/tests/test_temperature.py::test_ross\", \"pvlib/tests/test_temperature.py::test_faiman_series\", \"pvlib/tests/test_temperature.py::test__temperature_model_params\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_rackmount.csv-45]\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_roofmount.csv-49]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[None]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[Etc/GMT+5]\", \"pvlib/tests/test_temperature.py::test_noct_sam\", \"pvlib/tests/test_temperature.py::test_noct_sam_against_sam\", \"pvlib/tests/test_temperature.py::test_noct_sam_options\", \"pvlib/tests/test_temperature.py::test_noct_sam_errors\"]", "environment_setup_commit": "ef8ad2fee9840a77d14b0dfd17fc489dd85c9b91"}
{"instance_id": "pvlib__pvlib-python-1218_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nchange eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n32       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n33     </a>\n34   </td>\n35 </tr>\n36 <tr>\n37   <td>Code Quality</td>\n38  \u00a0<td>\n39     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n40     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n41     </a>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n43     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Coverage</td>\n49  \u00a0<td>\n50     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n51     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n52     </a>\n53     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n54     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Publications</td>\n60   <td>\n61     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n62     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n63     </a>\n64     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n65     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n66     </a>\n67   </td>\n68 </tr>\n69 <tr>\n70   <td>Downloads</td>\n71   <td>\n72     <a href=\"https://pypi.org/project/pvlib/\">\n73     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n74     </a>\n75     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n76     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n77     </a>\n78   </td>\n79 </tr>\n80 </table>\n81 \n82 \n83 pvlib python is a community supported tool that provides a set of\n84 functions and classes for simulating the performance of photovoltaic\n85 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n86 toolbox developed at Sandia National Laboratories and it implements many\n87 of the models and methods developed at the Labs. More information on\n88 Sandia Labs PV performance modeling programs can be found at\n89 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n90 but operate independently of it.\n91 \n92 \n93 Documentation\n94 =============\n95 \n96 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n97 \n98 \n99 Installation\n100 ============\n101 \n102 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n103 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n104 \n105 \n106 Contributing\n107 ============\n108 \n109 We need your help to make pvlib-python a great tool!\n110 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n111 The long-term success of pvlib-python requires substantial community support.\n112 \n113 \n114 License\n115 =======\n116 \n117 BSD 3-clause\n118 \n119 \n120 Getting support\n121 ===============\n122 \n123 pvlib usage questions can be asked on\n124 [Stack Overflow](http://stackoverflow.com) and tagged with\n125 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n126 \n127 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n128 is used for discussing various topics of interest to the pvlib-python\n129 community. We also make new version announcements on the google group.\n130 \n131 If you suspect that you may have discovered a bug or if you'd like to\n132 change something about pvlib, then please make an issue on our\n133 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n134 \n135 \n136 Citing\n137 ======\n138 \n139 If you use pvlib-python in a published work, please cite:\n140 \n141   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n142   \"pvlib python: a python package for modeling solar energy systems.\"\n143   Journal of Open Source Software, 3(29), 884, (2018).\n144   https://doi.org/10.21105/joss.00884\n145 \n146 Please also cite the DOI corresponding to the specific version of\n147 pvlib-python that you used. pvlib-python DOIs are listed at\n148 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n149 \n150 NumFOCUS\n151 ========\n152 \n153 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n154 \n155 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n156 \n[end of README.md]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 import pandas as pd\n8 from pvlib.tools import sind\n9 \n10 TEMPERATURE_MODEL_PARAMETERS = {\n11     'sapm': {\n12         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n13         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n14         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n15         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n16     },\n17     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n18                'insulated': {'u_c': 15.0, 'u_v': 0}}\n19 }\n20 \"\"\"Dictionary of temperature parameters organized by model.\n21 \n22 There are keys for each model at the top level. Currently there are two models,\n23 ``'sapm'`` for the Sandia Array Performance Model, and ``'pvsyst'``. Each model\n24 has a dictionary of configurations; a value is itself a dictionary containing\n25 model parameters. Retrieve parameters by indexing the model and configuration\n26 by name. Note: the keys are lower-cased and case sensitive.\n27 \n28 Example\n29 -------\n30 Retrieve the open rack glass-polymer configuration for SAPM::\n31 \n32     from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n33     temperature_model_parameters = (\n34         TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'])\n35     # {'a': -3.56, 'b': -0.075, 'deltaT': 3}\n36 \"\"\"\n37 \n38 \n39 def _temperature_model_params(model, parameter_set):\n40     try:\n41         params = TEMPERATURE_MODEL_PARAMETERS[model]\n42         return params[parameter_set]\n43     except KeyError:\n44         msg = ('{} is not a named set of parameters for the {} cell'\n45                ' temperature model.'\n46                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n47                ' for names'.format(parameter_set, model))\n48         raise KeyError(msg)\n49 \n50 \n51 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n52               irrad_ref=1000.):\n53     r'''\n54     Calculate cell temperature per the Sandia Array Performance Model.\n55 \n56     See [1]_ for details on the Sandia Array Performance Model.\n57 \n58     Parameters\n59     ----------\n60     poa_global : numeric\n61         Total incident irradiance [W/m^2].\n62 \n63     temp_air : numeric\n64         Ambient dry bulb temperature [C].\n65 \n66     wind_speed : numeric\n67         Wind speed at a height of 10 meters [m/s].\n68 \n69     a : float\n70         Parameter :math:`a` in :eq:`sapm1`.\n71 \n72     b : float\n73         Parameter :math:`b` in :eq:`sapm1`.\n74 \n75     deltaT : float\n76         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n77 \n78     irrad_ref : float, default 1000\n79         Reference irradiance, parameter :math:`E_{0}` in\n80         :eq:`sapm2` [W/m^2].\n81 \n82     Returns\n83     -------\n84     numeric, values in degrees C.\n85 \n86     Notes\n87     -----\n88     The model for cell temperature :math:`T_{C}` is given by a pair of\n89     equations (Eq. 11 and 12 in [1]_).\n90 \n91     .. math::\n92        :label: sapm1\n93 \n94        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n95 \n96     .. math::\n97        :label: sapm2\n98 \n99        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n100 \n101     The module back surface temperature :math:`T_{m}` is implemented in\n102     :py:func:`~pvlib.temperature.sapm_module`.\n103 \n104     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n105     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n106     the module construction and its mounting. Parameter sets are provided in\n107     [1]_ for representative modules and mounting, and are coded for convenience\n108     in :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n109 \n110     +---------------+----------------+-------+---------+---------------------+\n111     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n112     +===============+================+=======+=========+=====================+\n113     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n114     +---------------+----------------+-------+---------+---------------------+\n115     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n116     +---------------+----------------+-------+---------+---------------------+\n117     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n118     +---------------+----------------+-------+---------+---------------------+\n119     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n120     +---------------+----------------+-------+---------+---------------------+\n121 \n122     References\n123     ----------\n124     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n125        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n126        NM.\n127 \n128     See also\n129     --------\n130     sapm_cell_from_module\n131     sapm_module\n132 \n133     Examples\n134     --------\n135     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n136     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n137     >>> sapm_cell(1000, 10, 0, **params)\n138     44.11703066106086\n139     '''\n140     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n141                                      a, b)\n142     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n143                                  irrad_ref)\n144 \n145 \n146 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n147     r'''\n148     Calculate module back surface temperature per the Sandia Array\n149     Performance Model.\n150 \n151     See [1]_ for details on the Sandia Array Performance Model.\n152 \n153     Parameters\n154     ----------\n155     poa_global : numeric\n156         Total incident irradiance [W/m^2].\n157 \n158     temp_air : numeric\n159         Ambient dry bulb temperature [C].\n160 \n161     wind_speed : numeric\n162         Wind speed at a height of 10 meters [m/s].\n163 \n164     a : float\n165         Parameter :math:`a` in :eq:`sapm1mod`.\n166 \n167     b : float\n168         Parameter :math:`b` in :eq:`sapm1mod`.\n169 \n170     Returns\n171     -------\n172     numeric, values in degrees C.\n173 \n174     Notes\n175     -----\n176     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n177 \n178     .. math::\n179        :label: sapm1mod\n180 \n181        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n182 \n183     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n184     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n185     temperature at the back of the module :math:`T_{m}` and cell temperature\n186     :math:`T_{C}`. Model parameters depend both on the module construction and\n187     its mounting. Parameter sets are provided in [1]_ for representative\n188     modules and mounting, and are coded for convenience in\n189     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n190 \n191     +---------------+----------------+-------+---------+---------------------+\n192     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n193     +===============+================+=======+=========+=====================+\n194     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n195     +---------------+----------------+-------+---------+---------------------+\n196     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n197     +---------------+----------------+-------+---------+---------------------+\n198     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n199     +---------------+----------------+-------+---------+---------------------+\n200     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n201     +---------------+----------------+-------+---------+---------------------+\n202 \n203     References\n204     ----------\n205     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n206        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n207        NM.\n208 \n209     See also\n210     --------\n211     sapm_cell\n212     sapm_cell_from_module\n213     '''\n214     return poa_global * np.exp(a + b * wind_speed) + temp_air\n215 \n216 \n217 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n218                           irrad_ref=1000.):\n219     r'''\n220     Calculate cell temperature from module temperature using the Sandia Array\n221     Performance Model.\n222 \n223     See [1]_ for details on the Sandia Array Performance Model.\n224 \n225     Parameters\n226     ----------\n227     module_temperature : numeric\n228         Temperature of back of module surface [C].\n229 \n230     poa_global : numeric\n231         Total incident irradiance [W/m^2].\n232 \n233     deltaT : float\n234         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n235 \n236     irrad_ref : float, default 1000\n237         Reference irradiance, parameter :math:`E_{0}` in\n238         :eq:`sapm2` [W/m^2].\n239 \n240     Returns\n241     -------\n242     numeric, values in degrees C.\n243 \n244     Notes\n245     -----\n246     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n247 \n248     .. math::\n249        :label: sapm2_cell_from_mod\n250 \n251        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n252 \n253     The module back surface temperature :math:`T_{m}` is implemented in\n254     :py:func:`~pvlib.temperature.sapm_module`.\n255 \n256     Model parameters depend both on the module construction and its mounting.\n257     Parameter sets are provided in [1]_ for representative modules and\n258     mounting, and are coded for convenience in\n259     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n260 \n261     +---------------+----------------+-------+---------+---------------------+\n262     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n263     +===============+================+=======+=========+=====================+\n264     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n265     +---------------+----------------+-------+---------+---------------------+\n266     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n267     +---------------+----------------+-------+---------+---------------------+\n268     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n269     +---------------+----------------+-------+---------+---------------------+\n270     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n271     +---------------+----------------+-------+---------+---------------------+\n272 \n273     References\n274     ----------\n275     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n276        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n277        NM.\n278 \n279     See also\n280     --------\n281     sapm_cell\n282     sapm_module\n283     '''\n284     return module_temperature + (poa_global / irrad_ref) * deltaT\n285 \n286 \n287 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n288                 eta_m=0.1, alpha_absorption=0.9):\n289     r\"\"\"\n290     Calculate cell temperature using an empirical heat loss factor model\n291     as implemented in PVsyst.\n292 \n293     Parameters\n294     ----------\n295     poa_global : numeric\n296         Total incident irradiance [W/m^2].\n297 \n298     temp_air : numeric\n299         Ambient dry bulb temperature [C].\n300 \n301     wind_speed : numeric, default 1.0\n302         Wind speed in m/s measured at the same height for which the wind loss\n303         factor was determined.  The default value 1.0 m/2 is the wind\n304         speed at module height used to determine NOCT. [m/s]\n305 \n306     u_c : float, default 29.0\n307         Combined heat loss factor coefficient. The default value is\n308         representative of freestanding modules with the rear surfaces exposed\n309         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n310         :eq:`pvsyst`.\n311         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n312 \n313     u_v : float, default 0.0\n314         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n315         in :eq:`pvsyst`.\n316         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n317 \n318     eta_m : numeric, default 0.1\n319         Module external efficiency as a fraction, i.e.,\n320         :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n321         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n322 \n323     alpha_absorption : numeric, default 0.9\n324         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n325 \n326     Returns\n327     -------\n328     numeric, values in degrees Celsius\n329 \n330     Notes\n331     -----\n332     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n333 \n334     .. math::\n335        :label: pvsyst\n336 \n337         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n338 \n339     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n340     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n341     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n342     the module construction and its mounting. Parameters are provided in\n343     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n344     , and are coded for convenience in\n345     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`. The heat loss\n346     factors provided represent the combined effect of convection, radiation and\n347     conduction, and their values are experimentally determined.\n348 \n349     +--------------+---------------+---------------+\n350     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n351     +==============+===============+===============+\n352     | freestanding | 29.0          | 0.0           |\n353     +--------------+---------------+---------------+\n354     | insulated    | 15.0          | 0.0           |\n355     +--------------+---------------+---------------+\n356 \n357     References\n358     ----------\n359     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n360        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n361 \n362     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n363        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n364 \n365     Examples\n366     --------\n367     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n368     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n369     >>> pvsyst_cell(1000, 10, **params)\n370     37.93103448275862\n371     \"\"\"\n372 \n373     total_loss_factor = u_c + u_v * wind_speed\n374     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n375     temp_difference = heat_input / total_loss_factor\n376     return temp_air + temp_difference\n377 \n378 \n379 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n380     r'''\n381     Calculate cell or module temperature using the Faiman model.\n382 \n383     The Faiman model uses an empirical heat loss factor model [1]_ and is\n384     adopted in the IEC 61853 standards [2]_ and [3]_.\n385 \n386     Usage of this model in the IEC 61853 standard does not distinguish\n387     between cell and module temperature.\n388 \n389     Parameters\n390     ----------\n391     poa_global : numeric\n392         Total incident irradiance [W/m^2].\n393 \n394     temp_air : numeric\n395         Ambient dry bulb temperature [C].\n396 \n397     wind_speed : numeric, default 1.0\n398         Wind speed in m/s measured at the same height for which the wind loss\n399         factor was determined.  The default value 1.0 m/s is the wind\n400         speed at module height used to determine NOCT. [m/s]\n401 \n402     u0 : numeric, default 25.0\n403         Combined heat loss factor coefficient. The default value is one\n404         determined by Faiman for 7 silicon modules.\n405         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n406 \n407     u1 : numeric, default 6.84\n408         Combined heat loss factor influenced by wind. The default value is one\n409         determined by Faiman for 7 silicon modules.\n410         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n411 \n412     Returns\n413     -------\n414     numeric, values in degrees Celsius\n415 \n416     Notes\n417     -----\n418     All arguments may be scalars or vectors. If multiple arguments\n419     are vectors they must be the same length.\n420 \n421     References\n422     ----------\n423     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n424        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n425 \n426     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n427        rating - Part 2: Spectral responsivity, incidence angle and module\n428        operating temperature measurements\". IEC, Geneva, 2018.\n429 \n430     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n431        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n432 \n433     '''\n434     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n435 \n436     # The following lines may seem odd since u0 & u1 are probably scalar,\n437     # but it serves an indirect and easy way of allowing lists and\n438     # tuples for the other function arguments.\n439     u0 = np.asanyarray(u0)\n440     u1 = np.asanyarray(u1)\n441 \n442     total_loss_factor = u0 + u1 * wind_speed\n443     heat_input = poa_global\n444     temp_difference = heat_input / total_loss_factor\n445     return temp_air + temp_difference\n446 \n447 \n448 def ross(poa_global, temp_air, noct):\n449     r'''\n450     Calculate cell temperature using the Ross model.\n451 \n452     The Ross model [1]_ assumes the difference between cell temperature\n453     and ambient temperature is proportional to the plane of array irradiance,\n454     and assumes wind speed of 1 m/s. The model implicitly assumes steady or\n455     slowly changing irradiance conditions.\n456 \n457     Parameters\n458     ----------\n459     poa_global : numeric\n460         Total incident irradiance. [W/m^2]\n461 \n462     temp_air : numeric\n463         Ambient dry bulb temperature. [C]\n464 \n465     noct : numeric\n466         Nominal operating cell temperature [C], determined at conditions of\n467         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n468 \n469     Returns\n470     -------\n471     cell_temperature : numeric\n472         Cell temperature. [C]\n473 \n474     Notes\n475     -----\n476     The Ross model for cell temperature :math:`T_{C}` is given in [1]_ as\n477 \n478     .. math::\n479 \n480         T_{C} = T_{a} + \\frac{NOCT - 20}{80} S\n481 \n482     where :math:`S` is the plane of array irradiance in :math:`mW/{cm}^2`.\n483     This function expects irradiance in :math:`W/m^2`.\n484 \n485     References\n486     ----------\n487     .. [1] Ross, R. G. Jr., (1981). \"Design Techniques for Flat-Plate\n488        Photovoltaic Arrays\". 15th IEEE Photovoltaic Specialist Conference,\n489        Orlando, FL.\n490     '''\n491     # factor of 0.1 converts irradiance from W/m2 to mW/cm2\n492     return temp_air + (noct - 20.) / 80. * poa_global * 0.1\n493 \n494 \n495 def _fuentes_hconv(tave, windmod, tinoct, temp_delta, xlen, tilt,\n496                    check_reynold):\n497     # Calculate the convective coefficient as in Fuentes 1987 -- a mixture of\n498     # free, laminar, and turbulent convection.\n499     densair = 0.003484 * 101325.0 / tave  # density\n500     visair = 0.24237e-6 * tave**0.76 / densair  # kinematic viscosity\n501     condair = 2.1695e-4 * tave**0.84  # thermal conductivity\n502     reynold = windmod * xlen / visair\n503     # the boundary between laminar and turbulent is modeled as an abrupt\n504     # change at Re = 1.2e5:\n505     if check_reynold and reynold > 1.2e5:\n506         # turbulent convection\n507         hforce = 0.0282 / reynold**0.2 * densair * windmod * 1007 / 0.71**0.4\n508     else:\n509         # laminar convection\n510         hforce = 0.8600 / reynold**0.5 * densair * windmod * 1007 / 0.71**0.67\n511     # free convection via Grashof number\n512     # NB: Fuentes hardwires sind(tilt) as 0.5 for tilt=30\n513     grashof = 9.8 / tave * temp_delta * xlen**3 / visair**2 * sind(tilt)\n514     # product of Nusselt number and (k/l)\n515     hfree = 0.21 * (grashof * 0.71)**0.32 * condair / xlen\n516     # combine free and forced components\n517     hconv = (hfree**3 + hforce**3)**(1/3)\n518     return hconv\n519 \n520 \n521 def _hydraulic_diameter(width, height):\n522     # calculate the hydraulic diameter of a rectangle\n523     return 2 * (width * height) / (width + height)\n524 \n525 \n526 def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n527             wind_height=9.144, emissivity=0.84, absorption=0.83,\n528             surface_tilt=30, module_width=0.31579, module_length=1.2):\n529     \"\"\"\n530     Calculate cell or module temperature using the Fuentes model.\n531 \n532     The Fuentes model is a first-principles heat transfer energy balance\n533     model [1]_ that is used in PVWatts for cell temperature modeling [2]_.\n534 \n535     Parameters\n536     ----------\n537     poa_global : pandas Series\n538         Total incident irradiance [W/m^2]\n539 \n540     temp_air : pandas Series\n541         Ambient dry bulb temperature [C]\n542 \n543     wind_speed : pandas Series\n544         Wind speed [m/s]\n545 \n546     noct_installed : float\n547         The \"installed\" nominal operating cell temperature as defined in [1]_.\n548         PVWatts assumes this value to be 45 C for rack-mounted arrays and\n549         49 C for roof mount systems with restricted air flow around the\n550         module.  [C]\n551 \n552     module_height : float, default 5.0\n553         The height above ground of the center of the module. The PVWatts\n554         default is 5.0 [m]\n555 \n556     wind_height : float, default 9.144\n557         The height above ground at which ``wind_speed`` is measured. The\n558         PVWatts defauls is 9.144 [m]\n559 \n560     emissivity : float, default 0.84\n561         The effectiveness of the module at radiating thermal energy. [unitless]\n562 \n563     absorption : float, default 0.83\n564         The fraction of incident irradiance that is converted to thermal\n565         energy in the module. [unitless]\n566 \n567     surface_tilt : float, default 30\n568         Module tilt from horizontal. If not provided, the default value\n569         of 30 degrees from [1]_ and [2]_ is used. [degrees]\n570 \n571     module_width : float, default 0.31579\n572         Module width. The default value of 0.31579 meters in combination with\n573         the default `module_length` gives a hydraulic diameter of 0.5 as\n574         assumed in [1]_ and [2]_. [m]\n575 \n576     module_length : float, default 1.2\n577         Module length. The default value of 1.2 meters in combination with\n578         the default `module_width` gives a hydraulic diameter of 0.5 as\n579         assumed in [1]_ and [2]_. [m]\n580 \n581     Returns\n582     -------\n583     temperature_cell : pandas Series\n584         The modeled cell temperature [C]\n585 \n586     Notes\n587     -----\n588     This function returns slightly different values from PVWatts at night\n589     and just after dawn. This is because the SAM SSC assumes that module\n590     temperature equals ambient temperature when irradiance is zero so it can\n591     skip the heat balance calculation at night.\n592 \n593     References\n594     ----------\n595     .. [1] Fuentes, M. K., 1987, \"A Simplifed Thermal Model for Flat-Plate\n596            Photovoltaic Arrays\", SAND85-0330, Sandia National Laboratories,\n597            Albuquerque NM.\n598            http://prod.sandia.gov/techlib/access-control.cgi/1985/850330.pdf\n599     .. [2] Dobos, A. P., 2014, \"PVWatts Version 5 Manual\", NREL/TP-6A20-62641,\n600            National Renewable Energy Laboratory, Golden CO.\n601            doi:10.2172/1158421.\n602     \"\"\"\n603     # ported from the FORTRAN77 code provided in Appendix A of Fuentes 1987;\n604     # nearly all variable names are kept the same for ease of comparison.\n605 \n606     boltz = 5.669e-8\n607     emiss = emissivity\n608     absorp = absorption\n609     xlen = _hydraulic_diameter(module_width, module_length)\n610     # cap0 has units of [J / (m^2 K)], equal to mass per unit area times\n611     # specific heat of the module.\n612     cap0 = 11000\n613     tinoct = noct_installed + 273.15\n614 \n615     # convective coefficient of top surface of module at NOCT\n616     windmod = 1.0\n617     tave = (tinoct + 293.15) / 2\n618     hconv = _fuentes_hconv(tave, windmod, tinoct, tinoct - 293.15, xlen,\n619                            surface_tilt, False)\n620 \n621     # determine the ground temperature ratio and the ratio of the total\n622     # convection to the top side convection\n623     hground = emiss * boltz * (tinoct**2 + 293.15**2) * (tinoct + 293.15)\n624     backrat = (\n625         absorp * 800.0\n626         - emiss * boltz * (tinoct**4 - 282.21**4)\n627         - hconv * (tinoct - 293.15)\n628     ) / ((hground + hconv) * (tinoct - 293.15))\n629     tground = (tinoct**4 - backrat * (tinoct**4 - 293.15**4))**0.25\n630     tground = np.clip(tground, 293.15, tinoct)\n631 \n632     tgrat = (tground - 293.15) / (tinoct - 293.15)\n633     convrat = (absorp * 800 - emiss * boltz * (\n634         2 * tinoct**4 - 282.21**4 - tground**4)) / (hconv * (tinoct - 293.15))\n635 \n636     # adjust the capacitance (thermal mass) of the module based on the INOCT.\n637     # It is a function of INOCT because high INOCT implies thermal coupling\n638     # with the racking (e.g. roofmount), so the thermal mass is increased.\n639     # `cap` has units J/(m^2 C) -- see Table 3, Equations 26 & 27\n640     cap = cap0\n641     if tinoct > 321.15:\n642         cap = cap * (1 + (tinoct - 321.15) / 12)\n643 \n644     # iterate through timeseries inputs\n645     sun0 = 0\n646     tmod0 = 293.15\n647 \n648     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n649     # the value doesn't matter -- rather than recreate it here, just assume\n650     # it's the same as the second timedelta:\n651     timedelta_seconds = poa_global.index.to_series().diff().dt.total_seconds()\n652     timedelta_hours = timedelta_seconds / 3600\n653     timedelta_hours.iloc[0] = timedelta_hours.iloc[1]\n654 \n655     tamb_array = temp_air + 273.15\n656     sun_array = poa_global * absorp\n657 \n658     # Two of the calculations are easily vectorized, so precalculate them:\n659     # sky temperature -- Equation 24\n660     tsky_array = 0.68 * (0.0552 * tamb_array**1.5) + 0.32 * tamb_array\n661     # wind speed at module height -- Equation 22\n662     # not sure why the 1e-4 factor is included -- maybe the equations don't\n663     # behave well if wind == 0?\n664     windmod_array = wind_speed * (module_height/wind_height)**0.2 + 1e-4\n665 \n666     tmod0 = 293.15\n667     tmod_array = np.zeros_like(poa_global)\n668 \n669     iterator = zip(tamb_array, sun_array, windmod_array, tsky_array,\n670                    timedelta_hours)\n671     for i, (tamb, sun, windmod, tsky, dtime) in enumerate(iterator):\n672         # solve the heat transfer equation, iterating because the heat loss\n673         # terms depend on tmod. NB Fuentes doesn't show that 10 iterations is\n674         # sufficient for convergence.\n675         tmod = tmod0\n676         for j in range(10):\n677             # overall convective coefficient\n678             tave = (tmod + tamb) / 2\n679             hconv = convrat * _fuentes_hconv(tave, windmod, tinoct,\n680                                              abs(tmod-tamb), xlen,\n681                                              surface_tilt, True)\n682             # sky radiation coefficient (Equation 3)\n683             hsky = emiss * boltz * (tmod**2 + tsky**2) * (tmod + tsky)\n684             # ground radiation coeffieicient (Equation 4)\n685             tground = tamb + tgrat * (tmod - tamb)\n686             hground = emiss * boltz * (tmod**2 + tground**2) * (tmod + tground)\n687             # thermal lag -- Equation 8\n688             eigen = - (hconv + hsky + hground) / cap * dtime * 3600\n689             # not sure why this check is done, maybe as a speed optimization?\n690             if eigen > -10:\n691                 ex = np.exp(eigen)\n692             else:\n693                 ex = 0\n694             # Equation 7 -- note that `sun` and `sun0` already account for\n695             # absorption (alpha)\n696             tmod = tmod0 * ex + (\n697                 (1 - ex) * (\n698                     hconv * tamb\n699                     + hsky * tsky\n700                     + hground * tground\n701                     + sun0\n702                     + (sun - sun0) / eigen\n703                 ) + sun - sun0\n704             ) / (hconv + hsky + hground)\n705         tmod_array[i] = tmod\n706         tmod0 = tmod\n707         sun0 = sun\n708 \n709     return pd.Series(tmod_array - 273.15, index=poa_global.index, name='tmod')\n710 \n711 \n712 def _adj_for_mounting_standoff(x):\n713     # supports noct cell temperature function. Except for x > 3.5, the SAM code\n714     # and documentation aren't clear on the precise intervals. The choice of\n715     # < or <= here is pvlib's.\n716     return np.piecewise(x, [x <= 0, (x > 0) & (x < 0.5),\n717                             (x >= 0.5) & (x < 1.5), (x >= 1.5) & (x < 2.5),\n718                             (x >= 2.5) & (x <= 3.5), x > 3.5],\n719                         [0., 18., 11., 6., 2., 0.])\n720 \n721 \n722 def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n723              effective_irradiance=None, transmittance_absorptance=0.9,\n724              array_height=1, mount_standoff=4):\n725     r'''\n726     Cell temperature model from the System Advisor Model (SAM).\n727 \n728     The model is described in [1]_, Section 10.6.\n729 \n730     Parameters\n731     ----------\n732     poa_global : numeric\n733         Total incident irradiance. [W/m^2]\n734 \n735     temp_air : numeric\n736         Ambient dry bulb temperature. [C]\n737 \n738     wind_speed : numeric\n739         Wind speed in m/s measured at the same height for which the wind loss\n740         factor was determined.  The default value 1.0 m/s is the wind\n741         speed at module height used to determine NOCT. [m/s]\n742 \n743     noct : float\n744         Nominal operating cell temperature [C], determined at conditions of\n745         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n746 \n747     eta_m_ref : float\n748         Module external efficiency [unitless] at reference conditions of\n749         1000 W/m^2 and 20C. Calculate as\n750         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n751         where A is module area [m^2].\n752 \n753     effective_irradiance : numeric, default None.\n754         The irradiance that is converted to photocurrent. If None,\n755         assumed equal to poa_global. [W/m^2]\n756 \n757     transmittance_absorptance : numeric, default 0.9\n758         Coefficient for combined transmittance and absorptance effects.\n759         [unitless]\n760 \n761     array_height : int, default 1\n762         Height of array above ground in stories (one story is about 3m). Must\n763         be either 1 or 2. For systems elevated less than one story, use 1.\n764         If system is elevated more than two stories, use 2.\n765 \n766     mount_standoff : numeric, default 4\n767         Distance between array mounting and mounting surface. Use default\n768         if system is ground-mounted. [inches]\n769 \n770     Returns\n771     -------\n772     cell_temperature : numeric\n773         Cell temperature. [C]\n774 \n775     Raises\n776     ------\n777     ValueError\n778         If array_height is an invalid value (must be 1 or 2).\n779 \n780     References\n781     ----------\n782     .. [1] Gilman, P., Dobos, A., DiOrio, N., Freeman, J., Janzou, S.,\n783            Ryberg, D., 2018, \"SAM Photovoltaic Model Technical Reference\n784            Update\", National Renewable Energy Laboratory Report\n785            NREL/TP-6A20-67399.\n786     '''\n787     # in [1] the denominator for irr_ratio isn't precisely clear. From\n788     # reproducing output of the SAM function noct_celltemp_t, we determined\n789     # that:\n790     #  - G_total (SAM) is broadband plane-of-array irradiance before\n791     #    reflections. Equivalent to pvlib variable poa_global\n792     #  - Geff_total (SAM) is POA irradiance after reflections and\n793     #    adjustment for spectrum. Equivalent to effective_irradiance\n794     if effective_irradiance is None:\n795         irr_ratio = 1.\n796     else:\n797         irr_ratio = effective_irradiance / poa_global\n798 \n799     if array_height == 1:\n800         wind_adj = 0.51 * wind_speed\n801     elif array_height == 2:\n802         wind_adj = 0.61 * wind_speed\n803     else:\n804         raise ValueError(\n805             f'array_height must be 1 or 2, {array_height} was given')\n806 \n807     noct_adj = noct + _adj_for_mounting_standoff(mount_standoff)\n808     tau_alpha = transmittance_absorptance * irr_ratio\n809 \n810     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n811     # poa_global where G appears\n812     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n813     heat_loss = 1 - eta_m_ref / tau_alpha\n814     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n815     return temp_air + cell_temp_init * heat_loss * wind_loss\n816 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "40ba4bd5c8b91754aa73e638ed984ab9657847cd", "problem_statement": "change eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n", "hints_text": "I support this change.", "created_at": "2021-05-06T16:02:38Z", "patch": "<patch>\ndiff --git a/pvlib/modelchain.py b/pvlib/modelchain.py\n--- a/pvlib/modelchain.py\n+++ b/pvlib/modelchain.py\n@@ -977,7 +977,7 @@ def infer_temperature_model(self):\n             return self.faiman_temp\n         elif {'noct_installed'} <= params:\n             return self.fuentes_temp\n-        elif {'noct', 'eta_m_ref'} <= params:\n+        elif {'noct', 'module_efficiency'} <= params:\n             return self.noct_sam_temp\n         else:\n             raise ValueError(f'could not infer temperature model from '\ndiff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -671,7 +671,9 @@ def pvsyst_celltemp(self, poa_global, temp_air, wind_speed=1.0):\n         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n \n         def build_celltemp_kwargs(array):\n-            return {**_build_kwargs(['eta_m', 'alpha_absorption'],\n+            # TODO remove 'eta_m' after deprecation of this parameter\n+            return {**_build_kwargs(['eta_m', 'module_efficiency',\n+                                     'alpha_absorption'],\n                                     array.module_parameters),\n                     **_build_kwargs(['u_c', 'u_v'],\n                                     array.temperature_model_parameters)}\n@@ -843,10 +845,10 @@ def _build_kwargs_noct_sam(array):\n                 # bundled with kwargs for simplicity\n                 temp_model_kwargs['noct'] = \\\n                     array.temperature_model_parameters['noct']\n-                temp_model_kwargs['eta_m_ref'] = \\\n-                    array.temperature_model_parameters['eta_m_ref']\n+                temp_model_kwargs['module_efficiency'] = \\\n+                    array.temperature_model_parameters['module_efficiency']\n             except KeyError:\n-                msg = ('Parameters noct and eta_m_ref are required.'\n+                msg = ('Parameters noct and module_efficiency are required.'\n                        ' Found {} in temperature_model_parameters.'\n                        .format(array.temperature_model_parameters))\n                 raise KeyError(msg)\ndiff --git a/pvlib/temperature.py b/pvlib/temperature.py\n--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -6,6 +6,7 @@\n import numpy as np\n import pandas as pd\n from pvlib.tools import sind\n+from pvlib._deprecation import warn_deprecated\n \n TEMPERATURE_MODEL_PARAMETERS = {\n     'sapm': {\n@@ -285,7 +286,7 @@ def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n \n \n def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n-                eta_m=0.1, alpha_absorption=0.9):\n+                eta_m=None, module_efficiency=0.1, alpha_absorption=0.9):\n     r\"\"\"\n     Calculate cell temperature using an empirical heat loss factor model\n     as implemented in PVsyst.\n@@ -313,12 +314,14 @@ def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n     u_v : float, default 0.0\n         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n         in :eq:`pvsyst`.\n-        :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n+        :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`  # noQA: E501\n+\n+    eta_m : numeric, default None (deprecated, use module_efficiency instead)\n \n-    eta_m : numeric, default 0.1\n-        Module external efficiency as a fraction, i.e.,\n-        :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n-        Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n+    module_efficiency : numeric, default 0.1\n+        Module external efficiency as a fraction. Parameter :math:`\\eta_{m}`\n+        in :eq:`pvsyst`. Calculate as\n+        :math:`\\eta_{m} = DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n \n     alpha_absorption : numeric, default 0.9\n         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n@@ -370,8 +373,13 @@ def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n     37.93103448275862\n     \"\"\"\n \n+    if eta_m:\n+        warn_deprecated(\n+            since='v0.9', message='eta_m overwriting module_efficiency',\n+            name='eta_m', alternative='module_efficiency', removal='v0.10')\n+        module_efficiency = eta_m\n     total_loss_factor = u_c + u_v * wind_speed\n-    heat_input = poa_global * alpha_absorption * (1 - eta_m)\n+    heat_input = poa_global * alpha_absorption * (1 - module_efficiency)\n     temp_difference = heat_input / total_loss_factor\n     return temp_air + temp_difference\n \n@@ -719,7 +727,7 @@ def _adj_for_mounting_standoff(x):\n                         [0., 18., 11., 6., 2., 0.])\n \n \n-def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n+def noct_sam(poa_global, temp_air, wind_speed, noct, module_efficiency,\n              effective_irradiance=None, transmittance_absorptance=0.9,\n              array_height=1, mount_standoff=4):\n     r'''\n@@ -744,9 +752,9 @@ def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n         Nominal operating cell temperature [C], determined at conditions of\n         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n \n-    eta_m_ref : float\n+    module_efficiency : float\n         Module external efficiency [unitless] at reference conditions of\n-        1000 W/m^2 and 20C. Calculate as\n+        1000 W/m^2 and 20C. Denoted as :math:`eta_{m}` in [1]_. Calculate as\n         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n         where A is module area [m^2].\n \n@@ -810,6 +818,6 @@ def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n     # poa_global where G appears\n     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n-    heat_loss = 1 - eta_m_ref / tau_alpha\n+    heat_loss = 1 - module_efficiency / tau_alpha\n     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n     return temp_air + cell_temp_init * heat_loss * wind_loss\n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_modelchain.py b/pvlib/tests/test_modelchain.py\n--- a/pvlib/tests/test_modelchain.py\n+++ b/pvlib/tests/test_modelchain.py\n@@ -201,7 +201,7 @@ def pvwatts_dc_pvwatts_ac_faiman_temp_system():\n @pytest.fixture(scope=\"function\")\n def pvwatts_dc_pvwatts_ac_pvsyst_temp_system():\n     module_parameters = {'pdc0': 220, 'gamma_pdc': -0.003}\n-    temp_model_params = {'u_c': 29.0, 'u_v': 0.0, 'eta_m': 0.1,\n+    temp_model_params = {'u_c': 29.0, 'u_v': 0.0, 'module_efficiency': 0.1,\n                          'alpha_absorption': 0.9}\n     inverter_parameters = {'pdc0': 220, 'eta_inv_nom': 0.95}\n     system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n@@ -226,7 +226,7 @@ def pvwatts_dc_pvwatts_ac_fuentes_temp_system():\n @pytest.fixture(scope=\"function\")\n def pvwatts_dc_pvwatts_ac_noct_sam_temp_system():\n     module_parameters = {'pdc0': 220, 'gamma_pdc': -0.003}\n-    temp_model_params = {'noct': 45, 'eta_m_ref': 0.2}\n+    temp_model_params = {'noct': 45, 'module_efficiency': 0.2}\n     inverter_parameters = {'pdc0': 220, 'eta_inv_nom': 0.95}\n     system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n                       module_parameters=module_parameters,\n@@ -710,7 +710,7 @@ def test_run_model_with_weather_noct_sam_temp(sapm_dc_snl_ac_system, location,\n     weather['wind_speed'] = 5\n     weather['temp_air'] = 10\n     sapm_dc_snl_ac_system.temperature_model_parameters = {\n-        'noct': 45, 'eta_m_ref': 0.2\n+        'noct': 45, 'module_efficiency': 0.2\n     }\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     mc.temperature_model = 'noct_sam'\n@@ -941,7 +941,7 @@ def test__prepare_temperature_arrays_weather(sapm_dc_snl_ac_system_same_arrays,\n                            ModelChain.faiman_temp),\n                           ({'noct_installed': 45},\n                            ModelChain.fuentes_temp),\n-                          ({'noct': 45, 'eta_m_ref': 0.2},\n+                          ({'noct': 45, 'module_efficiency': 0.2},\n                            ModelChain.noct_sam_temp)])\n def test_temperature_models_arrays_multi_weather(\n         temp_params, temp_model,\ndiff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -392,7 +392,7 @@ def two_array_system(pvsyst_module_params, cec_module_params):\n     temperature_model['noct_installed'] = 45\n     # parameters for noct_sam temperature model\n     temperature_model['noct'] = 45.\n-    temperature_model['eta_m_ref'] = 0.2\n+    temperature_model['module_efficiency'] = 0.2\n     module_params = {**pvsyst_module_params, **cec_module_params}\n     return pvsystem.PVSystem(\n         arrays=[\n@@ -471,8 +471,9 @@ def test_PVSystem_pvsyst_celltemp(mocker):\n     temp_model_params = temperature.TEMPERATURE_MODEL_PARAMETERS['pvsyst'][\n         parameter_set]\n     alpha_absorption = 0.85\n-    eta_m = 0.17\n-    module_parameters = {'alpha_absorption': alpha_absorption, 'eta_m': eta_m}\n+    module_efficiency = 0.17\n+    module_parameters = {'alpha_absorption': alpha_absorption,\n+                         'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(module_parameters=module_parameters,\n                                temperature_model_parameters=temp_model_params)\n     mocker.spy(temperature, 'pvsyst_cell')\n@@ -481,8 +482,9 @@ def test_PVSystem_pvsyst_celltemp(mocker):\n     wind = 0.5\n     out = system.pvsyst_celltemp(irrad, temp, wind_speed=wind)\n     temperature.pvsyst_cell.assert_called_once_with(\n-        irrad, temp, wind, temp_model_params['u_c'], temp_model_params['u_v'],\n-        eta_m, alpha_absorption)\n+        irrad, temp, wind_speed=wind, u_c=temp_model_params['u_c'],\n+        u_v=temp_model_params['u_v'], module_efficiency=module_efficiency,\n+        alpha_absorption=alpha_absorption)\n     assert (out < 90) and (out > 70)\n \n \n@@ -500,16 +502,16 @@ def test_PVSystem_faiman_celltemp(mocker):\n \n \n def test_PVSystem_noct_celltemp(mocker):\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     expected = 55.230790492\n-    temp_model_params = {'noct': noct, 'eta_m_ref': eta_m_ref}\n+    temp_model_params = {'noct': noct, 'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(temperature_model_parameters=temp_model_params)\n     mocker.spy(temperature, 'noct_sam')\n     out = system.noct_sam_celltemp(poa_global, temp_air, wind_speed)\n     temperature.noct_sam.assert_called_once_with(\n         poa_global, temp_air, wind_speed, effective_irradiance=None, noct=noct,\n-        eta_m_ref=eta_m_ref)\n+        module_efficiency=module_efficiency)\n     assert_allclose(out, expected)\n     # dufferent types\n     out = system.noct_sam_celltemp(np.array(poa_global), np.array(temp_air),\n@@ -533,8 +535,8 @@ def test_PVSystem_noct_celltemp(mocker):\n \n \n def test_PVSystem_noct_celltemp_error():\n-    poa_global, temp_air, wind_speed, eta_m_ref = (1000., 25., 1., 0.2)\n-    temp_model_params = {'eta_m_ref': eta_m_ref}\n+    poa_global, temp_air, wind_speed, module_efficiency = (1000., 25., 1., 0.2)\n+    temp_model_params = {'module_efficiency': module_efficiency}\n     system = pvsystem.PVSystem(temperature_model_parameters=temp_model_params)\n     with pytest.raises(KeyError):\n         system.noct_sam_celltemp(poa_global, temp_air, wind_speed)\ndiff --git a/pvlib/tests/test_temperature.py b/pvlib/tests/test_temperature.py\n--- a/pvlib/tests/test_temperature.py\n+++ b/pvlib/tests/test_temperature.py\n@@ -6,6 +6,7 @@\n from numpy.testing import assert_allclose\n \n from pvlib import temperature, tools\n+from pvlib._deprecation import pvlibDeprecationWarning\n \n \n @pytest.fixture\n@@ -72,7 +73,7 @@ def test_pvsyst_cell_default():\n \n def test_pvsyst_cell_kwargs():\n     result = temperature.pvsyst_cell(900, 20, wind_speed=5.0, u_c=23.5,\n-                                     u_v=6.25, eta_m=0.1)\n+                                     u_v=6.25, module_efficiency=0.1)\n     assert_allclose(result, 33.315, 0.001)\n \n \n@@ -96,6 +97,13 @@ def test_pvsyst_cell_series():\n     assert_series_equal(expected, result)\n \n \n+def test_pvsyst_cell_eta_m_deprecated():\n+    with pytest.warns(pvlibDeprecationWarning):\n+        result = temperature.pvsyst_cell(900, 20, wind_speed=5.0, u_c=23.5,\n+                                         u_v=6.25, eta_m=0.1)\n+        assert_allclose(result, 33.315, 0.001)\n+\n+\n def test_faiman_default():\n     result = temperature.faiman(900, 20, 5)\n     assert_allclose(result, 35.203, 0.001)\n@@ -215,16 +223,16 @@ def test_fuentes_timezone(tz):\n \n \n def test_noct_sam():\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     expected = 55.230790492\n     result = temperature.noct_sam(poa_global, temp_air, wind_speed, noct,\n-                                  eta_m_ref)\n+                                  module_efficiency)\n     assert_allclose(result, expected)\n     # test with different types\n     result = temperature.noct_sam(np.array(poa_global), np.array(temp_air),\n                                   np.array(wind_speed), np.array(noct),\n-                                  np.array(eta_m_ref))\n+                                  np.array(module_efficiency))\n     assert_allclose(result, expected)\n     dr = pd.date_range(start='2020-01-01 12:00:00', end='2020-01-01 13:00:00',\n                        freq='1H')\n@@ -232,7 +240,7 @@ def test_noct_sam():\n                                   pd.Series(index=dr, data=temp_air),\n                                   pd.Series(index=dr, data=wind_speed),\n                                   pd.Series(index=dr, data=noct),\n-                                  eta_m_ref)\n+                                  module_efficiency)\n     assert_series_equal(result, pd.Series(index=dr, data=expected))\n \n \n@@ -242,7 +250,7 @@ def test_noct_sam_against_sam():\n     # NOCT cell temperature model), with the only change being the soiling\n     # loss is set to 0. Weather input is TMY3 for Phoenix AZ.\n     # Values are taken from the Jan 1 12:00:00 timestamp.\n-    poa_total, temp_air, wind_speed, noct, eta_m_ref = (\n+    poa_total, temp_air, wind_speed, noct, module_efficiency = (\n         860.673, 25, 3, 46.4, 0.20551)\n     poa_total_after_refl = 851.458  # from SAM output\n     # compute effective irradiance\n@@ -259,7 +267,7 @@ def test_noct_sam_against_sam():\n     array_height = 1\n     mount_standoff = 4.0\n     result = temperature.noct_sam(poa_total, temp_air, wind_speed, noct,\n-                                  eta_m_ref, effective_irradiance,\n+                                  module_efficiency, effective_irradiance,\n                                   transmittance_absorptance, array_height,\n                                   mount_standoff)\n     expected = 43.0655\n@@ -268,14 +276,14 @@ def test_noct_sam_against_sam():\n \n \n def test_noct_sam_options():\n-    poa_global, temp_air, wind_speed, noct, eta_m_ref = (1000., 25., 1., 45.,\n-                                                         0.2)\n+    poa_global, temp_air, wind_speed, noct, module_efficiency = (\n+        1000., 25., 1., 45., 0.2)\n     effective_irradiance = 1100.\n     transmittance_absorptance = 0.8\n     array_height = 2\n     mount_standoff = 2.0\n     result = temperature.noct_sam(poa_global, temp_air, wind_speed, noct,\n-                                  eta_m_ref, effective_irradiance,\n+                                  module_efficiency, effective_irradiance,\n                                   transmittance_absorptance, array_height,\n                                   mount_standoff)\n     expected = 60.477703576\n", "version": "0.8", "FAIL_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_run_model_with_weather_noct_sam_temp\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params4-noct_sam_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[noct_sam_temp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[noct_sam_celltemp]\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_kwargs\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_eta_m_deprecated\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_ModelChain_creation\", \"pvlib/tests/test_modelchain.py::test_with_sapm\", \"pvlib/tests/test_modelchain.py::test_with_pvwatts\", \"pvlib/tests/test_modelchain.py::test_run_model_with_irradiance\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss_input_type[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_irradiance_arrays_no_loss_input_type[list]\", \"pvlib/tests/test_modelchain.py::test_ModelChain_invalid_inverter_params_arrays[adr]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_multi_weather[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_multi_weather[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_no_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_arrays_one_missing_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_weather_wrong_length[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_weather_wrong_length[list]\", \"pvlib/tests/test_modelchain.py::test_ModelChain_times_error_arrays\", \"pvlib/tests/test_modelchain.py::test_ModelChain_times_arrays\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[dhi]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[ghi]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_missing_irrad_component[dni]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[tuple-sandia]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[tuple-pvwatts]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[list-sandia]\", \"pvlib/tests/test_modelchain.py::test_run_model_arrays_weather[list-pvwatts]\", \"pvlib/tests/test_modelchain.py::test_run_model_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_gueymard_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_sapm_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_pvsyst_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_faiman_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_fuentes_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker_list\", \"pvlib/tests/test_modelchain.py::test__assign_total_irrad\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_multi_data[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_multi_data[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_wrong_number_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_wrong_number_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_arrays_different_indices\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_from_poa_arrays_missing_column\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature_len1_weather_tuple\", \"pvlib/tests/test_modelchain.py::test__prepare_temperature_arrays_weather\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params0-sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params1-pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params2-faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_temperature_models_arrays_multi_weather[temp_params3-fuentes_temp]\", \"pvlib/tests/test_modelchain.py::test_run_model_solar_position_weather\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_arrays_solar_position_weather\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_tracking\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[<lambda>]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_multi_array[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_multi_array[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[<lambda>]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_no_poa_global[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_poa_global_differs\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays_error[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays_error[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_minimal_input\", \"pvlib/tests/test_modelchain.py::test_run_model_singleton_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_run_model_from_poa_singleton_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_run_model_from_effective_irradiance_weather_single_array\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[desoto]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[singlediode]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvwatts_dc]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[cec]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[desoto]\", \"pvlib/tests/test_modelchain.py::test_singlediode_dc_arrays[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec_native]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[fuentes_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model_invalid\", \"pvlib/tests/test_modelchain.py::test_temperature_model_inconsistent\", \"pvlib/tests/test_modelchain.py::test_dc_model_user_func\", \"pvlib/tests/test_modelchain.py::test_pvwatts_dc_multiple_strings\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia]\", \"pvlib/tests/test_modelchain.py::test_ac_models[adr]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts]\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia_multi]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts_multi]\", \"pvlib/tests/test_modelchain.py::test_ac_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_model_not_a_model\", \"pvlib/tests/test_modelchain.py::test_infer_ac_model_invalid_params\", \"pvlib/tests/test_modelchain.py::test_aoi_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models_singleon_weather_single_array[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_model_no_loss\", \"pvlib/tests/test_modelchain.py::test_aoi_model_user_func\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[ashrae]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[physical]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model_invalid\", \"pvlib/tests/test_modelchain.py::test_spectral_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models_singleton_weather_single_array[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_model_ohms_from_percent\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_model_no_dc_ohmic_loss\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_ext_def\", \"pvlib/tests/test_modelchain.py::test_dc_ohmic_not_a_model\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts_arrays\", \"pvlib/tests/test_modelchain.py::test_losses_models_ext_def\", \"pvlib/tests/test_modelchain.py::test_losses_models_no_loss\", \"pvlib/tests/test_modelchain.py::test_invalid_dc_model_params\", \"pvlib/tests/test_modelchain.py::test_invalid_models[dc_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[ac_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[aoi_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[spectral_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[temperature_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[losses_model]\", \"pvlib/tests/test_modelchain.py::test_bad_get_orientation\", \"pvlib/tests/test_modelchain.py::test_with_sapm_pvsystem_arrays\", \"pvlib/tests/test_modelchain.py::test_ModelChain_no_extra_kwargs\", \"pvlib/tests/test_modelchain.py::test_ModelChain_attributes_deprecated_10\", \"pvlib/tests/test_modelchain.py::test_basic_chain_alt_az\", \"pvlib/tests/test_modelchain.py::test_basic_chain_altitude_pressure\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_clean_run\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays[tuple]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays[list]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays_wrong_length[tuple]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_arrays_wrong_length[list]\", \"pvlib/tests/test_modelchain.py::test_unknown_attribute\", \"pvlib/tests/test_modelchain.py::test_inconsistent_array_params\", \"pvlib/tests/test_modelchain.py::test_modelchain__common_keys\", \"pvlib/tests/test_modelchain.py::test__irrad_for_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_iam\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[1.5-1.00028714375]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_first_solar_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[20-poa_diffuse0-aoi0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct1-poa_diffuse1-aoi1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance_value_error[poa_direct2-poa_diffuse2-20]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_sapm_celltemp_different_arrays\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_noct_celltemp_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_functions[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_temp[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_multi_wind[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_short[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_temp_too_long[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_short[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_wind_too_long[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[faiman_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[pvsyst_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[sapm_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[fuentes_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_celltemp_poa_length_mismatch[noct_sam_celltemp]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_fuentes_celltemp_override\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_Array__infer_cell_type\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_pvsyst]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_desoto]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams[calcparams_cec]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-1-celltemp0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_desoto-irrad1-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-1-celltemp2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_cec-irrad3-1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-1-celltemp4]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_calcparams_value_error[calcparams_pvsyst-irrad5-1]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_snlinverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_sandia_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_pvwatts_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[sandia]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[adr]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_single_array_tuple_input[pvwatts]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_adr_multi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_ac_invalid\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance_model\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array_get_irradiance_multi_irrad\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_change_surface_azimuth\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_albedo\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_modules_per_string\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_strings_per_inverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multi_array___repr__\", \"pvlib/tests/test_pvsystem.py::test_Array___repr__\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_multiple_array_pvwatts_dc_value_error\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_num_arrays\", \"pvlib/tests/test_pvsystem.py::test_combine_loss_factors\", \"pvlib/tests/test_pvsystem.py::test_no_extra_kwargs\", \"pvlib/tests/test_pvsystem.py::test_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_dc_ohms_from_percent\", \"pvlib/tests/test_pvsystem.py::test_dc_ohmic_losses\", \"pvlib/tests/test_pvsystem.py::test_Array_dc_ohms_from_percent\", \"pvlib/tests/test_temperature.py::test_sapm_cell\", \"pvlib/tests/test_temperature.py::test_sapm_module\", \"pvlib/tests/test_temperature.py::test_sapm_cell_from_module\", \"pvlib/tests/test_temperature.py::test_sapm_ndarray\", \"pvlib/tests/test_temperature.py::test_sapm_series\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_default\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_ndarray\", \"pvlib/tests/test_temperature.py::test_pvsyst_cell_series\", \"pvlib/tests/test_temperature.py::test_faiman_default\", \"pvlib/tests/test_temperature.py::test_faiman_kwargs\", \"pvlib/tests/test_temperature.py::test_faiman_list\", \"pvlib/tests/test_temperature.py::test_faiman_ndarray\", \"pvlib/tests/test_temperature.py::test_ross\", \"pvlib/tests/test_temperature.py::test_faiman_series\", \"pvlib/tests/test_temperature.py::test__temperature_model_params\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_rackmount.csv-45]\", \"pvlib/tests/test_temperature.py::test_fuentes[pvwatts_8760_roofmount.csv-49]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[None]\", \"pvlib/tests/test_temperature.py::test_fuentes_timezone[Etc/GMT+5]\", \"pvlib/tests/test_temperature.py::test_noct_sam\", \"pvlib/tests/test_temperature.py::test_noct_sam_against_sam\", \"pvlib/tests/test_temperature.py::test_noct_sam_options\", \"pvlib/tests/test_temperature.py::test_noct_sam_errors\"]", "environment_setup_commit": "ef8ad2fee9840a77d14b0dfd17fc489dd85c9b91"}
{"instance_id": "pvlib__pvlib-python-1033_1", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nPVSystem.temperature_model_parameters requirement\nThe `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to \r\n\r\n1. set default values `module_type=None` and `racking_model=None`.\r\n2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L208-L221\r\n\r\n@cwhanse is that correct?\r\n\r\nThe problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L201-L203\r\n\r\nSo I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9. \nremove deprecated functions in 0.8\n`pvsystem`:\r\n* `sapm_celltemp`\r\n* `pvsyst_celltemp`\r\n* `ashraeiam`\r\n* `physicaliam`\r\n* `sapm_aoi_loss`\r\n* `PVSystem.ashraeiam`\r\n* `PVSystem.physicaliam`\r\n* `PVSystem.sapm_aoi_loss`\r\n* inference of `PVSystem.temperature_model_parameters`\r\n\r\n`modelchain.ModelChain`:\r\n* remove `times` from `complete_irradiance`, `prepare_inputs`, `run_model`\r\n* remove `temp_model` kwarg\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of pvlib/atmosphere.py]\n1 \"\"\"\n2 The ``atmosphere`` module contains methods to calculate relative and\n3 absolute airmass and to determine pressure from altitude or vice versa.\n4 \"\"\"\n5 \n6 from warnings import warn\n7 \n8 import numpy as np\n9 import pandas as pd\n10 \n11 \n12 APPARENT_ZENITH_MODELS = ('simple', 'kasten1966', 'kastenyoung1989',\n13                           'gueymard1993', 'pickering2002')\n14 TRUE_ZENITH_MODELS = ('youngirvine1967', 'young1994')\n15 AIRMASS_MODELS = APPARENT_ZENITH_MODELS + TRUE_ZENITH_MODELS\n16 \n17 \n18 def pres2alt(pressure):\n19     '''\n20     Determine altitude from site pressure.\n21 \n22     Parameters\n23     ----------\n24     pressure : numeric\n25         Atmospheric pressure. [Pa]\n26 \n27     Returns\n28     -------\n29     altitude : numeric\n30         Altitude above sea level. [m]\n31 \n32     Notes\n33     ------\n34     The following assumptions are made\n35 \n36     ============================   ================\n37     Parameter                      Value\n38     ============================   ================\n39     Base pressure                  101325 Pa\n40     Temperature at zero altitude   288.15 K\n41     Gravitational acceleration     9.80665 m/s^2\n42     Lapse rate                     -6.5E-3 K/m\n43     Gas constant for air           287.053 J/(kg K)\n44     Relative Humidity              0%\n45     ============================   ================\n46 \n47     References\n48     -----------\n49     .. [1] \"A Quick Derivation relating altitude to air pressure\" from\n50        Portland State Aerospace Society, Version 1.03, 12/22/2004.\n51     '''\n52 \n53     alt = 44331.5 - 4946.62 * pressure ** (0.190263)\n54 \n55     return alt\n56 \n57 \n58 def alt2pres(altitude):\n59     '''\n60     Determine site pressure from altitude.\n61 \n62     Parameters\n63     ----------\n64     altitude : numeric\n65         Altitude above sea level. [m]\n66 \n67     Returns\n68     -------\n69     pressure : numeric\n70         Atmospheric pressure. [Pa]\n71 \n72     Notes\n73     ------\n74     The following assumptions are made\n75 \n76     ============================   ================\n77     Parameter                      Value\n78     ============================   ================\n79     Base pressure                  101325 Pa\n80     Temperature at zero altitude   288.15 K\n81     Gravitational acceleration     9.80665 m/s^2\n82     Lapse rate                     -6.5E-3 K/m\n83     Gas constant for air           287.053 J/(kg K)\n84     Relative Humidity              0%\n85     ============================   ================\n86 \n87     References\n88     -----------\n89     .. [1] \"A Quick Derivation relating altitude to air pressure\" from\n90        Portland State Aerospace Society, Version 1.03, 12/22/2004.\n91     '''\n92 \n93     press = 100 * ((44331.514 - altitude) / 11880.516) ** (1 / 0.1902632)\n94 \n95     return press\n96 \n97 \n98 def get_absolute_airmass(airmass_relative, pressure=101325.):\n99     r'''\n100     Determine absolute (pressure-adjusted) airmass from relative\n101     airmass and pressure.\n102 \n103     The calculation for absolute airmass (:math:`AM_a`) is\n104 \n105     .. math::\n106         AM_a = AM_r \\frac{P}{101325}\n107 \n108     where :math:`AM_r` is relative air mass at sea level and :math:`P` is\n109     atmospheric pressure.\n110 \n111     Parameters\n112     ----------\n113     airmass_relative : numeric\n114         The airmass at sea level. [unitless]\n115 \n116     pressure : numeric, default 101325\n117         Atmospheric pressure. [Pa]\n118 \n119     Returns\n120     -------\n121     airmass_absolute : numeric\n122         Absolute (pressure-adjusted) airmass\n123 \n124     References\n125     ----------\n126     .. [1] C. Gueymard, \"Critical analysis and performance assessment of\n127        clear sky solar irradiance models using theoretical and measured\n128        data,\" Solar Energy, vol. 51, pp. 121-138, 1993.\n129     '''\n130 \n131     airmass_absolute = airmass_relative * pressure / 101325.\n132 \n133     return airmass_absolute\n134 \n135 \n136 def get_relative_airmass(zenith, model='kastenyoung1989'):\n137     '''\n138     Calculate relative (not pressure-adjusted) airmass at sea level.\n139 \n140     Parameter ``model`` allows selection of different airmass models.\n141 \n142     Parameters\n143     ----------\n144     zenith : numeric\n145         Zenith angle of the sun. [degrees]\n146 \n147     model : string, default 'kastenyoung1989'\n148         Available models include the following:\n149 \n150         * 'simple' - secant(apparent zenith angle) -\n151           Note that this gives -Inf at zenith=90\n152         * 'kasten1966' - See reference [1] -\n153           requires apparent sun zenith\n154         * 'youngirvine1967' - See reference [2] -\n155           requires true sun zenith\n156         * 'kastenyoung1989' (default) - See reference [3] -\n157           requires apparent sun zenith\n158         * 'gueymard1993' - See reference [4] -\n159           requires apparent sun zenith\n160         * 'young1994' - See reference [5] -\n161           requries true sun zenith\n162         * 'pickering2002' - See reference [6] -\n163           requires apparent sun zenith\n164 \n165     Returns\n166     -------\n167     airmass_relative : numeric\n168         Relative airmass at sea level. Returns NaN values for any\n169         zenith angle greater than 90 degrees. [unitless]\n170 \n171     Notes\n172     -----\n173     Some models use apparent (refraction-adjusted) zenith angle while\n174     other models use true (not refraction-adjusted) zenith angle. Apparent\n175     zenith angles should be calculated at sea level.\n176 \n177     References\n178     ----------\n179     .. [1] Fritz Kasten. \"A New Table and Approximation Formula for the\n180        Relative Optical Air Mass\". Technical Report 136, Hanover, N.H.:\n181        U.S. Army Material Command, CRREL.\n182 \n183     .. [2] A. T. Young and W. M. Irvine, \"Multicolor Photoelectric\n184        Photometry of the Brighter Planets,\" The Astronomical Journal, vol.\n185        72, pp. 945-950, 1967.\n186 \n187     .. [3] Fritz Kasten and Andrew Young. \"Revised optical air mass tables\n188        and approximation formula\". Applied Optics 28:4735-4738\n189 \n190     .. [4] C. Gueymard, \"Critical analysis and performance assessment of\n191        clear sky solar irradiance models using theoretical and measured\n192        data,\" Solar Energy, vol. 51, pp. 121-138, 1993.\n193 \n194     .. [5] A. T. Young, \"AIR-MASS AND REFRACTION,\" Applied Optics, vol. 33,\n195        pp. 1108-1110, Feb 1994.\n196 \n197     .. [6] Keith A. Pickering. \"The Ancient Star Catalog\". DIO 12:1, 20,\n198 \n199     .. [7] Matthew J. Reno, Clifford W. Hansen and Joshua S. Stein, \"Global\n200        Horizontal Irradiance Clear Sky Models: Implementation and Analysis\"\n201        Sandia Report, (2012).\n202     '''\n203 \n204     # set zenith values greater than 90 to nans\n205     z = np.where(zenith > 90, np.nan, zenith)\n206     zenith_rad = np.radians(z)\n207 \n208     model = model.lower()\n209 \n210     if 'kastenyoung1989' == model:\n211         am = (1.0 / (np.cos(zenith_rad) +\n212               0.50572*(((6.07995 + (90 - z)) ** - 1.6364))))\n213     elif 'kasten1966' == model:\n214         am = 1.0 / (np.cos(zenith_rad) + 0.15*((93.885 - z) ** - 1.253))\n215     elif 'simple' == model:\n216         am = 1.0 / np.cos(zenith_rad)\n217     elif 'pickering2002' == model:\n218         am = (1.0 / (np.sin(np.radians(90 - z +\n219               244.0 / (165 + 47.0 * (90 - z) ** 1.1)))))\n220     elif 'youngirvine1967' == model:\n221         sec_zen = 1.0 / np.cos(zenith_rad)\n222         am = sec_zen * (1 - 0.0012 * (sec_zen * sec_zen - 1))\n223     elif 'young1994' == model:\n224         am = ((1.002432*((np.cos(zenith_rad)) ** 2) +\n225               0.148386*(np.cos(zenith_rad)) + 0.0096467) /\n226               (np.cos(zenith_rad) ** 3 +\n227               0.149864*(np.cos(zenith_rad) ** 2) +\n228               0.0102963*(np.cos(zenith_rad)) + 0.000303978))\n229     elif 'gueymard1993' == model:\n230         am = (1.0 / (np.cos(zenith_rad) +\n231               0.00176759*(z)*((94.37515 - z) ** - 1.21563)))\n232     else:\n233         raise ValueError('%s is not a valid model for relativeairmass', model)\n234 \n235     if isinstance(zenith, pd.Series):\n236         am = pd.Series(am, index=zenith.index)\n237 \n238     return am\n239 \n240 \n241 def gueymard94_pw(temp_air, relative_humidity):\n242     r\"\"\"\n243     Calculates precipitable water (cm) from ambient air temperature (C)\n244     and relatively humidity (%) using an empirical model. The\n245     accuracy of this method is approximately 20% for moderate PW (1-3\n246     cm) and less accurate otherwise.\n247 \n248     The model was developed by expanding Eq. 1 in [2]_:\n249 \n250     .. math::\n251 \n252            Pw = 0.1 H_v \\rho_v\n253 \n254     using Eq. 2 in [2]_\n255 \n256     .. math::\n257 \n258            \\rho_v = 216.7 R_H e_s /T\n259 \n260     :math:`Pw` is the precipitable water (cm), :math:`H_v` is the apparent\n261     water vapor scale height (km) and :math:`\\rho_v` is the surface water\n262     vapor density (g/m^3). . The expression for :math:`H_v` is Eq. 4 in [2]_:\n263 \n264     .. math::\n265 \n266            H_v = 0.4976 + 1.5265 \\frac{T}{273.15}\n267                + \\exp \\left(13.6897 \\frac{T}{273.15}\n268                - 14.9188 \\left( \\frac{T}{273.15} \\right)^3 \\right)\n269 \n270     In the expression for :math:`\\rho_v`, :math:`e_s` is the saturation water\n271     vapor pressure (millibar). The expression for :math:`e_s` is Eq. 1 in [3]_\n272 \n273     .. math::\n274 \n275           e_s = \\exp \\left(22.330 - 49.140 \\frac{100}{T} -\n276               10.922 \\left(\\frac{100}{T}\\right)^2 -\n277               0.39015 \\frac{T}{100} \\right)\n278 \n279     Parameters\n280     ----------\n281     temp_air : numeric\n282         ambient air temperature :math:`T` at the surface. [C]\n283     relative_humidity : numeric\n284         relative humidity :math:`R_H` at the surface. [%]\n285 \n286     Returns\n287     -------\n288     pw : numeric\n289         precipitable water. [cm]\n290 \n291     References\n292     ----------\n293     .. [1] W. M. Keogh and A. W. Blakers, Accurate Measurement, Using Natural\n294        Sunlight, of Silicon Solar Cells, Prog. in Photovoltaics: Res.\n295        and Appl. 2004, vol 12, pp. 1-19 (:doi:`10.1002/pip.517`)\n296 \n297     .. [2] C. Gueymard, Analysis of Monthly Average Atmospheric Precipitable\n298        Water and Turbidity in Canada and Northern United States,\n299        Solar Energy vol 53(1), pp. 57-71, 1994.\n300 \n301     .. [3] C. Gueymard, Assessment of the Accuracy and Computing Speed of\n302        simplified saturation vapor equations using a new reference\n303        dataset, J. of Applied Meteorology 1993, vol. 32(7), pp.\n304        1294-1300.\n305     \"\"\"\n306 \n307     T = temp_air + 273.15  # Convert to Kelvin                  # noqa: N806\n308     RH = relative_humidity                                      # noqa: N806\n309 \n310     theta = T / 273.15\n311 \n312     # Eq. 1 from Keogh and Blakers\n313     pw = (\n314         0.1 *\n315         (0.4976 + 1.5265*theta + np.exp(13.6897*theta - 14.9188*(theta)**3)) *\n316         (216.7*RH/(100*T)*np.exp(22.330 - 49.140*(100/T) -\n317          10.922*(100/T)**2 - 0.39015*T/100)))\n318 \n319     pw = np.maximum(pw, 0.1)\n320 \n321     return pw\n322 \n323 \n324 def first_solar_spectral_correction(pw, airmass_absolute,\n325                                     module_type=None, coefficients=None,\n326                                     min_pw=0.1, max_pw=8):\n327     r\"\"\"\n328     Spectral mismatch modifier based on precipitable water and absolute\n329     (pressure-adjusted) airmass.\n330 \n331     Estimates a spectral mismatch modifier :math:`M` representing the effect on\n332     module short circuit current of variation in the spectral\n333     irradiance. :math:`M`  is estimated from absolute (pressure currected) air\n334     mass, :math:`AM_a`, and precipitable water, :math:`Pw`, using the following\n335     function:\n336 \n337     .. math::\n338 \n339         M = c_1 + c_2 AM_a  + c_3 Pw  + c_4 AM_a^{0.5}\n340             + c_5 Pw^{0.5} + c_6 \\frac{AM_a} {Pw^{0.5}}\n341 \n342     Default coefficients are determined for several cell types with\n343     known quantum efficiency curves, by using the Simple Model of the\n344     Atmospheric Radiative Transfer of Sunshine (SMARTS) [1]_. Using\n345     SMARTS, spectrums are simulated with all combinations of AMa and\n346     Pw where:\n347 \n348        * :math:`0.5 \\textrm{cm} <= Pw <= 5 \\textrm{cm}`\n349        * :math:`1.0 <= AM_a <= 5.0`\n350        * Spectral range is limited to that of CMP11 (280 nm to 2800 nm)\n351        * spectrum simulated on a plane normal to the sun\n352        * All other parameters fixed at G173 standard\n353 \n354     From these simulated spectra, M is calculated using the known\n355     quantum efficiency curves. Multiple linear regression is then\n356     applied to fit Eq. 1 to determine the coefficients for each module.\n357 \n358     Based on the PVLIB Matlab function ``pvl_FSspeccorr`` by Mitchell\n359     Lee and Alex Panchula of First Solar, 2016 [2]_.\n360 \n361     Parameters\n362     ----------\n363     pw : array-like\n364         atmospheric precipitable water. [cm]\n365 \n366     airmass_absolute : array-like\n367         absolute (pressure-adjusted) airmass. [unitless]\n368 \n369     min_pw : float, default 0.1\n370         minimum atmospheric precipitable water. Any pw value lower than min_pw\n371         is set to min_pw to avoid model divergence. [cm]\n372 \n373     max_pw : float, default 8\n374         maximum atmospheric precipitable water. Any pw value higher than max_pw\n375         is set to NaN to avoid model divergence. [cm]\n376 \n377     module_type : None or string, default None\n378         a string specifying a cell type. Values of 'cdte', 'monosi', 'xsi',\n379         'multisi', and 'polysi' (can be lower or upper case). If provided,\n380         module_type selects default coefficients for the following modules:\n381 \n382             * 'cdte' - First Solar Series 4-2 CdTe module.\n383             * 'monosi', 'xsi' - First Solar TetraSun module.\n384             * 'multisi', 'polysi' - anonymous multi-crystalline silicon module.\n385             * 'cigs' - anonymous copper indium gallium selenide module.\n386             * 'asi' - anonymous amorphous silicon module.\n387 \n388         The module used to calculate the spectral correction\n389         coefficients corresponds to the Multi-crystalline silicon\n390         Manufacturer 2 Model C from [3]_. The spectral response (SR) of CIGS\n391         and a-Si modules used to derive coefficients can be found in [4]_\n392 \n393     coefficients : None or array-like, default None\n394         Allows for entry of user-defined spectral correction\n395         coefficients. Coefficients must be of length 6. Derivation of\n396         coefficients requires use of SMARTS and PV module quantum\n397         efficiency curve. Useful for modeling PV module types which are\n398         not included as defaults, or to fine tune the spectral\n399         correction to a particular PV module. Note that the parameters for\n400         modules with very similar quantum efficiency should be similar,\n401         in most cases limiting the need for module specific coefficients.\n402 \n403     Returns\n404     -------\n405     modifier: array-like\n406         spectral mismatch factor (unitless) which is can be multiplied\n407         with broadband irradiance reaching a module's cells to estimate\n408         effective irradiance, i.e., the irradiance that is converted to\n409         electrical current.\n410 \n411     References\n412     ----------\n413     .. [1] Gueymard, Christian. SMARTS2: a simple model of the atmospheric\n414        radiative transfer of sunshine: algorithms and performance\n415        assessment. Cocoa, FL: Florida Solar Energy Center, 1995.\n416     .. [2] Lee, Mitchell, and Panchula, Alex. \"Spectral Correction for\n417        Photovoltaic Module Performance Based on Air Mass and Precipitable\n418        Water.\" IEEE Photovoltaic Specialists Conference, Portland, 2016\n419     .. [3] Marion, William F., et al. User's Manual for Data for Validating\n420        Models for PV Module Performance. National Renewable Energy\n421        Laboratory, 2014. http://www.nrel.gov/docs/fy14osti/61610.pdf\n422     .. [4] Schweiger, M. and Hermann, W, Influence of Spectral Effects\n423        on Energy Yield of Different PV Modules: Comparison of Pwat and\n424        MMF Approach, TUV Rheinland Energy GmbH report 21237296.003,\n425        January 2017\n426     \"\"\"\n427 \n428     # --- Screen Input Data ---\n429 \n430     # *** Pw ***\n431     # Replace Pw Values below 0.1 cm with 0.1 cm to prevent model from\n432     # diverging\"\n433     pw = np.atleast_1d(pw)\n434     pw = pw.astype('float64')\n435     if np.min(pw) < min_pw:\n436         pw = np.maximum(pw, min_pw)\n437         warn('Exceptionally low pw values replaced with {0} cm to prevent '\n438              'model divergence'.format(min_pw))\n439 \n440     # Warn user about Pw data that is exceptionally high\n441     if np.max(pw) > max_pw:\n442         pw[pw > max_pw] = np.nan\n443         warn('Exceptionally high pw values replaced by np.nan: '\n444              'check input data.')\n445 \n446     # *** AMa ***\n447     # Replace Extremely High AM with AM 10 to prevent model divergence\n448     # AM > 10 will only occur very close to sunset\n449     if np.max(airmass_absolute) > 10:\n450         airmass_absolute = np.minimum(airmass_absolute, 10)\n451 \n452     # Warn user about AMa data that is exceptionally low\n453     if np.min(airmass_absolute) < 0.58:\n454         warn('Exceptionally low air mass: ' +\n455              'model not intended for extra-terrestrial use')\n456         # pvl_absoluteairmass(1,pvl_alt2pres(4340)) = 0.58 Elevation of\n457         # Mina Pirquita, Argentian = 4340 m. Highest elevation city with\n458         # population over 50,000.\n459 \n460     _coefficients = {}\n461     _coefficients['cdte'] = (\n462         0.86273, -0.038948, -0.012506, 0.098871, 0.084658, -0.0042948)\n463     _coefficients['monosi'] = (\n464         0.85914, -0.020880, -0.0058853, 0.12029, 0.026814, -0.0017810)\n465     _coefficients['xsi'] = _coefficients['monosi']\n466     _coefficients['polysi'] = (\n467         0.84090, -0.027539, -0.0079224, 0.13570, 0.038024, -0.0021218)\n468     _coefficients['multisi'] = _coefficients['polysi']\n469     _coefficients['cigs'] = (\n470         0.85252, -0.022314, -0.0047216, 0.13666, 0.013342, -0.0008945)\n471     _coefficients['asi'] = (\n472         1.12094, -0.047620, -0.0083627, -0.10443, 0.098382, -0.0033818)\n473 \n474     if module_type is not None and coefficients is None:\n475         coefficients = _coefficients[module_type.lower()]\n476     elif module_type is None and coefficients is not None:\n477         pass\n478     elif module_type is None and coefficients is None:\n479         raise TypeError('No valid input provided, both module_type and ' +\n480                         'coefficients are None')\n481     else:\n482         raise TypeError('Cannot resolve input, must supply only one of ' +\n483                         'module_type and coefficients')\n484 \n485     # Evaluate Spectral Shift\n486     coeff = coefficients\n487     ama = airmass_absolute\n488     modifier = (\n489         coeff[0] + coeff[1]*ama + coeff[2]*pw + coeff[3]*np.sqrt(ama) +\n490         coeff[4]*np.sqrt(pw) + coeff[5]*ama/np.sqrt(pw))\n491 \n492     return modifier\n493 \n494 \n495 def bird_hulstrom80_aod_bb(aod380, aod500):\n496     \"\"\"\n497     Approximate broadband aerosol optical depth.\n498 \n499     Bird and Hulstrom developed a correlation for broadband aerosol optical\n500     depth (AOD) using two wavelengths, 380 nm and 500 nm.\n501 \n502     Parameters\n503     ----------\n504     aod380 : numeric\n505         AOD measured at 380 nm. [unitless]\n506     aod500 : numeric\n507         AOD measured at 500 nm. [unitless]\n508 \n509     Returns\n510     -------\n511     aod_bb : numeric\n512         Broadband AOD.  [unitless]\n513 \n514     See also\n515     --------\n516     pvlib.atmosphere.kasten96_lt\n517 \n518     References\n519     ----------\n520     .. [1] Bird and Hulstrom, \"Direct Insolation Models\" (1980)\n521        `SERI/TR-335-344 <http://www.nrel.gov/docs/legosti/old/344.pdf>`_\n522 \n523     .. [2] R. E. Bird and R. L. Hulstrom, \"Review, Evaluation, and Improvement\n524        of Direct Irradiance Models\", Journal of Solar Energy Engineering\n525        103(3), pp. 182-192 (1981)\n526        :doi:`10.1115/1.3266239`\n527     \"\"\"\n528     # approximate broadband AOD using (Bird-Hulstrom 1980)\n529     return 0.27583 * aod380 + 0.35 * aod500\n530 \n531 \n532 def kasten96_lt(airmass_absolute, precipitable_water, aod_bb):\n533     \"\"\"\n534     Calculate Linke turbidity  using Kasten pyrheliometric formula.\n535 \n536     Note that broadband aerosol optical depth (AOD) can be approximated by AOD\n537     measured at 700 nm according to Molineaux [4] . Bird and Hulstrom offer an\n538     alternate approximation using AOD measured at 380 nm and 500 nm.\n539 \n540     Based on original implementation by Armel Oumbe.\n541 \n542     .. warning::\n543         These calculations are only valid for airmass less than 5 and\n544         precipitable water less than 5 cm.\n545 \n546     Parameters\n547     ----------\n548     airmass_absolute : numeric\n549         Pressure-adjusted airmass. [unitless]\n550     precipitable_water : numeric\n551         Precipitable water. [cm]\n552     aod_bb : numeric\n553         broadband AOD. [unitless]\n554 \n555     Returns\n556     -------\n557     lt : numeric\n558         Linke turbidity. [unitless]\n559 \n560     See also\n561     --------\n562     pvlib.atmosphere.bird_hulstrom80_aod_bb\n563     pvlib.atmosphere.angstrom_aod_at_lambda\n564 \n565     References\n566     ----------\n567     .. [1] F. Linke, \"Transmissions-Koeffizient und Trubungsfaktor\", Beitrage\n568        zur Physik der Atmosphare, Vol 10, pp. 91-103 (1922)\n569 \n570     .. [2] F. Kasten, \"A simple parameterization of the pyrheliometric formula\n571        for determining the Linke turbidity factor\", Meteorologische Rundschau\n572        33, pp. 124-127 (1980)\n573 \n574     .. [3] Kasten, \"The Linke turbidity factor based on improved values of the\n575        integral Rayleigh optical thickness\", Solar Energy, Vol. 56, No. 3,\n576        pp. 239-244 (1996)\n577        :doi:`10.1016/0038-092X(95)00114-7`\n578 \n579     .. [4] B. Molineaux, P. Ineichen, N. O'Neill, \"Equivalence of\n580        pyrheliometric and monochromatic aerosol optical depths at a single key\n581        wavelength\", Applied Optics Vol. 37, issue 10, 7008-7018 (1998)\n582        :doi:`10.1364/AO.37.007008`\n583 \n584     .. [5] P. Ineichen, \"Conversion function between the Linke turbidity and\n585        the atmospheric water vapor and aerosol content\", Solar Energy 82,\n586        pp. 1095-1097 (2008)\n587        :doi:`10.1016/j.solener.2008.04.010`\n588 \n589     .. [6] P. Ineichen and R. Perez, \"A new airmass independent formulation for\n590        the Linke Turbidity coefficient\", Solar Energy, Vol. 73, no. 3,\n591        pp. 151-157 (2002)\n592        :doi:`10.1016/S0038-092X(02)00045-2`\n593     \"\"\"\n594     # \"From numerically integrated spectral simulations done with Modtran\n595     # (Berk, 1989), Molineaux (1998) obtained for the broadband optical depth\n596     # of a clean and dry atmospshere (fictitious atmosphere that comprises only\n597     # the effects of Rayleigh scattering and absorption by the atmosphere gases\n598     # other than the water vapor) the following expression\"\n599     # - P. Ineichen (2008)\n600     delta_cda = -0.101 + 0.235 * airmass_absolute ** (-0.16)\n601     # \"and the broadband water vapor optical depth where pwat is the integrated\n602     # precipitable water vapor content of the atmosphere expressed in cm and am\n603     # the optical air mass. The precision of these fits is better than 1% when\n604     # compared with Modtran simulations in the range 1 < am < 5 and\n605     # 0 < pwat < 5 cm at sea level\" - P. Ineichen (2008)\n606     delta_w = 0.112 * airmass_absolute ** (-0.55) * precipitable_water ** 0.34\n607     # broadband AOD\n608     delta_a = aod_bb\n609     # \"Then using the Kasten pyrheliometric formula (1980, 1996), the Linke\n610     # turbidity at am = 2 can be written. The extension of the Linke turbidity\n611     # coefficient to other values of air mass was published by Ineichen and\n612     # Perez (2002)\" - P. Ineichen (2008)\n613     lt = -(9.4 + 0.9 * airmass_absolute) * np.log(\n614         np.exp(-airmass_absolute * (delta_cda + delta_w + delta_a))\n615     ) / airmass_absolute\n616     # filter out of extrapolated values\n617     return lt\n618 \n619 \n620 def angstrom_aod_at_lambda(aod0, lambda0, alpha=1.14, lambda1=700.0):\n621     r\"\"\"\n622     Get AOD at specified wavelength using Angstrom turbidity model.\n623 \n624     Parameters\n625     ----------\n626     aod0 : numeric\n627         Aerosol optical depth (AOD) measured at wavelength ``lambda0``.\n628         [unitless]\n629     lambda0 : numeric\n630         Wavelength corresponding to ``aod0``. [nm]\n631     alpha : numeric, default 1.14\n632         Angstrom :math:`\\alpha` exponent corresponding to ``aod0``. [unitless]\n633     lambda1 : numeric, default 700\n634         Desired wavelength. [nm]\n635 \n636     Returns\n637     -------\n638     aod1 : numeric\n639         AOD at desired wavelength ``lambda1``. [unitless]\n640 \n641     See also\n642     --------\n643     pvlib.atmosphere.angstrom_alpha\n644 \n645     References\n646     ----------\n647     .. [1] Anders Angstrom, \"On the Atmospheric Transmission of Sun Radiation\n648        and On Dust in the Air\", Geografiska Annaler Vol. 11, pp. 156-166 (1929)\n649        JSTOR\n650        :doi:`10.2307/519399`\n651 \n652     .. [2] Anders Angstrom, \"Techniques of Determining the Turbidity of the\n653        Atmosphere\", Tellus 13:2, pp. 214-223 (1961) Taylor & Francis\n654        :doi:`10.3402/tellusa.v13i2.9493` and Co-Action Publishing\n655        :doi:`10.1111/j.2153-3490.1961.tb00078.x`\n656     \"\"\"\n657     return aod0 * ((lambda1 / lambda0) ** (-alpha))\n658 \n659 \n660 def angstrom_alpha(aod1, lambda1, aod2, lambda2):\n661     r\"\"\"\n662     Calculate Angstrom alpha exponent.\n663 \n664     Parameters\n665     ----------\n666     aod1 : numeric\n667         Aerosol optical depth at wavelength ``lambda1``. [unitless]\n668     lambda1 : numeric\n669         Wavelength corresponding to ``aod1``. [nm]\n670     aod2 : numeric\n671         Aerosol optical depth  at wavelength ``lambda2``. [unitless]\n672     lambda2 : numeric\n673         Wavelength corresponding to ``aod2``. [nm]\n674 \n675     Returns\n676     -------\n677     alpha : numeric\n678         Angstrom :math:`\\alpha` exponent for wavelength in\n679         ``(lambda1, lambda2)``. [unitless]\n680 \n681     See also\n682     --------\n683     pvlib.atmosphere.angstrom_aod_at_lambda\n684     \"\"\"\n685     return - np.log(aod1 / aod2) / np.log(lambda1 / lambda2)\n686 \n[end of pvlib/atmosphere.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "a7edb8b582174ed45f2d3859f29261908f5e0ab5", "problem_statement": "PVSystem.temperature_model_parameters requirement\nThe `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to \r\n\r\n1. set default values `module_type=None` and `racking_model=None`.\r\n2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L208-L221\r\n\r\n@cwhanse is that correct?\r\n\r\nThe problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L201-L203\r\n\r\nSo I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9. \nremove deprecated functions in 0.8\n`pvsystem`:\r\n* `sapm_celltemp`\r\n* `pvsyst_celltemp`\r\n* `ashraeiam`\r\n* `physicaliam`\r\n* `sapm_aoi_loss`\r\n* `PVSystem.ashraeiam`\r\n* `PVSystem.physicaliam`\r\n* `PVSystem.sapm_aoi_loss`\r\n* inference of `PVSystem.temperature_model_parameters`\r\n\r\n`modelchain.ModelChain`:\r\n* remove `times` from `complete_irradiance`, `prepare_inputs`, `run_model`\r\n* remove `temp_model` kwarg\n", "hints_text": "> The `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to\r\n> \r\n> 1. set default values `module_type=None` and `racking_model=None`.\r\n> 2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n> \r\n> @cwhanse is that correct?\r\n\r\nYes, that is the intent.\r\n\r\n> So I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9.\r\n\r\nThe warning should have been raised whenever condition #2 above wasn't met; it looks to me that has been the case. If that hasn't been the case I would prefer to fix the warning and push the deprecation out to v0.9. pvlib-python has had that unadvertised default temperature model assignment for a long time.\r\n\n> The problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nI don't follow here - it looks to me that the warning should be raised if 1) `temperature_model_parameters` isn't specified, or 2) either `module_type` or `racking_model` are invalid. Maybe we're saying the same thing. `_infer_temperature_model` doesn't assign the default temperature model, that is done in the block of code that raises the warning. \r\n\r\n\nThe `module_type` and `racking_model` defaults prevent the warning from showing up in many use cases. If we change the defaults to `None` then the warning will be triggered. If we simultaneously remove the warning then code will break without users having ever seen the warning.\nWhat is the expected behavior for `PVSystem()`?\n> The `module_type` and `racking_model` defaults prevent the warning from showing up in many use cases. If we change the defaults to `None` then the warning will be triggered. If we simultaneously remove the warning then code will break without users having ever seen the warning.\r\n\r\nAha. I see the problem now, thanks.  Perhaps remove the defaults in v0.8 and leave the warning until v0.9?\nOk, I'll work on that.\n", "created_at": "2020-08-25T18:51:23Z", "patch": "<patch>\ndiff --git a/pvlib/modelchain.py b/pvlib/modelchain.py\n--- a/pvlib/modelchain.py\n+++ b/pvlib/modelchain.py\n@@ -179,7 +179,7 @@ def basic_chain(times, latitude, longitude,\n             linke_turbidity,\n             altitude=altitude,\n             dni_extra=dni_extra\n-            )\n+        )\n \n     total_irrad = pvlib.irradiance.get_total_irradiance(\n         surface_tilt,\n@@ -346,24 +346,6 @@ def __init__(self, system, location,\n         self.ac_model = ac_model\n         self.aoi_model = aoi_model\n         self.spectral_model = spectral_model\n-\n-        # TODO: deprecated kwarg temp_model. Remove use of temp_model in v0.8\n-        temp_model = kwargs.pop('temp_model', None)\n-        if temp_model is not None:\n-            if temperature_model is None:\n-                warnings.warn('The temp_model keyword argument is deprecated.'\n-                              ' Use temperature_model instead',\n-                              pvlibDeprecationWarning)\n-                temperature_model = temp_model\n-            elif temp_model == temperature_model:\n-                warnings.warn('Provide only one of temperature_model or '\n-                              'temp_model (deprecated).',\n-                              pvlibDeprecationWarning)\n-            else:\n-                raise ValueError(\n-                    'Conflicting temperature_model {} and temp_model {}. '\n-                    'temp_model is deprecated. Specify only temperature_model.'\n-                    .format(temperature_model, temp_model))\n         self.temperature_model = temperature_model\n \n         self.losses_model = losses_model\n@@ -544,7 +526,7 @@ def __repr__(self):\n             'transposition_model', 'solar_position_method',\n             'airmass_model', 'dc_model', 'ac_model', 'aoi_model',\n             'spectral_model', 'temperature_model', 'losses_model'\n-            ]\n+        ]\n \n         def getmcattr(self, attr):\n             \"\"\"needed to avoid recursion in property lookups\"\"\"\n@@ -588,8 +570,8 @@ def dc_model(self, model):\n             model = model.lower()\n             if model in _DC_MODEL_PARAMS.keys():\n                 # validate module parameters\n-                missing_params = _DC_MODEL_PARAMS[model] - \\\n-                                 set(self.system.module_parameters.keys())\n+                missing_params = (_DC_MODEL_PARAMS[model]\n+                                  - set(self.system.module_parameters.keys()))\n                 if missing_params:  # some parameters are not in module.keys()\n                     raise ValueError(model + ' selected for the DC model but '\n                                      'one or more required parameters are '\n@@ -834,8 +816,8 @@ def infer_spectral_model(self):\n \n     def first_solar_spectral_loss(self):\n         self.spectral_modifier = self.system.first_solar_spectral_loss(\n-                                        self.weather['precipitable_water'],\n-                                        self.airmass['airmass_absolute'])\n+            self.weather['precipitable_water'],\n+            self.airmass['airmass_absolute'])\n         return self\n \n     def sapm_spectral_loss(self):\n@@ -878,7 +860,10 @@ def temperature_model(self, model):\n \n     def infer_temperature_model(self):\n         params = set(self.system.temperature_model_parameters.keys())\n-        if set(['a', 'b', 'deltaT']) <= params:\n+        # remove or statement in v0.9\n+        if set(['a', 'b', 'deltaT']) <= params or (\n+                not params and self.system.racking_model is None\n+                and self.system.module_type is None):\n             return self.sapm_temp\n         elif set(['u_c', 'u_v']) <= params:\n             return self.pvsyst_temp\n@@ -945,7 +930,7 @@ def effective_irradiance_model(self):\n             fd*self.total_irrad['poa_diffuse'])\n         return self\n \n-    def complete_irradiance(self, weather, times=None):\n+    def complete_irradiance(self, weather):\n         \"\"\"\n         Determine the missing irradiation columns. Only two of the\n         following data columns (dni, ghi, dhi) are needed to calculate\n@@ -962,10 +947,6 @@ def complete_irradiance(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Returns\n         -------\n@@ -994,11 +975,6 @@ def complete_irradiance(self, weather, times=None):\n         \"\"\"\n         self.weather = weather\n \n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.solar_position = self.location.get_solarposition(\n             self.weather.index, method=self.solar_position_method)\n \n@@ -1029,7 +1005,7 @@ def complete_irradiance(self, weather, times=None):\n \n         return self\n \n-    def prepare_inputs(self, weather, times=None):\n+    def prepare_inputs(self, weather):\n         \"\"\"\n         Prepare the solar position, irradiance, and weather inputs to\n         the model.\n@@ -1041,10 +1017,6 @@ def prepare_inputs(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Notes\n         -----\n@@ -1064,11 +1036,6 @@ def prepare_inputs(self, weather, times=None):\n \n         self.weather = weather\n \n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.times = self.weather.index\n         try:\n             kwargs = _build_kwargs(['pressure', 'temp_air'], weather)\n@@ -1126,7 +1093,7 @@ def prepare_inputs(self, weather, times=None):\n             self.weather['temp_air'] = 20\n         return self\n \n-    def run_model(self, weather, times=None):\n+    def run_model(self, weather):\n         \"\"\"\n         Run the model.\n \n@@ -1137,10 +1104,6 @@ def run_model(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Returns\n         -------\n@@ -1152,11 +1115,6 @@ def run_model(self, weather, times=None):\n         ``dc``, ``ac``, ``losses``,\n         ``diode_params`` (if dc_model is a single diode model)\n         \"\"\"\n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.prepare_inputs(weather)\n         self.aoi_model()\n         self.spectral_model()\ndiff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -170,12 +170,12 @@ class PVSystem(object):\n     def __init__(self,\n                  surface_tilt=0, surface_azimuth=180,\n                  albedo=None, surface_type=None,\n-                 module=None, module_type='glass_polymer',\n+                 module=None, module_type=None,\n                  module_parameters=None,\n                  temperature_model_parameters=None,\n                  modules_per_string=1, strings_per_inverter=1,\n                  inverter=None, inverter_parameters=None,\n-                 racking_model='open_rack', losses_parameters=None, name=None,\n+                 racking_model=None, losses_parameters=None, name=None,\n                  **kwargs):\n \n         self.surface_tilt = surface_tilt\n@@ -201,25 +201,9 @@ def __init__(self,\n         if temperature_model_parameters is None:\n             self.temperature_model_parameters = \\\n                 self._infer_temperature_model_params()\n-            # TODO: in v0.8 check if an empty dict is returned and raise error\n         else:\n             self.temperature_model_parameters = temperature_model_parameters\n \n-        # TODO: deprecated behavior if PVSystem.temperature_model_parameters\n-        # are not specified. Remove in v0.8\n-        if not any(self.temperature_model_parameters):\n-            warnings.warn(\n-                'Required temperature_model_parameters is not specified '\n-                'and parameters are not inferred from racking_model and '\n-                'module_type. Reverting to deprecated default: SAPM cell '\n-                'temperature model parameters for a glass/glass module in '\n-                'open racking. In the future '\n-                'PVSystem.temperature_model_parameters will be required',\n-                pvlibDeprecationWarning)\n-            params = temperature._temperature_model_params(\n-                'sapm', 'open_rack_glass_glass')\n-            self.temperature_model_parameters = params\n-\n         self.modules_per_string = modules_per_string\n         self.strings_per_inverter = strings_per_inverter\n \n@@ -358,26 +342,6 @@ def get_iam(self, aoi, iam_model='physical'):\n         else:\n             raise ValueError(model + ' is not a valid IAM model')\n \n-    def ashraeiam(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.ashraeiam is deprecated and will be removed in'\n-                      'v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='ashrae')\n-\n-    def physicaliam(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.physicaliam is deprecated and will be removed'\n-                      ' in v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='physical')\n-\n     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_desoto` function, the input\n@@ -506,6 +470,21 @@ def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n         -------\n         numeric, values in degrees C.\n         \"\"\"\n+        # warn user about change in default behavior in 0.9.\n+        if (self.temperature_model_parameters == {} and self.module_type\n+                is None and self.racking_model is None):\n+            warnings.warn(\n+                'temperature_model_parameters, racking_model, and module_type '\n+                'are not specified. Reverting to deprecated default: SAPM '\n+                'cell temperature model parameters for a glass/glass module '\n+                'in open racking. In v0.9, temperature_model_parameters or a '\n+                'valid combination of racking_model and module_type will be '\n+                'required.',\n+                pvlibDeprecationWarning)\n+            params = temperature._temperature_model_params(\n+                'sapm', 'open_rack_glass_glass')\n+            self.temperature_model_parameters = params\n+\n         kwargs = _build_kwargs(['a', 'b', 'deltaT'],\n                                self.temperature_model_parameters)\n         return temperature.sapm_cell(poa_global, temp_air, wind_speed,\n@@ -514,7 +493,7 @@ def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n     def _infer_temperature_model_params(self):\n         # try to infer temperature model parameters from from racking_model\n         # and module_type\n-        param_set = self.racking_model + '_' + self.module_type\n+        param_set = '{}_{}'.format(self.racking_model, self.module_type)\n         if param_set in temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']:\n             return temperature._temperature_model_params('sapm', param_set)\n         elif 'freestanding' in param_set:\n@@ -543,16 +522,6 @@ def sapm_spectral_loss(self, airmass_absolute):\n         \"\"\"\n         return sapm_spectral_loss(airmass_absolute, self.module_parameters)\n \n-    def sapm_aoi_loss(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.sapm_aoi_loss is deprecated and will be'\n-                      ' removed in v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='sapm')\n-\n     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n                                   airmass_absolute, aoi,\n                                   reference_irradiance=1000):\n@@ -671,7 +640,7 @@ def first_solar_spectral_loss(self, pw, airmass_absolute):\n         if 'first_solar_spectral_coefficients' in \\\n                 self.module_parameters.keys():\n             coefficients = \\\n-                   self.module_parameters['first_solar_spectral_coefficients']\n+                self.module_parameters['first_solar_spectral_coefficients']\n             module_type = None\n         else:\n             module_type = self._infer_cell_type()\n@@ -1071,27 +1040,6 @@ def calcparams_desoto(effective_irradiance, temp_cell,\n          Source: [4]\n     '''\n \n-    # test for use of function pre-v0.6.0 API change\n-    if isinstance(a_ref, dict) or \\\n-       (isinstance(a_ref, pd.Series) and ('a_ref' in a_ref.keys())):\n-        import warnings\n-        warnings.warn('module_parameters detected as fourth positional'\n-                      + ' argument of calcparams_desoto. calcparams_desoto'\n-                      + ' will require one argument for each module model'\n-                      + ' parameter in v0.7.0 and later', DeprecationWarning)\n-        try:\n-            module_parameters = a_ref\n-            a_ref = module_parameters['a_ref']\n-            I_L_ref = module_parameters['I_L_ref']\n-            I_o_ref = module_parameters['I_o_ref']\n-            R_sh_ref = module_parameters['R_sh_ref']\n-            R_s = module_parameters['R_s']\n-        except Exception as e:\n-            raise e('Module parameters could not be extracted from fourth'\n-                    + ' positional argument of calcparams_desoto. Check that'\n-                    + ' parameters are from the CEC database and/or update'\n-                    + ' your code for the new API for calcparams_desoto')\n-\n     # Boltzmann constant in eV/K\n     k = 8.617332478e-05\n \n@@ -1624,16 +1572,6 @@ def sapm(effective_irradiance, temp_cell, module):\n     # reference_irradiance and expose\n     temp_ref = 25\n     irrad_ref = 1000\n-    # TODO: remove this warning in v0.8 after deprecation period for change in\n-    # effective irradiance units, made in v0.7\n-    with np.errstate(invalid='ignore'):  # turn off warning for NaN\n-        ee = np.asarray(effective_irradiance)\n-        ee_gt0 = ee[ee > 0.0]\n-        if ee_gt0.size > 0 and np.all(ee_gt0 < 2.0):\n-            import warnings\n-            msg = 'effective_irradiance inputs appear to be in suns. Units ' \\\n-                  'changed in v0.7 from suns to W/m2'\n-            warnings.warn(msg, RuntimeWarning)\n \n     q = 1.60218e-19  # Elementary charge in units of coulombs\n     kb = 1.38066e-23  # Boltzmann's constant in units of J/K\n@@ -1695,85 +1633,6 @@ def sapm(effective_irradiance, temp_cell, module):\n     return out\n \n \n-def _sapm_celltemp_translator(*args, **kwargs):\n-    # TODO: remove this function after deprecation period for sapm_celltemp\n-    new_kwargs = {}\n-    # convert position arguments to kwargs\n-    old_arg_list = ['poa_global', 'wind_speed', 'temp_air', 'model']\n-    for pos in range(len(args)):\n-        new_kwargs[old_arg_list[pos]] = args[pos]\n-    # determine value for new kwarg 'model'\n-    try:\n-        param_set = new_kwargs['model']\n-        new_kwargs.pop('model')  # model is not a new kwarg\n-    except KeyError:\n-        # 'model' not in positional arguments, check kwargs\n-        try:\n-            param_set = kwargs['model']\n-            kwargs.pop('model')\n-        except KeyError:\n-            # 'model' not in kwargs, use old default value\n-            param_set = 'open_rack_glass_glass'\n-    if type(param_set) is list:\n-        new_kwargs.update({'a': param_set[0],\n-                           'b': param_set[1],\n-                           'deltaT': param_set[2]})\n-    elif type(param_set) is dict:\n-        new_kwargs.update(param_set)\n-    else:  # string\n-        params = temperature._temperature_model_params('sapm', param_set)\n-        new_kwargs.update(params)\n-    new_kwargs.update(kwargs)  # kwargs with unchanged names\n-    new_kwargs['irrad_ref'] = 1000  # default for new kwarg\n-    # convert old positional arguments to named kwargs\n-    return temperature.sapm_cell(**new_kwargs)\n-\n-\n-sapm_celltemp = deprecated('0.7', alternative='temperature.sapm_cell',\n-                           name='sapm_celltemp', removal='0.8',\n-                           addendum='Note that the arguments and argument '\n-                           'order for temperature.sapm_cell are different '\n-                           'than for sapm_celltemp')(_sapm_celltemp_translator)\n-\n-\n-def _pvsyst_celltemp_translator(*args, **kwargs):\n-    # TODO: remove this function after deprecation period for pvsyst_celltemp\n-    new_kwargs = {}\n-    # convert position arguments to kwargs\n-    old_arg_list = ['poa_global', 'temp_air', 'wind_speed', 'eta_m',\n-                    'alpha_absorption', 'model_params']\n-    for pos in range(len(args)):\n-        new_kwargs[old_arg_list[pos]] = args[pos]\n-    # determine value for new kwarg 'model'\n-    try:\n-        param_set = new_kwargs['model_params']\n-        new_kwargs.pop('model_params')  # model_params is not a new kwarg\n-    except KeyError:\n-        # 'model_params' not in positional arguments, check kwargs\n-        try:\n-            param_set = kwargs['model_params']\n-            kwargs.pop('model_params')\n-        except KeyError:\n-            # 'model_params' not in kwargs, use old default value\n-            param_set = 'freestanding'\n-    if type(param_set) in (list, tuple):\n-        new_kwargs.update({'u_c': param_set[0],\n-                           'u_v': param_set[1]})\n-    else:  # string\n-        params = temperature._temperature_model_params('pvsyst', param_set)\n-        new_kwargs.update(params)\n-    new_kwargs.update(kwargs)  # kwargs with unchanged names\n-    # convert old positional arguments to named kwargs\n-    return temperature.pvsyst_cell(**new_kwargs)\n-\n-\n-pvsyst_celltemp = deprecated(\n-    '0.7', alternative='temperature.pvsyst_cell', name='pvsyst_celltemp',\n-    removal='0.8', addendum='Note that the argument names for '\n-    'temperature.pvsyst_cell are different than '\n-    'for pvsyst_celltemp')(_pvsyst_celltemp_translator)\n-\n-\n def sapm_spectral_loss(airmass_absolute, module):\n     \"\"\"\n     Calculates the SAPM spectral loss coefficient, F1.\n@@ -2051,8 +1910,7 @@ def singlediode(photocurrent, saturation_current, resistance_series,\n         # calculate the IV curve if requested using bishop88\n         if ivcurve_pnts:\n             vd = v_oc * (\n-                    (11.0 - np.logspace(np.log10(11.0), 0.0,\n-                                        ivcurve_pnts)) / 10.0\n+                (11.0 - np.logspace(np.log10(11.0), 0.0, ivcurve_pnts)) / 10.0\n             )\n             ivcurve_i, ivcurve_v, _ = _singlediode.bishop88(vd, *args)\n \n@@ -2301,17 +2159,17 @@ def i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n         # equation for the diode voltage V_d then backing out voltage\n         args = (voltage, photocurrent, saturation_current, resistance_series,\n                 resistance_shunt, nNsVth)\n-        I = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n+        current = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n         # find the right size and shape for returns\n         size, shape = _singlediode._get_size_and_shape(args)\n         if size <= 1:\n             if shape is not None:\n-                I = np.tile(I, shape)\n-        if np.isnan(I).any() and size <= 1:\n-            I = np.repeat(I, size)\n+                current = np.tile(current, shape)\n+        if np.isnan(current).any() and size <= 1:\n+            current = np.repeat(current, size)\n             if shape is not None:\n-                I = I.reshape(shape)\n-        return I\n+                current = current.reshape(shape)\n+        return current\n \n \n def scale_voltage_current_power(data, voltage=1, current=1):\n@@ -2390,7 +2248,7 @@ def pvwatts_dc(g_poa_effective, temp_cell, pdc0, gamma_pdc, temp_ref=25.):\n     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n            (2014).\n-    \"\"\"\n+    \"\"\"  # noqa: E501\n \n     pdc = (g_poa_effective * 0.001 * pdc0 *\n            (1 + gamma_pdc * (temp_cell - temp_ref)))\n@@ -2452,18 +2310,6 @@ def pvwatts_losses(soiling=2, shading=3, snow=0, mismatch=2, wiring=2,\n     return losses\n \n \n-ashraeiam = deprecated('0.7', alternative='iam.ashrae', name='ashraeiam',\n-                       removal='0.8')(iam.ashrae)\n-\n-\n-physicaliam = deprecated('0.7', alternative='iam.physical', name='physicaliam',\n-                         removal='0.8')(iam.physical)\n-\n-\n-sapm_aoi_loss = deprecated('0.7', alternative='iam.sapm', name='sapm_aoi_loss',\n-                           removal='0.8')(iam.sapm)\n-\n-\n snlinverter = deprecated('0.8', alternative='inverter.sandia',\n                          name='snlinverter', removal='0.9')(inverter.sandia)\n \n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_modelchain.py b/pvlib/tests/test_modelchain.py\n--- a/pvlib/tests/test_modelchain.py\n+++ b/pvlib/tests/test_modelchain.py\n@@ -13,7 +13,7 @@\n from conftest import assert_series_equal\n import pytest\n \n-from conftest import fail_on_pvlib_version, requires_scipy, requires_tables\n+from conftest import fail_on_pvlib_version, requires_scipy\n \n \n @pytest.fixture(scope='function')\n@@ -153,6 +153,18 @@ def system_no_aoi(cec_module_cs5p_220m, sapm_temperature_cs5p_220m,\n     return system\n \n \n+@pytest.fixture\n+def system_no_temp(cec_module_cs5p_220m, cec_inverter_parameters):\n+    module_parameters = cec_module_cs5p_220m.copy()\n+    module_parameters['EgRef'] = 1.121\n+    module_parameters['dEgdT'] = -0.0002677\n+    inverter_parameters = cec_inverter_parameters.copy()\n+    system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n+                      module_parameters=module_parameters,\n+                      inverter_parameters=inverter_parameters)\n+    return system\n+\n+\n @pytest.fixture\n def location():\n     return Location(32.2, -111, altitude=700)\n@@ -211,24 +223,6 @@ def test_run_model_with_irradiance(sapm_dc_snl_ac_system, location):\n     assert_series_equal(ac, expected)\n \n \n-def test_run_model_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'dni': 900, 'ghi': 600, 'dhi': 150},\n-                              index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.run_model(irradiance, times=times)\n-\n-\n-def test_prepare_inputs_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'dni': 900, 'ghi': 600, 'dhi': 150},\n-                              index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.prepare_inputs(irradiance, times=times)\n-\n-\n def test_prepare_inputs_no_irradiance(sapm_dc_snl_ac_system, location):\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     weather = pd.DataFrame()\n@@ -236,15 +230,6 @@ def test_prepare_inputs_no_irradiance(sapm_dc_snl_ac_system, location):\n         mc.prepare_inputs(weather)\n \n \n-@requires_tables\n-def test_complete_irradiance_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'ghi': 600., 'dhi': 150.}, index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.complete_irradiance(irradiance, times=times)\n-\n-\n def test_run_model_perez(sapm_dc_snl_ac_system, location):\n     mc = ModelChain(sapm_dc_snl_ac_system, location,\n                     transposition_model='perez')\n@@ -277,8 +262,6 @@ def test_run_model_with_weather_sapm_temp(sapm_dc_snl_ac_system, location,\n     # test with sapm cell temperature model\n     weather['wind_speed'] = 5\n     weather['temp_air'] = 10\n-    sapm_dc_snl_ac_system.racking_model = 'open_rack'\n-    sapm_dc_snl_ac_system.module_type = 'glass_glass'\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     mc.temperature_model = 'sapm'\n     m_sapm = mocker.spy(sapm_dc_snl_ac_system, 'sapm_celltemp')\n@@ -437,6 +420,17 @@ def test_infer_temp_model_invalid(location, sapm_dc_snl_ac_system):\n                    spectral_model='no_loss')\n \n \n+# ModelChain.infer_temperature_model. remove or statement in v0.9\n+@requires_scipy\n+@fail_on_pvlib_version('0.9')\n+def test_infer_temp_model_no_params(location, system_no_temp, weather):\n+    mc = ModelChain(system_no_temp, location, aoi_model='physical',\n+                    spectral_model='no_loss')\n+    match = \"Reverting to deprecated default: SAPM cell temperature\"\n+    with pytest.warns(pvlibDeprecationWarning, match=match):\n+        mc.run_model(weather)\n+\n+\n @requires_scipy\n def test_temperature_model_inconsistent(location, sapm_dc_snl_ac_system):\n     with pytest.raises(ValueError):\n@@ -688,36 +682,6 @@ def test_bad_get_orientation():\n         modelchain.get_orientation('bad value')\n \n \n-@fail_on_pvlib_version('0.8')\n-def test_deprecated_08():\n-    # explicit system creation call because fail_on_pvlib_version\n-    # does not support decorators.\n-    # does not matter what the parameters are, just fake it until we make it\n-    module_parameters = {'R_sh_ref': 1, 'a_ref': 1, 'I_o_ref': 1,\n-                         'alpha_sc': 1, 'I_L_ref': 1, 'R_s': 1}\n-    # do not assign PVSystem.temperature_model_parameters\n-    # leave out PVSystem.racking_model and PVSystem.module_type\n-    system = PVSystem(module_parameters=module_parameters)\n-    # deprecated temp_model kwarg\n-    warn_txt = 'temp_model keyword argument is deprecated'\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temp_model='sapm')\n-    # provide both temp_model and temperature_model kwargs\n-    warn_txt = 'Provide only one of temperature_model'\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temperature_model='sapm', temp_model='sapm')\n-    # conflicting temp_model and temperature_model kwargs\n-    exc_text = 'Conflicting temperature_model'\n-    with pytest.raises(ValueError, match=exc_text):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temperature_model='pvsyst', temp_model='sapm')\n-\n-\n @fail_on_pvlib_version('0.9')\n @pytest.mark.parametrize('ac_model', ['snlinverter', 'adrinverter'])\n def test_deprecated_09(sapm_dc_snl_ac_system, cec_dc_adr_ac_system,\ndiff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -198,17 +198,6 @@ def test_sapm(sapm_module_params):\n                   pd.Series(sapm_module_params))\n \n \n-def test_pvsystem_sapm_warning(sapm_module_params):\n-    # deprecation warning for change in effective_irradiance units in\n-    # pvsystem.sapm\n-    # TODO: remove after deprecation period (v0.8)\n-    effective_irradiance = np.array([0.1, 0.2, 1.3])\n-    temp_cell = np.array([25, 25, 50])\n-    warn_txt = 'effective_irradiance inputs appear to be in suns'\n-    with pytest.warns(RuntimeWarning, match=warn_txt):\n-        pvsystem.sapm(effective_irradiance, temp_cell, sapm_module_params)\n-\n-\n def test_PVSystem_sapm(sapm_module_params, mocker):\n     mocker.spy(pvsystem, 'sapm')\n     system = pvsystem.PVSystem(module_parameters=sapm_module_params)\n@@ -386,14 +375,6 @@ def test__infer_temperature_model_params():\n     assert expected == system._infer_temperature_model_params()\n \n \n-def test__infer_temperature_model_params_deprec_warning():\n-    warn_txt = \"Reverting to deprecated default\"\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        pvsystem.PVSystem(module_parameters={},\n-                          racking_model='not_a_rack_model',\n-                          module_type='glass_polymer')\n-\n-\n def test_calcparams_desoto(cec_module_params):\n     times = pd.date_range(start='2015-01-01', periods=3, freq='12H')\n     effective_irradiance = pd.Series([0.0, 800.0, 800.0], index=times)\n@@ -1130,8 +1111,8 @@ def test_PVSystem___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n     assert system.__repr__() == expected\n \n@@ -1153,8 +1134,8 @@ def test_PVSystem_localize___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n \n     assert localized_system.__repr__() == expected\n@@ -1193,8 +1174,8 @@ def test_LocalizedPVSystem___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n \n     assert localized_system.__repr__() == expected\n@@ -1318,94 +1299,6 @@ def test_PVSystem_pvwatts_ac_kwargs(mocker):\n     assert out < pdc\n \n \n-@fail_on_pvlib_version('0.8')\n-def test_deprecated_08():\n-    # deprecated function pvsystem.sapm_celltemp\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.sapm_celltemp(1000, 25, 1)\n-    # deprecated function pvsystem.pvsyst_celltemp\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.pvsyst_celltemp(1000, 25)\n-    module_parameters = {'R_sh_ref': 1, 'a_ref': 1, 'I_o_ref': 1,\n-                         'alpha_sc': 1, 'I_L_ref': 1, 'R_s': 1,\n-                         'B5': 0.0, 'B4': 0.0, 'B3': 0.0, 'B2': 0.0,\n-                         'B1': 0.0, 'B0': 1.0,\n-                         'b': 0.05, 'K': 4, 'L': 0.002, 'n': 1.526,\n-                         'a_r': 0.16}\n-    temp_model_params = temperature.TEMPERATURE_MODEL_PARAMETERS['sapm'][\n-        'open_rack_glass_glass']\n-    # for missing temperature_model_parameters\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.PVSystem(module_parameters=module_parameters,\n-                          racking_model='open', module_type='glass_glass')\n-    pv = pvsystem.PVSystem(module_parameters=module_parameters,\n-                           temperature_model_parameters=temp_model_params,\n-                           racking_model='open', module_type='glass_glass')\n-    # deprecated method PVSystem.ashraeiam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.ashraeiam(45)\n-    # deprecated function ashraeiam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.ashraeiam(45)\n-    # deprecated method PVSystem.physicaliam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.physicaliam(45)\n-    # deprecated function physicaliam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.physicaliam(45)\n-    # deprecated method PVSystem.sapm_aoi_loss\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.sapm_aoi_loss(45)\n-    # deprecated function sapm_aoi_loss\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.sapm_aoi_loss(45, {'B5': 0.0, 'B4': 0.0, 'B3': 0.0, 'B2': 0.0,\n-                                    'B1': 0.0, 'B0': 1.0})\n-\n-\n-@fail_on_pvlib_version('0.8')\n-def test__pvsyst_celltemp_translator():\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, 5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, 5, 0.1, 0.9,\n-                                                  [29.0, 0.0])\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(poa_global=900, temp_air=20,\n-                                                  wind_speed=5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  u_c=23.5, u_v=6.25,\n-                                                  eta_m=0.1)\n-    assert_allclose(result, 33.315, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  eta_m=0.1,\n-                                                  model_params=[23.5, 6.25])\n-    assert_allclose(result, 33.315, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  eta_m=0.1,\n-                                                  model_params=(23.5, 6.25))\n-    assert_allclose(result, 33.315, 0.001)\n-\n-\n-@fail_on_pvlib_version('0.8')\n-def test__sapm_celltemp_translator():\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20,\n-                                                'open_rack_glass_glass')\n-    assert_allclose(result, 43.509, 3)\n-    result = pvsystem._sapm_celltemp_translator(900, 5, temp_air=20,\n-                                                model='open_rack_glass_glass')\n-    assert_allclose(result, 43.509, 3)\n-    params = temperature.TEMPERATURE_MODEL_PARAMETERS['sapm'][\n-        'open_rack_glass_glass']\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20, params)\n-    assert_allclose(result, 43.509, 3)\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20,\n-                                                [params['a'], params['b'],\n-                                                 params['deltaT']])\n-    assert_allclose(result, 43.509, 3)\n-\n-\n @fail_on_pvlib_version('0.9')\n def test_deprecated_09(cec_inverter_parameters, adr_inverter_parameters):\n     # deprecated function pvsystem.snlinverter\n@@ -1417,3 +1310,8 @@ def test_deprecated_09(cec_inverter_parameters, adr_inverter_parameters):\n     # deprecated function pvsystem.spvwatts_ac\n     with pytest.warns(pvlibDeprecationWarning):\n         pvsystem.pvwatts_ac(90, 100, 0.95)\n+    # for missing temperature_model_parameters\n+    match = \"Reverting to deprecated default: SAPM cell temperature\"\n+    system = pvsystem.PVSystem()\n+    with pytest.warns(pvlibDeprecationWarning, match=match):\n+        system.sapm_celltemp(1, 2, 3)\ndiff --git a/pvlib/tests/test_tracking.py b/pvlib/tests/test_tracking.py\n--- a/pvlib/tests/test_tracking.py\n+++ b/pvlib/tests/test_tracking.py\n@@ -453,8 +453,8 @@ def test_SingleAxisTracker___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n     assert system.__repr__() == expected\n \n@@ -477,8 +477,8 @@ def test_LocalizedSingleAxisTracker___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\n   latitude: 32\n   longitude: -111\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_infer_temp_model_no_params\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize___repr__\", \"pvlib/tests/test_pvsystem.py::test_LocalizedPVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_deprecated_09\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker___repr__\", \"pvlib/tests/test_tracking.py::test_LocalizedSingleAxisTracker___repr__\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_ModelChain_creation\", \"pvlib/tests/test_modelchain.py::test_with_sapm\", \"pvlib/tests/test_modelchain.py::test_with_pvwatts\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[None-expected0]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[None-expected1]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[flat-expected2]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[south_at_latitude_tilt-expected3]\", \"pvlib/tests/test_modelchain.py::test_run_model_with_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_no_irradiance\", \"pvlib/tests/test_modelchain.py::test_run_model_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_gueymard_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_sapm_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_pvsyst_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_faiman_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[desoto]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[singlediode]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvwatts_dc]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec_native]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model_invalid\", \"pvlib/tests/test_modelchain.py::test_temperature_model_inconsistent\", \"pvlib/tests/test_modelchain.py::test_dc_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia]\", \"pvlib/tests/test_modelchain.py::test_ac_models[adr]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts]\", \"pvlib/tests/test_modelchain.py::test_ac_models_deprecated[snlinverter]\", \"pvlib/tests/test_modelchain.py::test_ac_models_deprecated[adrinverter]\", \"pvlib/tests/test_modelchain.py::test_ac_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_model_not_a_model\", \"pvlib/tests/test_modelchain.py::test_aoi_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_model_no_loss\", \"pvlib/tests/test_modelchain.py::test_aoi_model_user_func\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[ashrae]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[physical]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model_invalid\", \"pvlib/tests/test_modelchain.py::test_spectral_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts\", \"pvlib/tests/test_modelchain.py::test_losses_models_ext_def\", \"pvlib/tests/test_modelchain.py::test_losses_models_no_loss\", \"pvlib/tests/test_modelchain.py::test_invalid_dc_model_params\", \"pvlib/tests/test_modelchain.py::test_invalid_models[dc_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[ac_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[aoi_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[spectral_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[temperature_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[losses_model]\", \"pvlib/tests/test_modelchain.py::test_bad_get_orientation\", \"pvlib/tests/test_modelchain.py::test_deprecated_09[snlinverter]\", \"pvlib/tests/test_modelchain.py::test_deprecated_09[adrinverter]\", \"pvlib/tests/test_modelchain.py::test_basic_chain_required\", \"pvlib/tests/test_modelchain.py::test_basic_chain_alt_az\", \"pvlib/tests/test_modelchain.py::test_basic_chain_strategy\", \"pvlib/tests/test_modelchain.py::test_basic_chain_altitude_pressure\", \"pvlib/tests/test_modelchain.py::test_ModelChain___repr__[south_at_latitude_tilt-south_at_latitude_tilt]\", \"pvlib/tests/test_modelchain.py::test_ModelChain___repr__[None-None]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_clean_run\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[1.5-1.00028714375]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_snlinverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize_with_location\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize_with_latlon\", \"pvlib/tests/test_pvsystem.py::test_LocalizedPVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac_kwargs\", \"pvlib/tests/test_tracking.py::test_solar_noon\", \"pvlib/tests/test_tracking.py::test_scalars\", \"pvlib/tests/test_tracking.py::test_arrays\", \"pvlib/tests/test_tracking.py::test_nans\", \"pvlib/tests/test_tracking.py::test_arrays_multi\", \"pvlib/tests/test_tracking.py::test_azimuth_north_south\", \"pvlib/tests/test_tracking.py::test_max_angle\", \"pvlib/tests/test_tracking.py::test_backtrack\", \"pvlib/tests/test_tracking.py::test_axis_tilt\", \"pvlib/tests/test_tracking.py::test_axis_azimuth\", \"pvlib/tests/test_tracking.py::test_horizon_flat\", \"pvlib/tests/test_tracking.py::test_horizon_tilted\", \"pvlib/tests/test_tracking.py::test_low_sun_angles\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_creation\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_tracking\", \"pvlib/tests/test_tracking.py::test_LocalizedSingleAxisTracker_creation\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_localize\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_localize_location\", \"pvlib/tests/test_tracking.py::test_get_aoi\", \"pvlib/tests/test_tracking.py::test_get_irradiance\"]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-1033_2", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nPVSystem.temperature_model_parameters requirement\nThe `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to \r\n\r\n1. set default values `module_type=None` and `racking_model=None`.\r\n2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L208-L221\r\n\r\n@cwhanse is that correct?\r\n\r\nThe problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L201-L203\r\n\r\nSo I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9. \nremove deprecated functions in 0.8\n`pvsystem`:\r\n* `sapm_celltemp`\r\n* `pvsyst_celltemp`\r\n* `ashraeiam`\r\n* `physicaliam`\r\n* `sapm_aoi_loss`\r\n* `PVSystem.ashraeiam`\r\n* `PVSystem.physicaliam`\r\n* `PVSystem.sapm_aoi_loss`\r\n* inference of `PVSystem.temperature_model_parameters`\r\n\r\n`modelchain.ModelChain`:\r\n* remove `times` from `complete_irradiance`, `prepare_inputs`, `run_model`\r\n* remove `temp_model` kwarg\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of pvlib/atmosphere.py]\n1 \"\"\"\n2 The ``atmosphere`` module contains methods to calculate relative and\n3 absolute airmass and to determine pressure from altitude or vice versa.\n4 \"\"\"\n5 \n6 from warnings import warn\n7 \n8 import numpy as np\n9 import pandas as pd\n10 \n11 \n12 APPARENT_ZENITH_MODELS = ('simple', 'kasten1966', 'kastenyoung1989',\n13                           'gueymard1993', 'pickering2002')\n14 TRUE_ZENITH_MODELS = ('youngirvine1967', 'young1994')\n15 AIRMASS_MODELS = APPARENT_ZENITH_MODELS + TRUE_ZENITH_MODELS\n16 \n17 \n18 def pres2alt(pressure):\n19     '''\n20     Determine altitude from site pressure.\n21 \n22     Parameters\n23     ----------\n24     pressure : numeric\n25         Atmospheric pressure. [Pa]\n26 \n27     Returns\n28     -------\n29     altitude : numeric\n30         Altitude above sea level. [m]\n31 \n32     Notes\n33     ------\n34     The following assumptions are made\n35 \n36     ============================   ================\n37     Parameter                      Value\n38     ============================   ================\n39     Base pressure                  101325 Pa\n40     Temperature at zero altitude   288.15 K\n41     Gravitational acceleration     9.80665 m/s^2\n42     Lapse rate                     -6.5E-3 K/m\n43     Gas constant for air           287.053 J/(kg K)\n44     Relative Humidity              0%\n45     ============================   ================\n46 \n47     References\n48     -----------\n49     .. [1] \"A Quick Derivation relating altitude to air pressure\" from\n50        Portland State Aerospace Society, Version 1.03, 12/22/2004.\n51     '''\n52 \n53     alt = 44331.5 - 4946.62 * pressure ** (0.190263)\n54 \n55     return alt\n56 \n57 \n58 def alt2pres(altitude):\n59     '''\n60     Determine site pressure from altitude.\n61 \n62     Parameters\n63     ----------\n64     altitude : numeric\n65         Altitude above sea level. [m]\n66 \n67     Returns\n68     -------\n69     pressure : numeric\n70         Atmospheric pressure. [Pa]\n71 \n72     Notes\n73     ------\n74     The following assumptions are made\n75 \n76     ============================   ================\n77     Parameter                      Value\n78     ============================   ================\n79     Base pressure                  101325 Pa\n80     Temperature at zero altitude   288.15 K\n81     Gravitational acceleration     9.80665 m/s^2\n82     Lapse rate                     -6.5E-3 K/m\n83     Gas constant for air           287.053 J/(kg K)\n84     Relative Humidity              0%\n85     ============================   ================\n86 \n87     References\n88     -----------\n89     .. [1] \"A Quick Derivation relating altitude to air pressure\" from\n90        Portland State Aerospace Society, Version 1.03, 12/22/2004.\n91     '''\n92 \n93     press = 100 * ((44331.514 - altitude) / 11880.516) ** (1 / 0.1902632)\n94 \n95     return press\n96 \n97 \n98 def get_absolute_airmass(airmass_relative, pressure=101325.):\n99     r'''\n100     Determine absolute (pressure-adjusted) airmass from relative\n101     airmass and pressure.\n102 \n103     The calculation for absolute airmass (:math:`AM_a`) is\n104 \n105     .. math::\n106         AM_a = AM_r \\frac{P}{101325}\n107 \n108     where :math:`AM_r` is relative air mass at sea level and :math:`P` is\n109     atmospheric pressure.\n110 \n111     Parameters\n112     ----------\n113     airmass_relative : numeric\n114         The airmass at sea level. [unitless]\n115 \n116     pressure : numeric, default 101325\n117         Atmospheric pressure. [Pa]\n118 \n119     Returns\n120     -------\n121     airmass_absolute : numeric\n122         Absolute (pressure-adjusted) airmass\n123 \n124     References\n125     ----------\n126     .. [1] C. Gueymard, \"Critical analysis and performance assessment of\n127        clear sky solar irradiance models using theoretical and measured\n128        data,\" Solar Energy, vol. 51, pp. 121-138, 1993.\n129     '''\n130 \n131     airmass_absolute = airmass_relative * pressure / 101325.\n132 \n133     return airmass_absolute\n134 \n135 \n136 def get_relative_airmass(zenith, model='kastenyoung1989'):\n137     '''\n138     Calculate relative (not pressure-adjusted) airmass at sea level.\n139 \n140     Parameter ``model`` allows selection of different airmass models.\n141 \n142     Parameters\n143     ----------\n144     zenith : numeric\n145         Zenith angle of the sun. [degrees]\n146 \n147     model : string, default 'kastenyoung1989'\n148         Available models include the following:\n149 \n150         * 'simple' - secant(apparent zenith angle) -\n151           Note that this gives -Inf at zenith=90\n152         * 'kasten1966' - See reference [1] -\n153           requires apparent sun zenith\n154         * 'youngirvine1967' - See reference [2] -\n155           requires true sun zenith\n156         * 'kastenyoung1989' (default) - See reference [3] -\n157           requires apparent sun zenith\n158         * 'gueymard1993' - See reference [4] -\n159           requires apparent sun zenith\n160         * 'young1994' - See reference [5] -\n161           requries true sun zenith\n162         * 'pickering2002' - See reference [6] -\n163           requires apparent sun zenith\n164 \n165     Returns\n166     -------\n167     airmass_relative : numeric\n168         Relative airmass at sea level. Returns NaN values for any\n169         zenith angle greater than 90 degrees. [unitless]\n170 \n171     Notes\n172     -----\n173     Some models use apparent (refraction-adjusted) zenith angle while\n174     other models use true (not refraction-adjusted) zenith angle. Apparent\n175     zenith angles should be calculated at sea level.\n176 \n177     References\n178     ----------\n179     .. [1] Fritz Kasten. \"A New Table and Approximation Formula for the\n180        Relative Optical Air Mass\". Technical Report 136, Hanover, N.H.:\n181        U.S. Army Material Command, CRREL.\n182 \n183     .. [2] A. T. Young and W. M. Irvine, \"Multicolor Photoelectric\n184        Photometry of the Brighter Planets,\" The Astronomical Journal, vol.\n185        72, pp. 945-950, 1967.\n186 \n187     .. [3] Fritz Kasten and Andrew Young. \"Revised optical air mass tables\n188        and approximation formula\". Applied Optics 28:4735-4738\n189 \n190     .. [4] C. Gueymard, \"Critical analysis and performance assessment of\n191        clear sky solar irradiance models using theoretical and measured\n192        data,\" Solar Energy, vol. 51, pp. 121-138, 1993.\n193 \n194     .. [5] A. T. Young, \"AIR-MASS AND REFRACTION,\" Applied Optics, vol. 33,\n195        pp. 1108-1110, Feb 1994.\n196 \n197     .. [6] Keith A. Pickering. \"The Ancient Star Catalog\". DIO 12:1, 20,\n198 \n199     .. [7] Matthew J. Reno, Clifford W. Hansen and Joshua S. Stein, \"Global\n200        Horizontal Irradiance Clear Sky Models: Implementation and Analysis\"\n201        Sandia Report, (2012).\n202     '''\n203 \n204     # set zenith values greater than 90 to nans\n205     z = np.where(zenith > 90, np.nan, zenith)\n206     zenith_rad = np.radians(z)\n207 \n208     model = model.lower()\n209 \n210     if 'kastenyoung1989' == model:\n211         am = (1.0 / (np.cos(zenith_rad) +\n212               0.50572*(((6.07995 + (90 - z)) ** - 1.6364))))\n213     elif 'kasten1966' == model:\n214         am = 1.0 / (np.cos(zenith_rad) + 0.15*((93.885 - z) ** - 1.253))\n215     elif 'simple' == model:\n216         am = 1.0 / np.cos(zenith_rad)\n217     elif 'pickering2002' == model:\n218         am = (1.0 / (np.sin(np.radians(90 - z +\n219               244.0 / (165 + 47.0 * (90 - z) ** 1.1)))))\n220     elif 'youngirvine1967' == model:\n221         sec_zen = 1.0 / np.cos(zenith_rad)\n222         am = sec_zen * (1 - 0.0012 * (sec_zen * sec_zen - 1))\n223     elif 'young1994' == model:\n224         am = ((1.002432*((np.cos(zenith_rad)) ** 2) +\n225               0.148386*(np.cos(zenith_rad)) + 0.0096467) /\n226               (np.cos(zenith_rad) ** 3 +\n227               0.149864*(np.cos(zenith_rad) ** 2) +\n228               0.0102963*(np.cos(zenith_rad)) + 0.000303978))\n229     elif 'gueymard1993' == model:\n230         am = (1.0 / (np.cos(zenith_rad) +\n231               0.00176759*(z)*((94.37515 - z) ** - 1.21563)))\n232     else:\n233         raise ValueError('%s is not a valid model for relativeairmass', model)\n234 \n235     if isinstance(zenith, pd.Series):\n236         am = pd.Series(am, index=zenith.index)\n237 \n238     return am\n239 \n240 \n241 def gueymard94_pw(temp_air, relative_humidity):\n242     r\"\"\"\n243     Calculates precipitable water (cm) from ambient air temperature (C)\n244     and relatively humidity (%) using an empirical model. The\n245     accuracy of this method is approximately 20% for moderate PW (1-3\n246     cm) and less accurate otherwise.\n247 \n248     The model was developed by expanding Eq. 1 in [2]_:\n249 \n250     .. math::\n251 \n252            Pw = 0.1 H_v \\rho_v\n253 \n254     using Eq. 2 in [2]_\n255 \n256     .. math::\n257 \n258            \\rho_v = 216.7 R_H e_s /T\n259 \n260     :math:`Pw` is the precipitable water (cm), :math:`H_v` is the apparent\n261     water vapor scale height (km) and :math:`\\rho_v` is the surface water\n262     vapor density (g/m^3). . The expression for :math:`H_v` is Eq. 4 in [2]_:\n263 \n264     .. math::\n265 \n266            H_v = 0.4976 + 1.5265 \\frac{T}{273.15}\n267                + \\exp \\left(13.6897 \\frac{T}{273.15}\n268                - 14.9188 \\left( \\frac{T}{273.15} \\right)^3 \\right)\n269 \n270     In the expression for :math:`\\rho_v`, :math:`e_s` is the saturation water\n271     vapor pressure (millibar). The expression for :math:`e_s` is Eq. 1 in [3]_\n272 \n273     .. math::\n274 \n275           e_s = \\exp \\left(22.330 - 49.140 \\frac{100}{T} -\n276               10.922 \\left(\\frac{100}{T}\\right)^2 -\n277               0.39015 \\frac{T}{100} \\right)\n278 \n279     Parameters\n280     ----------\n281     temp_air : numeric\n282         ambient air temperature :math:`T` at the surface. [C]\n283     relative_humidity : numeric\n284         relative humidity :math:`R_H` at the surface. [%]\n285 \n286     Returns\n287     -------\n288     pw : numeric\n289         precipitable water. [cm]\n290 \n291     References\n292     ----------\n293     .. [1] W. M. Keogh and A. W. Blakers, Accurate Measurement, Using Natural\n294        Sunlight, of Silicon Solar Cells, Prog. in Photovoltaics: Res.\n295        and Appl. 2004, vol 12, pp. 1-19 (:doi:`10.1002/pip.517`)\n296 \n297     .. [2] C. Gueymard, Analysis of Monthly Average Atmospheric Precipitable\n298        Water and Turbidity in Canada and Northern United States,\n299        Solar Energy vol 53(1), pp. 57-71, 1994.\n300 \n301     .. [3] C. Gueymard, Assessment of the Accuracy and Computing Speed of\n302        simplified saturation vapor equations using a new reference\n303        dataset, J. of Applied Meteorology 1993, vol. 32(7), pp.\n304        1294-1300.\n305     \"\"\"\n306 \n307     T = temp_air + 273.15  # Convert to Kelvin                  # noqa: N806\n308     RH = relative_humidity                                      # noqa: N806\n309 \n310     theta = T / 273.15\n311 \n312     # Eq. 1 from Keogh and Blakers\n313     pw = (\n314         0.1 *\n315         (0.4976 + 1.5265*theta + np.exp(13.6897*theta - 14.9188*(theta)**3)) *\n316         (216.7*RH/(100*T)*np.exp(22.330 - 49.140*(100/T) -\n317          10.922*(100/T)**2 - 0.39015*T/100)))\n318 \n319     pw = np.maximum(pw, 0.1)\n320 \n321     return pw\n322 \n323 \n324 def first_solar_spectral_correction(pw, airmass_absolute,\n325                                     module_type=None, coefficients=None,\n326                                     min_pw=0.1, max_pw=8):\n327     r\"\"\"\n328     Spectral mismatch modifier based on precipitable water and absolute\n329     (pressure-adjusted) airmass.\n330 \n331     Estimates a spectral mismatch modifier :math:`M` representing the effect on\n332     module short circuit current of variation in the spectral\n333     irradiance. :math:`M`  is estimated from absolute (pressure currected) air\n334     mass, :math:`AM_a`, and precipitable water, :math:`Pw`, using the following\n335     function:\n336 \n337     .. math::\n338 \n339         M = c_1 + c_2 AM_a  + c_3 Pw  + c_4 AM_a^{0.5}\n340             + c_5 Pw^{0.5} + c_6 \\frac{AM_a} {Pw^{0.5}}\n341 \n342     Default coefficients are determined for several cell types with\n343     known quantum efficiency curves, by using the Simple Model of the\n344     Atmospheric Radiative Transfer of Sunshine (SMARTS) [1]_. Using\n345     SMARTS, spectrums are simulated with all combinations of AMa and\n346     Pw where:\n347 \n348        * :math:`0.5 \\textrm{cm} <= Pw <= 5 \\textrm{cm}`\n349        * :math:`1.0 <= AM_a <= 5.0`\n350        * Spectral range is limited to that of CMP11 (280 nm to 2800 nm)\n351        * spectrum simulated on a plane normal to the sun\n352        * All other parameters fixed at G173 standard\n353 \n354     From these simulated spectra, M is calculated using the known\n355     quantum efficiency curves. Multiple linear regression is then\n356     applied to fit Eq. 1 to determine the coefficients for each module.\n357 \n358     Based on the PVLIB Matlab function ``pvl_FSspeccorr`` by Mitchell\n359     Lee and Alex Panchula of First Solar, 2016 [2]_.\n360 \n361     Parameters\n362     ----------\n363     pw : array-like\n364         atmospheric precipitable water. [cm]\n365 \n366     airmass_absolute : array-like\n367         absolute (pressure-adjusted) airmass. [unitless]\n368 \n369     min_pw : float, default 0.1\n370         minimum atmospheric precipitable water. Any pw value lower than min_pw\n371         is set to min_pw to avoid model divergence. [cm]\n372 \n373     max_pw : float, default 8\n374         maximum atmospheric precipitable water. Any pw value higher than max_pw\n375         is set to NaN to avoid model divergence. [cm]\n376 \n377     module_type : None or string, default None\n378         a string specifying a cell type. Values of 'cdte', 'monosi', 'xsi',\n379         'multisi', and 'polysi' (can be lower or upper case). If provided,\n380         module_type selects default coefficients for the following modules:\n381 \n382             * 'cdte' - First Solar Series 4-2 CdTe module.\n383             * 'monosi', 'xsi' - First Solar TetraSun module.\n384             * 'multisi', 'polysi' - anonymous multi-crystalline silicon module.\n385             * 'cigs' - anonymous copper indium gallium selenide module.\n386             * 'asi' - anonymous amorphous silicon module.\n387 \n388         The module used to calculate the spectral correction\n389         coefficients corresponds to the Multi-crystalline silicon\n390         Manufacturer 2 Model C from [3]_. The spectral response (SR) of CIGS\n391         and a-Si modules used to derive coefficients can be found in [4]_\n392 \n393     coefficients : None or array-like, default None\n394         Allows for entry of user-defined spectral correction\n395         coefficients. Coefficients must be of length 6. Derivation of\n396         coefficients requires use of SMARTS and PV module quantum\n397         efficiency curve. Useful for modeling PV module types which are\n398         not included as defaults, or to fine tune the spectral\n399         correction to a particular PV module. Note that the parameters for\n400         modules with very similar quantum efficiency should be similar,\n401         in most cases limiting the need for module specific coefficients.\n402 \n403     Returns\n404     -------\n405     modifier: array-like\n406         spectral mismatch factor (unitless) which is can be multiplied\n407         with broadband irradiance reaching a module's cells to estimate\n408         effective irradiance, i.e., the irradiance that is converted to\n409         electrical current.\n410 \n411     References\n412     ----------\n413     .. [1] Gueymard, Christian. SMARTS2: a simple model of the atmospheric\n414        radiative transfer of sunshine: algorithms and performance\n415        assessment. Cocoa, FL: Florida Solar Energy Center, 1995.\n416     .. [2] Lee, Mitchell, and Panchula, Alex. \"Spectral Correction for\n417        Photovoltaic Module Performance Based on Air Mass and Precipitable\n418        Water.\" IEEE Photovoltaic Specialists Conference, Portland, 2016\n419     .. [3] Marion, William F., et al. User's Manual for Data for Validating\n420        Models for PV Module Performance. National Renewable Energy\n421        Laboratory, 2014. http://www.nrel.gov/docs/fy14osti/61610.pdf\n422     .. [4] Schweiger, M. and Hermann, W, Influence of Spectral Effects\n423        on Energy Yield of Different PV Modules: Comparison of Pwat and\n424        MMF Approach, TUV Rheinland Energy GmbH report 21237296.003,\n425        January 2017\n426     \"\"\"\n427 \n428     # --- Screen Input Data ---\n429 \n430     # *** Pw ***\n431     # Replace Pw Values below 0.1 cm with 0.1 cm to prevent model from\n432     # diverging\"\n433     pw = np.atleast_1d(pw)\n434     pw = pw.astype('float64')\n435     if np.min(pw) < min_pw:\n436         pw = np.maximum(pw, min_pw)\n437         warn('Exceptionally low pw values replaced with {0} cm to prevent '\n438              'model divergence'.format(min_pw))\n439 \n440     # Warn user about Pw data that is exceptionally high\n441     if np.max(pw) > max_pw:\n442         pw[pw > max_pw] = np.nan\n443         warn('Exceptionally high pw values replaced by np.nan: '\n444              'check input data.')\n445 \n446     # *** AMa ***\n447     # Replace Extremely High AM with AM 10 to prevent model divergence\n448     # AM > 10 will only occur very close to sunset\n449     if np.max(airmass_absolute) > 10:\n450         airmass_absolute = np.minimum(airmass_absolute, 10)\n451 \n452     # Warn user about AMa data that is exceptionally low\n453     if np.min(airmass_absolute) < 0.58:\n454         warn('Exceptionally low air mass: ' +\n455              'model not intended for extra-terrestrial use')\n456         # pvl_absoluteairmass(1,pvl_alt2pres(4340)) = 0.58 Elevation of\n457         # Mina Pirquita, Argentian = 4340 m. Highest elevation city with\n458         # population over 50,000.\n459 \n460     _coefficients = {}\n461     _coefficients['cdte'] = (\n462         0.86273, -0.038948, -0.012506, 0.098871, 0.084658, -0.0042948)\n463     _coefficients['monosi'] = (\n464         0.85914, -0.020880, -0.0058853, 0.12029, 0.026814, -0.0017810)\n465     _coefficients['xsi'] = _coefficients['monosi']\n466     _coefficients['polysi'] = (\n467         0.84090, -0.027539, -0.0079224, 0.13570, 0.038024, -0.0021218)\n468     _coefficients['multisi'] = _coefficients['polysi']\n469     _coefficients['cigs'] = (\n470         0.85252, -0.022314, -0.0047216, 0.13666, 0.013342, -0.0008945)\n471     _coefficients['asi'] = (\n472         1.12094, -0.047620, -0.0083627, -0.10443, 0.098382, -0.0033818)\n473 \n474     if module_type is not None and coefficients is None:\n475         coefficients = _coefficients[module_type.lower()]\n476     elif module_type is None and coefficients is not None:\n477         pass\n478     elif module_type is None and coefficients is None:\n479         raise TypeError('No valid input provided, both module_type and ' +\n480                         'coefficients are None')\n481     else:\n482         raise TypeError('Cannot resolve input, must supply only one of ' +\n483                         'module_type and coefficients')\n484 \n485     # Evaluate Spectral Shift\n486     coeff = coefficients\n487     ama = airmass_absolute\n488     modifier = (\n489         coeff[0] + coeff[1]*ama + coeff[2]*pw + coeff[3]*np.sqrt(ama) +\n490         coeff[4]*np.sqrt(pw) + coeff[5]*ama/np.sqrt(pw))\n491 \n492     return modifier\n493 \n494 \n495 def bird_hulstrom80_aod_bb(aod380, aod500):\n496     \"\"\"\n497     Approximate broadband aerosol optical depth.\n498 \n499     Bird and Hulstrom developed a correlation for broadband aerosol optical\n500     depth (AOD) using two wavelengths, 380 nm and 500 nm.\n501 \n502     Parameters\n503     ----------\n504     aod380 : numeric\n505         AOD measured at 380 nm. [unitless]\n506     aod500 : numeric\n507         AOD measured at 500 nm. [unitless]\n508 \n509     Returns\n510     -------\n511     aod_bb : numeric\n512         Broadband AOD.  [unitless]\n513 \n514     See also\n515     --------\n516     pvlib.atmosphere.kasten96_lt\n517 \n518     References\n519     ----------\n520     .. [1] Bird and Hulstrom, \"Direct Insolation Models\" (1980)\n521        `SERI/TR-335-344 <http://www.nrel.gov/docs/legosti/old/344.pdf>`_\n522 \n523     .. [2] R. E. Bird and R. L. Hulstrom, \"Review, Evaluation, and Improvement\n524        of Direct Irradiance Models\", Journal of Solar Energy Engineering\n525        103(3), pp. 182-192 (1981)\n526        :doi:`10.1115/1.3266239`\n527     \"\"\"\n528     # approximate broadband AOD using (Bird-Hulstrom 1980)\n529     return 0.27583 * aod380 + 0.35 * aod500\n530 \n531 \n532 def kasten96_lt(airmass_absolute, precipitable_water, aod_bb):\n533     \"\"\"\n534     Calculate Linke turbidity  using Kasten pyrheliometric formula.\n535 \n536     Note that broadband aerosol optical depth (AOD) can be approximated by AOD\n537     measured at 700 nm according to Molineaux [4] . Bird and Hulstrom offer an\n538     alternate approximation using AOD measured at 380 nm and 500 nm.\n539 \n540     Based on original implementation by Armel Oumbe.\n541 \n542     .. warning::\n543         These calculations are only valid for airmass less than 5 and\n544         precipitable water less than 5 cm.\n545 \n546     Parameters\n547     ----------\n548     airmass_absolute : numeric\n549         Pressure-adjusted airmass. [unitless]\n550     precipitable_water : numeric\n551         Precipitable water. [cm]\n552     aod_bb : numeric\n553         broadband AOD. [unitless]\n554 \n555     Returns\n556     -------\n557     lt : numeric\n558         Linke turbidity. [unitless]\n559 \n560     See also\n561     --------\n562     pvlib.atmosphere.bird_hulstrom80_aod_bb\n563     pvlib.atmosphere.angstrom_aod_at_lambda\n564 \n565     References\n566     ----------\n567     .. [1] F. Linke, \"Transmissions-Koeffizient und Trubungsfaktor\", Beitrage\n568        zur Physik der Atmosphare, Vol 10, pp. 91-103 (1922)\n569 \n570     .. [2] F. Kasten, \"A simple parameterization of the pyrheliometric formula\n571        for determining the Linke turbidity factor\", Meteorologische Rundschau\n572        33, pp. 124-127 (1980)\n573 \n574     .. [3] Kasten, \"The Linke turbidity factor based on improved values of the\n575        integral Rayleigh optical thickness\", Solar Energy, Vol. 56, No. 3,\n576        pp. 239-244 (1996)\n577        :doi:`10.1016/0038-092X(95)00114-7`\n578 \n579     .. [4] B. Molineaux, P. Ineichen, N. O'Neill, \"Equivalence of\n580        pyrheliometric and monochromatic aerosol optical depths at a single key\n581        wavelength\", Applied Optics Vol. 37, issue 10, 7008-7018 (1998)\n582        :doi:`10.1364/AO.37.007008`\n583 \n584     .. [5] P. Ineichen, \"Conversion function between the Linke turbidity and\n585        the atmospheric water vapor and aerosol content\", Solar Energy 82,\n586        pp. 1095-1097 (2008)\n587        :doi:`10.1016/j.solener.2008.04.010`\n588 \n589     .. [6] P. Ineichen and R. Perez, \"A new airmass independent formulation for\n590        the Linke Turbidity coefficient\", Solar Energy, Vol. 73, no. 3,\n591        pp. 151-157 (2002)\n592        :doi:`10.1016/S0038-092X(02)00045-2`\n593     \"\"\"\n594     # \"From numerically integrated spectral simulations done with Modtran\n595     # (Berk, 1989), Molineaux (1998) obtained for the broadband optical depth\n596     # of a clean and dry atmospshere (fictitious atmosphere that comprises only\n597     # the effects of Rayleigh scattering and absorption by the atmosphere gases\n598     # other than the water vapor) the following expression\"\n599     # - P. Ineichen (2008)\n600     delta_cda = -0.101 + 0.235 * airmass_absolute ** (-0.16)\n601     # \"and the broadband water vapor optical depth where pwat is the integrated\n602     # precipitable water vapor content of the atmosphere expressed in cm and am\n603     # the optical air mass. The precision of these fits is better than 1% when\n604     # compared with Modtran simulations in the range 1 < am < 5 and\n605     # 0 < pwat < 5 cm at sea level\" - P. Ineichen (2008)\n606     delta_w = 0.112 * airmass_absolute ** (-0.55) * precipitable_water ** 0.34\n607     # broadband AOD\n608     delta_a = aod_bb\n609     # \"Then using the Kasten pyrheliometric formula (1980, 1996), the Linke\n610     # turbidity at am = 2 can be written. The extension of the Linke turbidity\n611     # coefficient to other values of air mass was published by Ineichen and\n612     # Perez (2002)\" - P. Ineichen (2008)\n613     lt = -(9.4 + 0.9 * airmass_absolute) * np.log(\n614         np.exp(-airmass_absolute * (delta_cda + delta_w + delta_a))\n615     ) / airmass_absolute\n616     # filter out of extrapolated values\n617     return lt\n618 \n619 \n620 def angstrom_aod_at_lambda(aod0, lambda0, alpha=1.14, lambda1=700.0):\n621     r\"\"\"\n622     Get AOD at specified wavelength using Angstrom turbidity model.\n623 \n624     Parameters\n625     ----------\n626     aod0 : numeric\n627         Aerosol optical depth (AOD) measured at wavelength ``lambda0``.\n628         [unitless]\n629     lambda0 : numeric\n630         Wavelength corresponding to ``aod0``. [nm]\n631     alpha : numeric, default 1.14\n632         Angstrom :math:`\\alpha` exponent corresponding to ``aod0``. [unitless]\n633     lambda1 : numeric, default 700\n634         Desired wavelength. [nm]\n635 \n636     Returns\n637     -------\n638     aod1 : numeric\n639         AOD at desired wavelength ``lambda1``. [unitless]\n640 \n641     See also\n642     --------\n643     pvlib.atmosphere.angstrom_alpha\n644 \n645     References\n646     ----------\n647     .. [1] Anders Angstrom, \"On the Atmospheric Transmission of Sun Radiation\n648        and On Dust in the Air\", Geografiska Annaler Vol. 11, pp. 156-166 (1929)\n649        JSTOR\n650        :doi:`10.2307/519399`\n651 \n652     .. [2] Anders Angstrom, \"Techniques of Determining the Turbidity of the\n653        Atmosphere\", Tellus 13:2, pp. 214-223 (1961) Taylor & Francis\n654        :doi:`10.3402/tellusa.v13i2.9493` and Co-Action Publishing\n655        :doi:`10.1111/j.2153-3490.1961.tb00078.x`\n656     \"\"\"\n657     return aod0 * ((lambda1 / lambda0) ** (-alpha))\n658 \n659 \n660 def angstrom_alpha(aod1, lambda1, aod2, lambda2):\n661     r\"\"\"\n662     Calculate Angstrom alpha exponent.\n663 \n664     Parameters\n665     ----------\n666     aod1 : numeric\n667         Aerosol optical depth at wavelength ``lambda1``. [unitless]\n668     lambda1 : numeric\n669         Wavelength corresponding to ``aod1``. [nm]\n670     aod2 : numeric\n671         Aerosol optical depth  at wavelength ``lambda2``. [unitless]\n672     lambda2 : numeric\n673         Wavelength corresponding to ``aod2``. [nm]\n674 \n675     Returns\n676     -------\n677     alpha : numeric\n678         Angstrom :math:`\\alpha` exponent for wavelength in\n679         ``(lambda1, lambda2)``. [unitless]\n680 \n681     See also\n682     --------\n683     pvlib.atmosphere.angstrom_aod_at_lambda\n684     \"\"\"\n685     return - np.log(aod1 / aod2) / np.log(lambda1 / lambda2)\n686 \n[end of pvlib/atmosphere.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "a7edb8b582174ed45f2d3859f29261908f5e0ab5", "problem_statement": "PVSystem.temperature_model_parameters requirement\nThe `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to \r\n\r\n1. set default values `module_type=None` and `racking_model=None`.\r\n2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L208-L221\r\n\r\n@cwhanse is that correct?\r\n\r\nThe problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L201-L203\r\n\r\nSo I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9. \nremove deprecated functions in 0.8\n`pvsystem`:\r\n* `sapm_celltemp`\r\n* `pvsyst_celltemp`\r\n* `ashraeiam`\r\n* `physicaliam`\r\n* `sapm_aoi_loss`\r\n* `PVSystem.ashraeiam`\r\n* `PVSystem.physicaliam`\r\n* `PVSystem.sapm_aoi_loss`\r\n* inference of `PVSystem.temperature_model_parameters`\r\n\r\n`modelchain.ModelChain`:\r\n* remove `times` from `complete_irradiance`, `prepare_inputs`, `run_model`\r\n* remove `temp_model` kwarg\n", "hints_text": "> The `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to\r\n> \r\n> 1. set default values `module_type=None` and `racking_model=None`.\r\n> 2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n> \r\n> @cwhanse is that correct?\r\n\r\nYes, that is the intent.\r\n\r\n> So I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9.\r\n\r\nThe warning should have been raised whenever condition #2 above wasn't met; it looks to me that has been the case. If that hasn't been the case I would prefer to fix the warning and push the deprecation out to v0.9. pvlib-python has had that unadvertised default temperature model assignment for a long time.\r\n\n> The problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nI don't follow here - it looks to me that the warning should be raised if 1) `temperature_model_parameters` isn't specified, or 2) either `module_type` or `racking_model` are invalid. Maybe we're saying the same thing. `_infer_temperature_model` doesn't assign the default temperature model, that is done in the block of code that raises the warning. \r\n\r\n\nThe `module_type` and `racking_model` defaults prevent the warning from showing up in many use cases. If we change the defaults to `None` then the warning will be triggered. If we simultaneously remove the warning then code will break without users having ever seen the warning.\nWhat is the expected behavior for `PVSystem()`?\n> The `module_type` and `racking_model` defaults prevent the warning from showing up in many use cases. If we change the defaults to `None` then the warning will be triggered. If we simultaneously remove the warning then code will break without users having ever seen the warning.\r\n\r\nAha. I see the problem now, thanks.  Perhaps remove the defaults in v0.8 and leave the warning until v0.9?\nOk, I'll work on that.\n", "created_at": "2020-08-25T18:51:23Z", "patch": "<patch>\ndiff --git a/pvlib/modelchain.py b/pvlib/modelchain.py\n--- a/pvlib/modelchain.py\n+++ b/pvlib/modelchain.py\n@@ -179,7 +179,7 @@ def basic_chain(times, latitude, longitude,\n             linke_turbidity,\n             altitude=altitude,\n             dni_extra=dni_extra\n-            )\n+        )\n \n     total_irrad = pvlib.irradiance.get_total_irradiance(\n         surface_tilt,\n@@ -346,24 +346,6 @@ def __init__(self, system, location,\n         self.ac_model = ac_model\n         self.aoi_model = aoi_model\n         self.spectral_model = spectral_model\n-\n-        # TODO: deprecated kwarg temp_model. Remove use of temp_model in v0.8\n-        temp_model = kwargs.pop('temp_model', None)\n-        if temp_model is not None:\n-            if temperature_model is None:\n-                warnings.warn('The temp_model keyword argument is deprecated.'\n-                              ' Use temperature_model instead',\n-                              pvlibDeprecationWarning)\n-                temperature_model = temp_model\n-            elif temp_model == temperature_model:\n-                warnings.warn('Provide only one of temperature_model or '\n-                              'temp_model (deprecated).',\n-                              pvlibDeprecationWarning)\n-            else:\n-                raise ValueError(\n-                    'Conflicting temperature_model {} and temp_model {}. '\n-                    'temp_model is deprecated. Specify only temperature_model.'\n-                    .format(temperature_model, temp_model))\n         self.temperature_model = temperature_model\n \n         self.losses_model = losses_model\n@@ -544,7 +526,7 @@ def __repr__(self):\n             'transposition_model', 'solar_position_method',\n             'airmass_model', 'dc_model', 'ac_model', 'aoi_model',\n             'spectral_model', 'temperature_model', 'losses_model'\n-            ]\n+        ]\n \n         def getmcattr(self, attr):\n             \"\"\"needed to avoid recursion in property lookups\"\"\"\n@@ -588,8 +570,8 @@ def dc_model(self, model):\n             model = model.lower()\n             if model in _DC_MODEL_PARAMS.keys():\n                 # validate module parameters\n-                missing_params = _DC_MODEL_PARAMS[model] - \\\n-                                 set(self.system.module_parameters.keys())\n+                missing_params = (_DC_MODEL_PARAMS[model]\n+                                  - set(self.system.module_parameters.keys()))\n                 if missing_params:  # some parameters are not in module.keys()\n                     raise ValueError(model + ' selected for the DC model but '\n                                      'one or more required parameters are '\n@@ -834,8 +816,8 @@ def infer_spectral_model(self):\n \n     def first_solar_spectral_loss(self):\n         self.spectral_modifier = self.system.first_solar_spectral_loss(\n-                                        self.weather['precipitable_water'],\n-                                        self.airmass['airmass_absolute'])\n+            self.weather['precipitable_water'],\n+            self.airmass['airmass_absolute'])\n         return self\n \n     def sapm_spectral_loss(self):\n@@ -878,7 +860,10 @@ def temperature_model(self, model):\n \n     def infer_temperature_model(self):\n         params = set(self.system.temperature_model_parameters.keys())\n-        if set(['a', 'b', 'deltaT']) <= params:\n+        # remove or statement in v0.9\n+        if set(['a', 'b', 'deltaT']) <= params or (\n+                not params and self.system.racking_model is None\n+                and self.system.module_type is None):\n             return self.sapm_temp\n         elif set(['u_c', 'u_v']) <= params:\n             return self.pvsyst_temp\n@@ -945,7 +930,7 @@ def effective_irradiance_model(self):\n             fd*self.total_irrad['poa_diffuse'])\n         return self\n \n-    def complete_irradiance(self, weather, times=None):\n+    def complete_irradiance(self, weather):\n         \"\"\"\n         Determine the missing irradiation columns. Only two of the\n         following data columns (dni, ghi, dhi) are needed to calculate\n@@ -962,10 +947,6 @@ def complete_irradiance(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Returns\n         -------\n@@ -994,11 +975,6 @@ def complete_irradiance(self, weather, times=None):\n         \"\"\"\n         self.weather = weather\n \n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.solar_position = self.location.get_solarposition(\n             self.weather.index, method=self.solar_position_method)\n \n@@ -1029,7 +1005,7 @@ def complete_irradiance(self, weather, times=None):\n \n         return self\n \n-    def prepare_inputs(self, weather, times=None):\n+    def prepare_inputs(self, weather):\n         \"\"\"\n         Prepare the solar position, irradiance, and weather inputs to\n         the model.\n@@ -1041,10 +1017,6 @@ def prepare_inputs(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Notes\n         -----\n@@ -1064,11 +1036,6 @@ def prepare_inputs(self, weather, times=None):\n \n         self.weather = weather\n \n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.times = self.weather.index\n         try:\n             kwargs = _build_kwargs(['pressure', 'temp_air'], weather)\n@@ -1126,7 +1093,7 @@ def prepare_inputs(self, weather, times=None):\n             self.weather['temp_air'] = 20\n         return self\n \n-    def run_model(self, weather, times=None):\n+    def run_model(self, weather):\n         \"\"\"\n         Run the model.\n \n@@ -1137,10 +1104,6 @@ def run_model(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Returns\n         -------\n@@ -1152,11 +1115,6 @@ def run_model(self, weather, times=None):\n         ``dc``, ``ac``, ``losses``,\n         ``diode_params`` (if dc_model is a single diode model)\n         \"\"\"\n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.prepare_inputs(weather)\n         self.aoi_model()\n         self.spectral_model()\ndiff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -170,12 +170,12 @@ class PVSystem(object):\n     def __init__(self,\n                  surface_tilt=0, surface_azimuth=180,\n                  albedo=None, surface_type=None,\n-                 module=None, module_type='glass_polymer',\n+                 module=None, module_type=None,\n                  module_parameters=None,\n                  temperature_model_parameters=None,\n                  modules_per_string=1, strings_per_inverter=1,\n                  inverter=None, inverter_parameters=None,\n-                 racking_model='open_rack', losses_parameters=None, name=None,\n+                 racking_model=None, losses_parameters=None, name=None,\n                  **kwargs):\n \n         self.surface_tilt = surface_tilt\n@@ -201,25 +201,9 @@ def __init__(self,\n         if temperature_model_parameters is None:\n             self.temperature_model_parameters = \\\n                 self._infer_temperature_model_params()\n-            # TODO: in v0.8 check if an empty dict is returned and raise error\n         else:\n             self.temperature_model_parameters = temperature_model_parameters\n \n-        # TODO: deprecated behavior if PVSystem.temperature_model_parameters\n-        # are not specified. Remove in v0.8\n-        if not any(self.temperature_model_parameters):\n-            warnings.warn(\n-                'Required temperature_model_parameters is not specified '\n-                'and parameters are not inferred from racking_model and '\n-                'module_type. Reverting to deprecated default: SAPM cell '\n-                'temperature model parameters for a glass/glass module in '\n-                'open racking. In the future '\n-                'PVSystem.temperature_model_parameters will be required',\n-                pvlibDeprecationWarning)\n-            params = temperature._temperature_model_params(\n-                'sapm', 'open_rack_glass_glass')\n-            self.temperature_model_parameters = params\n-\n         self.modules_per_string = modules_per_string\n         self.strings_per_inverter = strings_per_inverter\n \n@@ -358,26 +342,6 @@ def get_iam(self, aoi, iam_model='physical'):\n         else:\n             raise ValueError(model + ' is not a valid IAM model')\n \n-    def ashraeiam(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.ashraeiam is deprecated and will be removed in'\n-                      'v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='ashrae')\n-\n-    def physicaliam(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.physicaliam is deprecated and will be removed'\n-                      ' in v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='physical')\n-\n     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_desoto` function, the input\n@@ -506,6 +470,21 @@ def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n         -------\n         numeric, values in degrees C.\n         \"\"\"\n+        # warn user about change in default behavior in 0.9.\n+        if (self.temperature_model_parameters == {} and self.module_type\n+                is None and self.racking_model is None):\n+            warnings.warn(\n+                'temperature_model_parameters, racking_model, and module_type '\n+                'are not specified. Reverting to deprecated default: SAPM '\n+                'cell temperature model parameters for a glass/glass module '\n+                'in open racking. In v0.9, temperature_model_parameters or a '\n+                'valid combination of racking_model and module_type will be '\n+                'required.',\n+                pvlibDeprecationWarning)\n+            params = temperature._temperature_model_params(\n+                'sapm', 'open_rack_glass_glass')\n+            self.temperature_model_parameters = params\n+\n         kwargs = _build_kwargs(['a', 'b', 'deltaT'],\n                                self.temperature_model_parameters)\n         return temperature.sapm_cell(poa_global, temp_air, wind_speed,\n@@ -514,7 +493,7 @@ def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n     def _infer_temperature_model_params(self):\n         # try to infer temperature model parameters from from racking_model\n         # and module_type\n-        param_set = self.racking_model + '_' + self.module_type\n+        param_set = '{}_{}'.format(self.racking_model, self.module_type)\n         if param_set in temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']:\n             return temperature._temperature_model_params('sapm', param_set)\n         elif 'freestanding' in param_set:\n@@ -543,16 +522,6 @@ def sapm_spectral_loss(self, airmass_absolute):\n         \"\"\"\n         return sapm_spectral_loss(airmass_absolute, self.module_parameters)\n \n-    def sapm_aoi_loss(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.sapm_aoi_loss is deprecated and will be'\n-                      ' removed in v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='sapm')\n-\n     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n                                   airmass_absolute, aoi,\n                                   reference_irradiance=1000):\n@@ -671,7 +640,7 @@ def first_solar_spectral_loss(self, pw, airmass_absolute):\n         if 'first_solar_spectral_coefficients' in \\\n                 self.module_parameters.keys():\n             coefficients = \\\n-                   self.module_parameters['first_solar_spectral_coefficients']\n+                self.module_parameters['first_solar_spectral_coefficients']\n             module_type = None\n         else:\n             module_type = self._infer_cell_type()\n@@ -1071,27 +1040,6 @@ def calcparams_desoto(effective_irradiance, temp_cell,\n          Source: [4]\n     '''\n \n-    # test for use of function pre-v0.6.0 API change\n-    if isinstance(a_ref, dict) or \\\n-       (isinstance(a_ref, pd.Series) and ('a_ref' in a_ref.keys())):\n-        import warnings\n-        warnings.warn('module_parameters detected as fourth positional'\n-                      + ' argument of calcparams_desoto. calcparams_desoto'\n-                      + ' will require one argument for each module model'\n-                      + ' parameter in v0.7.0 and later', DeprecationWarning)\n-        try:\n-            module_parameters = a_ref\n-            a_ref = module_parameters['a_ref']\n-            I_L_ref = module_parameters['I_L_ref']\n-            I_o_ref = module_parameters['I_o_ref']\n-            R_sh_ref = module_parameters['R_sh_ref']\n-            R_s = module_parameters['R_s']\n-        except Exception as e:\n-            raise e('Module parameters could not be extracted from fourth'\n-                    + ' positional argument of calcparams_desoto. Check that'\n-                    + ' parameters are from the CEC database and/or update'\n-                    + ' your code for the new API for calcparams_desoto')\n-\n     # Boltzmann constant in eV/K\n     k = 8.617332478e-05\n \n@@ -1624,16 +1572,6 @@ def sapm(effective_irradiance, temp_cell, module):\n     # reference_irradiance and expose\n     temp_ref = 25\n     irrad_ref = 1000\n-    # TODO: remove this warning in v0.8 after deprecation period for change in\n-    # effective irradiance units, made in v0.7\n-    with np.errstate(invalid='ignore'):  # turn off warning for NaN\n-        ee = np.asarray(effective_irradiance)\n-        ee_gt0 = ee[ee > 0.0]\n-        if ee_gt0.size > 0 and np.all(ee_gt0 < 2.0):\n-            import warnings\n-            msg = 'effective_irradiance inputs appear to be in suns. Units ' \\\n-                  'changed in v0.7 from suns to W/m2'\n-            warnings.warn(msg, RuntimeWarning)\n \n     q = 1.60218e-19  # Elementary charge in units of coulombs\n     kb = 1.38066e-23  # Boltzmann's constant in units of J/K\n@@ -1695,85 +1633,6 @@ def sapm(effective_irradiance, temp_cell, module):\n     return out\n \n \n-def _sapm_celltemp_translator(*args, **kwargs):\n-    # TODO: remove this function after deprecation period for sapm_celltemp\n-    new_kwargs = {}\n-    # convert position arguments to kwargs\n-    old_arg_list = ['poa_global', 'wind_speed', 'temp_air', 'model']\n-    for pos in range(len(args)):\n-        new_kwargs[old_arg_list[pos]] = args[pos]\n-    # determine value for new kwarg 'model'\n-    try:\n-        param_set = new_kwargs['model']\n-        new_kwargs.pop('model')  # model is not a new kwarg\n-    except KeyError:\n-        # 'model' not in positional arguments, check kwargs\n-        try:\n-            param_set = kwargs['model']\n-            kwargs.pop('model')\n-        except KeyError:\n-            # 'model' not in kwargs, use old default value\n-            param_set = 'open_rack_glass_glass'\n-    if type(param_set) is list:\n-        new_kwargs.update({'a': param_set[0],\n-                           'b': param_set[1],\n-                           'deltaT': param_set[2]})\n-    elif type(param_set) is dict:\n-        new_kwargs.update(param_set)\n-    else:  # string\n-        params = temperature._temperature_model_params('sapm', param_set)\n-        new_kwargs.update(params)\n-    new_kwargs.update(kwargs)  # kwargs with unchanged names\n-    new_kwargs['irrad_ref'] = 1000  # default for new kwarg\n-    # convert old positional arguments to named kwargs\n-    return temperature.sapm_cell(**new_kwargs)\n-\n-\n-sapm_celltemp = deprecated('0.7', alternative='temperature.sapm_cell',\n-                           name='sapm_celltemp', removal='0.8',\n-                           addendum='Note that the arguments and argument '\n-                           'order for temperature.sapm_cell are different '\n-                           'than for sapm_celltemp')(_sapm_celltemp_translator)\n-\n-\n-def _pvsyst_celltemp_translator(*args, **kwargs):\n-    # TODO: remove this function after deprecation period for pvsyst_celltemp\n-    new_kwargs = {}\n-    # convert position arguments to kwargs\n-    old_arg_list = ['poa_global', 'temp_air', 'wind_speed', 'eta_m',\n-                    'alpha_absorption', 'model_params']\n-    for pos in range(len(args)):\n-        new_kwargs[old_arg_list[pos]] = args[pos]\n-    # determine value for new kwarg 'model'\n-    try:\n-        param_set = new_kwargs['model_params']\n-        new_kwargs.pop('model_params')  # model_params is not a new kwarg\n-    except KeyError:\n-        # 'model_params' not in positional arguments, check kwargs\n-        try:\n-            param_set = kwargs['model_params']\n-            kwargs.pop('model_params')\n-        except KeyError:\n-            # 'model_params' not in kwargs, use old default value\n-            param_set = 'freestanding'\n-    if type(param_set) in (list, tuple):\n-        new_kwargs.update({'u_c': param_set[0],\n-                           'u_v': param_set[1]})\n-    else:  # string\n-        params = temperature._temperature_model_params('pvsyst', param_set)\n-        new_kwargs.update(params)\n-    new_kwargs.update(kwargs)  # kwargs with unchanged names\n-    # convert old positional arguments to named kwargs\n-    return temperature.pvsyst_cell(**new_kwargs)\n-\n-\n-pvsyst_celltemp = deprecated(\n-    '0.7', alternative='temperature.pvsyst_cell', name='pvsyst_celltemp',\n-    removal='0.8', addendum='Note that the argument names for '\n-    'temperature.pvsyst_cell are different than '\n-    'for pvsyst_celltemp')(_pvsyst_celltemp_translator)\n-\n-\n def sapm_spectral_loss(airmass_absolute, module):\n     \"\"\"\n     Calculates the SAPM spectral loss coefficient, F1.\n@@ -2051,8 +1910,7 @@ def singlediode(photocurrent, saturation_current, resistance_series,\n         # calculate the IV curve if requested using bishop88\n         if ivcurve_pnts:\n             vd = v_oc * (\n-                    (11.0 - np.logspace(np.log10(11.0), 0.0,\n-                                        ivcurve_pnts)) / 10.0\n+                (11.0 - np.logspace(np.log10(11.0), 0.0, ivcurve_pnts)) / 10.0\n             )\n             ivcurve_i, ivcurve_v, _ = _singlediode.bishop88(vd, *args)\n \n@@ -2301,17 +2159,17 @@ def i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n         # equation for the diode voltage V_d then backing out voltage\n         args = (voltage, photocurrent, saturation_current, resistance_series,\n                 resistance_shunt, nNsVth)\n-        I = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n+        current = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n         # find the right size and shape for returns\n         size, shape = _singlediode._get_size_and_shape(args)\n         if size <= 1:\n             if shape is not None:\n-                I = np.tile(I, shape)\n-        if np.isnan(I).any() and size <= 1:\n-            I = np.repeat(I, size)\n+                current = np.tile(current, shape)\n+        if np.isnan(current).any() and size <= 1:\n+            current = np.repeat(current, size)\n             if shape is not None:\n-                I = I.reshape(shape)\n-        return I\n+                current = current.reshape(shape)\n+        return current\n \n \n def scale_voltage_current_power(data, voltage=1, current=1):\n@@ -2390,7 +2248,7 @@ def pvwatts_dc(g_poa_effective, temp_cell, pdc0, gamma_pdc, temp_ref=25.):\n     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n            (2014).\n-    \"\"\"\n+    \"\"\"  # noqa: E501\n \n     pdc = (g_poa_effective * 0.001 * pdc0 *\n            (1 + gamma_pdc * (temp_cell - temp_ref)))\n@@ -2452,18 +2310,6 @@ def pvwatts_losses(soiling=2, shading=3, snow=0, mismatch=2, wiring=2,\n     return losses\n \n \n-ashraeiam = deprecated('0.7', alternative='iam.ashrae', name='ashraeiam',\n-                       removal='0.8')(iam.ashrae)\n-\n-\n-physicaliam = deprecated('0.7', alternative='iam.physical', name='physicaliam',\n-                         removal='0.8')(iam.physical)\n-\n-\n-sapm_aoi_loss = deprecated('0.7', alternative='iam.sapm', name='sapm_aoi_loss',\n-                           removal='0.8')(iam.sapm)\n-\n-\n snlinverter = deprecated('0.8', alternative='inverter.sandia',\n                          name='snlinverter', removal='0.9')(inverter.sandia)\n \n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_modelchain.py b/pvlib/tests/test_modelchain.py\n--- a/pvlib/tests/test_modelchain.py\n+++ b/pvlib/tests/test_modelchain.py\n@@ -13,7 +13,7 @@\n from conftest import assert_series_equal\n import pytest\n \n-from conftest import fail_on_pvlib_version, requires_scipy, requires_tables\n+from conftest import fail_on_pvlib_version, requires_scipy\n \n \n @pytest.fixture(scope='function')\n@@ -153,6 +153,18 @@ def system_no_aoi(cec_module_cs5p_220m, sapm_temperature_cs5p_220m,\n     return system\n \n \n+@pytest.fixture\n+def system_no_temp(cec_module_cs5p_220m, cec_inverter_parameters):\n+    module_parameters = cec_module_cs5p_220m.copy()\n+    module_parameters['EgRef'] = 1.121\n+    module_parameters['dEgdT'] = -0.0002677\n+    inverter_parameters = cec_inverter_parameters.copy()\n+    system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n+                      module_parameters=module_parameters,\n+                      inverter_parameters=inverter_parameters)\n+    return system\n+\n+\n @pytest.fixture\n def location():\n     return Location(32.2, -111, altitude=700)\n@@ -211,24 +223,6 @@ def test_run_model_with_irradiance(sapm_dc_snl_ac_system, location):\n     assert_series_equal(ac, expected)\n \n \n-def test_run_model_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'dni': 900, 'ghi': 600, 'dhi': 150},\n-                              index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.run_model(irradiance, times=times)\n-\n-\n-def test_prepare_inputs_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'dni': 900, 'ghi': 600, 'dhi': 150},\n-                              index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.prepare_inputs(irradiance, times=times)\n-\n-\n def test_prepare_inputs_no_irradiance(sapm_dc_snl_ac_system, location):\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     weather = pd.DataFrame()\n@@ -236,15 +230,6 @@ def test_prepare_inputs_no_irradiance(sapm_dc_snl_ac_system, location):\n         mc.prepare_inputs(weather)\n \n \n-@requires_tables\n-def test_complete_irradiance_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'ghi': 600., 'dhi': 150.}, index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.complete_irradiance(irradiance, times=times)\n-\n-\n def test_run_model_perez(sapm_dc_snl_ac_system, location):\n     mc = ModelChain(sapm_dc_snl_ac_system, location,\n                     transposition_model='perez')\n@@ -277,8 +262,6 @@ def test_run_model_with_weather_sapm_temp(sapm_dc_snl_ac_system, location,\n     # test with sapm cell temperature model\n     weather['wind_speed'] = 5\n     weather['temp_air'] = 10\n-    sapm_dc_snl_ac_system.racking_model = 'open_rack'\n-    sapm_dc_snl_ac_system.module_type = 'glass_glass'\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     mc.temperature_model = 'sapm'\n     m_sapm = mocker.spy(sapm_dc_snl_ac_system, 'sapm_celltemp')\n@@ -437,6 +420,17 @@ def test_infer_temp_model_invalid(location, sapm_dc_snl_ac_system):\n                    spectral_model='no_loss')\n \n \n+# ModelChain.infer_temperature_model. remove or statement in v0.9\n+@requires_scipy\n+@fail_on_pvlib_version('0.9')\n+def test_infer_temp_model_no_params(location, system_no_temp, weather):\n+    mc = ModelChain(system_no_temp, location, aoi_model='physical',\n+                    spectral_model='no_loss')\n+    match = \"Reverting to deprecated default: SAPM cell temperature\"\n+    with pytest.warns(pvlibDeprecationWarning, match=match):\n+        mc.run_model(weather)\n+\n+\n @requires_scipy\n def test_temperature_model_inconsistent(location, sapm_dc_snl_ac_system):\n     with pytest.raises(ValueError):\n@@ -688,36 +682,6 @@ def test_bad_get_orientation():\n         modelchain.get_orientation('bad value')\n \n \n-@fail_on_pvlib_version('0.8')\n-def test_deprecated_08():\n-    # explicit system creation call because fail_on_pvlib_version\n-    # does not support decorators.\n-    # does not matter what the parameters are, just fake it until we make it\n-    module_parameters = {'R_sh_ref': 1, 'a_ref': 1, 'I_o_ref': 1,\n-                         'alpha_sc': 1, 'I_L_ref': 1, 'R_s': 1}\n-    # do not assign PVSystem.temperature_model_parameters\n-    # leave out PVSystem.racking_model and PVSystem.module_type\n-    system = PVSystem(module_parameters=module_parameters)\n-    # deprecated temp_model kwarg\n-    warn_txt = 'temp_model keyword argument is deprecated'\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temp_model='sapm')\n-    # provide both temp_model and temperature_model kwargs\n-    warn_txt = 'Provide only one of temperature_model'\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temperature_model='sapm', temp_model='sapm')\n-    # conflicting temp_model and temperature_model kwargs\n-    exc_text = 'Conflicting temperature_model'\n-    with pytest.raises(ValueError, match=exc_text):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temperature_model='pvsyst', temp_model='sapm')\n-\n-\n @fail_on_pvlib_version('0.9')\n @pytest.mark.parametrize('ac_model', ['snlinverter', 'adrinverter'])\n def test_deprecated_09(sapm_dc_snl_ac_system, cec_dc_adr_ac_system,\ndiff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -198,17 +198,6 @@ def test_sapm(sapm_module_params):\n                   pd.Series(sapm_module_params))\n \n \n-def test_pvsystem_sapm_warning(sapm_module_params):\n-    # deprecation warning for change in effective_irradiance units in\n-    # pvsystem.sapm\n-    # TODO: remove after deprecation period (v0.8)\n-    effective_irradiance = np.array([0.1, 0.2, 1.3])\n-    temp_cell = np.array([25, 25, 50])\n-    warn_txt = 'effective_irradiance inputs appear to be in suns'\n-    with pytest.warns(RuntimeWarning, match=warn_txt):\n-        pvsystem.sapm(effective_irradiance, temp_cell, sapm_module_params)\n-\n-\n def test_PVSystem_sapm(sapm_module_params, mocker):\n     mocker.spy(pvsystem, 'sapm')\n     system = pvsystem.PVSystem(module_parameters=sapm_module_params)\n@@ -386,14 +375,6 @@ def test__infer_temperature_model_params():\n     assert expected == system._infer_temperature_model_params()\n \n \n-def test__infer_temperature_model_params_deprec_warning():\n-    warn_txt = \"Reverting to deprecated default\"\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        pvsystem.PVSystem(module_parameters={},\n-                          racking_model='not_a_rack_model',\n-                          module_type='glass_polymer')\n-\n-\n def test_calcparams_desoto(cec_module_params):\n     times = pd.date_range(start='2015-01-01', periods=3, freq='12H')\n     effective_irradiance = pd.Series([0.0, 800.0, 800.0], index=times)\n@@ -1130,8 +1111,8 @@ def test_PVSystem___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n     assert system.__repr__() == expected\n \n@@ -1153,8 +1134,8 @@ def test_PVSystem_localize___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n \n     assert localized_system.__repr__() == expected\n@@ -1193,8 +1174,8 @@ def test_LocalizedPVSystem___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n \n     assert localized_system.__repr__() == expected\n@@ -1318,94 +1299,6 @@ def test_PVSystem_pvwatts_ac_kwargs(mocker):\n     assert out < pdc\n \n \n-@fail_on_pvlib_version('0.8')\n-def test_deprecated_08():\n-    # deprecated function pvsystem.sapm_celltemp\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.sapm_celltemp(1000, 25, 1)\n-    # deprecated function pvsystem.pvsyst_celltemp\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.pvsyst_celltemp(1000, 25)\n-    module_parameters = {'R_sh_ref': 1, 'a_ref': 1, 'I_o_ref': 1,\n-                         'alpha_sc': 1, 'I_L_ref': 1, 'R_s': 1,\n-                         'B5': 0.0, 'B4': 0.0, 'B3': 0.0, 'B2': 0.0,\n-                         'B1': 0.0, 'B0': 1.0,\n-                         'b': 0.05, 'K': 4, 'L': 0.002, 'n': 1.526,\n-                         'a_r': 0.16}\n-    temp_model_params = temperature.TEMPERATURE_MODEL_PARAMETERS['sapm'][\n-        'open_rack_glass_glass']\n-    # for missing temperature_model_parameters\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.PVSystem(module_parameters=module_parameters,\n-                          racking_model='open', module_type='glass_glass')\n-    pv = pvsystem.PVSystem(module_parameters=module_parameters,\n-                           temperature_model_parameters=temp_model_params,\n-                           racking_model='open', module_type='glass_glass')\n-    # deprecated method PVSystem.ashraeiam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.ashraeiam(45)\n-    # deprecated function ashraeiam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.ashraeiam(45)\n-    # deprecated method PVSystem.physicaliam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.physicaliam(45)\n-    # deprecated function physicaliam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.physicaliam(45)\n-    # deprecated method PVSystem.sapm_aoi_loss\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.sapm_aoi_loss(45)\n-    # deprecated function sapm_aoi_loss\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.sapm_aoi_loss(45, {'B5': 0.0, 'B4': 0.0, 'B3': 0.0, 'B2': 0.0,\n-                                    'B1': 0.0, 'B0': 1.0})\n-\n-\n-@fail_on_pvlib_version('0.8')\n-def test__pvsyst_celltemp_translator():\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, 5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, 5, 0.1, 0.9,\n-                                                  [29.0, 0.0])\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(poa_global=900, temp_air=20,\n-                                                  wind_speed=5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  u_c=23.5, u_v=6.25,\n-                                                  eta_m=0.1)\n-    assert_allclose(result, 33.315, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  eta_m=0.1,\n-                                                  model_params=[23.5, 6.25])\n-    assert_allclose(result, 33.315, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  eta_m=0.1,\n-                                                  model_params=(23.5, 6.25))\n-    assert_allclose(result, 33.315, 0.001)\n-\n-\n-@fail_on_pvlib_version('0.8')\n-def test__sapm_celltemp_translator():\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20,\n-                                                'open_rack_glass_glass')\n-    assert_allclose(result, 43.509, 3)\n-    result = pvsystem._sapm_celltemp_translator(900, 5, temp_air=20,\n-                                                model='open_rack_glass_glass')\n-    assert_allclose(result, 43.509, 3)\n-    params = temperature.TEMPERATURE_MODEL_PARAMETERS['sapm'][\n-        'open_rack_glass_glass']\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20, params)\n-    assert_allclose(result, 43.509, 3)\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20,\n-                                                [params['a'], params['b'],\n-                                                 params['deltaT']])\n-    assert_allclose(result, 43.509, 3)\n-\n-\n @fail_on_pvlib_version('0.9')\n def test_deprecated_09(cec_inverter_parameters, adr_inverter_parameters):\n     # deprecated function pvsystem.snlinverter\n@@ -1417,3 +1310,8 @@ def test_deprecated_09(cec_inverter_parameters, adr_inverter_parameters):\n     # deprecated function pvsystem.spvwatts_ac\n     with pytest.warns(pvlibDeprecationWarning):\n         pvsystem.pvwatts_ac(90, 100, 0.95)\n+    # for missing temperature_model_parameters\n+    match = \"Reverting to deprecated default: SAPM cell temperature\"\n+    system = pvsystem.PVSystem()\n+    with pytest.warns(pvlibDeprecationWarning, match=match):\n+        system.sapm_celltemp(1, 2, 3)\ndiff --git a/pvlib/tests/test_tracking.py b/pvlib/tests/test_tracking.py\n--- a/pvlib/tests/test_tracking.py\n+++ b/pvlib/tests/test_tracking.py\n@@ -453,8 +453,8 @@ def test_SingleAxisTracker___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n     assert system.__repr__() == expected\n \n@@ -477,8 +477,8 @@ def test_LocalizedSingleAxisTracker___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\n   latitude: 32\n   longitude: -111\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_infer_temp_model_no_params\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize___repr__\", \"pvlib/tests/test_pvsystem.py::test_LocalizedPVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_deprecated_09\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker___repr__\", \"pvlib/tests/test_tracking.py::test_LocalizedSingleAxisTracker___repr__\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_ModelChain_creation\", \"pvlib/tests/test_modelchain.py::test_with_sapm\", \"pvlib/tests/test_modelchain.py::test_with_pvwatts\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[None-expected0]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[None-expected1]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[flat-expected2]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[south_at_latitude_tilt-expected3]\", \"pvlib/tests/test_modelchain.py::test_run_model_with_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_no_irradiance\", \"pvlib/tests/test_modelchain.py::test_run_model_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_gueymard_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_sapm_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_pvsyst_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_faiman_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[desoto]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[singlediode]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvwatts_dc]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec_native]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model_invalid\", \"pvlib/tests/test_modelchain.py::test_temperature_model_inconsistent\", \"pvlib/tests/test_modelchain.py::test_dc_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia]\", \"pvlib/tests/test_modelchain.py::test_ac_models[adr]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts]\", \"pvlib/tests/test_modelchain.py::test_ac_models_deprecated[snlinverter]\", \"pvlib/tests/test_modelchain.py::test_ac_models_deprecated[adrinverter]\", \"pvlib/tests/test_modelchain.py::test_ac_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_model_not_a_model\", \"pvlib/tests/test_modelchain.py::test_aoi_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_model_no_loss\", \"pvlib/tests/test_modelchain.py::test_aoi_model_user_func\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[ashrae]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[physical]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model_invalid\", \"pvlib/tests/test_modelchain.py::test_spectral_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts\", \"pvlib/tests/test_modelchain.py::test_losses_models_ext_def\", \"pvlib/tests/test_modelchain.py::test_losses_models_no_loss\", \"pvlib/tests/test_modelchain.py::test_invalid_dc_model_params\", \"pvlib/tests/test_modelchain.py::test_invalid_models[dc_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[ac_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[aoi_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[spectral_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[temperature_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[losses_model]\", \"pvlib/tests/test_modelchain.py::test_bad_get_orientation\", \"pvlib/tests/test_modelchain.py::test_deprecated_09[snlinverter]\", \"pvlib/tests/test_modelchain.py::test_deprecated_09[adrinverter]\", \"pvlib/tests/test_modelchain.py::test_basic_chain_required\", \"pvlib/tests/test_modelchain.py::test_basic_chain_alt_az\", \"pvlib/tests/test_modelchain.py::test_basic_chain_strategy\", \"pvlib/tests/test_modelchain.py::test_basic_chain_altitude_pressure\", \"pvlib/tests/test_modelchain.py::test_ModelChain___repr__[south_at_latitude_tilt-south_at_latitude_tilt]\", \"pvlib/tests/test_modelchain.py::test_ModelChain___repr__[None-None]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_clean_run\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[1.5-1.00028714375]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_snlinverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize_with_location\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize_with_latlon\", \"pvlib/tests/test_pvsystem.py::test_LocalizedPVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac_kwargs\", \"pvlib/tests/test_tracking.py::test_solar_noon\", \"pvlib/tests/test_tracking.py::test_scalars\", \"pvlib/tests/test_tracking.py::test_arrays\", \"pvlib/tests/test_tracking.py::test_nans\", \"pvlib/tests/test_tracking.py::test_arrays_multi\", \"pvlib/tests/test_tracking.py::test_azimuth_north_south\", \"pvlib/tests/test_tracking.py::test_max_angle\", \"pvlib/tests/test_tracking.py::test_backtrack\", \"pvlib/tests/test_tracking.py::test_axis_tilt\", \"pvlib/tests/test_tracking.py::test_axis_azimuth\", \"pvlib/tests/test_tracking.py::test_horizon_flat\", \"pvlib/tests/test_tracking.py::test_horizon_tilted\", \"pvlib/tests/test_tracking.py::test_low_sun_angles\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_creation\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_tracking\", \"pvlib/tests/test_tracking.py::test_LocalizedSingleAxisTracker_creation\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_localize\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_localize_location\", \"pvlib/tests/test_tracking.py::test_get_aoi\", \"pvlib/tests/test_tracking.py::test_get_irradiance\"]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
{"instance_id": "pvlib__pvlib-python-1033_3", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nPVSystem.temperature_model_parameters requirement\nThe `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to \r\n\r\n1. set default values `module_type=None` and `racking_model=None`.\r\n2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L208-L221\r\n\r\n@cwhanse is that correct?\r\n\r\nThe problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L201-L203\r\n\r\nSo I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9. \nremove deprecated functions in 0.8\n`pvsystem`:\r\n* `sapm_celltemp`\r\n* `pvsyst_celltemp`\r\n* `ashraeiam`\r\n* `physicaliam`\r\n* `sapm_aoi_loss`\r\n* `PVSystem.ashraeiam`\r\n* `PVSystem.physicaliam`\r\n* `PVSystem.sapm_aoi_loss`\r\n* inference of `PVSystem.temperature_model_parameters`\r\n\r\n`modelchain.ModelChain`:\r\n* remove `times` from `complete_irradiance`, `prepare_inputs`, `run_model`\r\n* remove `temp_model` kwarg\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"https://travis-ci.org/pvlib/pvlib-python\">\n29     <img src=\"https://travis-ci.org/pvlib/pvlib-python.svg?branch=master\" alt=\"travis build status\" />\n30     </a>\n31     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n32     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n33     </a>\n34     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n35       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Code Quality</td>\n41  \u00a0<td>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n43     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n44     </a>\n45     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n46     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n47     </a>\n48   </td>\n49 </tr>\n50 <tr>\n51   <td>Coverage</td>\n52  \u00a0<td>\n53     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n54     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n55     </a>\n56     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n57     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n58     </a>\n59   </td>\n60 </tr>\n61 <tr>\n62   <td>Publications</td>\n63   <td>\n64     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n65     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n66     </a>\n67     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n68     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n69     </a>\n70   </td>\n71 </tr>\n72 <tr>\n73   <td>Downloads</td>\n74   <td>\n75     <a href=\"https://pypi.org/project/pvlib/\">\n76     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n77     </a>\n78     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n79     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n80     </a>\n81   </td>\n82 </tr>\n83 </table>\n84 \n85 \n86 pvlib python is a community supported tool that provides a set of\n87 functions and classes for simulating the performance of photovoltaic\n88 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n89 toolbox developed at Sandia National Laboratories and it implements many\n90 of the models and methods developed at the Labs. More information on\n91 Sandia Labs PV performance modeling programs can be found at\n92 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n93 but operate independently of it.\n94 \n95 \n96 Documentation\n97 =============\n98 \n99 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n100 \n101 \n102 Installation\n103 ============\n104 \n105 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n106 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n107 \n108 pvlib-python is compatible with Python 3.5 and above.\n109 \n110 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n111 \n112 \n113 Contributing\n114 ============\n115 \n116 We need your help to make pvlib-python a great tool!\n117 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n118 The long-term success of pvlib-python requires substantial community support.\n119 \n120 \n121 License\n122 =======\n123 \n124 BSD 3-clause\n125 \n126 \n127 Getting support\n128 ===============\n129 \n130 pvlib usage questions can be asked on\n131 [Stack Overflow](http://stackoverflow.com) and tagged with\n132 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n133 \n134 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n135 is used for discussing various topics of interest to the pvlib-python\n136 community. We also make new version announcements on the google group.\n137 \n138 If you suspect that you may have discovered a bug or if you'd like to\n139 change something about pvlib, then please make an issue on our\n140 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n141 \n142 \n143 Citing\n144 ======\n145 \n146 If you use pvlib-python in a published work, please cite:\n147 \n148   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n149   \"pvlib python: a python package for modeling solar energy systems.\"\n150   Journal of Open Source Software, 3(29), 884, (2018).\n151   https://doi.org/10.21105/joss.00884\n152 \n153 Please also cite the DOI corresponding to the specific version of\n154 pvlib-python that you used. pvlib-python DOIs are listed at\n155 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n156 \n157 NumFOCUS\n158 ========\n159 \n160 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n161 \n162 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n163 \n[end of README.md]\n[start of pvlib/atmosphere.py]\n1 \"\"\"\n2 The ``atmosphere`` module contains methods to calculate relative and\n3 absolute airmass and to determine pressure from altitude or vice versa.\n4 \"\"\"\n5 \n6 from warnings import warn\n7 \n8 import numpy as np\n9 import pandas as pd\n10 \n11 \n12 APPARENT_ZENITH_MODELS = ('simple', 'kasten1966', 'kastenyoung1989',\n13                           'gueymard1993', 'pickering2002')\n14 TRUE_ZENITH_MODELS = ('youngirvine1967', 'young1994')\n15 AIRMASS_MODELS = APPARENT_ZENITH_MODELS + TRUE_ZENITH_MODELS\n16 \n17 \n18 def pres2alt(pressure):\n19     '''\n20     Determine altitude from site pressure.\n21 \n22     Parameters\n23     ----------\n24     pressure : numeric\n25         Atmospheric pressure. [Pa]\n26 \n27     Returns\n28     -------\n29     altitude : numeric\n30         Altitude above sea level. [m]\n31 \n32     Notes\n33     ------\n34     The following assumptions are made\n35 \n36     ============================   ================\n37     Parameter                      Value\n38     ============================   ================\n39     Base pressure                  101325 Pa\n40     Temperature at zero altitude   288.15 K\n41     Gravitational acceleration     9.80665 m/s^2\n42     Lapse rate                     -6.5E-3 K/m\n43     Gas constant for air           287.053 J/(kg K)\n44     Relative Humidity              0%\n45     ============================   ================\n46 \n47     References\n48     -----------\n49     .. [1] \"A Quick Derivation relating altitude to air pressure\" from\n50        Portland State Aerospace Society, Version 1.03, 12/22/2004.\n51     '''\n52 \n53     alt = 44331.5 - 4946.62 * pressure ** (0.190263)\n54 \n55     return alt\n56 \n57 \n58 def alt2pres(altitude):\n59     '''\n60     Determine site pressure from altitude.\n61 \n62     Parameters\n63     ----------\n64     altitude : numeric\n65         Altitude above sea level. [m]\n66 \n67     Returns\n68     -------\n69     pressure : numeric\n70         Atmospheric pressure. [Pa]\n71 \n72     Notes\n73     ------\n74     The following assumptions are made\n75 \n76     ============================   ================\n77     Parameter                      Value\n78     ============================   ================\n79     Base pressure                  101325 Pa\n80     Temperature at zero altitude   288.15 K\n81     Gravitational acceleration     9.80665 m/s^2\n82     Lapse rate                     -6.5E-3 K/m\n83     Gas constant for air           287.053 J/(kg K)\n84     Relative Humidity              0%\n85     ============================   ================\n86 \n87     References\n88     -----------\n89     .. [1] \"A Quick Derivation relating altitude to air pressure\" from\n90        Portland State Aerospace Society, Version 1.03, 12/22/2004.\n91     '''\n92 \n93     press = 100 * ((44331.514 - altitude) / 11880.516) ** (1 / 0.1902632)\n94 \n95     return press\n96 \n97 \n98 def get_absolute_airmass(airmass_relative, pressure=101325.):\n99     r'''\n100     Determine absolute (pressure-adjusted) airmass from relative\n101     airmass and pressure.\n102 \n103     The calculation for absolute airmass (:math:`AM_a`) is\n104 \n105     .. math::\n106         AM_a = AM_r \\frac{P}{101325}\n107 \n108     where :math:`AM_r` is relative air mass at sea level and :math:`P` is\n109     atmospheric pressure.\n110 \n111     Parameters\n112     ----------\n113     airmass_relative : numeric\n114         The airmass at sea level. [unitless]\n115 \n116     pressure : numeric, default 101325\n117         Atmospheric pressure. [Pa]\n118 \n119     Returns\n120     -------\n121     airmass_absolute : numeric\n122         Absolute (pressure-adjusted) airmass\n123 \n124     References\n125     ----------\n126     .. [1] C. Gueymard, \"Critical analysis and performance assessment of\n127        clear sky solar irradiance models using theoretical and measured\n128        data,\" Solar Energy, vol. 51, pp. 121-138, 1993.\n129     '''\n130 \n131     airmass_absolute = airmass_relative * pressure / 101325.\n132 \n133     return airmass_absolute\n134 \n135 \n136 def get_relative_airmass(zenith, model='kastenyoung1989'):\n137     '''\n138     Calculate relative (not pressure-adjusted) airmass at sea level.\n139 \n140     Parameter ``model`` allows selection of different airmass models.\n141 \n142     Parameters\n143     ----------\n144     zenith : numeric\n145         Zenith angle of the sun. [degrees]\n146 \n147     model : string, default 'kastenyoung1989'\n148         Available models include the following:\n149 \n150         * 'simple' - secant(apparent zenith angle) -\n151           Note that this gives -Inf at zenith=90\n152         * 'kasten1966' - See reference [1] -\n153           requires apparent sun zenith\n154         * 'youngirvine1967' - See reference [2] -\n155           requires true sun zenith\n156         * 'kastenyoung1989' (default) - See reference [3] -\n157           requires apparent sun zenith\n158         * 'gueymard1993' - See reference [4] -\n159           requires apparent sun zenith\n160         * 'young1994' - See reference [5] -\n161           requries true sun zenith\n162         * 'pickering2002' - See reference [6] -\n163           requires apparent sun zenith\n164 \n165     Returns\n166     -------\n167     airmass_relative : numeric\n168         Relative airmass at sea level. Returns NaN values for any\n169         zenith angle greater than 90 degrees. [unitless]\n170 \n171     Notes\n172     -----\n173     Some models use apparent (refraction-adjusted) zenith angle while\n174     other models use true (not refraction-adjusted) zenith angle. Apparent\n175     zenith angles should be calculated at sea level.\n176 \n177     References\n178     ----------\n179     .. [1] Fritz Kasten. \"A New Table and Approximation Formula for the\n180        Relative Optical Air Mass\". Technical Report 136, Hanover, N.H.:\n181        U.S. Army Material Command, CRREL.\n182 \n183     .. [2] A. T. Young and W. M. Irvine, \"Multicolor Photoelectric\n184        Photometry of the Brighter Planets,\" The Astronomical Journal, vol.\n185        72, pp. 945-950, 1967.\n186 \n187     .. [3] Fritz Kasten and Andrew Young. \"Revised optical air mass tables\n188        and approximation formula\". Applied Optics 28:4735-4738\n189 \n190     .. [4] C. Gueymard, \"Critical analysis and performance assessment of\n191        clear sky solar irradiance models using theoretical and measured\n192        data,\" Solar Energy, vol. 51, pp. 121-138, 1993.\n193 \n194     .. [5] A. T. Young, \"AIR-MASS AND REFRACTION,\" Applied Optics, vol. 33,\n195        pp. 1108-1110, Feb 1994.\n196 \n197     .. [6] Keith A. Pickering. \"The Ancient Star Catalog\". DIO 12:1, 20,\n198 \n199     .. [7] Matthew J. Reno, Clifford W. Hansen and Joshua S. Stein, \"Global\n200        Horizontal Irradiance Clear Sky Models: Implementation and Analysis\"\n201        Sandia Report, (2012).\n202     '''\n203 \n204     # set zenith values greater than 90 to nans\n205     z = np.where(zenith > 90, np.nan, zenith)\n206     zenith_rad = np.radians(z)\n207 \n208     model = model.lower()\n209 \n210     if 'kastenyoung1989' == model:\n211         am = (1.0 / (np.cos(zenith_rad) +\n212               0.50572*(((6.07995 + (90 - z)) ** - 1.6364))))\n213     elif 'kasten1966' == model:\n214         am = 1.0 / (np.cos(zenith_rad) + 0.15*((93.885 - z) ** - 1.253))\n215     elif 'simple' == model:\n216         am = 1.0 / np.cos(zenith_rad)\n217     elif 'pickering2002' == model:\n218         am = (1.0 / (np.sin(np.radians(90 - z +\n219               244.0 / (165 + 47.0 * (90 - z) ** 1.1)))))\n220     elif 'youngirvine1967' == model:\n221         sec_zen = 1.0 / np.cos(zenith_rad)\n222         am = sec_zen * (1 - 0.0012 * (sec_zen * sec_zen - 1))\n223     elif 'young1994' == model:\n224         am = ((1.002432*((np.cos(zenith_rad)) ** 2) +\n225               0.148386*(np.cos(zenith_rad)) + 0.0096467) /\n226               (np.cos(zenith_rad) ** 3 +\n227               0.149864*(np.cos(zenith_rad) ** 2) +\n228               0.0102963*(np.cos(zenith_rad)) + 0.000303978))\n229     elif 'gueymard1993' == model:\n230         am = (1.0 / (np.cos(zenith_rad) +\n231               0.00176759*(z)*((94.37515 - z) ** - 1.21563)))\n232     else:\n233         raise ValueError('%s is not a valid model for relativeairmass', model)\n234 \n235     if isinstance(zenith, pd.Series):\n236         am = pd.Series(am, index=zenith.index)\n237 \n238     return am\n239 \n240 \n241 def gueymard94_pw(temp_air, relative_humidity):\n242     r\"\"\"\n243     Calculates precipitable water (cm) from ambient air temperature (C)\n244     and relatively humidity (%) using an empirical model. The\n245     accuracy of this method is approximately 20% for moderate PW (1-3\n246     cm) and less accurate otherwise.\n247 \n248     The model was developed by expanding Eq. 1 in [2]_:\n249 \n250     .. math::\n251 \n252            Pw = 0.1 H_v \\rho_v\n253 \n254     using Eq. 2 in [2]_\n255 \n256     .. math::\n257 \n258            \\rho_v = 216.7 R_H e_s /T\n259 \n260     :math:`Pw` is the precipitable water (cm), :math:`H_v` is the apparent\n261     water vapor scale height (km) and :math:`\\rho_v` is the surface water\n262     vapor density (g/m^3). . The expression for :math:`H_v` is Eq. 4 in [2]_:\n263 \n264     .. math::\n265 \n266            H_v = 0.4976 + 1.5265 \\frac{T}{273.15}\n267                + \\exp \\left(13.6897 \\frac{T}{273.15}\n268                - 14.9188 \\left( \\frac{T}{273.15} \\right)^3 \\right)\n269 \n270     In the expression for :math:`\\rho_v`, :math:`e_s` is the saturation water\n271     vapor pressure (millibar). The expression for :math:`e_s` is Eq. 1 in [3]_\n272 \n273     .. math::\n274 \n275           e_s = \\exp \\left(22.330 - 49.140 \\frac{100}{T} -\n276               10.922 \\left(\\frac{100}{T}\\right)^2 -\n277               0.39015 \\frac{T}{100} \\right)\n278 \n279     Parameters\n280     ----------\n281     temp_air : numeric\n282         ambient air temperature :math:`T` at the surface. [C]\n283     relative_humidity : numeric\n284         relative humidity :math:`R_H` at the surface. [%]\n285 \n286     Returns\n287     -------\n288     pw : numeric\n289         precipitable water. [cm]\n290 \n291     References\n292     ----------\n293     .. [1] W. M. Keogh and A. W. Blakers, Accurate Measurement, Using Natural\n294        Sunlight, of Silicon Solar Cells, Prog. in Photovoltaics: Res.\n295        and Appl. 2004, vol 12, pp. 1-19 (:doi:`10.1002/pip.517`)\n296 \n297     .. [2] C. Gueymard, Analysis of Monthly Average Atmospheric Precipitable\n298        Water and Turbidity in Canada and Northern United States,\n299        Solar Energy vol 53(1), pp. 57-71, 1994.\n300 \n301     .. [3] C. Gueymard, Assessment of the Accuracy and Computing Speed of\n302        simplified saturation vapor equations using a new reference\n303        dataset, J. of Applied Meteorology 1993, vol. 32(7), pp.\n304        1294-1300.\n305     \"\"\"\n306 \n307     T = temp_air + 273.15  # Convert to Kelvin                  # noqa: N806\n308     RH = relative_humidity                                      # noqa: N806\n309 \n310     theta = T / 273.15\n311 \n312     # Eq. 1 from Keogh and Blakers\n313     pw = (\n314         0.1 *\n315         (0.4976 + 1.5265*theta + np.exp(13.6897*theta - 14.9188*(theta)**3)) *\n316         (216.7*RH/(100*T)*np.exp(22.330 - 49.140*(100/T) -\n317          10.922*(100/T)**2 - 0.39015*T/100)))\n318 \n319     pw = np.maximum(pw, 0.1)\n320 \n321     return pw\n322 \n323 \n324 def first_solar_spectral_correction(pw, airmass_absolute,\n325                                     module_type=None, coefficients=None,\n326                                     min_pw=0.1, max_pw=8):\n327     r\"\"\"\n328     Spectral mismatch modifier based on precipitable water and absolute\n329     (pressure-adjusted) airmass.\n330 \n331     Estimates a spectral mismatch modifier :math:`M` representing the effect on\n332     module short circuit current of variation in the spectral\n333     irradiance. :math:`M`  is estimated from absolute (pressure currected) air\n334     mass, :math:`AM_a`, and precipitable water, :math:`Pw`, using the following\n335     function:\n336 \n337     .. math::\n338 \n339         M = c_1 + c_2 AM_a  + c_3 Pw  + c_4 AM_a^{0.5}\n340             + c_5 Pw^{0.5} + c_6 \\frac{AM_a} {Pw^{0.5}}\n341 \n342     Default coefficients are determined for several cell types with\n343     known quantum efficiency curves, by using the Simple Model of the\n344     Atmospheric Radiative Transfer of Sunshine (SMARTS) [1]_. Using\n345     SMARTS, spectrums are simulated with all combinations of AMa and\n346     Pw where:\n347 \n348        * :math:`0.5 \\textrm{cm} <= Pw <= 5 \\textrm{cm}`\n349        * :math:`1.0 <= AM_a <= 5.0`\n350        * Spectral range is limited to that of CMP11 (280 nm to 2800 nm)\n351        * spectrum simulated on a plane normal to the sun\n352        * All other parameters fixed at G173 standard\n353 \n354     From these simulated spectra, M is calculated using the known\n355     quantum efficiency curves. Multiple linear regression is then\n356     applied to fit Eq. 1 to determine the coefficients for each module.\n357 \n358     Based on the PVLIB Matlab function ``pvl_FSspeccorr`` by Mitchell\n359     Lee and Alex Panchula of First Solar, 2016 [2]_.\n360 \n361     Parameters\n362     ----------\n363     pw : array-like\n364         atmospheric precipitable water. [cm]\n365 \n366     airmass_absolute : array-like\n367         absolute (pressure-adjusted) airmass. [unitless]\n368 \n369     min_pw : float, default 0.1\n370         minimum atmospheric precipitable water. Any pw value lower than min_pw\n371         is set to min_pw to avoid model divergence. [cm]\n372 \n373     max_pw : float, default 8\n374         maximum atmospheric precipitable water. Any pw value higher than max_pw\n375         is set to NaN to avoid model divergence. [cm]\n376 \n377     module_type : None or string, default None\n378         a string specifying a cell type. Values of 'cdte', 'monosi', 'xsi',\n379         'multisi', and 'polysi' (can be lower or upper case). If provided,\n380         module_type selects default coefficients for the following modules:\n381 \n382             * 'cdte' - First Solar Series 4-2 CdTe module.\n383             * 'monosi', 'xsi' - First Solar TetraSun module.\n384             * 'multisi', 'polysi' - anonymous multi-crystalline silicon module.\n385             * 'cigs' - anonymous copper indium gallium selenide module.\n386             * 'asi' - anonymous amorphous silicon module.\n387 \n388         The module used to calculate the spectral correction\n389         coefficients corresponds to the Multi-crystalline silicon\n390         Manufacturer 2 Model C from [3]_. The spectral response (SR) of CIGS\n391         and a-Si modules used to derive coefficients can be found in [4]_\n392 \n393     coefficients : None or array-like, default None\n394         Allows for entry of user-defined spectral correction\n395         coefficients. Coefficients must be of length 6. Derivation of\n396         coefficients requires use of SMARTS and PV module quantum\n397         efficiency curve. Useful for modeling PV module types which are\n398         not included as defaults, or to fine tune the spectral\n399         correction to a particular PV module. Note that the parameters for\n400         modules with very similar quantum efficiency should be similar,\n401         in most cases limiting the need for module specific coefficients.\n402 \n403     Returns\n404     -------\n405     modifier: array-like\n406         spectral mismatch factor (unitless) which is can be multiplied\n407         with broadband irradiance reaching a module's cells to estimate\n408         effective irradiance, i.e., the irradiance that is converted to\n409         electrical current.\n410 \n411     References\n412     ----------\n413     .. [1] Gueymard, Christian. SMARTS2: a simple model of the atmospheric\n414        radiative transfer of sunshine: algorithms and performance\n415        assessment. Cocoa, FL: Florida Solar Energy Center, 1995.\n416     .. [2] Lee, Mitchell, and Panchula, Alex. \"Spectral Correction for\n417        Photovoltaic Module Performance Based on Air Mass and Precipitable\n418        Water.\" IEEE Photovoltaic Specialists Conference, Portland, 2016\n419     .. [3] Marion, William F., et al. User's Manual for Data for Validating\n420        Models for PV Module Performance. National Renewable Energy\n421        Laboratory, 2014. http://www.nrel.gov/docs/fy14osti/61610.pdf\n422     .. [4] Schweiger, M. and Hermann, W, Influence of Spectral Effects\n423        on Energy Yield of Different PV Modules: Comparison of Pwat and\n424        MMF Approach, TUV Rheinland Energy GmbH report 21237296.003,\n425        January 2017\n426     \"\"\"\n427 \n428     # --- Screen Input Data ---\n429 \n430     # *** Pw ***\n431     # Replace Pw Values below 0.1 cm with 0.1 cm to prevent model from\n432     # diverging\"\n433     pw = np.atleast_1d(pw)\n434     pw = pw.astype('float64')\n435     if np.min(pw) < min_pw:\n436         pw = np.maximum(pw, min_pw)\n437         warn('Exceptionally low pw values replaced with {0} cm to prevent '\n438              'model divergence'.format(min_pw))\n439 \n440     # Warn user about Pw data that is exceptionally high\n441     if np.max(pw) > max_pw:\n442         pw[pw > max_pw] = np.nan\n443         warn('Exceptionally high pw values replaced by np.nan: '\n444              'check input data.')\n445 \n446     # *** AMa ***\n447     # Replace Extremely High AM with AM 10 to prevent model divergence\n448     # AM > 10 will only occur very close to sunset\n449     if np.max(airmass_absolute) > 10:\n450         airmass_absolute = np.minimum(airmass_absolute, 10)\n451 \n452     # Warn user about AMa data that is exceptionally low\n453     if np.min(airmass_absolute) < 0.58:\n454         warn('Exceptionally low air mass: ' +\n455              'model not intended for extra-terrestrial use')\n456         # pvl_absoluteairmass(1,pvl_alt2pres(4340)) = 0.58 Elevation of\n457         # Mina Pirquita, Argentian = 4340 m. Highest elevation city with\n458         # population over 50,000.\n459 \n460     _coefficients = {}\n461     _coefficients['cdte'] = (\n462         0.86273, -0.038948, -0.012506, 0.098871, 0.084658, -0.0042948)\n463     _coefficients['monosi'] = (\n464         0.85914, -0.020880, -0.0058853, 0.12029, 0.026814, -0.0017810)\n465     _coefficients['xsi'] = _coefficients['monosi']\n466     _coefficients['polysi'] = (\n467         0.84090, -0.027539, -0.0079224, 0.13570, 0.038024, -0.0021218)\n468     _coefficients['multisi'] = _coefficients['polysi']\n469     _coefficients['cigs'] = (\n470         0.85252, -0.022314, -0.0047216, 0.13666, 0.013342, -0.0008945)\n471     _coefficients['asi'] = (\n472         1.12094, -0.047620, -0.0083627, -0.10443, 0.098382, -0.0033818)\n473 \n474     if module_type is not None and coefficients is None:\n475         coefficients = _coefficients[module_type.lower()]\n476     elif module_type is None and coefficients is not None:\n477         pass\n478     elif module_type is None and coefficients is None:\n479         raise TypeError('No valid input provided, both module_type and ' +\n480                         'coefficients are None')\n481     else:\n482         raise TypeError('Cannot resolve input, must supply only one of ' +\n483                         'module_type and coefficients')\n484 \n485     # Evaluate Spectral Shift\n486     coeff = coefficients\n487     ama = airmass_absolute\n488     modifier = (\n489         coeff[0] + coeff[1]*ama + coeff[2]*pw + coeff[3]*np.sqrt(ama) +\n490         coeff[4]*np.sqrt(pw) + coeff[5]*ama/np.sqrt(pw))\n491 \n492     return modifier\n493 \n494 \n495 def bird_hulstrom80_aod_bb(aod380, aod500):\n496     \"\"\"\n497     Approximate broadband aerosol optical depth.\n498 \n499     Bird and Hulstrom developed a correlation for broadband aerosol optical\n500     depth (AOD) using two wavelengths, 380 nm and 500 nm.\n501 \n502     Parameters\n503     ----------\n504     aod380 : numeric\n505         AOD measured at 380 nm. [unitless]\n506     aod500 : numeric\n507         AOD measured at 500 nm. [unitless]\n508 \n509     Returns\n510     -------\n511     aod_bb : numeric\n512         Broadband AOD.  [unitless]\n513 \n514     See also\n515     --------\n516     pvlib.atmosphere.kasten96_lt\n517 \n518     References\n519     ----------\n520     .. [1] Bird and Hulstrom, \"Direct Insolation Models\" (1980)\n521        `SERI/TR-335-344 <http://www.nrel.gov/docs/legosti/old/344.pdf>`_\n522 \n523     .. [2] R. E. Bird and R. L. Hulstrom, \"Review, Evaluation, and Improvement\n524        of Direct Irradiance Models\", Journal of Solar Energy Engineering\n525        103(3), pp. 182-192 (1981)\n526        :doi:`10.1115/1.3266239`\n527     \"\"\"\n528     # approximate broadband AOD using (Bird-Hulstrom 1980)\n529     return 0.27583 * aod380 + 0.35 * aod500\n530 \n531 \n532 def kasten96_lt(airmass_absolute, precipitable_water, aod_bb):\n533     \"\"\"\n534     Calculate Linke turbidity  using Kasten pyrheliometric formula.\n535 \n536     Note that broadband aerosol optical depth (AOD) can be approximated by AOD\n537     measured at 700 nm according to Molineaux [4] . Bird and Hulstrom offer an\n538     alternate approximation using AOD measured at 380 nm and 500 nm.\n539 \n540     Based on original implementation by Armel Oumbe.\n541 \n542     .. warning::\n543         These calculations are only valid for airmass less than 5 and\n544         precipitable water less than 5 cm.\n545 \n546     Parameters\n547     ----------\n548     airmass_absolute : numeric\n549         Pressure-adjusted airmass. [unitless]\n550     precipitable_water : numeric\n551         Precipitable water. [cm]\n552     aod_bb : numeric\n553         broadband AOD. [unitless]\n554 \n555     Returns\n556     -------\n557     lt : numeric\n558         Linke turbidity. [unitless]\n559 \n560     See also\n561     --------\n562     pvlib.atmosphere.bird_hulstrom80_aod_bb\n563     pvlib.atmosphere.angstrom_aod_at_lambda\n564 \n565     References\n566     ----------\n567     .. [1] F. Linke, \"Transmissions-Koeffizient und Trubungsfaktor\", Beitrage\n568        zur Physik der Atmosphare, Vol 10, pp. 91-103 (1922)\n569 \n570     .. [2] F. Kasten, \"A simple parameterization of the pyrheliometric formula\n571        for determining the Linke turbidity factor\", Meteorologische Rundschau\n572        33, pp. 124-127 (1980)\n573 \n574     .. [3] Kasten, \"The Linke turbidity factor based on improved values of the\n575        integral Rayleigh optical thickness\", Solar Energy, Vol. 56, No. 3,\n576        pp. 239-244 (1996)\n577        :doi:`10.1016/0038-092X(95)00114-7`\n578 \n579     .. [4] B. Molineaux, P. Ineichen, N. O'Neill, \"Equivalence of\n580        pyrheliometric and monochromatic aerosol optical depths at a single key\n581        wavelength\", Applied Optics Vol. 37, issue 10, 7008-7018 (1998)\n582        :doi:`10.1364/AO.37.007008`\n583 \n584     .. [5] P. Ineichen, \"Conversion function between the Linke turbidity and\n585        the atmospheric water vapor and aerosol content\", Solar Energy 82,\n586        pp. 1095-1097 (2008)\n587        :doi:`10.1016/j.solener.2008.04.010`\n588 \n589     .. [6] P. Ineichen and R. Perez, \"A new airmass independent formulation for\n590        the Linke Turbidity coefficient\", Solar Energy, Vol. 73, no. 3,\n591        pp. 151-157 (2002)\n592        :doi:`10.1016/S0038-092X(02)00045-2`\n593     \"\"\"\n594     # \"From numerically integrated spectral simulations done with Modtran\n595     # (Berk, 1989), Molineaux (1998) obtained for the broadband optical depth\n596     # of a clean and dry atmospshere (fictitious atmosphere that comprises only\n597     # the effects of Rayleigh scattering and absorption by the atmosphere gases\n598     # other than the water vapor) the following expression\"\n599     # - P. Ineichen (2008)\n600     delta_cda = -0.101 + 0.235 * airmass_absolute ** (-0.16)\n601     # \"and the broadband water vapor optical depth where pwat is the integrated\n602     # precipitable water vapor content of the atmosphere expressed in cm and am\n603     # the optical air mass. The precision of these fits is better than 1% when\n604     # compared with Modtran simulations in the range 1 < am < 5 and\n605     # 0 < pwat < 5 cm at sea level\" - P. Ineichen (2008)\n606     delta_w = 0.112 * airmass_absolute ** (-0.55) * precipitable_water ** 0.34\n607     # broadband AOD\n608     delta_a = aod_bb\n609     # \"Then using the Kasten pyrheliometric formula (1980, 1996), the Linke\n610     # turbidity at am = 2 can be written. The extension of the Linke turbidity\n611     # coefficient to other values of air mass was published by Ineichen and\n612     # Perez (2002)\" - P. Ineichen (2008)\n613     lt = -(9.4 + 0.9 * airmass_absolute) * np.log(\n614         np.exp(-airmass_absolute * (delta_cda + delta_w + delta_a))\n615     ) / airmass_absolute\n616     # filter out of extrapolated values\n617     return lt\n618 \n619 \n620 def angstrom_aod_at_lambda(aod0, lambda0, alpha=1.14, lambda1=700.0):\n621     r\"\"\"\n622     Get AOD at specified wavelength using Angstrom turbidity model.\n623 \n624     Parameters\n625     ----------\n626     aod0 : numeric\n627         Aerosol optical depth (AOD) measured at wavelength ``lambda0``.\n628         [unitless]\n629     lambda0 : numeric\n630         Wavelength corresponding to ``aod0``. [nm]\n631     alpha : numeric, default 1.14\n632         Angstrom :math:`\\alpha` exponent corresponding to ``aod0``. [unitless]\n633     lambda1 : numeric, default 700\n634         Desired wavelength. [nm]\n635 \n636     Returns\n637     -------\n638     aod1 : numeric\n639         AOD at desired wavelength ``lambda1``. [unitless]\n640 \n641     See also\n642     --------\n643     pvlib.atmosphere.angstrom_alpha\n644 \n645     References\n646     ----------\n647     .. [1] Anders Angstrom, \"On the Atmospheric Transmission of Sun Radiation\n648        and On Dust in the Air\", Geografiska Annaler Vol. 11, pp. 156-166 (1929)\n649        JSTOR\n650        :doi:`10.2307/519399`\n651 \n652     .. [2] Anders Angstrom, \"Techniques of Determining the Turbidity of the\n653        Atmosphere\", Tellus 13:2, pp. 214-223 (1961) Taylor & Francis\n654        :doi:`10.3402/tellusa.v13i2.9493` and Co-Action Publishing\n655        :doi:`10.1111/j.2153-3490.1961.tb00078.x`\n656     \"\"\"\n657     return aod0 * ((lambda1 / lambda0) ** (-alpha))\n658 \n659 \n660 def angstrom_alpha(aod1, lambda1, aod2, lambda2):\n661     r\"\"\"\n662     Calculate Angstrom alpha exponent.\n663 \n664     Parameters\n665     ----------\n666     aod1 : numeric\n667         Aerosol optical depth at wavelength ``lambda1``. [unitless]\n668     lambda1 : numeric\n669         Wavelength corresponding to ``aod1``. [nm]\n670     aod2 : numeric\n671         Aerosol optical depth  at wavelength ``lambda2``. [unitless]\n672     lambda2 : numeric\n673         Wavelength corresponding to ``aod2``. [nm]\n674 \n675     Returns\n676     -------\n677     alpha : numeric\n678         Angstrom :math:`\\alpha` exponent for wavelength in\n679         ``(lambda1, lambda2)``. [unitless]\n680 \n681     See also\n682     --------\n683     pvlib.atmosphere.angstrom_aod_at_lambda\n684     \"\"\"\n685     return - np.log(aod1 / aod2) / np.log(lambda1 / lambda2)\n686 \n[end of pvlib/atmosphere.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n", "repo": "pvlib/pvlib-python", "base_commit": "a7edb8b582174ed45f2d3859f29261908f5e0ab5", "problem_statement": "PVSystem.temperature_model_parameters requirement\nThe `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to \r\n\r\n1. set default values `module_type=None` and `racking_model=None`.\r\n2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L208-L221\r\n\r\n@cwhanse is that correct?\r\n\r\nThe problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nhttps://github.com/pvlib/pvlib-python/blob/27872b83b0932cc419116f79e442963cced935bb/pvlib/pvsystem.py#L201-L203\r\n\r\nSo I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9. \nremove deprecated functions in 0.8\n`pvsystem`:\r\n* `sapm_celltemp`\r\n* `pvsyst_celltemp`\r\n* `ashraeiam`\r\n* `physicaliam`\r\n* `sapm_aoi_loss`\r\n* `PVSystem.ashraeiam`\r\n* `PVSystem.physicaliam`\r\n* `PVSystem.sapm_aoi_loss`\r\n* inference of `PVSystem.temperature_model_parameters`\r\n\r\n`modelchain.ModelChain`:\r\n* remove `times` from `complete_irradiance`, `prepare_inputs`, `run_model`\r\n* remove `temp_model` kwarg\n", "hints_text": "> The `temperature_model_parameters` handling code below suggests to me that in 0.8 we're going to\r\n> \r\n> 1. set default values `module_type=None` and `racking_model=None`.\r\n> 2. require user to specify either `temperature_model_parameters` or both `module_type` and `racking_model`.\r\n> \r\n> @cwhanse is that correct?\r\n\r\nYes, that is the intent.\r\n\r\n> So I'm guessing that this warning has been seen by only a small fraction of people that need to see it. I'm ok moving forward with the removal in 0.8 or pushing to 0.9.\r\n\r\nThe warning should have been raised whenever condition #2 above wasn't met; it looks to me that has been the case. If that hasn't been the case I would prefer to fix the warning and push the deprecation out to v0.9. pvlib-python has had that unadvertised default temperature model assignment for a long time.\r\n\n> The problem is that the only way to see this warning is to supply an invalid `module_type` or `racking_model`. That's because `PVSystem._infer_temperature_model` is called before the code above, and it looks up the default `module_type` and `racking_model` and successfully finds temperature coefficients.\r\n\r\nI don't follow here - it looks to me that the warning should be raised if 1) `temperature_model_parameters` isn't specified, or 2) either `module_type` or `racking_model` are invalid. Maybe we're saying the same thing. `_infer_temperature_model` doesn't assign the default temperature model, that is done in the block of code that raises the warning. \r\n\r\n\nThe `module_type` and `racking_model` defaults prevent the warning from showing up in many use cases. If we change the defaults to `None` then the warning will be triggered. If we simultaneously remove the warning then code will break without users having ever seen the warning.\nWhat is the expected behavior for `PVSystem()`?\n> The `module_type` and `racking_model` defaults prevent the warning from showing up in many use cases. If we change the defaults to `None` then the warning will be triggered. If we simultaneously remove the warning then code will break without users having ever seen the warning.\r\n\r\nAha. I see the problem now, thanks.  Perhaps remove the defaults in v0.8 and leave the warning until v0.9?\nOk, I'll work on that.\n", "created_at": "2020-08-25T18:51:23Z", "patch": "<patch>\ndiff --git a/pvlib/modelchain.py b/pvlib/modelchain.py\n--- a/pvlib/modelchain.py\n+++ b/pvlib/modelchain.py\n@@ -179,7 +179,7 @@ def basic_chain(times, latitude, longitude,\n             linke_turbidity,\n             altitude=altitude,\n             dni_extra=dni_extra\n-            )\n+        )\n \n     total_irrad = pvlib.irradiance.get_total_irradiance(\n         surface_tilt,\n@@ -346,24 +346,6 @@ def __init__(self, system, location,\n         self.ac_model = ac_model\n         self.aoi_model = aoi_model\n         self.spectral_model = spectral_model\n-\n-        # TODO: deprecated kwarg temp_model. Remove use of temp_model in v0.8\n-        temp_model = kwargs.pop('temp_model', None)\n-        if temp_model is not None:\n-            if temperature_model is None:\n-                warnings.warn('The temp_model keyword argument is deprecated.'\n-                              ' Use temperature_model instead',\n-                              pvlibDeprecationWarning)\n-                temperature_model = temp_model\n-            elif temp_model == temperature_model:\n-                warnings.warn('Provide only one of temperature_model or '\n-                              'temp_model (deprecated).',\n-                              pvlibDeprecationWarning)\n-            else:\n-                raise ValueError(\n-                    'Conflicting temperature_model {} and temp_model {}. '\n-                    'temp_model is deprecated. Specify only temperature_model.'\n-                    .format(temperature_model, temp_model))\n         self.temperature_model = temperature_model\n \n         self.losses_model = losses_model\n@@ -544,7 +526,7 @@ def __repr__(self):\n             'transposition_model', 'solar_position_method',\n             'airmass_model', 'dc_model', 'ac_model', 'aoi_model',\n             'spectral_model', 'temperature_model', 'losses_model'\n-            ]\n+        ]\n \n         def getmcattr(self, attr):\n             \"\"\"needed to avoid recursion in property lookups\"\"\"\n@@ -588,8 +570,8 @@ def dc_model(self, model):\n             model = model.lower()\n             if model in _DC_MODEL_PARAMS.keys():\n                 # validate module parameters\n-                missing_params = _DC_MODEL_PARAMS[model] - \\\n-                                 set(self.system.module_parameters.keys())\n+                missing_params = (_DC_MODEL_PARAMS[model]\n+                                  - set(self.system.module_parameters.keys()))\n                 if missing_params:  # some parameters are not in module.keys()\n                     raise ValueError(model + ' selected for the DC model but '\n                                      'one or more required parameters are '\n@@ -834,8 +816,8 @@ def infer_spectral_model(self):\n \n     def first_solar_spectral_loss(self):\n         self.spectral_modifier = self.system.first_solar_spectral_loss(\n-                                        self.weather['precipitable_water'],\n-                                        self.airmass['airmass_absolute'])\n+            self.weather['precipitable_water'],\n+            self.airmass['airmass_absolute'])\n         return self\n \n     def sapm_spectral_loss(self):\n@@ -878,7 +860,10 @@ def temperature_model(self, model):\n \n     def infer_temperature_model(self):\n         params = set(self.system.temperature_model_parameters.keys())\n-        if set(['a', 'b', 'deltaT']) <= params:\n+        # remove or statement in v0.9\n+        if set(['a', 'b', 'deltaT']) <= params or (\n+                not params and self.system.racking_model is None\n+                and self.system.module_type is None):\n             return self.sapm_temp\n         elif set(['u_c', 'u_v']) <= params:\n             return self.pvsyst_temp\n@@ -945,7 +930,7 @@ def effective_irradiance_model(self):\n             fd*self.total_irrad['poa_diffuse'])\n         return self\n \n-    def complete_irradiance(self, weather, times=None):\n+    def complete_irradiance(self, weather):\n         \"\"\"\n         Determine the missing irradiation columns. Only two of the\n         following data columns (dni, ghi, dhi) are needed to calculate\n@@ -962,10 +947,6 @@ def complete_irradiance(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Returns\n         -------\n@@ -994,11 +975,6 @@ def complete_irradiance(self, weather, times=None):\n         \"\"\"\n         self.weather = weather\n \n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.solar_position = self.location.get_solarposition(\n             self.weather.index, method=self.solar_position_method)\n \n@@ -1029,7 +1005,7 @@ def complete_irradiance(self, weather, times=None):\n \n         return self\n \n-    def prepare_inputs(self, weather, times=None):\n+    def prepare_inputs(self, weather):\n         \"\"\"\n         Prepare the solar position, irradiance, and weather inputs to\n         the model.\n@@ -1041,10 +1017,6 @@ def prepare_inputs(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Notes\n         -----\n@@ -1064,11 +1036,6 @@ def prepare_inputs(self, weather, times=None):\n \n         self.weather = weather\n \n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.times = self.weather.index\n         try:\n             kwargs = _build_kwargs(['pressure', 'temp_air'], weather)\n@@ -1126,7 +1093,7 @@ def prepare_inputs(self, weather, times=None):\n             self.weather['temp_air'] = 20\n         return self\n \n-    def run_model(self, weather, times=None):\n+    def run_model(self, weather):\n         \"\"\"\n         Run the model.\n \n@@ -1137,10 +1104,6 @@ def run_model(self, weather, times=None):\n             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n             are required. Air temperature of 20 C and wind speed\n             of 0 m/s will be added to the DataFrame if not provided.\n-        times : None, deprecated\n-            Deprecated argument included for API compatibility, but not\n-            used internally. The index of the weather DataFrame is used\n-            for times.\n \n         Returns\n         -------\n@@ -1152,11 +1115,6 @@ def run_model(self, weather, times=None):\n         ``dc``, ``ac``, ``losses``,\n         ``diode_params`` (if dc_model is a single diode model)\n         \"\"\"\n-        if times is not None:\n-            warnings.warn('times keyword argument is deprecated and will be '\n-                          'removed in 0.8. The index of the weather DataFrame '\n-                          'is used for times.', pvlibDeprecationWarning)\n-\n         self.prepare_inputs(weather)\n         self.aoi_model()\n         self.spectral_model()\ndiff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -170,12 +170,12 @@ class PVSystem(object):\n     def __init__(self,\n                  surface_tilt=0, surface_azimuth=180,\n                  albedo=None, surface_type=None,\n-                 module=None, module_type='glass_polymer',\n+                 module=None, module_type=None,\n                  module_parameters=None,\n                  temperature_model_parameters=None,\n                  modules_per_string=1, strings_per_inverter=1,\n                  inverter=None, inverter_parameters=None,\n-                 racking_model='open_rack', losses_parameters=None, name=None,\n+                 racking_model=None, losses_parameters=None, name=None,\n                  **kwargs):\n \n         self.surface_tilt = surface_tilt\n@@ -201,25 +201,9 @@ def __init__(self,\n         if temperature_model_parameters is None:\n             self.temperature_model_parameters = \\\n                 self._infer_temperature_model_params()\n-            # TODO: in v0.8 check if an empty dict is returned and raise error\n         else:\n             self.temperature_model_parameters = temperature_model_parameters\n \n-        # TODO: deprecated behavior if PVSystem.temperature_model_parameters\n-        # are not specified. Remove in v0.8\n-        if not any(self.temperature_model_parameters):\n-            warnings.warn(\n-                'Required temperature_model_parameters is not specified '\n-                'and parameters are not inferred from racking_model and '\n-                'module_type. Reverting to deprecated default: SAPM cell '\n-                'temperature model parameters for a glass/glass module in '\n-                'open racking. In the future '\n-                'PVSystem.temperature_model_parameters will be required',\n-                pvlibDeprecationWarning)\n-            params = temperature._temperature_model_params(\n-                'sapm', 'open_rack_glass_glass')\n-            self.temperature_model_parameters = params\n-\n         self.modules_per_string = modules_per_string\n         self.strings_per_inverter = strings_per_inverter\n \n@@ -358,26 +342,6 @@ def get_iam(self, aoi, iam_model='physical'):\n         else:\n             raise ValueError(model + ' is not a valid IAM model')\n \n-    def ashraeiam(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.ashraeiam is deprecated and will be removed in'\n-                      'v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='ashrae')\n-\n-    def physicaliam(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.physicaliam is deprecated and will be removed'\n-                      ' in v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='physical')\n-\n     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_desoto` function, the input\n@@ -506,6 +470,21 @@ def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n         -------\n         numeric, values in degrees C.\n         \"\"\"\n+        # warn user about change in default behavior in 0.9.\n+        if (self.temperature_model_parameters == {} and self.module_type\n+                is None and self.racking_model is None):\n+            warnings.warn(\n+                'temperature_model_parameters, racking_model, and module_type '\n+                'are not specified. Reverting to deprecated default: SAPM '\n+                'cell temperature model parameters for a glass/glass module '\n+                'in open racking. In v0.9, temperature_model_parameters or a '\n+                'valid combination of racking_model and module_type will be '\n+                'required.',\n+                pvlibDeprecationWarning)\n+            params = temperature._temperature_model_params(\n+                'sapm', 'open_rack_glass_glass')\n+            self.temperature_model_parameters = params\n+\n         kwargs = _build_kwargs(['a', 'b', 'deltaT'],\n                                self.temperature_model_parameters)\n         return temperature.sapm_cell(poa_global, temp_air, wind_speed,\n@@ -514,7 +493,7 @@ def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n     def _infer_temperature_model_params(self):\n         # try to infer temperature model parameters from from racking_model\n         # and module_type\n-        param_set = self.racking_model + '_' + self.module_type\n+        param_set = '{}_{}'.format(self.racking_model, self.module_type)\n         if param_set in temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']:\n             return temperature._temperature_model_params('sapm', param_set)\n         elif 'freestanding' in param_set:\n@@ -543,16 +522,6 @@ def sapm_spectral_loss(self, airmass_absolute):\n         \"\"\"\n         return sapm_spectral_loss(airmass_absolute, self.module_parameters)\n \n-    def sapm_aoi_loss(self, aoi):\n-        \"\"\"\n-        Deprecated. Use ``PVSystem.get_iam`` instead.\n-        \"\"\"\n-        import warnings\n-        warnings.warn('PVSystem.sapm_aoi_loss is deprecated and will be'\n-                      ' removed in v0.8, use PVSystem.get_iam instead',\n-                      pvlibDeprecationWarning)\n-        return PVSystem.get_iam(self, aoi, iam_model='sapm')\n-\n     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n                                   airmass_absolute, aoi,\n                                   reference_irradiance=1000):\n@@ -671,7 +640,7 @@ def first_solar_spectral_loss(self, pw, airmass_absolute):\n         if 'first_solar_spectral_coefficients' in \\\n                 self.module_parameters.keys():\n             coefficients = \\\n-                   self.module_parameters['first_solar_spectral_coefficients']\n+                self.module_parameters['first_solar_spectral_coefficients']\n             module_type = None\n         else:\n             module_type = self._infer_cell_type()\n@@ -1071,27 +1040,6 @@ def calcparams_desoto(effective_irradiance, temp_cell,\n          Source: [4]\n     '''\n \n-    # test for use of function pre-v0.6.0 API change\n-    if isinstance(a_ref, dict) or \\\n-       (isinstance(a_ref, pd.Series) and ('a_ref' in a_ref.keys())):\n-        import warnings\n-        warnings.warn('module_parameters detected as fourth positional'\n-                      + ' argument of calcparams_desoto. calcparams_desoto'\n-                      + ' will require one argument for each module model'\n-                      + ' parameter in v0.7.0 and later', DeprecationWarning)\n-        try:\n-            module_parameters = a_ref\n-            a_ref = module_parameters['a_ref']\n-            I_L_ref = module_parameters['I_L_ref']\n-            I_o_ref = module_parameters['I_o_ref']\n-            R_sh_ref = module_parameters['R_sh_ref']\n-            R_s = module_parameters['R_s']\n-        except Exception as e:\n-            raise e('Module parameters could not be extracted from fourth'\n-                    + ' positional argument of calcparams_desoto. Check that'\n-                    + ' parameters are from the CEC database and/or update'\n-                    + ' your code for the new API for calcparams_desoto')\n-\n     # Boltzmann constant in eV/K\n     k = 8.617332478e-05\n \n@@ -1624,16 +1572,6 @@ def sapm(effective_irradiance, temp_cell, module):\n     # reference_irradiance and expose\n     temp_ref = 25\n     irrad_ref = 1000\n-    # TODO: remove this warning in v0.8 after deprecation period for change in\n-    # effective irradiance units, made in v0.7\n-    with np.errstate(invalid='ignore'):  # turn off warning for NaN\n-        ee = np.asarray(effective_irradiance)\n-        ee_gt0 = ee[ee > 0.0]\n-        if ee_gt0.size > 0 and np.all(ee_gt0 < 2.0):\n-            import warnings\n-            msg = 'effective_irradiance inputs appear to be in suns. Units ' \\\n-                  'changed in v0.7 from suns to W/m2'\n-            warnings.warn(msg, RuntimeWarning)\n \n     q = 1.60218e-19  # Elementary charge in units of coulombs\n     kb = 1.38066e-23  # Boltzmann's constant in units of J/K\n@@ -1695,85 +1633,6 @@ def sapm(effective_irradiance, temp_cell, module):\n     return out\n \n \n-def _sapm_celltemp_translator(*args, **kwargs):\n-    # TODO: remove this function after deprecation period for sapm_celltemp\n-    new_kwargs = {}\n-    # convert position arguments to kwargs\n-    old_arg_list = ['poa_global', 'wind_speed', 'temp_air', 'model']\n-    for pos in range(len(args)):\n-        new_kwargs[old_arg_list[pos]] = args[pos]\n-    # determine value for new kwarg 'model'\n-    try:\n-        param_set = new_kwargs['model']\n-        new_kwargs.pop('model')  # model is not a new kwarg\n-    except KeyError:\n-        # 'model' not in positional arguments, check kwargs\n-        try:\n-            param_set = kwargs['model']\n-            kwargs.pop('model')\n-        except KeyError:\n-            # 'model' not in kwargs, use old default value\n-            param_set = 'open_rack_glass_glass'\n-    if type(param_set) is list:\n-        new_kwargs.update({'a': param_set[0],\n-                           'b': param_set[1],\n-                           'deltaT': param_set[2]})\n-    elif type(param_set) is dict:\n-        new_kwargs.update(param_set)\n-    else:  # string\n-        params = temperature._temperature_model_params('sapm', param_set)\n-        new_kwargs.update(params)\n-    new_kwargs.update(kwargs)  # kwargs with unchanged names\n-    new_kwargs['irrad_ref'] = 1000  # default for new kwarg\n-    # convert old positional arguments to named kwargs\n-    return temperature.sapm_cell(**new_kwargs)\n-\n-\n-sapm_celltemp = deprecated('0.7', alternative='temperature.sapm_cell',\n-                           name='sapm_celltemp', removal='0.8',\n-                           addendum='Note that the arguments and argument '\n-                           'order for temperature.sapm_cell are different '\n-                           'than for sapm_celltemp')(_sapm_celltemp_translator)\n-\n-\n-def _pvsyst_celltemp_translator(*args, **kwargs):\n-    # TODO: remove this function after deprecation period for pvsyst_celltemp\n-    new_kwargs = {}\n-    # convert position arguments to kwargs\n-    old_arg_list = ['poa_global', 'temp_air', 'wind_speed', 'eta_m',\n-                    'alpha_absorption', 'model_params']\n-    for pos in range(len(args)):\n-        new_kwargs[old_arg_list[pos]] = args[pos]\n-    # determine value for new kwarg 'model'\n-    try:\n-        param_set = new_kwargs['model_params']\n-        new_kwargs.pop('model_params')  # model_params is not a new kwarg\n-    except KeyError:\n-        # 'model_params' not in positional arguments, check kwargs\n-        try:\n-            param_set = kwargs['model_params']\n-            kwargs.pop('model_params')\n-        except KeyError:\n-            # 'model_params' not in kwargs, use old default value\n-            param_set = 'freestanding'\n-    if type(param_set) in (list, tuple):\n-        new_kwargs.update({'u_c': param_set[0],\n-                           'u_v': param_set[1]})\n-    else:  # string\n-        params = temperature._temperature_model_params('pvsyst', param_set)\n-        new_kwargs.update(params)\n-    new_kwargs.update(kwargs)  # kwargs with unchanged names\n-    # convert old positional arguments to named kwargs\n-    return temperature.pvsyst_cell(**new_kwargs)\n-\n-\n-pvsyst_celltemp = deprecated(\n-    '0.7', alternative='temperature.pvsyst_cell', name='pvsyst_celltemp',\n-    removal='0.8', addendum='Note that the argument names for '\n-    'temperature.pvsyst_cell are different than '\n-    'for pvsyst_celltemp')(_pvsyst_celltemp_translator)\n-\n-\n def sapm_spectral_loss(airmass_absolute, module):\n     \"\"\"\n     Calculates the SAPM spectral loss coefficient, F1.\n@@ -2051,8 +1910,7 @@ def singlediode(photocurrent, saturation_current, resistance_series,\n         # calculate the IV curve if requested using bishop88\n         if ivcurve_pnts:\n             vd = v_oc * (\n-                    (11.0 - np.logspace(np.log10(11.0), 0.0,\n-                                        ivcurve_pnts)) / 10.0\n+                (11.0 - np.logspace(np.log10(11.0), 0.0, ivcurve_pnts)) / 10.0\n             )\n             ivcurve_i, ivcurve_v, _ = _singlediode.bishop88(vd, *args)\n \n@@ -2301,17 +2159,17 @@ def i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n         # equation for the diode voltage V_d then backing out voltage\n         args = (voltage, photocurrent, saturation_current, resistance_series,\n                 resistance_shunt, nNsVth)\n-        I = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n+        current = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n         # find the right size and shape for returns\n         size, shape = _singlediode._get_size_and_shape(args)\n         if size <= 1:\n             if shape is not None:\n-                I = np.tile(I, shape)\n-        if np.isnan(I).any() and size <= 1:\n-            I = np.repeat(I, size)\n+                current = np.tile(current, shape)\n+        if np.isnan(current).any() and size <= 1:\n+            current = np.repeat(current, size)\n             if shape is not None:\n-                I = I.reshape(shape)\n-        return I\n+                current = current.reshape(shape)\n+        return current\n \n \n def scale_voltage_current_power(data, voltage=1, current=1):\n@@ -2390,7 +2248,7 @@ def pvwatts_dc(g_poa_effective, temp_cell, pdc0, gamma_pdc, temp_ref=25.):\n     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n            (2014).\n-    \"\"\"\n+    \"\"\"  # noqa: E501\n \n     pdc = (g_poa_effective * 0.001 * pdc0 *\n            (1 + gamma_pdc * (temp_cell - temp_ref)))\n@@ -2452,18 +2310,6 @@ def pvwatts_losses(soiling=2, shading=3, snow=0, mismatch=2, wiring=2,\n     return losses\n \n \n-ashraeiam = deprecated('0.7', alternative='iam.ashrae', name='ashraeiam',\n-                       removal='0.8')(iam.ashrae)\n-\n-\n-physicaliam = deprecated('0.7', alternative='iam.physical', name='physicaliam',\n-                         removal='0.8')(iam.physical)\n-\n-\n-sapm_aoi_loss = deprecated('0.7', alternative='iam.sapm', name='sapm_aoi_loss',\n-                           removal='0.8')(iam.sapm)\n-\n-\n snlinverter = deprecated('0.8', alternative='inverter.sandia',\n                          name='snlinverter', removal='0.9')(inverter.sandia)\n \n\n</patch>", "test_patch": "diff --git a/pvlib/tests/test_modelchain.py b/pvlib/tests/test_modelchain.py\n--- a/pvlib/tests/test_modelchain.py\n+++ b/pvlib/tests/test_modelchain.py\n@@ -13,7 +13,7 @@\n from conftest import assert_series_equal\n import pytest\n \n-from conftest import fail_on_pvlib_version, requires_scipy, requires_tables\n+from conftest import fail_on_pvlib_version, requires_scipy\n \n \n @pytest.fixture(scope='function')\n@@ -153,6 +153,18 @@ def system_no_aoi(cec_module_cs5p_220m, sapm_temperature_cs5p_220m,\n     return system\n \n \n+@pytest.fixture\n+def system_no_temp(cec_module_cs5p_220m, cec_inverter_parameters):\n+    module_parameters = cec_module_cs5p_220m.copy()\n+    module_parameters['EgRef'] = 1.121\n+    module_parameters['dEgdT'] = -0.0002677\n+    inverter_parameters = cec_inverter_parameters.copy()\n+    system = PVSystem(surface_tilt=32.2, surface_azimuth=180,\n+                      module_parameters=module_parameters,\n+                      inverter_parameters=inverter_parameters)\n+    return system\n+\n+\n @pytest.fixture\n def location():\n     return Location(32.2, -111, altitude=700)\n@@ -211,24 +223,6 @@ def test_run_model_with_irradiance(sapm_dc_snl_ac_system, location):\n     assert_series_equal(ac, expected)\n \n \n-def test_run_model_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'dni': 900, 'ghi': 600, 'dhi': 150},\n-                              index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.run_model(irradiance, times=times)\n-\n-\n-def test_prepare_inputs_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'dni': 900, 'ghi': 600, 'dhi': 150},\n-                              index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.prepare_inputs(irradiance, times=times)\n-\n-\n def test_prepare_inputs_no_irradiance(sapm_dc_snl_ac_system, location):\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     weather = pd.DataFrame()\n@@ -236,15 +230,6 @@ def test_prepare_inputs_no_irradiance(sapm_dc_snl_ac_system, location):\n         mc.prepare_inputs(weather)\n \n \n-@requires_tables\n-def test_complete_irradiance_times(sapm_dc_snl_ac_system, location):\n-    mc = ModelChain(sapm_dc_snl_ac_system, location)\n-    times = pd.date_range('20160101 1200-0700', periods=2, freq='6H')\n-    irradiance = pd.DataFrame({'ghi': 600., 'dhi': 150.}, index=times)\n-    with pytest.warns(pvlibDeprecationWarning):\n-        mc.complete_irradiance(irradiance, times=times)\n-\n-\n def test_run_model_perez(sapm_dc_snl_ac_system, location):\n     mc = ModelChain(sapm_dc_snl_ac_system, location,\n                     transposition_model='perez')\n@@ -277,8 +262,6 @@ def test_run_model_with_weather_sapm_temp(sapm_dc_snl_ac_system, location,\n     # test with sapm cell temperature model\n     weather['wind_speed'] = 5\n     weather['temp_air'] = 10\n-    sapm_dc_snl_ac_system.racking_model = 'open_rack'\n-    sapm_dc_snl_ac_system.module_type = 'glass_glass'\n     mc = ModelChain(sapm_dc_snl_ac_system, location)\n     mc.temperature_model = 'sapm'\n     m_sapm = mocker.spy(sapm_dc_snl_ac_system, 'sapm_celltemp')\n@@ -437,6 +420,17 @@ def test_infer_temp_model_invalid(location, sapm_dc_snl_ac_system):\n                    spectral_model='no_loss')\n \n \n+# ModelChain.infer_temperature_model. remove or statement in v0.9\n+@requires_scipy\n+@fail_on_pvlib_version('0.9')\n+def test_infer_temp_model_no_params(location, system_no_temp, weather):\n+    mc = ModelChain(system_no_temp, location, aoi_model='physical',\n+                    spectral_model='no_loss')\n+    match = \"Reverting to deprecated default: SAPM cell temperature\"\n+    with pytest.warns(pvlibDeprecationWarning, match=match):\n+        mc.run_model(weather)\n+\n+\n @requires_scipy\n def test_temperature_model_inconsistent(location, sapm_dc_snl_ac_system):\n     with pytest.raises(ValueError):\n@@ -688,36 +682,6 @@ def test_bad_get_orientation():\n         modelchain.get_orientation('bad value')\n \n \n-@fail_on_pvlib_version('0.8')\n-def test_deprecated_08():\n-    # explicit system creation call because fail_on_pvlib_version\n-    # does not support decorators.\n-    # does not matter what the parameters are, just fake it until we make it\n-    module_parameters = {'R_sh_ref': 1, 'a_ref': 1, 'I_o_ref': 1,\n-                         'alpha_sc': 1, 'I_L_ref': 1, 'R_s': 1}\n-    # do not assign PVSystem.temperature_model_parameters\n-    # leave out PVSystem.racking_model and PVSystem.module_type\n-    system = PVSystem(module_parameters=module_parameters)\n-    # deprecated temp_model kwarg\n-    warn_txt = 'temp_model keyword argument is deprecated'\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temp_model='sapm')\n-    # provide both temp_model and temperature_model kwargs\n-    warn_txt = 'Provide only one of temperature_model'\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temperature_model='sapm', temp_model='sapm')\n-    # conflicting temp_model and temperature_model kwargs\n-    exc_text = 'Conflicting temperature_model'\n-    with pytest.raises(ValueError, match=exc_text):\n-        ModelChain(system, location, dc_model='desoto', aoi_model='no_loss',\n-                   spectral_model='no_loss', ac_model='sandia',\n-                   temperature_model='pvsyst', temp_model='sapm')\n-\n-\n @fail_on_pvlib_version('0.9')\n @pytest.mark.parametrize('ac_model', ['snlinverter', 'adrinverter'])\n def test_deprecated_09(sapm_dc_snl_ac_system, cec_dc_adr_ac_system,\ndiff --git a/pvlib/tests/test_pvsystem.py b/pvlib/tests/test_pvsystem.py\n--- a/pvlib/tests/test_pvsystem.py\n+++ b/pvlib/tests/test_pvsystem.py\n@@ -198,17 +198,6 @@ def test_sapm(sapm_module_params):\n                   pd.Series(sapm_module_params))\n \n \n-def test_pvsystem_sapm_warning(sapm_module_params):\n-    # deprecation warning for change in effective_irradiance units in\n-    # pvsystem.sapm\n-    # TODO: remove after deprecation period (v0.8)\n-    effective_irradiance = np.array([0.1, 0.2, 1.3])\n-    temp_cell = np.array([25, 25, 50])\n-    warn_txt = 'effective_irradiance inputs appear to be in suns'\n-    with pytest.warns(RuntimeWarning, match=warn_txt):\n-        pvsystem.sapm(effective_irradiance, temp_cell, sapm_module_params)\n-\n-\n def test_PVSystem_sapm(sapm_module_params, mocker):\n     mocker.spy(pvsystem, 'sapm')\n     system = pvsystem.PVSystem(module_parameters=sapm_module_params)\n@@ -386,14 +375,6 @@ def test__infer_temperature_model_params():\n     assert expected == system._infer_temperature_model_params()\n \n \n-def test__infer_temperature_model_params_deprec_warning():\n-    warn_txt = \"Reverting to deprecated default\"\n-    with pytest.warns(pvlibDeprecationWarning, match=warn_txt):\n-        pvsystem.PVSystem(module_parameters={},\n-                          racking_model='not_a_rack_model',\n-                          module_type='glass_polymer')\n-\n-\n def test_calcparams_desoto(cec_module_params):\n     times = pd.date_range(start='2015-01-01', periods=3, freq='12H')\n     effective_irradiance = pd.Series([0.0, 800.0, 800.0], index=times)\n@@ -1130,8 +1111,8 @@ def test_PVSystem___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n     assert system.__repr__() == expected\n \n@@ -1153,8 +1134,8 @@ def test_PVSystem_localize___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n \n     assert localized_system.__repr__() == expected\n@@ -1193,8 +1174,8 @@ def test_LocalizedPVSystem___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n \n     assert localized_system.__repr__() == expected\n@@ -1318,94 +1299,6 @@ def test_PVSystem_pvwatts_ac_kwargs(mocker):\n     assert out < pdc\n \n \n-@fail_on_pvlib_version('0.8')\n-def test_deprecated_08():\n-    # deprecated function pvsystem.sapm_celltemp\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.sapm_celltemp(1000, 25, 1)\n-    # deprecated function pvsystem.pvsyst_celltemp\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.pvsyst_celltemp(1000, 25)\n-    module_parameters = {'R_sh_ref': 1, 'a_ref': 1, 'I_o_ref': 1,\n-                         'alpha_sc': 1, 'I_L_ref': 1, 'R_s': 1,\n-                         'B5': 0.0, 'B4': 0.0, 'B3': 0.0, 'B2': 0.0,\n-                         'B1': 0.0, 'B0': 1.0,\n-                         'b': 0.05, 'K': 4, 'L': 0.002, 'n': 1.526,\n-                         'a_r': 0.16}\n-    temp_model_params = temperature.TEMPERATURE_MODEL_PARAMETERS['sapm'][\n-        'open_rack_glass_glass']\n-    # for missing temperature_model_parameters\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.PVSystem(module_parameters=module_parameters,\n-                          racking_model='open', module_type='glass_glass')\n-    pv = pvsystem.PVSystem(module_parameters=module_parameters,\n-                           temperature_model_parameters=temp_model_params,\n-                           racking_model='open', module_type='glass_glass')\n-    # deprecated method PVSystem.ashraeiam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.ashraeiam(45)\n-    # deprecated function ashraeiam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.ashraeiam(45)\n-    # deprecated method PVSystem.physicaliam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.physicaliam(45)\n-    # deprecated function physicaliam\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.physicaliam(45)\n-    # deprecated method PVSystem.sapm_aoi_loss\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pv.sapm_aoi_loss(45)\n-    # deprecated function sapm_aoi_loss\n-    with pytest.warns(pvlibDeprecationWarning):\n-        pvsystem.sapm_aoi_loss(45, {'B5': 0.0, 'B4': 0.0, 'B3': 0.0, 'B2': 0.0,\n-                                    'B1': 0.0, 'B0': 1.0})\n-\n-\n-@fail_on_pvlib_version('0.8')\n-def test__pvsyst_celltemp_translator():\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, 5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, 5, 0.1, 0.9,\n-                                                  [29.0, 0.0])\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(poa_global=900, temp_air=20,\n-                                                  wind_speed=5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5)\n-    assert_allclose(result, 45.137, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  u_c=23.5, u_v=6.25,\n-                                                  eta_m=0.1)\n-    assert_allclose(result, 33.315, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  eta_m=0.1,\n-                                                  model_params=[23.5, 6.25])\n-    assert_allclose(result, 33.315, 0.001)\n-    result = pvsystem._pvsyst_celltemp_translator(900, 20, wind_speed=5.0,\n-                                                  eta_m=0.1,\n-                                                  model_params=(23.5, 6.25))\n-    assert_allclose(result, 33.315, 0.001)\n-\n-\n-@fail_on_pvlib_version('0.8')\n-def test__sapm_celltemp_translator():\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20,\n-                                                'open_rack_glass_glass')\n-    assert_allclose(result, 43.509, 3)\n-    result = pvsystem._sapm_celltemp_translator(900, 5, temp_air=20,\n-                                                model='open_rack_glass_glass')\n-    assert_allclose(result, 43.509, 3)\n-    params = temperature.TEMPERATURE_MODEL_PARAMETERS['sapm'][\n-        'open_rack_glass_glass']\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20, params)\n-    assert_allclose(result, 43.509, 3)\n-    result = pvsystem._sapm_celltemp_translator(900, 5, 20,\n-                                                [params['a'], params['b'],\n-                                                 params['deltaT']])\n-    assert_allclose(result, 43.509, 3)\n-\n-\n @fail_on_pvlib_version('0.9')\n def test_deprecated_09(cec_inverter_parameters, adr_inverter_parameters):\n     # deprecated function pvsystem.snlinverter\n@@ -1417,3 +1310,8 @@ def test_deprecated_09(cec_inverter_parameters, adr_inverter_parameters):\n     # deprecated function pvsystem.spvwatts_ac\n     with pytest.warns(pvlibDeprecationWarning):\n         pvsystem.pvwatts_ac(90, 100, 0.95)\n+    # for missing temperature_model_parameters\n+    match = \"Reverting to deprecated default: SAPM cell temperature\"\n+    system = pvsystem.PVSystem()\n+    with pytest.warns(pvlibDeprecationWarning, match=match):\n+        system.sapm_celltemp(1, 2, 3)\ndiff --git a/pvlib/tests/test_tracking.py b/pvlib/tests/test_tracking.py\n--- a/pvlib/tests/test_tracking.py\n+++ b/pvlib/tests/test_tracking.py\n@@ -453,8 +453,8 @@ def test_SingleAxisTracker___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\"\"\"\n     assert system.__repr__() == expected\n \n@@ -477,8 +477,8 @@ def test_LocalizedSingleAxisTracker___repr__():\n   module: blah\n   inverter: blarg\n   albedo: 0.25\n-  racking_model: open_rack\n-  module_type: glass_polymer\n+  racking_model: None\n+  module_type: None\n   temperature_model_parameters: {'a': -3.56}\n   latitude: 32\n   longitude: -111\n", "version": "0.7", "FAIL_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_infer_temp_model_no_params\", \"pvlib/tests/test_pvsystem.py::test_PVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize___repr__\", \"pvlib/tests/test_pvsystem.py::test_LocalizedPVSystem___repr__\", \"pvlib/tests/test_pvsystem.py::test_deprecated_09\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker___repr__\", \"pvlib/tests/test_tracking.py::test_LocalizedSingleAxisTracker___repr__\"]", "PASS_TO_PASS": "[\"pvlib/tests/test_modelchain.py::test_ModelChain_creation\", \"pvlib/tests/test_modelchain.py::test_with_sapm\", \"pvlib/tests/test_modelchain.py::test_with_pvwatts\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[None-expected0]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[None-expected1]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[flat-expected2]\", \"pvlib/tests/test_modelchain.py::test_orientation_strategy[south_at_latitude_tilt-expected3]\", \"pvlib/tests/test_modelchain.py::test_run_model_with_irradiance\", \"pvlib/tests/test_modelchain.py::test_prepare_inputs_no_irradiance\", \"pvlib/tests/test_modelchain.py::test_run_model_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_gueymard_perez\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_sapm_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_pvsyst_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_with_weather_faiman_temp\", \"pvlib/tests/test_modelchain.py::test_run_model_tracker\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[desoto]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvsyst]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[singlediode]\", \"pvlib/tests/test_modelchain.py::test_infer_dc_model[pvwatts_dc]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec]\", \"pvlib/tests/test_modelchain.py::test_infer_spectral_model[cec_native]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[sapm_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[faiman_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model[pvsyst_temp]\", \"pvlib/tests/test_modelchain.py::test_infer_temp_model_invalid\", \"pvlib/tests/test_modelchain.py::test_temperature_model_inconsistent\", \"pvlib/tests/test_modelchain.py::test_dc_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_models[sandia]\", \"pvlib/tests/test_modelchain.py::test_ac_models[adr]\", \"pvlib/tests/test_modelchain.py::test_ac_models[pvwatts]\", \"pvlib/tests/test_modelchain.py::test_ac_models_deprecated[snlinverter]\", \"pvlib/tests/test_modelchain.py::test_ac_models_deprecated[adrinverter]\", \"pvlib/tests/test_modelchain.py::test_ac_model_user_func\", \"pvlib/tests/test_modelchain.py::test_ac_model_not_a_model\", \"pvlib/tests/test_modelchain.py::test_aoi_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[ashrae]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[physical]\", \"pvlib/tests/test_modelchain.py::test_aoi_models[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_aoi_model_no_loss\", \"pvlib/tests/test_modelchain.py::test_aoi_model_user_func\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[sapm]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[ashrae]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[physical]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model[martin_ruiz]\", \"pvlib/tests/test_modelchain.py::test_infer_aoi_model_invalid\", \"pvlib/tests/test_modelchain.py::test_spectral_models[sapm]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[first_solar]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[no_loss]\", \"pvlib/tests/test_modelchain.py::test_spectral_models[constant_spectral_loss]\", \"pvlib/tests/test_modelchain.py::test_losses_models_pvwatts\", \"pvlib/tests/test_modelchain.py::test_losses_models_ext_def\", \"pvlib/tests/test_modelchain.py::test_losses_models_no_loss\", \"pvlib/tests/test_modelchain.py::test_invalid_dc_model_params\", \"pvlib/tests/test_modelchain.py::test_invalid_models[dc_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[ac_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[aoi_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[spectral_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[temperature_model]\", \"pvlib/tests/test_modelchain.py::test_invalid_models[losses_model]\", \"pvlib/tests/test_modelchain.py::test_bad_get_orientation\", \"pvlib/tests/test_modelchain.py::test_deprecated_09[snlinverter]\", \"pvlib/tests/test_modelchain.py::test_deprecated_09[adrinverter]\", \"pvlib/tests/test_modelchain.py::test_basic_chain_required\", \"pvlib/tests/test_modelchain.py::test_basic_chain_alt_az\", \"pvlib/tests/test_modelchain.py::test_basic_chain_strategy\", \"pvlib/tests/test_modelchain.py::test_basic_chain_altitude_pressure\", \"pvlib/tests/test_modelchain.py::test_ModelChain___repr__[south_at_latitude_tilt-south_at_latitude_tilt]\", \"pvlib/tests/test_modelchain.py::test_ModelChain___repr__[None-None]\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance_clean_run\", \"pvlib/tests/test_modelchain.py::test_complete_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[ashrae-model_params0]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[physical-model_params1]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam[martin_ruiz-model_params2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_interp\", \"pvlib/tests/test_pvsystem.py::test__normalize_sam_product_names\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_iam_invalid\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_raise_no_parameters\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecmod\", \"pvlib/tests/test_pvsystem.py::test_retrieve_sam_cecinverter\", \"pvlib/tests/test_pvsystem.py::test_sapm\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[1.5-1.00028714375]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_spectral_loss[airmass2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_spectral_loss\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters0-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters1-multisi-None]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_first_solar_spectral_loss[module_parameters2-None-coefficients2]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input0-1140.0510967821876]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input1-expected1]\", \"pvlib/tests/test_pvsystem.py::test_sapm_effective_irradiance[test_input2-expected2]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_effective_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_sapm_celltemp_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvsyst_celltemp\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_faiman_celltemp\", \"pvlib/tests/test_pvsystem.py::test__infer_temperature_model_params\", \"pvlib/tests/test_pvsystem.py::test_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_calcparams_cec\", \"pvlib/tests/test_pvsystem.py::test_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_desoto\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_calcparams_pvsyst\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i0-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i1-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i2-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i3-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i4-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i5-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i6-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i7-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i8-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i9-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_v_from_i[fixture_v_from_i10-newton-1e-08]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i0]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i1]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i2]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i3]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i4]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i5]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i6]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i7]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i8]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i9]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_from_i[fixture_v_from_i10]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v0-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v1-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v2-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v3-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v4-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v5-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-lambertw-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-brentq-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_i_from_v[fixture_i_from_v6-newton-1e-11]\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_i_from_v\", \"pvlib/tests/test_pvsystem.py::test_i_from_v_size\", \"pvlib/tests/test_pvsystem.py::test_v_from_i_size\", \"pvlib/tests/test_pvsystem.py::test_mpp_floats\", \"pvlib/tests/test_pvsystem.py::test_mpp_array\", \"pvlib/tests/test_pvsystem.py::test_mpp_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series\", \"pvlib/tests/test_pvsystem.py::test_singlediode_array\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats\", \"pvlib/tests/test_pvsystem.py::test_singlediode_floats_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_singlediode_series_ivcurve\", \"pvlib/tests/test_pvsystem.py::test_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_scale_voltage_current_power\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_snlinverter\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_aoi\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_get_irradiance\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize_with_location\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_localize_with_latlon\", \"pvlib/tests/test_pvsystem.py::test_LocalizedPVSystem_creation\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_scalars\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_dc_series\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_default\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_arrays\", \"pvlib/tests/test_pvsystem.py::test_pvwatts_losses_series\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_dc_kwargs\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_losses\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac\", \"pvlib/tests/test_pvsystem.py::test_PVSystem_pvwatts_ac_kwargs\", \"pvlib/tests/test_tracking.py::test_solar_noon\", \"pvlib/tests/test_tracking.py::test_scalars\", \"pvlib/tests/test_tracking.py::test_arrays\", \"pvlib/tests/test_tracking.py::test_nans\", \"pvlib/tests/test_tracking.py::test_arrays_multi\", \"pvlib/tests/test_tracking.py::test_azimuth_north_south\", \"pvlib/tests/test_tracking.py::test_max_angle\", \"pvlib/tests/test_tracking.py::test_backtrack\", \"pvlib/tests/test_tracking.py::test_axis_tilt\", \"pvlib/tests/test_tracking.py::test_axis_azimuth\", \"pvlib/tests/test_tracking.py::test_horizon_flat\", \"pvlib/tests/test_tracking.py::test_horizon_tilted\", \"pvlib/tests/test_tracking.py::test_low_sun_angles\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_creation\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_tracking\", \"pvlib/tests/test_tracking.py::test_LocalizedSingleAxisTracker_creation\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_localize\", \"pvlib/tests/test_tracking.py::test_SingleAxisTracker_localize_location\", \"pvlib/tests/test_tracking.py::test_get_aoi\", \"pvlib/tests/test_tracking.py::test_get_irradiance\"]", "environment_setup_commit": "6e5148f59c5050e8f7a0084b7ae39e93b80f72e6"}
